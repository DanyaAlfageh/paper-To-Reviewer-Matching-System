ersCITATION,,
 WePS Datasets We used three datasets in our experiments, WePS1 Training and Testing CITATION, WePS2 Testing (Javier et al,,
4 Results and Discussion We adopt the same evaluation process as CITATION, and evaluating these models using Purity, Inverse Purity and the F-measure (also used in WePS Task CITATION),,
 These features include plain wordsCITATION, biographical information(CITATION; CITATION), named entities, compound key phrases, hyperlinksCITATION, etc,,
 The similarity between namesakes are usually measured by the cosine similarityCITATION, or other graph based met833 \x0crics(CITATION; CITATIONa; CITATION),,
 All the linking relations in Wikipedia construct a huge semantic graph, where we can mine rich semantic relationship between conceptsCITATION,,
 We further prune the extracted concepts according to their keyphrasenessCITATION,,
 Initially, each concept is weighted according to its average semantic relatenessCITATION with other concepts in the current page,,
 Specifically, for each name observation set, we connect all Wikipedia concepts appearing in the current observation set by their pairwise semantic relatednessCITATIONto form a semantic graph,,
CITATION) with other concepts in the current page,,
 We use Stanford Named Entity RecognizerCITATION to collect named entities which are not in the Wikipedia list,,
, have been introduced to bridge the gap(CITATION; CITATIONa; CITATION; CITATION), 832 \x0cand external knowledge resources are also employed to capture the semantic relationship between entities(CITATION, 2010),,
 Traditional vector space model (VSM) is most widely used to accommodate various features, but it ignores any relations between them(CITATION; CITATION),,
 More recent works adopt one of these relationships(CITATION; CITATIONa; CITATION),,
aph simultaneouslyCITATION,,
 In terms of extra resources, the Wikipedia based model (WS) by CITATION is close to our model,,
 Before we weight a topic, we first explain how we re-weight a hub concept in a topic since our initial feature weighting schemeCITATION works on individual web page, lacks cross document information and is likely to over-estimate the impor836 \x0ctance of a hub node (general concept) by by assigning a higher weight,,
 (2)GRAPECITATION: we re-implement the state-of-the-art system which outperforms any models that do not use extra knowledge resources reported in WePS1 and WePS2,,
 (3)WS: the Wikipedia 838 \x0cSemantic methodCITATION,,
 (4)SSR: the Structural Semantic relatedness modelCITATION creates a semantic graph to re-calculate the semantic relatedness between features, and captures both explicit semantic relations and implicit structural semantic knowledge,,
meters according to CITATION with an exception: the weight is tuned exhaustively to be 0,,
4 Results and Discussion We adopt the same evaluation process as CITATION, and evaluating these models using Purity, Inverse Purity and the F-measure (also used in WePS Task CITATION),,
 They also combine multiple knowledge sources and capture explicit semantic relatedness between concepts and implicit semantic relationship embedded in a semantic graph simultaneouslyCITATION,,
 In terms of extra resources, the Wikipedia based model (WS) by CITATION is close to our mo,,
 (2)GRAPECITATION: we re-implement the state-of-the-art system which outperforms any models that do not use extra knowledge resources reported in WePS1 and WePS2,,
 (3)WS: the Wikipedia 838 \x0cSemantic methodCITATION,,
 (4)SSR: the Structural Semantic relatedness modelCITATION creates a semantic graph to re-calculate the semantic relatedness between features, and captures both explicit semantic relations and implicit structural semantic knowledge,,
, have been introduced to bridge the gap(CITATION; CITATIONa; CITATION; CITATION), 832 \x0cand external knowledge resources are also employed to capture the semantic relationship between entities(CITATION, 2010),,
 These features include plain wordsCITATION, biographical information(CITATION; CITATION), named entities, compound key phrases, hyperlinksCITATION, etc,,
 The similarity between namesakes are usually measured by the cosine similarityCITATION, or other graph based met833 \x0crics(CITATION; CITATIONa; CITATION),,
 These features include plain wordsCITATION, biographical information(CITATION; CITATION), named entities, compound key phrases, hyperlinksCITATION, etc,,
 The similarity between namesakes are usually measured by the cosine similarityCITATION, or other graph based met833 \x0crics(CITATION; CITATIONa; CITATION),,
, have been introduced to bridge the gap(CITATION; CITATIONa; CITATION; CITATION), 832 \x0cand external knowledge resources are also employed to capture the semantic relationship between entities(CITATION, 2010),,
 Traditional vector space model (VSM) is most widely used to accommodate various features, but it ignores any relations between them(CITATION; CITATION),,
 More recent works adopt one of these relationships(CITATION; CITATIONa; CITATION),,
 These features include plain wordsCITATION, biographical information(CITATION; CITATION), named entities, compound key phrases, hyperlinksCITATION, etc,,
 The similarity between namesakes are usually measured by the cosine similarityCITATION, or other graph based met833 \x0crics(CITATION; CITATIONa; CITATION),,
 The similarity proposed in GRAPECITATION measures two documents by bridge tags (common features) shared by two document graphs,,
 Inspired by the use of bridge tags in GRAPECITATION, we propose to capture the connection strength between concept sets by the means of our topics,,
 (2)GRAPECITATION: we re-implement the state-of-the-art system which outperforms any models that do not use extra knowledge resources reported in WePS1 and WePS2,,
 (3)WS: the Wikipedia 838 \x0cSemantic methodCITATION,,
 (4)SSR: the Structural Semantic relatedness modelCITATION creates a semantic graph to re-calculate the semantic relatedness between features, and captures both explicit semantic relations and implicit structural semantic knowledge,,
, have been introduced to bridge the gap(CITATION; CITATIONa; CITATION; CITATION), 832 \x0cand external knowledge resources are also employed to capture the semantic relationship between entities(CITATION, 2010),,
 Traditional vector space model (VSM) is most widely used to accommodate various features, but it ignores any relations between them(CITATION; CITATION),,
 More recent works adopt one of these relationships(CITATION; CITATIONa; CITATION),,
 These features include plain wordsCITATION, biographical information(CITATION; CITATION), named entities, compound key phrases, hyperlinksCITATION, etc,,
 The similarity between namesakes are usually measured by the cosine similarityCITATION, or other graph based met833 \x0crics(CITATION; CITATIONa; CITATION),,
, have been introduced to bridge the gap(CITATION; CITATIONa; CITATION; CITATION), 832 \x0cand external knowledge resources are also employed to capture the semantic relationship between entities(CITATION, 2010),,
 Traditional vector space model (VSM) is most widely used to accommodate various features, but it ignores any relations between them(CITATION; CITATION),,
 More recent works adopt one of these relationships(CITATION; CITATIONa; CITATION),,
 These features include plain wordsCITATION, biographical information(CITATION; CITATION), named entities, compound key phrases, hyperlinksCITATION, etc,,
 The similarity between namesakes are usually measured by the cosine similarityCITATION, or other graph based met833 \x0crics(CITATION; CITATIONa; CITATION),,
, have been introduced to bridge the gap(CITATION; CITATIONa; CITATION; CITATION), 832 \x0cand external knowledge resources are also employed to capture the semantic relationship between entities(CITATION, 2010),,
 These features include plain wordsCITATION, biographical information(CITATION; CITATION), named entities, compound key phrases, hyperlinksCITATION, etc,,
 The similarity between namesakes are usually measured by the cosine similarityCITATION, or other graph based met833 \x0crics(CITATION; CITATIONa; CITATION),,
 The third part is the original connectivity strength defined in GRAPECITATION: CS(o1, o2), calculated using plain features without topics (we omit the details for brevity),,
 This final similarity function will then be embedded into a normal HAC algorithm to group the web pages into different namesakes where we compute the centroid-based distance between clustersCITATION,,
 WePS Datasets We used three datasets in our experiments, WePS1 Training and Testing CITATION, WePS2,,
 All the linking relations in Wikipedia construct a huge semantic graph, where we can mine rich semantic relationship between conceptsCITATION,,
 We further prune the extracted concepts according to their keyphrasenessCITATION,,
 Initially, each concept is weighted according to its average semantic relatenessCITATION with other concepts in the current page,,
 These features include plain wordsCITATION, biographical information(CITATION; CITATION), named entities, compound key phrases, hyperlinksCITATION, etc,,
 The similarity between namesakes are usually measured by the cosine similarityCITATION, or other graph based met833 \x0crics(CITATION; CITATIONa; CITATION),,
 1 Introduction Resolving ambiguity associated with person names found on the Web is a key challenge in many Internet applications, such as information retrieval, question answering, open information extraction, automatic knowledge acquisitionCITATION and so on,,
 We choose SCAN algorithm CITATION to perform the clustering step,,
 Intuitively, each 1 We omit the details of SCAN for brevity, and refer interested reader to CITATION for more details,,
 In the SCAN algorithm, we use default parameters according to CITATION with an exception: the weight is tuned exhaustively to be 0,,
4 Results and Discussion We adopt the same evaluation process as CITATION, and evaluating t,,
