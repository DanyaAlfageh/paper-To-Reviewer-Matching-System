 We show that, on the NER task, DAB outperforms supervised, transductive and standard bootstrapping algorithms, as well as a bootstrapping variant, called balanced bootstrapping CITATION, that has recently been proposed for domain adaptation,,
 CITATION discriminatively learns a scaling factor for source domain training data, so as to adapt the source domain data distribution to resemble the target domain data distribution, under the [S+T-] setting,,
 CITATION proposed an instance re-weighting framework that handles both the [S+T+] and [S+T-],,
 (CITATION; CITATION; Daume III, 2007; CITATION), or [S+T-], where no labeled target domain data is available, e,,
 (CITATION; CITATION),,
 Using a different approach, CITATION induces correspondences between feature spaces in different domains, by detecting pivot features,,
 Active learning, which has been applied to the problem of NER in CITATION, is used in situations where a large amount of unlabeled data exists and data labeling is expensive,,
 It has also been applied to the problem of domain adaptation for word sense disambiguation in CITATION,,
 For named entity recognition (NER), for example, CITATION reported that a system trained on a labeled Reuters corpus achieved an F-measure of 91% on a Reuters test set, but only 64% on a Wall Street Journal test set,,
 (CITATION; CITATION; Daume III, 2007; CITATION), or [S+T-], where no labeled target domain data is available, e,,
 (CITATION; CITATION),,
1 NER features We used the features generated by the CRF package CITATION,,
 (CITATION; CITATION; Daume III, 2007; CITATION), or [S+T-], where no labeled target domain data is available, e,,
 (CITATION; CITATION),,
 We show that, on the NER task, DAB outperforms supervised, transductive and standard bootstrapping algorithms, as well as a bootstrapping variant, called balanced bootstrapping CITATION, that has recently been proposed for domain adaptation,,
 CITATION discriminatively learns a scaling factor for source domain training data, so as to adapt the source domain data distribution to resemble the target domain data distribution, under the [S+T-] setting,,
 CITATION),,
 CITATION recently proposed an instance re-weighting framework to take domain shift into account,,
 is not mentioned in the paper CITATION, we assume that bootstrapping is simply run for either a single iteration, or a small and fixed number of iterations,,
 Balanced bootstrapping has been shown to be more effective for domain adaptation than standard bootstrapping CITATION for named entity classification on a subset of the dataset used here,,
 CITATION),,
 CITATION recently proposed an instance re-weighting framework to take domain shift into account,,
 We also compare our approach with the transductive SVM CITATION in our experimental results,,
 In this paper, we are interested in the problem of recognition of the proper names (the named entity recognition task), and hence use only entities labeled with the type NAM CITATION,,
 If there exists no hyperplane that can split the two labels, the soft margin version of SVM will choose a hyperplane that splits the examples as cleanly as possible, while still maximizing the distance to the nearest cleanly split examples CITATION,,
 We used the SVMlight package for our experiments CITATION,,
 We also compare our approach with the transductive SVM CITATION in our experimental results,,
 In this paper, we are interested in the problem of recognition of the proper names (the named entity recognition task), and hence use only entities labeled with the type NAM CITATION,,
 We used the implementation of MaxEnt classifier described in CITATION,,
 Active learning, which has been applied to the problem of NER in CITATION, is used in situations where a large amount of unlabeled data exists and data labeling is expensive,,
 It has also been applied to the problem of domain adaptation for word sense disambiguation in CITATION,,
