ve been evaluated in the CoNLL 2006 and 2007 shared tasks (CITATION; CITATION),,
Approaches to dependency parsing either generate such trees by considering all possible spanning trees CITATION, or build a single tree by means of shift-reduce parsing actions CITATION,,
Deterministic dependency parsers which run in linear time have also been developed (CITATION; CITATION),,
CITATION showed that learning an SVM model in the dual space with higher-degree polynomial kernel functions improves significantly the parsers accuracy,,
CITATION have shown that incorporating second order features relating to adjacent edge pairs impr,,
Similar deterministic approaches to parsing have been investigated also in the context of constituent parsing (CITATION; CITATION),,
CITATION proposed a variant of the model of Yamada and Matsumoto that reduces the complexity, from the worst case quadratic to linear,,
CITATION proposed a variant of the rules that handle non-projective relations while parsing deterministically in a single pass,,
3 A shift-reduce parser We build upon DeSR, the shift-reduce parser described in CITATION,,
CITATION) have been introduced for handling non-projective dependency trees: i.e., trees that cannot be drawn in the plane without crossing edges,,
4.1 BBN Entity corpus The BBN corpus CITATION supplements the Wall Street Journal Penn Treebank with annotation of a large set of entity types,,
Dependency trees capture grammatical structures that can be useful in several language processing tasks such as information extraction CITATION and machine translation CITATION,,
Dependency treebanks are becoming available in many languages, and several approaches to dependency parsing on multiple languages have been evaluated in the CoNLL 2006 and 2007 shared tasks (CITATION; CITATION),,
Approaches to dependency parsing either generate such trees by considering all possible spanning trees CITATION, or build a single tree by means of shift-reduce parsing actions CITATION,,
Deterministic dependency parsers which run in linear time have also been developed (CITATION; CITATION),,
CITATION show that full parsing is effective for semantic role labeling (see also related approaches evaluated within the CoNNL 2005 shared task (Carreras et al., 2005)),,
Collins and Koo CITATION introduced an improved reranking model for parsing which includes a hidden layer of semantic features,,
Yi and Palmer CITATION retrained a constituent parser in which phrases were annotated with argument information to improve SRL, however this didnt improve over the output of the basic parser,,
There is evidence that dependency and constituent parsing can be helpful in these and other tasks; e.g., by means of tree kernels in question classification and semantic role labeling (Zhang & Lee, 2003; CITATION),,
We learn the parameters from the training data with the perceptron CITATION, in the online multiclass formulation of the algorithm CITATION with uniform negative updates,,
The perceptron has been used in previous work on dependency parsing by CITATION, with a parser based on Eisners algorithm CITATION, and also on incremental constituent parsing (Collins & Roark, 2006),,
Also the MST parser of McDonald uses a variant of the perceptron algorithm CITATION,,
The choice is motivated by the simplicity and performance of perceptrons, which have proved competitive on a number of tasks; e.g., in shallow parsing, where perceptrons performance is comparable to that of Conditional Random Field models CITATION,,
Semantic features could be also easily included in other types of dependency parsing algorithms, e.g., MST, and in current methods for constituent parse reranking (CITATION; CITATION),,
CITATION show that full parsing is effective for semantic role labeling (see also related approaches evaluated within the CoNNL 2005 shared task (Carreras et al., 2005)),,
Collins and Koo CITATION introduced an improved reranking model for parsing which includes a hidden layer of semantic features,,
Yi and Palmer CITATION retrained a constituent parser in which phrases were annotated with argument information to improve SRL, however this didnt improve over the output of the basic parser,,
There is evidence that dependency and constituent parsing can be helpful in these and other tasks; e.g., by means of tree kernels in question classification and semantic role labeling (Zhang & Lee, 2003; CITATION),,
We briefly describe the tagger (see CITATION for more details), a Hidden Markov Model trained with the perceptron algorithm introduced in CITATION,,
 Conditional Random Field models CITATION,,
To regularize the model we take as the final model the average of all weight vectors posited during training CITATION,,
The final average model can be computed efficiently during training without storing the individual vectors (e.g., see CITATION),,
Algorithm 2: Average multiclass perceptron input : S = (xi, yi)N ; 0 k = ~ 0, k Y for t = 1 to T do choose j Et = {r Y : hxj, t ri hxj, t yj i} if |Et |&gt; 0 then t+1 r = t r xj |Et |, r Et t+1 yj = t yj + xj output: k = 1 T P t t k, k Y 3.4 Higher-order feature spaces CITATION and CITATION have shown that higher-order feature representations and modeling can improve parsing accuracy, although at significant computational costs,,
5 Parsing experiments 5.1 Data and setup We used the standard partitions of the Wall Street Journal Penn Treebank CITATION; i.e., sections 2-21 for training, section 22 for development and section 23 for evaluation,,
The constituent trees were transformed into dependency trees by means of a program created by Joakim Nivre that implements the rules proposed by Yamada and Matsumoto, which in turn are based on the head rules of Collins parser CITATION5,,
The lemma for each token was produced using the morph function of the WordNet CITATION library6,,
In statistical syntactic parsing a generator (e.g., a PCFG) is used to produce a number of candidate trees CITATION with associated probability scores,,
This approach has been used also for dependency parsing, generating spanning trees as candidates and computing the maximum spanning tree (MST) using discriminative learning algorithms CITATION,,
CITATION proposed a deterministic classifierbased parser,,
Semantic features could be also easily included in other types of dependency parsing algorithms, e.g., MST, and in current methods for constituent parse reranking (CITATION; CITATION),,
s motivated by the simplicity and performance of perceptrons, which have proved competitive on a number of tasks; e.g., in shallow parsing, where perceptrons performance is comparable to that of Conditional Random Field models CITATION,,
To regularize the model we take as the final model the average of all weight vectors posited during training CITATION,,
The final average model can be computed efficiently during training without storing the individual vectors (e.g., see CITATION),,
Algorithm 2: Average multiclass perceptron input : S = (xi, yi)N ; 0 k = ~ 0, k Y for t = 1 to T do choose j Et = {r Y : hxj, t ri hxj, t yj i} if |Et |&gt; 0 then t+1 r = t r xj |Et |, r Et t+1 yj = t yj + xj output: k = 1 T P t t k, k Y 3.4 Higher-order feature spaces CITATION and CITATION have shown that higher-order feature representations and modeli,,
We briefly describe the tagger (see CITATION for more details), a Hidden Markov Model trained with the perceptron algorithm introduced in CITATION,,
Collins and Koo CITATION introduced an improved reranking model for parsing which includes a hidden layer of semantic features,,
Yi and Palmer CITATION retrained a constituent parser in which phrases were annotated with argument information to improve SRL, however this didnt improve over the output of the basic parser,,
We learn the parameters from the training data with the perceptron CITATION, in the online multiclass formulation of the algorithm CITATION with uniform negative updates,,
The perceptron has been used in previous work on dependency parsing by CITATION, with a parser based on Eisners algorithm CITATION, and also on incremental constituent parsing (Collins & Roark, 2006),,
Also the MST parser of McDonald uses a variant of the perceptron algorithm CITATION,,
MIRA CITATION) could provide further gains in accuracy, as shown with the MST parser CITATION,,
Dependency trees capture grammatical structures that can be useful in several language processing tasks such as information extraction CITATION and machine translation CITATION,,
Dependency treebanks are becoming available in many languages, and several approaches to dependency parsing on multiple languages have been evaluated in the CoNLL 2006 and 2007 shared tasks (CITATION; CITATION),,
Approaches to dependency parsing either generate such trees by considering all possible spanning trees CITATION, or build a single ,,
Dependency trees capture grammatical structures that can be useful in several language processing tasks such as information extraction CITATION and machine translation CITATION,,
Dependency treebanks are becoming available in many languages, and several approaches to dependency parsing on multiple languages have been evaluated in the CoNLL 2006 and 2007 shared tasks (CITATION; CITATION),,
Approaches to dependency parsing either generate such trees by considering all possible spanning trees CITATION, or build a single tree by means of shift-reduce parsing actions ,,
We learn the parameters from the training data with the perceptron CITATION, in the online multiclass formulation of the algorithm CITATION with uniform negative updates,,
The perceptron has been used in previous work on dependency parsing by CITATION, with a parser based on Eisners algorithm CITATION, and also on incremental constituent parsing (Collins & Roark, 2006),,
Also the MST parser of McDonald uses a variant of the perceptron algorithm CITATION,,
The choice is motivated by the simplicity and performance of perceptrons, which have proved competitive on a number of tasks; e.g., in shallow parsing, where perceptrons performance is comparable to that of Conditional Random Field models CITATION,,
5 Parsing experiments 5.1 Data and setup We used the standard partitions of the Wall Street Journal Penn Treebank CITATION; i.e., sections 2-21 for training, section 22 for development and section 23 for evaluation,,
The constituent trees were transformed into dependency trees by means of a program created by Joakim Nivre that implements the rules proposed by Yamada and Matsumoto, which in turn are based on the head rules of Collins parser CITATION5,,
The lemma for each token was produced using the morph function of the WordNet CITATION library6,,
CITATION showed that learning an SVM model in the dual space with higher-degree polynomial kernel functions improves significantly the parsers accuracy,,
CITATION have shown that incorporating second order features relating to adjacent edge pairs improves the accuracy of maximum spanning tree parsers (MST),,
Rather, Yamada and Matsumoto (see also CITATION) partition the training data in different sets, on the basis of Partof-Speech, then train one dual SVM model per set,,
For non-projective languages the algorithm is NP-hard and CITATION introduce an approximate algorithm to handle such cases,,
The magnitude of the improvement is remarkable and reflects the 4.6% improvement that Yamada and Matsumoto CITATION report going from the linear SVM to the polynomial of degree two,,
Our base models accuracy (90.55% UAS) compares well with the accuracy of the parsers based on the polynomial kernel trained with SVM of Yamada and Matsumoto (UAS 90.3%), and CITATION (UAS 89.4%),,
We notice in particular that, given the lack of nonprojective cases/rules, the parser of CITATION is almost identical to our parser, hence the difference in accuracy (+1.1%) might effectively be due to a better classifier,,
As a comparison, CITATION reports 1.5 hours for training the partitioned SVM model and 10 minutes for parsing the evaluation set on the same Penn Treebank data,,
Similar deterministic approaches to parsing have been investigated also in the context of constituent parsing (CITATION; CITATION),,
CITATION proposed a variant of the model of Yamada and Matsumoto that reduces the complexity, from the worst case quadratic to linear,,
CITATION proposed a variant of the rules that handle non-projective relations while parsing deterministically in a single pass,,
5 Parsing experiments 5.1 Data and setup We used the standard partitions of the Wall Street Journal Penn Treebank CITATION; i.e., sections 2-21 for training, section 22 for development and section 23 for evaluation,,
The constituent trees were transformed into dependency trees by means of a program created by Joakim Nivre that implements the rules proposed by Yamada and Matsumoto, which in turn are based on the head rules of Collins parser CITATION5,,
The lemma for each token was produced using the morph function of the WordNet CITATION library6,,
We learn the parameters from the training data with the perceptron CITATION, in the online multiclass formulation of the algorithm CITATION with uniform negative updates,,
The perceptron has been used in previous work on dependency parsing by CITATION, with a parser based on Eisners algorithm CITATION, and also on incremental constituent parsing (Collins & Roark, 2006),,
Also the MST parser of McDonald uses a variant of the perceptron algorithm CITATION,,
The choice is motivated by the simplicity and performance of perceptrons, which have proved competitive on a number of tasks; e.g., in shallow parsing, where perceptrons performance is comparable to that of Conditional Random Field models CITATION,,
tion extraction CITATION and machine translation CITATION,,
Dependency treebanks are becoming available in many languages, and several approaches to dependency parsing on multiple languages have been evaluated in the CoNLL 2006 and 2007 shared tasks (CITATION; CITATION),,
Approaches to dependency parsing either generate such trees by considering all possible spanning trees CITATION, or build a single tree by means of shift-reduce parsing actions CITATION,,
Deterministic dependency parsers which run in linear time have also been developed (CITATION; CITATION),,
CITATION showed that learning an SVM model in the dual ,,
In statistical syntactic parsing a generator (e.g., a PCFG) is used to produce a number of candidate trees CITATION with associated probability scores,,
This approach has been used also for dependency parsing, generating spanning trees as candidates and computing the maximum spanning tree (MST) using discriminative learning algorithms CITATION,,
CITATION proposed a deterministic classifierbased parser,,
MIRA CITATION) could provide further gains in accuracy, as shown with the MST parser CITATION,,
CITATION show that full parsing is effective for semantic role labeling (see also related approaches evaluated within the CoNNL 2005 shared task (Carreras et al., 2005)),,
Collins and Koo CITATION introduced an improved reranking model for parsing which includes a hidden layer of semantic features,,
Yi and Palmer CITATION retrained a constituent parser in which phrases were annotated with argument information to improve SRL, however this didnt improve over the output of the basic parser,,
There is evidence that dependency and constituent parsing can be helpful in these and other tasks; e.g., by means of tree kernels in question classification and semantic role labeling (Zhang & Lee, 2003; CITATION),,
rministic dependency parsers which run in linear time have also been developed (CITATION; CITATION),,
CITATION showed that learning an SVM model in the dual space with higher-degree polynomial kernel functions improves significantly the parsers accuracy,,
CITATION have shown that incorporating second order features relating to adjacent edge pairs improves the accuracy of maximum spanning tree parsers (MST),,
Rather, Yamada and Matsumoto (see also CITATION) partition the training data in different sets, on the basis of Partof-Speech, then train one dual SVM model per set,,
s the final model the average of all weight vectors posited during training CITATION,,
The final average model can be computed efficiently during training without storing the individual vectors (e.g., see CITATION),,
Algorithm 2: Average multiclass perceptron input : S = (xi, yi)N ; 0 k = ~ 0, k Y for t = 1 to T do choose j Et = {r Y : hxj, t ri hxj, t yj i} if |Et |&gt; 0 then t+1 r = t r xj |Et |, r Et t+1 yj = t yj + xj output: k = 1 T P t t k, k Y 3.4 Higher-order feature spaces CITATION and CITATION have shown that higher-order feature representations and modeling can improve parsing accuracy, although at significant computational costs,,
Overall the accuracy of the DeSR parser with semantic information is slightly inferior to that of the second-order MST parser CITATION (91.5% UAS),,
As originally pointed out by CITATION, there are problems which require non-linear solutions that cannot be learned by such models,,
Yi and Palmer CITATION retrained a constituent parser in which phrases were annotated with argument information to improve SRL, however this didnt improve over the output of the basic parser,,
There is evidence that dependency and constituent parsing can be helpful in these and other tasks; e.g., by means of tree kernels in question classification and semantic role labeling (Zhang & Lee, 2003; CITATION),,
CITATION investigated the issue of (strict) incrementality for this type of parsers; i.e., if at any point of the analysis the processed input forms one connected structure,,
Dependency trees capture grammatical structures that can be useful in several language processing tasks such as information extraction CITATION and machine translation CITATION,,
Dependency treebanks are becoming available in many languages, and several approaches to dependency parsing on multiple languages have been evaluated in the CoNLL 2006 and 2007 shared tasks (CITATION; CITATION),,
Approaches to dependency parsing either generate such trees by considering all possible spanning trees CITATION, or build a single tree by means of shift-reduce parsing actions CITATION,,
Deterministic dependency parsers which run in linear time have also been developed (CITATION; CITATION),,
Similar deterministic approaches to parsing have been investigated also in the context of constituent parsing (CITATION; CITATION),,
CITATION proposed a variant of the model of Yamada and Matsumoto that reduces the complexity, from the worst case quadratic to linear,,
CITATION proposed a variant of the rules that handle non-projective relations while parsing deterministically in a single pass,,
 multiple languages have been evaluated in the CoNLL 2006 and 2007 shared tasks (CITATION; CITATION),,
Approaches to dependency parsing either generate such trees by considering all possible spanning trees CITATION, or build a single tree by means of shift-reduce parsing actions CITATION,,
Deterministic dependency parsers which run in linear time have also been developed (CITATION; CITATION),,
CITATION showed that learning an SVM model in the dual space with higher-degree polynomial kernel functions improves significantly the parsers accuracy,,
CITATION have shown that incorporating second order features relating to adjacent,,
CITATION show that full parsing is effective for semantic role labeling (see also related approaches evaluated within the CoNNL 2005 shared task (Carreras et al., 2005)),,
CITATION show that full parsing is effective for semantic role labeling (see also related approaches evaluated within the CoNNL 2005 shared task (Carreras et al., 2005)),,
Collins and Koo CITATION introduced an improved reranking model for parsing which includes a hidden layer of semantic features,,
Yi and Palmer CITATION retrained a constituent parser in which phrases were annotated with argument information to improve SRL, however this didnt improve over the output of the basic parser,,
There is evidence that dependency and constituent parsing can be helpful in these and other tasks; e.g., by means of tree kernels in question classification and semantic role labeling (Zhang & Lee, 2003; CITATION),,
We learn the parameters from the training data with the perceptron CITATION, in the online multiclass formulation of the algorithm CITATION with uniform negative updates,,
The perceptron has been used in previous work on dependency parsing by CITATION, with a parser based on Eisners algorithm CITATION, and also on incremental constituent parsing (Collins & Roark, 2006),,
Also the MST parser of McDonald uses a variant of the perceptron algorithm CITATION,,
The perceptron has been used in previous work on dependency parsing by CITATION, with a parser based on Eisners algorithm CITATION, and also on incremental constituent parsing (Collins & Roark, 2006),,
Also the MST parser of McDonald uses a variant of the perceptron algorithm CITATION,,
The choice is motivated by the simplicity and performance of perceptrons, which have proved competitive on a number of tasks; e.g., in shallow parsing, where perceptrons performance is comparable to that of Conditional Random Field models CITATION,,
To regularize the model we take as the final model the average of all weight vectors posited during training CITATION,,
The final average model can be computed efficiently during training without storing the individual vectors (e.g., see CITATION),,
h trees by considering all possible spanning trees CITATION, or build a single tree by means of shift-reduce parsing actions CITATION,,
Deterministic dependency parsers which run in linear time have also been developed (CITATION; CITATION),,
CITATION showed that learning an SVM model in the dual space with higher-degree polynomial kernel functions improves significantly the parsers accuracy,,
CITATION have shown that incorporating second order features relating to adjacent edge pairs improves the accuracy of maximum spanning tree parsers (MST),,
Rather, Yamada and Matsumoto (see also CITATION) partition the training data in different sets, on the basis of Partof-Speech, then train one dual SVM model per set,,
In statistical syntactic parsing a generator (e.g., a PCFG) is used to produce a number of candidate trees CITATION with associated probability scores,,
This approach has been used also for dependency parsing, generating spanning trees as candidates and computing the maximum spanning tree (MST) using discriminative learning algorithms CITATION,,
CITATION proposed a deterministic classifierbased parser,,
Similar deterministic approaches to parsing have been investigated also in the context of constituent parsing (CITATION; Kalt, ,,
o regularize the model we take as the final model the average of all weight vectors posited during training CITATION,,
The final average model can be computed efficiently during training without storing the individual vectors (e.g., see CITATION),,
Algorithm 2: Average multiclass perceptron input : S = (xi, yi)N ; 0 k = ~ 0, k Y for t = 1 to T do choose j Et = {r Y : hxj, t ri hxj, t yj i} if |Et |&gt; 0 then t+1 r = t r xj |Et |, r Et t+1 yj = t yj + xj output: k = 1 T P t t k, k Y 3.4 Higher-order feature spaces CITATION and CITATION have shown that higher-order feature representations and modeling can improve parsing accuracy, although at significant computational costs,,
CITATION have shown that the degree two polynomial kernel has superior accuracy than the linear model and polynomial kernels of higher degrees,,
 Dependency treebanks are becoming available in many languages, and several approaches to dependency parsing on multiple languages have been evaluated in the CoNLL 2006 and 2007 shared tasks (CITATION; CITATION),,
Approaches to dependency parsing either generate such trees by considering all possible spanning trees CITATION, or build a single tree by means of shift-reduce parsing actions CITATION,,
Deterministic dependency parsers which run in linear time have also been developed (CITATION; CITATION),,
CITATION showed that learning an SVM model in the dual space with higher-degree polynomial kernel functions improves significantly the parsers accu,,
The magnitude of the improvement is remarkable and reflects the 4.6% improvement that Yamada and Matsumoto CITATION report going from the linear SVM to the polynomial of degree two,,
Our base models accuracy (90.55% UAS) compares well with the accuracy of the parsers based on the polynomial kernel trained with SVM of Yamada and Matsumoto (UAS 90.3%), and CITATION (UAS 89.4%),,
We notice in particular that, given the lack of nonprojective cases/rules, the parser of CITATION is almost identical to our parser, hence the difference in accuracy (+1.1%) might effectively be due to a better classifier,,
Collins and Koo CITATION introduced an improved reranking model for parsing which includes a hidden layer of semantic features,,
Yi and Palmer CITATION retrained a constituent parser in which phrases were annotated with argument information to improve SRL, however this didnt improve over the output of the basic parser,,
There is evidence that dependency and constituent parsing can be helpful in these and other tasks; e.g., by means of tree kernels in question classification and semantic role labeling (Zhang & Lee, 2003; CITATION),,
Similar deterministic approaches to parsing have been investigated also in the context of constituent parsing (CITATION; CITATION),,
CITATION proposed a variant of the model of Yamada and Matsumoto that reduces the complexity, from the worst case quadratic to linear,,
CITATION proposed a variant of the rules that handle non-projective relations while parsing deterministically in a single pass,,
