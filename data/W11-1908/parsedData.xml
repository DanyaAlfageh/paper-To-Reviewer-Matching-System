<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<bodyText confidence="0.594882">
b&apos;Proceedings of the 15th Conference on Computational Natural Language Learning: Shared Task, pages 6165,
Portland, Oregon, 23-24 June 2011. c
</bodyText>
<sectionHeader confidence="0.757892" genericHeader="abstract">
2011 Association for Computational Linguistics
</sectionHeader>
<bodyText confidence="0.9268175">
Multi-metric optimization for coreference: The UniTN / IITP / Essex
submission to the 2011 CONLL Shared Task
</bodyText>
<figure confidence="0.471554">
Olga Uryupina
Sriparna Saha
Asif Ekbal
Massimo Poesio
</figure>
<affiliation confidence="0.983066333333333">
University of Trento
Indian Institute of Technology Patna
University of Essex
</affiliation>
<email confidence="0.946234">
uryupina@gmail.com, sriparna@iitp.ac.in,
asif@iitp.ac.in, massimo.poesio@unitn.it
</email>
<sectionHeader confidence="0.990143" genericHeader="keywords">
Abstract
</sectionHeader>
<bodyText confidence="0.9983218">
Because there is no generally accepted met-
ric for measuring the performance of anaphora
resolution systems, a combination of met-
rics was proposed to evaluate submissions to
the 2011 CONLL Shared Task (Pradhan et
al., 2011). We investigate therefore Multi-
objective function Optimization (MOO) tech-
niques based on Genetic Algorithms to opti-
mize models according to multiple metrics si-
multaneously.
</bodyText>
<sectionHeader confidence="0.998227" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998124209302325">
Many evaluation metrics have been proposed for
anaphora resolution (Vilain et al., 1995; Bagga and
Baldwin, 1998; Doddington et al., 2000; Luo, 2005;
Recasens and Hovy, 2011). Each of these metrics
seems to capture some genuine intuition about the
the task, so that, unlike in other areas of HLT, none
has really taken over. This makes it difficult to com-
pare systems, as dramatically demonstrated by the
results of the Coreference Task at SEMEVAL 2010
(Recasens et al., 2010). It was therefore wise of the
CONLL organizers to use a basket of metrics to as-
sess performance instead of a single one.
This situation suggests using methods to opti-
mize systems according to more than one metric
at once. And as it happens, techniques for doing
just that have been developed in the area of Ge-
netic Algorithmsso-called multi-objective opti-
mization techniques (MOO) (Deb, 2001). The key
idea of our submission is to use MOO techniques
to optimize our anaphora resolution system accord-
ing to three metrics simultaneously: the MUC scorer
(a member of what one might call the link-based
cluster of metrics) and the two CEAF metrics (rep-
resentative of the entity-based cluster). In a pre-
vious study (Saha et al., 2011), we show that our
MOO-based approach yields more robust results than
single-objective optimization.
We test two types of optimization: feature se-
lection and architecturewhether to learn a single
model for all types of anaphors, or to learn sepa-
rate models for pronouns and for other nominals.
We also discuss how the default mention extraction
techniques of the system we used for this submis-
sion, BART (Versley et al., 2008), were modified to
handle the all-mention annotation in the OntoNotes
corpus.
In this paper, we first briefly provide some back-
ground on optimization for anaphora resolution, on
genetic algorithms, and on the method for multi-
objective optimization we used, Non-Dominated
Sorting Genetic Algorithm II (Deb et al., 2002). Af-
ter that we discuss our experiments, and present our
results.
</bodyText>
<sectionHeader confidence="0.991707" genericHeader="method">
2 Background
</sectionHeader>
<subsectionHeader confidence="0.587939">
2.1 Optimization for Anaphora Resolution
</subsectionHeader>
<bodyText confidence="0.999053125">
There have only been few attempts at optimization
for anaphora resolution, and with a few exceptions,
this was done by hand.
The first systematic attempt at automatic opti-
mization of anaphora resolution we are aware of was
carried out by Hoste (2005), who used genetic algo-
rithms for automatic optimization of both feature se-
lection and of learning parameters, also considering
</bodyText>
<page confidence="0.998287">
61
</page>
<bodyText confidence="0.999608533333333">
\x0ctwo different machine learners, TimBL and Ripper.
Her results suggest that such techniques yield im-
provements on the MUC-6/7 datasets. Recasens and
Hovy (2009) carried out an investigation of feature
selection for Spanish using the ANCORA corpus.
A form of multi-objective optimization was ap-
plied to coreference by Munson et al. (2005). Mun-
son et al. (2005) did not propose to train models so
as to simultaneously optimize according to multi-
ple metrics; instead, they used ensemble selection to
learn to choose among previously trained models the
best model for each example. Their general conclu-
sion was negative, stating that ensemble selection
seems too unreliable for use in NLP, but they did
see some improvements for coreference.
</bodyText>
<subsectionHeader confidence="0.992281">
2.2 Genetic Algorithms
</subsectionHeader>
<bodyText confidence="0.99854505882353">
Genetic algorithms (GAs) (Goldberg, 1989) are ran-
domized search and optimization techniques guided
by the principles of evolution and natural genetics.
In GAs the parameters of the search space are en-
coded in the form of strings called chromosomes. A
collection of such strings is called a population. An
objective or fitness function is associated with each
chromosome that represents the degree of goodness
of that chromosome. A few of the chromosomes are
selected on the basis of the principle of survival of
the fittest, and assigned a number of copies that go
into the mating pool. Biologically inspired opera-
tors like crossover and mutation are applied on these
chromosomes to yield a new generation of strings.
The processes of selection, crossover and mutation
continues for a fixed number of generations or till a
termination condition is satisfied.
</bodyText>
<subsectionHeader confidence="0.904203">
2.3 Multi-objective Optimization
</subsectionHeader>
<bodyText confidence="0.995893">
Multi-objective optimization (MOO) can be formally
stated as follows (Deb, 2001). Find the vectors
</bodyText>
<equation confidence="0.864977">
x = [x
1, x
2, . . . , x
</equation>
<bodyText confidence="0.843579733333333">
n]T of decision variables that si-
multaneously optimize the M objective values
{f1(x), f2(x), . . . , fM (x)}
while satisfying the constraints, if any.
An important concept in MOO is that of dom-
ination. In the context of a maximization prob-
lem, a solution xi is said to dominate xj if
k 1, 2, . . . , M, fk(xi) fk(xj) and k
1, 2, . . . , M, such that fk(xi) &gt; fk(xj).
Genetic algorithms are known to be more effec-
tive for solving MOO than classical methods such as
weighted metrics, goal programming (Deb, 2001),
because of their population-based nature. A particu-
larly popular genetic algorithm of this type is NSGA-
II (Deb et al., 2002), which we used for our runs.
</bodyText>
<sectionHeader confidence="0.3316895" genericHeader="method">
3 Using MOO for Optimization in
Anaphora Resolution
</sectionHeader>
<bodyText confidence="0.99551775">
We used multi-objective optimization techniques for
feature selection and for identifying the optimal ar-
chitecture for the CONLL data. In this section we
briefly discuss each aspect of the methodology.
</bodyText>
<subsectionHeader confidence="0.991237">
3.1 The BART System
</subsectionHeader>
<bodyText confidence="0.998307096774193">
For our experiments, we use BART (Versley et al.,
2008), a modular toolkit for anaphora resolution that
supports state-of-the-art statistical approaches to the
task and enables efficient feature engineering. BART
comes with a set of already implemented features,
along with the possibility to design new ones. It
also implements different models of anaphora reso-
lution, allowing the choice between single and split
classifiers that we explore in our runs, as well as
between mention-pair and entity-mention, and be-
tween best-first and ranking. It also has interfaces
to different machine learners (MaxEnt, SVM, de-
cision trees). It is thus ideally suited for experi-
menting with feature selection and other aspects of
optimization. However, considering all the param-
eters, it was unfeasible to run an optimization on
the amount of data available on CONLL; we fo-
cused therefore on feature selection and the choice
between single and split classifiers. We considered
42 features, including 7 classifying mention type, 8
for string matching of different subparts and differ-
ent levels of exactness, 2 for aliasing, 4 for agree-
ment, 12 for syntactic information including also
binding constraints, 3 encoding salience, 1 encod-
ing patterns extracted from the Web, 3 for proximity,
and 2 for 1st and 2nd person pronouns. Again be-
cause of time considerations, we used decision trees
as implemented in Weka as our classification model
instead of maximum-entropy or SVMs. Finally, we
used a simple mention-pair model without ranking
as in (Soon et al., 2001).
</bodyText>
<page confidence="0.983235">
62
</page>
<table confidence="0.6724545">
\x0c3.2 Mention detection
BART supports several solutions to the mention
</table>
<bodyText confidence="0.994802142857143">
detection (MD) task. The users can input pre-
computed mentions, thus, experimenting with gold
boundaries or system boundaries computed by ex-
ternal modules (e.g., CARAFE). BART also has
a built-in mention extraction module, computing
boundaries heuristically from the output of a parser.
For the CoNLL shared task, we use the BART
internal MD module, as it corresponds better to
the mention detection guidelines of the OntoNotes
dataset. We have further adjusted this module to im-
prove the MD accuracy. The process of mention de-
tection involves two steps.
First, we create a list of candidate mentions by
merging basic NP chunks with named entities. NP
chunks are computed from the parse trees provided
in the CoNLL distribution, Named entities are ex-
tracted with the Stanford NER tool (Finkel et al.,
2005). For each candidate mention, we store it mini-
mal and maximal span. The former is used for com-
puting feature values (e.g., for string matching); it
corresponds to either the basic NP chunk or the NE,
depending on the mention type. The latter is used
for alignment with CoNLL mentions; it is computed
by climbing up the parse tree.
This procedure, combined with the perfect (gold)
coreference resolution, gives us an F-score of
91.56% for the mention detection task on the
CoNLL development set1.
At the second step, we aim at discarding men-
tions that are unlikely to participate in corefer-
ence chains. We have identified several groups of
such mentions: erroneous ([uh]), (parts of) multi-
word expressions (for [example]), web addresses,
emails ([http://conll.bbn.com]), time/date expres-
sions (two times [a year]), non-referring pronouns
([there],[nobody]), pronouns that are unlikely
to participate in a chain ([somebody], [that]),
time/date expressions that are unlikely to participate
in a chain ([this time]), and expletive it.
Our experiments on the development data show
that the first five groups can be reliably identified
and safely discarded from the processing: even with
</bodyText>
<page confidence="0.844723">
1
</page>
<bodyText confidence="0.99874725">
Note that, due to the fact that OntoNotes guidelines exclude
singleton mentions, it is impossible to evaluate the MD compo-
nent independently from coreference resolution.
the perfect resolution, we observe virtually no per-
formance loss (the F-score for our MD module with
the gold coreference resolution remains at 91.45%
once we discard mentions from groups 1-5).
The remaining groups are more problematic:
when we eliminate such mentions, we see perfor-
mance drops with the gold resolution. The exact im-
pact of discarding those mentions can only be as-
sessed once we have trained the classifier.
In practice, we have performed our optimization
experiments, selected the best classifier and then
have done additional runs to fine-tune the mention
detection module.
</bodyText>
<subsectionHeader confidence="0.992576">
3.3 Using NSGA-II
</subsectionHeader>
<bodyText confidence="0.893154875">
Chromosome Representation of Feature and Ar-
chitecture Parameters We used chromosomes of
length 43, each binary gene encoding whether or not
to use a particular feature in constructing the classi-
fier, plus one gene set to 1 to use a split classifier, 0
to use a single classifier for all types of anaphors.
Fitness Computation and Mutations For fitness
computation, the following procedure is executed.
</bodyText>
<listItem confidence="0.971935857142857">
1. Suppose there are N number of features
present in a particular chromosome (i.e., there
are total N number of 1s in that chromosome).
2. Construct the coreference resolution system
(i.e., BART) with only these N features.
3. This coreference system is evaluated on the de-
velopment data. The recall, precision and F-
</listItem>
<bodyText confidence="0.978074">
measure values of three metrics are calculated.
For MOO, the objective functions corresponding to
a particular chromosome are F1 = F-measureMUC
(for the MUC metric), F2 = F-measure3 (for CEAF
using the 3 entity alignment function (Luo, 2005))
and F3 = F-measure4 (for CEAF using the 3
entity alignment function). The objective is to:
max[F1, F2, F3]: i.e., these three objective func-
tions are simultaneously optimized using the search
capability of NSGA-II.
We use crowded binary tournament selection as
in NSGA-II, followed by conventional crossover and
mutation for the MOO based optimization. The
most characteristic part of NSGA-II is its elitism op-
eration, where the non-dominated solutions (Deb,
</bodyText>
<page confidence="0.997216">
63
</page>
<bodyText confidence="0.923607">
\x0c2001) among the parent and child populations are
propagated to the next generation. The near-Pareto-
optimal strings of the last generation provide the dif-
ferent solutions to the feature selection problem.
Genetic Algorithms Parameters Using the
CONLL development set, we set the following pa-
rameter values for MOO (i.e., NSGA-II): population
size=20, number of generations=20, probability of
mutation=0.1 and probability of crossover=0.9.
</bodyText>
<subsectionHeader confidence="0.940919">
3.4 Running the Optimization
</subsectionHeader>
<bodyText confidence="0.993326384615385">
Considering the size of the OntoNotes corpus, it
would be very time-consuming to run an optimiza-
tion experiment on the whole dataset. We have
therefore split the data into 3 sub-samples and per-
formed separate MOO experiments on each one.
The MOO approach provides a set of non-
dominated solutions on the final Pareto optimal
front. All the solutions are equally important from
the algorithmic point of view. We have collected sets
of chromosomes for each sub-sample and evaluated
them on the whole train/development set, picking
the solution with the highest FINAL2 score for our
CoNLL submission.
</bodyText>
<sectionHeader confidence="0.999771" genericHeader="method">
4 Results
</sectionHeader>
<subsectionHeader confidence="0.996309">
4.1 Development set
</subsectionHeader>
<bodyText confidence="0.9986265">
Table 1 compares the performance level obtained
using all the features with that of loose re-
implementations of the systems proposed by Soon
et al. (2001) and Ng and Cardie (2002), commonly
used as baselines. Our reimplementation of the Ng
&amp; Cardie model uses only a subset of features.
The results in Table 1 show that our system with
a rich feature set does not outperform simpler base-
lines (and, in fact, yields poorer results). A similar
trend has been observed by Ng and Cardie (2002),
where the improvement was only possible after man-
ual feature selection.
The last line of Table 1 shows the performance
level of the best chromosome found through the
MOO technique. As it can be seen, it outperforms
all the baselines according to all the measures, lead-
ing to an improvement of 2-5 percentage points in
the FINAL score.
</bodyText>
<page confidence="0.965143">
2
</page>
<bodyText confidence="0.958297571428571">
The FINAL score is an average of FMUC , FB3 and
FCEAF E.
This suggests that automatic feature selection is
essential to improve performance i.e., that an effi-
cient coreference resolution system should combine
rich linguistic feature sets with automatic feature se-
lection mechanisms.
</bodyText>
<subsectionHeader confidence="0.994127">
4.2 Test set
</subsectionHeader>
<bodyText confidence="0.97362">
We have re-trained our best solution on the com-
bined train and development set, running it on the
test data. This system has showed the following per-
formance in the official evaluation (open track): the
FINAL score of 54.32, FMUC = 57.53%, FB3 =
</bodyText>
<sectionHeader confidence="0.8660905" genericHeader="method">
65.18%, FCEAF E = 40.16%.
5 Conclusion
</sectionHeader>
<bodyText confidence="0.9938625">
Our results on the development set suggest that a
linguistically-rich system for coreference resolution
might benefit a lot from feature selection. In partic-
ular, we have investigated Non-Dominated Sorting
Genetic Algorithm II (Deb et al., 2002) for multi-
objective optimization.
In subsequent work, we plan to expand the opti-
mization technique to consider also learning param-
eters optimization, classifier selection, and learning
model selection.
</bodyText>
<sectionHeader confidence="0.959009" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.7413875">
This work was in part supported by the Provincia
di Trento Grande Progetto LiveMemories, in part by
an Erasmus Mundus scholarship for Asif Ekbal and
Sriparna Saha.
</bodyText>
<page confidence="0.824011">
64
</page>
<table confidence="0.96108225">
\x0cFeatures FMUC FCEAF E FB3 FINAL
following Soon et al. (2001) 54.12 41.08 66.67 53.42
-*-, with splitting 53.81 41.03 66.70 53.31
following Ng &amp; Cardie (2002) 52.97 42.40 66.18 53.31
-*-, with splitting 53.28 40.46 66.03 52.72
All features 50.18 38.54 63.79 50.33
-*-, with splitting 50.19 39.47 65.38 51.16
Optimized feature set (splitting) 57.05 42.61 67.46 55.15
</table>
<tableCaption confidence="0.999328">
Table 1: Performance on the development set
</tableCaption>
<sectionHeader confidence="0.954701" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999514337662338">
A. Bagga and B. Baldwin. 1998. Algorithms for scoring
coreference chains. In Proc. of the LREC workshop on
Linguistic Coreference, pages 563566, Granada.
Kalyanmoy Deb, Amrit Pratap, Sameer Agarwal, and
T. Meyarivan. 2002. A fast and elitist multiobjective
genetic algorithm: NSGA-II. IEEE Transactions on
Evolutionary Computation, 6(2):181197.
Kalyanmoy Deb. 2001. Multi-objective Optimization
Using Evolutionary Algorithms. John Wiley and Sons,
Ltd, England.
G. Doddington, A. Mitchell, M. Przybocki, L. Ramshaw,
S. Strassell, and R. Weischedel. 2000. The auto-
matic content extraction (ACE) programtasks, data,
and evaluation. In Proc. of LREC.
Jenny Rose Finkel, Trond Grenager, and Christopher
Manning. 2005. Incorporating non-local informa-
tion into information extraction systems by Gibbs sam-
pling. In Proceedings of the 43rd Annual Meeting of
the Association for Computational Linguistics, pages
363370.
D. E. Goldberg. 1989. Genetic Algorithms in Search,
Optimization and Machine Learning. Addison-
Wesley, New York.
Veronique Hoste. 2005. Optimization Issues in Ma-
chine Learning of Coreference Resolution. Ph.D. the-
sis, Antwerp University.
X. Luo. 2005. On coreference resolution performance
metrics. In Proc. NAACL / EMNLP, Vancouver.
Art Munson, Claire Cardie, and Rich Caruana. 2005.
Optimizing to arbitrary NLP metrics using ensem-
ble selection. In Proceedings of Human Lan-
guage Technology Conference and Conference on
Empirical Methods in Natural Language Processing
(HLT/EMNLP), pages 539546.
Vincent Ng and Claire Cardie. 2002. Improving machine
learning approaches to coreference resolution. In Pro-
ceedings of the 40th Annual Meeting on Association
for C omputational Linguistics, pages 104111.
Sameer Pradhan, Lance Ramshaw, Mitchell Marcus,
Martha Palmer, Ralph Weischedel, and Nianwen Xue.
2011. Conll-2011 shared task: Modeling unrestricted
coreference in ontonotes. In Proceedings of the Fif-
teenth Conference on Computational Natural Lan-
guage Learning (CoNLL 2011), Portland, Oregon,
June.
M. Recasens and E. Hovy. 2009. A deeper look into fea-
tures for coreference resolution. In S. Lalitha Devi,
A. Branco, and R. Mitkov, editors, Anaphora Pro-
cessing and Applications (DAARC 2009, number 5847
in LNAI, pages 2942, Berlin / Heidelberg. Springer-
Verlag.
M. Recasens and E. Hovy. 2011. Blanc: Implement-
ing the rand index for coreference evaluation. Natural
Language Engineering.
M. Recasens, L. Marquez, E. Sapena, M. A. Mart,
M. Taule, V. Hoste, M. Poesio, and Y. Versley. 2010.
Semeval-2010 task 1: Coreference resolution in multi-
ple languages. In Proc. SEMEVAL 2010, Uppsala.
Sriparna Saha, Massimo Poesio, Asif Ekbal, and Olga
Uryupina. 2011. Single and multi-objective optimiza-
tion for feature selection in anaphora resolution. Sub-
mitted.
Wee Meng Soon, Hwee Tou Ng, and Daniel Chung Yong
Lim. 2001. A machine learning approach to corefer-
ence resolution of noun phrases. Computational Lin-
guistic, 27(4):521544.
Yannick Versley, Simone Paolo Ponzetto, Massimo Poe-
sio, Vladimir Eidelman, Alan Jern, Jason Smith,
Xiaofeng Yang, and Alessandro Moschitti. 2008.
BART: a modular toolkit for coreference resolution. In
Proceedings of the 46th Annual Meeting of the Asso-
ciation for Computational Linguistics on Human Lan-
guage Technologies, pages 912.
M. Vilain, J. Burger, J. Aberdeen, D. Connolly, and
L. Hirschman. 1995. A model-theoretic coreference
scoring scheme. In Proc. of the Sixth Message Under-
standing Conference, pages 4552.
</reference>
<page confidence="0.967982">
65
</page>
<figure confidence="0.262854">
\x0c&apos;
</figure>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.208301">
<title>Multi-metric optimization for coreference: The UniTN / IITP / Essex submission to the 2011 CONLL Shared Task</title>
<note confidence="0.9177572">b&apos;Proceedings of the 15th Conference on Computational Natural Language Learning: Shared Task, pages 6165, Portland, Oregon, 23-24 June 2011. c 2011 Association for Computational Linguistics Multi-metric optimization for coreference: The UniTN / IITP / Essex submission to the 2011 CONLL Shared Task</note>
<author confidence="0.82518625">Olga Uryupina Sriparna Saha Asif Ekbal Massimo Poesio</author>
<affiliation confidence="0.999469">University of Trento Indian Institute of Technology Patna University of Essex</affiliation>
<email confidence="0.8830195">uryupina@gmail.com,sriparna@iitp.ac.in,asif@iitp.ac.in,massimo.poesio@unitn.it</email>
<abstract confidence="0.976732545454545">Because there is no generally accepted metric for measuring the performance of anaphora resolution systems, a combination of metrics was proposed to evaluate submissions to the 2011 CONLL Shared Task (Pradhan et al., 2011). We investigate therefore Multiobjective function Optimization (MOO) techniques based on Genetic Algorithms to optimize models according to multiple metrics simultaneously.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Bagga</author>
<author>B Baldwin</author>
</authors>
<title>Algorithms for scoring coreference chains.</title>
<date>1998</date>
<booktitle>In Proc. of the LREC workshop on Linguistic Coreference,</booktitle>
<pages>563566</pages>
<location>Granada.</location>
<contexts>
<context position="1045" citStr="Bagga and Baldwin, 1998" startWordPosition="141" endWordPosition="144">of Essex uryupina@gmail.com, sriparna@iitp.ac.in, asif@iitp.ac.in, massimo.poesio@unitn.it Abstract Because there is no generally accepted metric for measuring the performance of anaphora resolution systems, a combination of metrics was proposed to evaluate submissions to the 2011 CONLL Shared Task (Pradhan et al., 2011). We investigate therefore Multiobjective function Optimization (MOO) techniques based on Genetic Algorithms to optimize models according to multiple metrics simultaneously. 1 Introduction Many evaluation metrics have been proposed for anaphora resolution (Vilain et al., 1995; Bagga and Baldwin, 1998; Doddington et al., 2000; Luo, 2005; Recasens and Hovy, 2011). Each of these metrics seems to capture some genuine intuition about the the task, so that, unlike in other areas of HLT, none has really taken over. This makes it difficult to compare systems, as dramatically demonstrated by the results of the Coreference Task at SEMEVAL 2010 (Recasens et al., 2010). It was therefore wise of the CONLL organizers to use a basket of metrics to assess performance instead of a single one. This situation suggests using methods to optimize systems according to more than one metric at once. And as it hap</context>
</contexts>
<marker>Bagga, Baldwin, 1998</marker>
<rawString>A. Bagga and B. Baldwin. 1998. Algorithms for scoring coreference chains. In Proc. of the LREC workshop on Linguistic Coreference, pages 563566, Granada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kalyanmoy Deb</author>
<author>Amrit Pratap</author>
<author>Sameer Agarwal</author>
<author>T Meyarivan</author>
</authors>
<title>A fast and elitist multiobjective genetic algorithm: NSGA-II.</title>
<date>2002</date>
<journal>IEEE Transactions on Evolutionary Computation,</journal>
<volume>6</volume>
<issue>2</issue>
<contexts>
<context position="2883" citStr="Deb et al., 2002" startWordPosition="444" endWordPosition="447">ization: feature selection and architecturewhether to learn a single model for all types of anaphors, or to learn separate models for pronouns and for other nominals. We also discuss how the default mention extraction techniques of the system we used for this submission, BART (Versley et al., 2008), were modified to handle the all-mention annotation in the OntoNotes corpus. In this paper, we first briefly provide some background on optimization for anaphora resolution, on genetic algorithms, and on the method for multiobjective optimization we used, Non-Dominated Sorting Genetic Algorithm II (Deb et al., 2002). After that we discuss our experiments, and present our results. 2 Background 2.1 Optimization for Anaphora Resolution There have only been few attempts at optimization for anaphora resolution, and with a few exceptions, this was done by hand. The first systematic attempt at automatic optimization of anaphora resolution we are aware of was carried out by Hoste (2005), who used genetic algorithms for automatic optimization of both feature selection and of learning parameters, also considering 61 \x0ctwo different machine learners, TimBL and Ripper. Her results suggest that such techniques yiel</context>
<context position="5800" citStr="Deb et al., 2002" startWordPosition="931" endWordPosition="934">iables that simultaneously optimize the M objective values {f1(x), f2(x), . . . , fM (x)} while satisfying the constraints, if any. An important concept in MOO is that of domination. In the context of a maximization problem, a solution xi is said to dominate xj if k 1, 2, . . . , M, fk(xi) fk(xj) and k 1, 2, . . . , M, such that fk(xi) &gt; fk(xj). Genetic algorithms are known to be more effective for solving MOO than classical methods such as weighted metrics, goal programming (Deb, 2001), because of their population-based nature. A particularly popular genetic algorithm of this type is NSGAII (Deb et al., 2002), which we used for our runs. 3 Using MOO for Optimization in Anaphora Resolution We used multi-objective optimization techniques for feature selection and for identifying the optimal architecture for the CONLL data. In this section we briefly discuss each aspect of the methodology. 3.1 The BART System For our experiments, we use BART (Versley et al., 2008), a modular toolkit for anaphora resolution that supports state-of-the-art statistical approaches to the task and enables efficient feature engineering. BART comes with a set of already implemented features, along with the possibility to des</context>
<context position="14672" citStr="Deb et al., 2002" startWordPosition="2346" endWordPosition="2349">rich linguistic feature sets with automatic feature selection mechanisms. 4.2 Test set We have re-trained our best solution on the combined train and development set, running it on the test data. This system has showed the following performance in the official evaluation (open track): the FINAL score of 54.32, FMUC = 57.53%, FB3 = 65.18%, FCEAF E = 40.16%. 5 Conclusion Our results on the development set suggest that a linguistically-rich system for coreference resolution might benefit a lot from feature selection. In particular, we have investigated Non-Dominated Sorting Genetic Algorithm II (Deb et al., 2002) for multiobjective optimization. In subsequent work, we plan to expand the optimization technique to consider also learning parameters optimization, classifier selection, and learning model selection. Acknowledgments This work was in part supported by the Provincia di Trento Grande Progetto LiveMemories, in part by an Erasmus Mundus scholarship for Asif Ekbal and Sriparna Saha. 64 \x0cFeatures FMUC FCEAF E FB3 FINAL following Soon et al. (2001) 54.12 41.08 66.67 53.42 -*-, with splitting 53.81 41.03 66.70 53.31 following Ng &amp; Cardie (2002) 52.97 42.40 66.18 53.31 -*-, with splitting 53.28 40.</context>
</contexts>
<marker>Deb, Pratap, Agarwal, Meyarivan, 2002</marker>
<rawString>Kalyanmoy Deb, Amrit Pratap, Sameer Agarwal, and T. Meyarivan. 2002. A fast and elitist multiobjective genetic algorithm: NSGA-II. IEEE Transactions on Evolutionary Computation, 6(2):181197.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kalyanmoy Deb</author>
</authors>
<title>Multi-objective Optimization Using Evolutionary Algorithms.</title>
<date>2001</date>
<publisher>John Wiley and Sons, Ltd,</publisher>
<location>England.</location>
<contexts>
<context position="1802" citStr="Deb, 2001" startWordPosition="271" endWordPosition="272">o that, unlike in other areas of HLT, none has really taken over. This makes it difficult to compare systems, as dramatically demonstrated by the results of the Coreference Task at SEMEVAL 2010 (Recasens et al., 2010). It was therefore wise of the CONLL organizers to use a basket of metrics to assess performance instead of a single one. This situation suggests using methods to optimize systems according to more than one metric at once. And as it happens, techniques for doing just that have been developed in the area of Genetic Algorithmsso-called multi-objective optimization techniques (MOO) (Deb, 2001). The key idea of our submission is to use MOO techniques to optimize our anaphora resolution system according to three metrics simultaneously: the MUC scorer (a member of what one might call the link-based cluster of metrics) and the two CEAF metrics (representative of the entity-based cluster). In a previous study (Saha et al., 2011), we show that our MOO-based approach yields more robust results than single-objective optimization. We test two types of optimization: feature selection and architecturewhether to learn a single model for all types of anaphors, or to learn separate models for pr</context>
<context position="5120" citStr="Deb, 2001" startWordPosition="798" endWordPosition="799">omosome that represents the degree of goodness of that chromosome. A few of the chromosomes are selected on the basis of the principle of survival of the fittest, and assigned a number of copies that go into the mating pool. Biologically inspired operators like crossover and mutation are applied on these chromosomes to yield a new generation of strings. The processes of selection, crossover and mutation continues for a fixed number of generations or till a termination condition is satisfied. 2.3 Multi-objective Optimization Multi-objective optimization (MOO) can be formally stated as follows (Deb, 2001). Find the vectors x = [x 1, x 2, . . . , x n]T of decision variables that simultaneously optimize the M objective values {f1(x), f2(x), . . . , fM (x)} while satisfying the constraints, if any. An important concept in MOO is that of domination. In the context of a maximization problem, a solution xi is said to dominate xj if k 1, 2, . . . , M, fk(xi) fk(xj) and k 1, 2, . . . , M, such that fk(xi) &gt; fk(xj). Genetic algorithms are known to be more effective for solving MOO than classical methods such as weighted metrics, goal programming (Deb, 2001), because of their population-based nature. A </context>
</contexts>
<marker>Deb, 2001</marker>
<rawString>Kalyanmoy Deb. 2001. Multi-objective Optimization Using Evolutionary Algorithms. John Wiley and Sons, Ltd, England.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Doddington</author>
<author>A Mitchell</author>
<author>M Przybocki</author>
<author>L Ramshaw</author>
<author>S Strassell</author>
<author>R Weischedel</author>
</authors>
<title>The automatic content extraction (ACE) programtasks, data, and evaluation.</title>
<date>2000</date>
<booktitle>In Proc. of LREC.</booktitle>
<contexts>
<context position="1070" citStr="Doddington et al., 2000" startWordPosition="145" endWordPosition="148">om, sriparna@iitp.ac.in, asif@iitp.ac.in, massimo.poesio@unitn.it Abstract Because there is no generally accepted metric for measuring the performance of anaphora resolution systems, a combination of metrics was proposed to evaluate submissions to the 2011 CONLL Shared Task (Pradhan et al., 2011). We investigate therefore Multiobjective function Optimization (MOO) techniques based on Genetic Algorithms to optimize models according to multiple metrics simultaneously. 1 Introduction Many evaluation metrics have been proposed for anaphora resolution (Vilain et al., 1995; Bagga and Baldwin, 1998; Doddington et al., 2000; Luo, 2005; Recasens and Hovy, 2011). Each of these metrics seems to capture some genuine intuition about the the task, so that, unlike in other areas of HLT, none has really taken over. This makes it difficult to compare systems, as dramatically demonstrated by the results of the Coreference Task at SEMEVAL 2010 (Recasens et al., 2010). It was therefore wise of the CONLL organizers to use a basket of metrics to assess performance instead of a single one. This situation suggests using methods to optimize systems according to more than one metric at once. And as it happens, techniques for doin</context>
</contexts>
<marker>Doddington, Mitchell, Przybocki, Ramshaw, Strassell, Weischedel, 2000</marker>
<rawString>G. Doddington, A. Mitchell, M. Przybocki, L. Ramshaw, S. Strassell, and R. Weischedel. 2000. The automatic content extraction (ACE) programtasks, data, and evaluation. In Proc. of LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Trond Grenager</author>
<author>Christopher Manning</author>
</authors>
<title>Incorporating non-local information into information extraction systems by Gibbs sampling.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>363370</pages>
<contexts>
<context position="8533" citStr="Finkel et al., 2005" startWordPosition="1365" endWordPosition="1368"> built-in mention extraction module, computing boundaries heuristically from the output of a parser. For the CoNLL shared task, we use the BART internal MD module, as it corresponds better to the mention detection guidelines of the OntoNotes dataset. We have further adjusted this module to improve the MD accuracy. The process of mention detection involves two steps. First, we create a list of candidate mentions by merging basic NP chunks with named entities. NP chunks are computed from the parse trees provided in the CoNLL distribution, Named entities are extracted with the Stanford NER tool (Finkel et al., 2005). For each candidate mention, we store it minimal and maximal span. The former is used for computing feature values (e.g., for string matching); it corresponds to either the basic NP chunk or the NE, depending on the mention type. The latter is used for alignment with CoNLL mentions; it is computed by climbing up the parse tree. This procedure, combined with the perfect (gold) coreference resolution, gives us an F-score of 91.56% for the mention detection task on the CoNLL development set1. At the second step, we aim at discarding mentions that are unlikely to participate in coreference chains</context>
</contexts>
<marker>Finkel, Grenager, Manning, 2005</marker>
<rawString>Jenny Rose Finkel, Trond Grenager, and Christopher Manning. 2005. Incorporating non-local information into information extraction systems by Gibbs sampling. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics, pages 363370.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D E Goldberg</author>
</authors>
<date>1989</date>
<booktitle>Genetic Algorithms in Search, Optimization and Machine Learning.</booktitle>
<publisher>AddisonWesley,</publisher>
<location>New York.</location>
<contexts>
<context position="4189" citStr="Goldberg, 1989" startWordPosition="651" endWordPosition="652">on of feature selection for Spanish using the ANCORA corpus. A form of multi-objective optimization was applied to coreference by Munson et al. (2005). Munson et al. (2005) did not propose to train models so as to simultaneously optimize according to multiple metrics; instead, they used ensemble selection to learn to choose among previously trained models the best model for each example. Their general conclusion was negative, stating that ensemble selection seems too unreliable for use in NLP, but they did see some improvements for coreference. 2.2 Genetic Algorithms Genetic algorithms (GAs) (Goldberg, 1989) are randomized search and optimization techniques guided by the principles of evolution and natural genetics. In GAs the parameters of the search space are encoded in the form of strings called chromosomes. A collection of such strings is called a population. An objective or fitness function is associated with each chromosome that represents the degree of goodness of that chromosome. A few of the chromosomes are selected on the basis of the principle of survival of the fittest, and assigned a number of copies that go into the mating pool. Biologically inspired operators like crossover and mut</context>
</contexts>
<marker>Goldberg, 1989</marker>
<rawString>D. E. Goldberg. 1989. Genetic Algorithms in Search, Optimization and Machine Learning. AddisonWesley, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Veronique Hoste</author>
</authors>
<title>Optimization Issues in Machine Learning of Coreference Resolution.</title>
<date>2005</date>
<tech>Ph.D. thesis,</tech>
<institution>Antwerp University.</institution>
<contexts>
<context position="3253" citStr="Hoste (2005)" startWordPosition="506" endWordPosition="507">. In this paper, we first briefly provide some background on optimization for anaphora resolution, on genetic algorithms, and on the method for multiobjective optimization we used, Non-Dominated Sorting Genetic Algorithm II (Deb et al., 2002). After that we discuss our experiments, and present our results. 2 Background 2.1 Optimization for Anaphora Resolution There have only been few attempts at optimization for anaphora resolution, and with a few exceptions, this was done by hand. The first systematic attempt at automatic optimization of anaphora resolution we are aware of was carried out by Hoste (2005), who used genetic algorithms for automatic optimization of both feature selection and of learning parameters, also considering 61 \x0ctwo different machine learners, TimBL and Ripper. Her results suggest that such techniques yield improvements on the MUC-6/7 datasets. Recasens and Hovy (2009) carried out an investigation of feature selection for Spanish using the ANCORA corpus. A form of multi-objective optimization was applied to coreference by Munson et al. (2005). Munson et al. (2005) did not propose to train models so as to simultaneously optimize according to multiple metrics; instead, t</context>
</contexts>
<marker>Hoste, 2005</marker>
<rawString>Veronique Hoste. 2005. Optimization Issues in Machine Learning of Coreference Resolution. Ph.D. thesis, Antwerp University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Luo</author>
</authors>
<title>On coreference resolution performance metrics.</title>
<date>2005</date>
<booktitle>In Proc. NAACL / EMNLP,</booktitle>
<location>Vancouver.</location>
<contexts>
<context position="1081" citStr="Luo, 2005" startWordPosition="149" endWordPosition="150">asif@iitp.ac.in, massimo.poesio@unitn.it Abstract Because there is no generally accepted metric for measuring the performance of anaphora resolution systems, a combination of metrics was proposed to evaluate submissions to the 2011 CONLL Shared Task (Pradhan et al., 2011). We investigate therefore Multiobjective function Optimization (MOO) techniques based on Genetic Algorithms to optimize models according to multiple metrics simultaneously. 1 Introduction Many evaluation metrics have been proposed for anaphora resolution (Vilain et al., 1995; Bagga and Baldwin, 1998; Doddington et al., 2000; Luo, 2005; Recasens and Hovy, 2011). Each of these metrics seems to capture some genuine intuition about the the task, so that, unlike in other areas of HLT, none has really taken over. This makes it difficult to compare systems, as dramatically demonstrated by the results of the Coreference Task at SEMEVAL 2010 (Recasens et al., 2010). It was therefore wise of the CONLL organizers to use a basket of metrics to assess performance instead of a single one. This situation suggests using methods to optimize systems according to more than one metric at once. And as it happens, techniques for doing just that</context>
<context position="11457" citStr="Luo, 2005" startWordPosition="1830" endWordPosition="1831">ss computation, the following procedure is executed. 1. Suppose there are N number of features present in a particular chromosome (i.e., there are total N number of 1s in that chromosome). 2. Construct the coreference resolution system (i.e., BART) with only these N features. 3. This coreference system is evaluated on the development data. The recall, precision and Fmeasure values of three metrics are calculated. For MOO, the objective functions corresponding to a particular chromosome are F1 = F-measureMUC (for the MUC metric), F2 = F-measure3 (for CEAF using the 3 entity alignment function (Luo, 2005)) and F3 = F-measure4 (for CEAF using the 3 entity alignment function). The objective is to: max[F1, F2, F3]: i.e., these three objective functions are simultaneously optimized using the search capability of NSGA-II. We use crowded binary tournament selection as in NSGA-II, followed by conventional crossover and mutation for the MOO based optimization. The most characteristic part of NSGA-II is its elitism operation, where the non-dominated solutions (Deb, 63 \x0c2001) among the parent and child populations are propagated to the next generation. The near-Paretooptimal strings of the last gener</context>
</contexts>
<marker>Luo, 2005</marker>
<rawString>X. Luo. 2005. On coreference resolution performance metrics. In Proc. NAACL / EMNLP, Vancouver.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Art Munson</author>
<author>Claire Cardie</author>
<author>Rich Caruana</author>
</authors>
<title>Optimizing to arbitrary NLP metrics using ensemble selection.</title>
<date>2005</date>
<booktitle>In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing (HLT/EMNLP),</booktitle>
<pages>539546</pages>
<contexts>
<context position="3724" citStr="Munson et al. (2005)" startWordPosition="576" endWordPosition="579"> this was done by hand. The first systematic attempt at automatic optimization of anaphora resolution we are aware of was carried out by Hoste (2005), who used genetic algorithms for automatic optimization of both feature selection and of learning parameters, also considering 61 \x0ctwo different machine learners, TimBL and Ripper. Her results suggest that such techniques yield improvements on the MUC-6/7 datasets. Recasens and Hovy (2009) carried out an investigation of feature selection for Spanish using the ANCORA corpus. A form of multi-objective optimization was applied to coreference by Munson et al. (2005). Munson et al. (2005) did not propose to train models so as to simultaneously optimize according to multiple metrics; instead, they used ensemble selection to learn to choose among previously trained models the best model for each example. Their general conclusion was negative, stating that ensemble selection seems too unreliable for use in NLP, but they did see some improvements for coreference. 2.2 Genetic Algorithms Genetic algorithms (GAs) (Goldberg, 1989) are randomized search and optimization techniques guided by the principles of evolution and natural genetics. In GAs the parameters of</context>
</contexts>
<marker>Munson, Cardie, Caruana, 2005</marker>
<rawString>Art Munson, Claire Cardie, and Rich Caruana. 2005. Optimizing to arbitrary NLP metrics using ensemble selection. In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing (HLT/EMNLP), pages 539546.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vincent Ng</author>
<author>Claire Cardie</author>
</authors>
<title>Improving machine learning approaches to coreference resolution.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting on Association for C omputational Linguistics,</booktitle>
<pages>104111</pages>
<contexts>
<context position="13197" citStr="Ng and Cardie (2002)" startWordPosition="2098" endWordPosition="2101"> and performed separate MOO experiments on each one. The MOO approach provides a set of nondominated solutions on the final Pareto optimal front. All the solutions are equally important from the algorithmic point of view. We have collected sets of chromosomes for each sub-sample and evaluated them on the whole train/development set, picking the solution with the highest FINAL2 score for our CoNLL submission. 4 Results 4.1 Development set Table 1 compares the performance level obtained using all the features with that of loose reimplementations of the systems proposed by Soon et al. (2001) and Ng and Cardie (2002), commonly used as baselines. Our reimplementation of the Ng &amp; Cardie model uses only a subset of features. The results in Table 1 show that our system with a rich feature set does not outperform simpler baselines (and, in fact, yields poorer results). A similar trend has been observed by Ng and Cardie (2002), where the improvement was only possible after manual feature selection. The last line of Table 1 shows the performance level of the best chromosome found through the MOO technique. As it can be seen, it outperforms all the baselines according to all the measures, leading to an improvemen</context>
</contexts>
<marker>Ng, Cardie, 2002</marker>
<rawString>Vincent Ng and Claire Cardie. 2002. Improving machine learning approaches to coreference resolution. In Proceedings of the 40th Annual Meeting on Association for C omputational Linguistics, pages 104111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Pradhan</author>
<author>Lance Ramshaw</author>
<author>Mitchell Marcus</author>
<author>Martha Palmer</author>
<author>Ralph Weischedel</author>
<author>Nianwen Xue</author>
</authors>
<title>Conll-2011 shared task: Modeling unrestricted coreference in ontonotes.</title>
<date>2011</date>
<booktitle>In Proceedings of the Fifteenth Conference on Computational Natural Language Learning (CoNLL 2011),</booktitle>
<location>Portland, Oregon,</location>
<contexts>
<context position="744" citStr="Pradhan et al., 2011" startWordPosition="98" endWordPosition="101"> 23-24 June 2011. c 2011 Association for Computational Linguistics Multi-metric optimization for coreference: The UniTN / IITP / Essex submission to the 2011 CONLL Shared Task Olga Uryupina Sriparna Saha Asif Ekbal Massimo Poesio University of Trento Indian Institute of Technology Patna University of Essex uryupina@gmail.com, sriparna@iitp.ac.in, asif@iitp.ac.in, massimo.poesio@unitn.it Abstract Because there is no generally accepted metric for measuring the performance of anaphora resolution systems, a combination of metrics was proposed to evaluate submissions to the 2011 CONLL Shared Task (Pradhan et al., 2011). We investigate therefore Multiobjective function Optimization (MOO) techniques based on Genetic Algorithms to optimize models according to multiple metrics simultaneously. 1 Introduction Many evaluation metrics have been proposed for anaphora resolution (Vilain et al., 1995; Bagga and Baldwin, 1998; Doddington et al., 2000; Luo, 2005; Recasens and Hovy, 2011). Each of these metrics seems to capture some genuine intuition about the the task, so that, unlike in other areas of HLT, none has really taken over. This makes it difficult to compare systems, as dramatically demonstrated by the result</context>
</contexts>
<marker>Pradhan, Ramshaw, Marcus, Palmer, Weischedel, Xue, 2011</marker>
<rawString>Sameer Pradhan, Lance Ramshaw, Mitchell Marcus, Martha Palmer, Ralph Weischedel, and Nianwen Xue. 2011. Conll-2011 shared task: Modeling unrestricted coreference in ontonotes. In Proceedings of the Fifteenth Conference on Computational Natural Language Learning (CoNLL 2011), Portland, Oregon, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Recasens</author>
<author>E Hovy</author>
</authors>
<title>A deeper look into features for coreference resolution.</title>
<date>2009</date>
<booktitle>Anaphora Processing and Applications (DAARC 2009, number 5847 in LNAI,</booktitle>
<pages>2942</pages>
<editor>In S. Lalitha Devi, A. Branco, and R. Mitkov, editors,</editor>
<publisher>SpringerVerlag.</publisher>
<location>Berlin / Heidelberg.</location>
<contexts>
<context position="3547" citStr="Recasens and Hovy (2009)" startWordPosition="548" endWordPosition="551"> and present our results. 2 Background 2.1 Optimization for Anaphora Resolution There have only been few attempts at optimization for anaphora resolution, and with a few exceptions, this was done by hand. The first systematic attempt at automatic optimization of anaphora resolution we are aware of was carried out by Hoste (2005), who used genetic algorithms for automatic optimization of both feature selection and of learning parameters, also considering 61 \x0ctwo different machine learners, TimBL and Ripper. Her results suggest that such techniques yield improvements on the MUC-6/7 datasets. Recasens and Hovy (2009) carried out an investigation of feature selection for Spanish using the ANCORA corpus. A form of multi-objective optimization was applied to coreference by Munson et al. (2005). Munson et al. (2005) did not propose to train models so as to simultaneously optimize according to multiple metrics; instead, they used ensemble selection to learn to choose among previously trained models the best model for each example. Their general conclusion was negative, stating that ensemble selection seems too unreliable for use in NLP, but they did see some improvements for coreference. 2.2 Genetic Algorithms</context>
</contexts>
<marker>Recasens, Hovy, 2009</marker>
<rawString>M. Recasens and E. Hovy. 2009. A deeper look into features for coreference resolution. In S. Lalitha Devi, A. Branco, and R. Mitkov, editors, Anaphora Processing and Applications (DAARC 2009, number 5847 in LNAI, pages 2942, Berlin / Heidelberg. SpringerVerlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Recasens</author>
<author>E Hovy</author>
</authors>
<title>Blanc: Implementing the rand index for coreference evaluation. Natural Language Engineering.</title>
<date>2011</date>
<contexts>
<context position="1107" citStr="Recasens and Hovy, 2011" startWordPosition="151" endWordPosition="154">c.in, massimo.poesio@unitn.it Abstract Because there is no generally accepted metric for measuring the performance of anaphora resolution systems, a combination of metrics was proposed to evaluate submissions to the 2011 CONLL Shared Task (Pradhan et al., 2011). We investigate therefore Multiobjective function Optimization (MOO) techniques based on Genetic Algorithms to optimize models according to multiple metrics simultaneously. 1 Introduction Many evaluation metrics have been proposed for anaphora resolution (Vilain et al., 1995; Bagga and Baldwin, 1998; Doddington et al., 2000; Luo, 2005; Recasens and Hovy, 2011). Each of these metrics seems to capture some genuine intuition about the the task, so that, unlike in other areas of HLT, none has really taken over. This makes it difficult to compare systems, as dramatically demonstrated by the results of the Coreference Task at SEMEVAL 2010 (Recasens et al., 2010). It was therefore wise of the CONLL organizers to use a basket of metrics to assess performance instead of a single one. This situation suggests using methods to optimize systems according to more than one metric at once. And as it happens, techniques for doing just that have been developed in th</context>
</contexts>
<marker>Recasens, Hovy, 2011</marker>
<rawString>M. Recasens and E. Hovy. 2011. Blanc: Implementing the rand index for coreference evaluation. Natural Language Engineering.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Recasens</author>
<author>L Marquez</author>
<author>E Sapena</author>
<author>M A Mart</author>
<author>M Taule</author>
<author>V Hoste</author>
<author>M Poesio</author>
<author>Y Versley</author>
</authors>
<date>2010</date>
<contexts>
<context position="1409" citStr="Recasens et al., 2010" startWordPosition="203" endWordPosition="206">unction Optimization (MOO) techniques based on Genetic Algorithms to optimize models according to multiple metrics simultaneously. 1 Introduction Many evaluation metrics have been proposed for anaphora resolution (Vilain et al., 1995; Bagga and Baldwin, 1998; Doddington et al., 2000; Luo, 2005; Recasens and Hovy, 2011). Each of these metrics seems to capture some genuine intuition about the the task, so that, unlike in other areas of HLT, none has really taken over. This makes it difficult to compare systems, as dramatically demonstrated by the results of the Coreference Task at SEMEVAL 2010 (Recasens et al., 2010). It was therefore wise of the CONLL organizers to use a basket of metrics to assess performance instead of a single one. This situation suggests using methods to optimize systems according to more than one metric at once. And as it happens, techniques for doing just that have been developed in the area of Genetic Algorithmsso-called multi-objective optimization techniques (MOO) (Deb, 2001). The key idea of our submission is to use MOO techniques to optimize our anaphora resolution system according to three metrics simultaneously: the MUC scorer (a member of what one might call the link-based </context>
</contexts>
<marker>Recasens, Marquez, Sapena, Mart, Taule, Hoste, Poesio, Versley, 2010</marker>
<rawString>M. Recasens, L. Marquez, E. Sapena, M. A. Mart, M. Taule, V. Hoste, M. Poesio, and Y. Versley. 2010.</rawString>
</citation>
<citation valid="false">
<title>Semeval-2010 task 1: Coreference resolution in multiple languages.</title>
<booktitle>In Proc. SEMEVAL 2010,</booktitle>
<location>Uppsala.</location>
<marker></marker>
<rawString>Semeval-2010 task 1: Coreference resolution in multiple languages. In Proc. SEMEVAL 2010, Uppsala.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sriparna Saha</author>
<author>Massimo Poesio</author>
<author>Asif Ekbal</author>
<author>Olga Uryupina</author>
</authors>
<title>Single and multi-objective optimization for feature selection in anaphora resolution.</title>
<date>2011</date>
<note>Submitted.</note>
<contexts>
<context position="2139" citStr="Saha et al., 2011" startWordPosition="327" endWordPosition="330">ngle one. This situation suggests using methods to optimize systems according to more than one metric at once. And as it happens, techniques for doing just that have been developed in the area of Genetic Algorithmsso-called multi-objective optimization techniques (MOO) (Deb, 2001). The key idea of our submission is to use MOO techniques to optimize our anaphora resolution system according to three metrics simultaneously: the MUC scorer (a member of what one might call the link-based cluster of metrics) and the two CEAF metrics (representative of the entity-based cluster). In a previous study (Saha et al., 2011), we show that our MOO-based approach yields more robust results than single-objective optimization. We test two types of optimization: feature selection and architecturewhether to learn a single model for all types of anaphors, or to learn separate models for pronouns and for other nominals. We also discuss how the default mention extraction techniques of the system we used for this submission, BART (Versley et al., 2008), were modified to handle the all-mention annotation in the OntoNotes corpus. In this paper, we first briefly provide some background on optimization for anaphora resolution,</context>
</contexts>
<marker>Saha, Poesio, Ekbal, Uryupina, 2011</marker>
<rawString>Sriparna Saha, Massimo Poesio, Asif Ekbal, and Olga Uryupina. 2011. Single and multi-objective optimization for feature selection in anaphora resolution. Submitted.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wee Meng Soon</author>
<author>Hwee Tou Ng</author>
<author>Daniel Chung Yong Lim</author>
</authors>
<title>A machine learning approach to coreference resolution of noun phrases.</title>
<date>2001</date>
<journal>Computational Linguistic,</journal>
<volume>27</volume>
<issue>4</issue>
<contexts>
<context position="7650" citStr="Soon et al., 2001" startWordPosition="1223" endWordPosition="1226">d split classifiers. We considered 42 features, including 7 classifying mention type, 8 for string matching of different subparts and different levels of exactness, 2 for aliasing, 4 for agreement, 12 for syntactic information including also binding constraints, 3 encoding salience, 1 encoding patterns extracted from the Web, 3 for proximity, and 2 for 1st and 2nd person pronouns. Again because of time considerations, we used decision trees as implemented in Weka as our classification model instead of maximum-entropy or SVMs. Finally, we used a simple mention-pair model without ranking as in (Soon et al., 2001). 62 \x0c3.2 Mention detection BART supports several solutions to the mention detection (MD) task. The users can input precomputed mentions, thus, experimenting with gold boundaries or system boundaries computed by external modules (e.g., CARAFE). BART also has a built-in mention extraction module, computing boundaries heuristically from the output of a parser. For the CoNLL shared task, we use the BART internal MD module, as it corresponds better to the mention detection guidelines of the OntoNotes dataset. We have further adjusted this module to improve the MD accuracy. The process of mentio</context>
<context position="13172" citStr="Soon et al. (2001)" startWordPosition="2093" endWordPosition="2096">data into 3 sub-samples and performed separate MOO experiments on each one. The MOO approach provides a set of nondominated solutions on the final Pareto optimal front. All the solutions are equally important from the algorithmic point of view. We have collected sets of chromosomes for each sub-sample and evaluated them on the whole train/development set, picking the solution with the highest FINAL2 score for our CoNLL submission. 4 Results 4.1 Development set Table 1 compares the performance level obtained using all the features with that of loose reimplementations of the systems proposed by Soon et al. (2001) and Ng and Cardie (2002), commonly used as baselines. Our reimplementation of the Ng &amp; Cardie model uses only a subset of features. The results in Table 1 show that our system with a rich feature set does not outperform simpler baselines (and, in fact, yields poorer results). A similar trend has been observed by Ng and Cardie (2002), where the improvement was only possible after manual feature selection. The last line of Table 1 shows the performance level of the best chromosome found through the MOO technique. As it can be seen, it outperforms all the baselines according to all the measures,</context>
</contexts>
<marker>Soon, Ng, Lim, 2001</marker>
<rawString>Wee Meng Soon, Hwee Tou Ng, and Daniel Chung Yong Lim. 2001. A machine learning approach to coreference resolution of noun phrases. Computational Linguistic, 27(4):521544.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yannick Versley</author>
<author>Simone Paolo Ponzetto</author>
<author>Massimo Poesio</author>
<author>Vladimir Eidelman</author>
<author>Alan Jern</author>
<author>Jason Smith</author>
<author>Xiaofeng Yang</author>
<author>Alessandro Moschitti</author>
</authors>
<title>BART: a modular toolkit for coreference resolution.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics on Human Language Technologies,</booktitle>
<pages>912</pages>
<contexts>
<context position="2565" citStr="Versley et al., 2008" startWordPosition="396" endWordPosition="399">: the MUC scorer (a member of what one might call the link-based cluster of metrics) and the two CEAF metrics (representative of the entity-based cluster). In a previous study (Saha et al., 2011), we show that our MOO-based approach yields more robust results than single-objective optimization. We test two types of optimization: feature selection and architecturewhether to learn a single model for all types of anaphors, or to learn separate models for pronouns and for other nominals. We also discuss how the default mention extraction techniques of the system we used for this submission, BART (Versley et al., 2008), were modified to handle the all-mention annotation in the OntoNotes corpus. In this paper, we first briefly provide some background on optimization for anaphora resolution, on genetic algorithms, and on the method for multiobjective optimization we used, Non-Dominated Sorting Genetic Algorithm II (Deb et al., 2002). After that we discuss our experiments, and present our results. 2 Background 2.1 Optimization for Anaphora Resolution There have only been few attempts at optimization for anaphora resolution, and with a few exceptions, this was done by hand. The first systematic attempt at autom</context>
<context position="6159" citStr="Versley et al., 2008" startWordPosition="989" endWordPosition="992"> algorithms are known to be more effective for solving MOO than classical methods such as weighted metrics, goal programming (Deb, 2001), because of their population-based nature. A particularly popular genetic algorithm of this type is NSGAII (Deb et al., 2002), which we used for our runs. 3 Using MOO for Optimization in Anaphora Resolution We used multi-objective optimization techniques for feature selection and for identifying the optimal architecture for the CONLL data. In this section we briefly discuss each aspect of the methodology. 3.1 The BART System For our experiments, we use BART (Versley et al., 2008), a modular toolkit for anaphora resolution that supports state-of-the-art statistical approaches to the task and enables efficient feature engineering. BART comes with a set of already implemented features, along with the possibility to design new ones. It also implements different models of anaphora resolution, allowing the choice between single and split classifiers that we explore in our runs, as well as between mention-pair and entity-mention, and between best-first and ranking. It also has interfaces to different machine learners (MaxEnt, SVM, decision trees). It is thus ideally suited f</context>
</contexts>
<marker>Versley, Ponzetto, Poesio, Eidelman, Jern, Smith, Yang, Moschitti, 2008</marker>
<rawString>Yannick Versley, Simone Paolo Ponzetto, Massimo Poesio, Vladimir Eidelman, Alan Jern, Jason Smith, Xiaofeng Yang, and Alessandro Moschitti. 2008. BART: a modular toolkit for coreference resolution. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics on Human Language Technologies, pages 912.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Vilain</author>
<author>J Burger</author>
<author>J Aberdeen</author>
<author>D Connolly</author>
<author>L Hirschman</author>
</authors>
<title>A model-theoretic coreference scoring scheme.</title>
<date>1995</date>
<booktitle>In Proc. of the Sixth Message Understanding Conference,</booktitle>
<pages>4552</pages>
<contexts>
<context position="1020" citStr="Vilain et al., 1995" startWordPosition="137" endWordPosition="140">ogy Patna University of Essex uryupina@gmail.com, sriparna@iitp.ac.in, asif@iitp.ac.in, massimo.poesio@unitn.it Abstract Because there is no generally accepted metric for measuring the performance of anaphora resolution systems, a combination of metrics was proposed to evaluate submissions to the 2011 CONLL Shared Task (Pradhan et al., 2011). We investigate therefore Multiobjective function Optimization (MOO) techniques based on Genetic Algorithms to optimize models according to multiple metrics simultaneously. 1 Introduction Many evaluation metrics have been proposed for anaphora resolution (Vilain et al., 1995; Bagga and Baldwin, 1998; Doddington et al., 2000; Luo, 2005; Recasens and Hovy, 2011). Each of these metrics seems to capture some genuine intuition about the the task, so that, unlike in other areas of HLT, none has really taken over. This makes it difficult to compare systems, as dramatically demonstrated by the results of the Coreference Task at SEMEVAL 2010 (Recasens et al., 2010). It was therefore wise of the CONLL organizers to use a basket of metrics to assess performance instead of a single one. This situation suggests using methods to optimize systems according to more than one metr</context>
</contexts>
<marker>Vilain, Burger, Aberdeen, Connolly, Hirschman, 1995</marker>
<rawString>M. Vilain, J. Burger, J. Aberdeen, D. Connolly, and L. Hirschman. 1995. A model-theoretic coreference scoring scheme. In Proc. of the Sixth Message Understanding Conference, pages 4552.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>