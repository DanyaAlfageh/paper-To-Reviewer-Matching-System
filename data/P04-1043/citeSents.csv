3 Predicate/Argument structure Kernel (PAK) Given the semantic objects defined in the previous section, we design a convolution kernel in a way similar to the parse-tree kernel proposed in CITATION,,
 In CITATION, it has been shown that P i Ii(nx)Ii(nz) = (nx, nz) can be computed in O(|Nx ||Nz|) by the following recursive relation: (1) if the productions at nx and nz are different then (nx, nz) = 0; 2 A fragment can appear several times in a parse-tree, thus each fragment occurrence is considered as a different element in F 0 p,a,,
 This kind of kernel has the drawback of assigning more weight to larger structures while the argument type does not strictly depend on the size of the argument CITATION,,
 It is worth noting that even if the above equations define a kernel function similar to the one proposed in CITATION, the substructures on which it operates are different from the parse-tree kernel,,
 The sentences were processed using Collins parser CITATION to generate parse-trees automatically,,
2 Classification set-up The classifier evaluations were carried out using the SVM-light software CITATION available at svmlight,,
, 2003; CITATION),,
berkeley 3 It can be proven that the resulting kernels still satisfy Mercers conditions CITATION,,
 In other words, CArg0 = Position XOR Voice, which is the classical example of a non-linear separable function that becomes separable in a superlinear space CITATION,,
 In particular, these problems affect the processing of predicate argument structures annotated in PropBank CITATION or FrameNet CITATION,,
 Several machine learning approaches for argument identification and classification have been developed (CITATION; CITATION; CITATION; CITATION),,
 These standard features, firstly proposed in CITATION, refer to a flat information derived from parse trees, i,,
CITATION to generate parse-trees automatically,,
2 Classification set-up The classifier evaluations were carried out using the SVM-light software CITATION available at svmlight,,
 (CITATION; CITATION; CITATION),,
 Several machine learning approaches for argument identification and classification have been developed (CITATION; CITATION; CITATION; CITATION),,
, (CITATION; CITATION; CITATION),,
 \x0cis substantially equal to the SVM performance (88%) obtained in CITATION with degree 2 and (c) the accuracy on FrameNet (85,,
0% in CITATION,,
 CITATION claim that semantic information in natural language texts is connected to syntactic structures,,
 The sentences were processed using Collins parser CITATION to generate parse-trees automatically,,
2 Classification set-up The classifier evaluations were carried out using the SVM-light software CITATION available at svmlight,,
 (CITATION; CITATION; CITATION),,
 CITATION claim that semantic information in natural language texts is connected to syntactic structures,,
 In particular, these problems affect the processing of predicate argument structures annotated in PropBank CITATION or FrameNet CITATION,,
 This kind of kernel has the drawback of assigning more weight to larger structures while the argument type does not strictly depend on the size of the argument CITATION,,
 It is worth noting that even if the above equations define a kernel function similar to the one proposed in CITATION, the substructures on which it operates are different from the parse-tree kernel,,
 Several machine learning approaches for argument identification and classification have been developed (CITATION; CITATION; CITATION; CITATION),,
 We adopted this solution as it is simple and effective CITATION,,
, (CITATION; CITATION; CITATION),,
berkeley 3 It can be proven that the resulting kernels still satisfy Mercers conditions CITATION,,
2 Classification set-up The classifier evaluations were carried out using the SVM-light software CITATION available at svmlight,,
 (CITATION; CITATION; CITATION),,
 Several machine learning approaches for argument identification and classification have been developed (CITATION; CITATION; CITATION; CITATION),,
, (CITATION; CITATION; CITATION),,
2 Classification set-up The classifier evaluations were carried out using the SVM-light software CITATION available at svmlight,,
 (CITATION; CITATION; CITATION),,
2 Support Vector Machine approach Given a vector space in &lt;n and a set of positive and negative points, SVMs classify vectors according to a separating hyperplane, H(~ x) = ~ w ~ x + b = 0, where ~ w &lt;n and b &lt; are learned by applying the Structural Risk Minimization principle CITATION,,
