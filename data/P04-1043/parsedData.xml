<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<address confidence="0.217503">
b&apos;A Study on Convolution Kernels for Shallow Semantic Parsing
</address>
<author confidence="0.950286">
Alessandro Moschitti
</author>
<affiliation confidence="0.835505">
University of Texas at Dallas
Human Language Technology Research Institute
</affiliation>
<address confidence="0.87563">
Richardson, TX 75083-0688, USA
</address>
<email confidence="0.995191">
alessandro.moschitti@utdallas.edu
</email>
<sectionHeader confidence="0.988604" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.991426214285714">
In this paper we have designed and experi-
mented novel convolution kernels for automatic
classification of predicate arguments. Their
main property is the ability to process struc-
tured representations. Support Vector Ma-
chines (SVMs), using a combination of such ker-
nels and the flat feature kernel, classify Prop-
Bank predicate arguments with accuracy higher
than the current argument classification state-
of-the-art.
Additionally, experiments on FrameNet data
have shown that SVMs are appealing for the
classification of semantic roles even if the pro-
posed kernels do not produce any improvement.
</bodyText>
<sectionHeader confidence="0.996981" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99132603030303">
Several linguistic theories, e.g. (Jackendoff,
1990) claim that semantic information in nat-
ural language texts is connected to syntactic
structures. Hence, to deal with natural lan-
guage semantics, the learning algorithm should
be able to represent and process structured
data. The classical solution adopted for such
tasks is to convert syntax structures into flat
feature representations which are suitable for a
given learning model. The main drawback is
that structures may not be properly represented
by flat features.
In particular, these problems affect the pro-
cessing of predicate argument structures an-
notated in PropBank (Kingsbury and Palmer,
2002) or FrameNet (Fillmore, 1982). Figure
1 shows an example of a predicate annotation
in PropBank for the sentence: &amp;quot;Paul gives a
lecture in Rome&amp;quot;. A predicate may be a verb
or a noun or an adjective and most of the time
Arg 0 is the logical subject, Arg 1 is the logical
object and ArgM may indicate locations, as in
our example.
FrameNet also describes predicate/argument
structures but for this purpose it uses richer
semantic structures called frames. These lat-
ter are schematic representations of situations
involving various participants, properties and
roles in which a word may be typically used.
Frame elements or semantic roles are arguments
of predicates called target words. In FrameNet,
the argument names are local to a particular
frame.
</bodyText>
<figure confidence="0.965725529411765">
Predicate
Arg. 0
Arg. M
S
N
NP
D N
VP
V
Paul
in
gives
a lecture
PP
IN N
Rome
Arg. 1
</figure>
<figureCaption confidence="0.999906">
Figure 1: A predicate argument structure in a
</figureCaption>
<bodyText confidence="0.977937675675676">
parse-tree representation.
Several machine learning approaches for argu-
ment identification and classification have been
developed (Gildea and Jurasfky, 2002; Gildea
and Palmer, 2002; Surdeanu et al., 2003; Ha-
cioglu et al., 2003). Their common characteris-
tic is the adoption of feature spaces that model
predicate-argument structures in a flat repre-
sentation. On the contrary, convolution kernels
aim to capture structural information in term
of sub-structures, providing a viable alternative
to flat features.
In this paper, we select portions of syntactic
trees, which include predicate/argument salient
sub-structures, to define convolution kernels for
the task of predicate argument classification. In
particular, our kernels aim to (a) represent the
relation between predicate and one of its argu-
ments and (b) to capture the overall argument
structure of the target predicate. Additionally,
we define novel kernels as combinations of the
above two with the polynomial kernel of stan-
dard flat features.
Experiments on Support Vector Machines us-
ing the above kernels show an improvement
\x0cof the state-of-the-art for PropBank argument
classification. On the contrary, FrameNet se-
mantic parsing seems to not take advantage of
the structural information provided by our ker-
nels.
The remainder of this paper is organized as
follows: Section 2 defines the Predicate Argu-
ment Extraction problem and the standard so-
lution to solve it. In Section 3 we present our
kernels whereas in Section 4 we show compar-
ative results among SVMs using standard fea-
tures and the proposed kernels. Finally, Section
</bodyText>
<sectionHeader confidence="0.8270945" genericHeader="method">
5 summarizes the conclusions.
2 Predicate Argument Extraction: a
</sectionHeader>
<bodyText confidence="0.725136083333333">
standard approach
Given a sentence in natural language and the
target predicates, all arguments have to be rec-
ognized. This problem can be divided into two
subtasks: (a) the detection of the argument
boundaries, i.e. all its compounding words and
(b) the classification of the argument type, e.g.
Arg0 or ArgM in PropBank or Agent and Goal
in FrameNet.
The standard approach to learn both detec-
tion and classification of predicate arguments
is summarized by the following steps:
</bodyText>
<listItem confidence="0.926374">
1. Given a sentence from the training-set gene-
rate a full syntactic parse-tree;
2. let P and A be the set of predicates and
the set of parse-tree nodes (i.e. the potential
arguments), respectively;
3. for each pair &amp;lt;p, a&amp;gt; P A:
</listItem>
<bodyText confidence="0.97111575">
extract the feature representation set, Fp,a;
if the subtree rooted in a covers exactly the
words of one argument of p, put Fp,a in T+
(positive examples), otherwise put it in T
(negative examples).
For example, in Figure 1, for each combina-
tion of the predicate give with the nodes N, S,
VP, V, NP, PP, D or IN the instances Fgive,a are
generated. In case the node a exactly covers
Paul, a lecture or in Rome, it will be a positive
instance otherwise it will be a negative one, e.g.
Fgive,IN.
To learn the argument classifiers the T + set
can be re-organized as positive T +
argi
and neg-
ative T
argi
examples for each argument i. In
this way, an individual ONE-vs-ALL classifier
for each argument i can be trained. We adopted
this solution as it is simple and effective (Ha-
cioglu et al., 2003). In the classification phase,
given a sentence of the test-set, all its Fp,a
are generated and classified by each individ-
ual classifier. As a final decision, we select the
argument associated with the maximum value
among the scores provided by the SVMs, i.e.
</bodyText>
<listItem confidence="0.887484814814815">
argmaxiS Ci, where S is the target set of ar-
guments.
- Phrase Type: This feature indicates the syntactic type
of the phrase labeled as a predicate argument, e.g. NP
for Arg1.
- Parse Tree Path: This feature contains the path in
the parse tree between the predicate and the argument
phrase, expressed as a sequence of nonterminal labels
linked by direction (up or down) symbols, e.g. V VP
NP for Arg1.
- Position: Indicates if the constituent, i.e. the potential
argument, appears before or after the predicate in the
sentence, e.g. after for Arg1 and before for Arg0.
- Voice: This feature distinguishes between active or pas-
sive voice for the predicate phrase, e.g. active for every
argument.
- Head Word: This feature contains the headword of the
evaluated phrase. Case and morphological information
are preserved, e.g. lecture for Arg1.
- Governing Category indicates if an NP is dominated by
a sentence phrase or by a verb phrase, e.g. the NP asso-
ciated with Arg1 is dominated by a VP.
- Predicate Word: This feature consists of two compo-
nents: (1) the word itself, e.g. gives for all arguments;
and (2) the lemma which represents the verb normalized
to lower case and infinitive form, e.g. give for all argu-
ments.
</listItem>
<tableCaption confidence="0.883846">
Table 1: Standard features extracted from the
</tableCaption>
<bodyText confidence="0.815367">
parse-tree in Figure 1.
</bodyText>
<subsectionHeader confidence="0.980154">
2.1 Standard feature space
</subsectionHeader>
<bodyText confidence="0.972610857142857">
The discovery of relevant features is, as usual, a
complex task, nevertheless, there is a common
consensus on the basic features that should be
adopted. These standard features, firstly pro-
posed in (Gildea and Jurasfky, 2002), refer to
a flat information derived from parse trees, i.e.
Phrase Type, Predicate Word, Head Word, Gov-
erning Category, Position and Voice. Table 1
presents the standard features and exemplifies
how they are extracted from the parse tree in
Figure 1.
For example, the Parse Tree Path feature rep-
resents the path in the parse-tree between a
predicate node and one of its argument nodes.
It is expressed as a sequence of nonterminal la-
bels linked by direction symbols (up or down),
e.g. in Figure 1, VVPNP is the path between
the predicate to give and the argument 1, a lec-
ture. Two pairs &amp;lt;p1, a1&amp;gt; and &amp;lt;p2, a2&amp;gt; have
two different Path features even if the paths dif-
fer only for a node in the parse-tree. This pre-
</bodyText>
<figure confidence="0.989811418181818">
\x0cS
N
NP
D N
VP
V
Paul
in
delivers
a talk
PP
IN NP
jj
Fdeliver, Arg0
formal
N
style
Arg. 0
a) S
N
NP
D N
VP
V
Paul
in
delivers
a talk
PP
IN NP
jj
formal
N
style
Fdeliver, Arg1
b) S
N
NP
D N
VP
V
Paul
in
delivers
a talk
PP
IN NP
jj
formal
N
style
Arg. 1
Fdeliver, ArgM
c)
Arg. M
</figure>
<figureCaption confidence="0.993626">
Figure 2: Structured features for Arg0, Arg1 and ArgM.
</figureCaption>
<bodyText confidence="0.913018">
vents the learning algorithm to generalize well
on unseen data. In order to address this prob-
lem, the next section describes a novel kernel
space for predicate argument classification.
</bodyText>
<subsectionHeader confidence="0.999635">
2.2 Support Vector Machine approach
</subsectionHeader>
<bodyText confidence="0.999338333333333">
Given a vector space in &amp;lt;n and a set of posi-
tive and negative points, SVMs classify vectors
according to a separating hyperplane, H(~
</bodyText>
<equation confidence="0.9407722">
x) =
~
w ~
x + b = 0, where ~
w &amp;lt;n and b &amp;lt; are
</equation>
<bodyText confidence="0.935555">
learned by applying the Structural Risk Mini-
mization principle (Vapnik, 1995).
To apply the SVM algorithm to Predicate
</bodyText>
<listItem confidence="0.46537775">
Argument Classification, we need a function
: F &amp;lt;n to map our features space F =
{f1, .., f|F|} and our predicate/argument pair
representation, Fp,a = Fz, into &amp;lt;n, such that:
</listItem>
<equation confidence="0.643193">
Fz (Fz) = (1(Fz), .., n(Fz))
</equation>
<bodyText confidence="0.657926">
From the kernel theory we have that:
</bodyText>
<equation confidence="0.994794722222222">
H(~
x) =
\x10 X
i=1..l
i~
xi
\x11
~
x+b =
X
i=1..l
i~
xi ~
x+b =
=
X
i=1..l
i(Fi) (Fz) + b.
</equation>
<bodyText confidence="0.99603625">
where, Fi i {1, .., l} are the training in-
stances and the product K(Fi, Fz) =&amp;lt;(Fi)
(Fz)&amp;gt; is the kernel function associated with
the mapping . The simplest mapping that we
</bodyText>
<equation confidence="0.969501666666667">
can apply is (Fz) = ~
z = (z1, ..., zn) where
zi = 1 if fi Fz otherwise zi = 0, i.e.
</equation>
<bodyText confidence="0.738230666666667">
the characteristic vector of the set Fz with re-
spect to F. If we choose as a kernel function
the scalar product we obtain the linear kernel
</bodyText>
<equation confidence="0.938002">
KL(Fx, Fz) = ~
x ~
z.
</equation>
<bodyText confidence="0.905306142857143">
Another function which is the current state-
of-the-art of predicate argument classification is
the polynomial kernel: Kp(Fx, Fz) = (c+~
x~
z)d,
where c is a constant and d is the degree of the
polynom.
</bodyText>
<sectionHeader confidence="0.681036" genericHeader="method">
3 Convolution Kernels for Semantic
</sectionHeader>
<subsectionHeader confidence="0.620137">
Parsing
</subsectionHeader>
<bodyText confidence="0.999724692307692">
We propose two different convolution kernels
associated with two different predicate argu-
ment sub-structures: the first includes the tar-
get predicate with one of its arguments. We will
show that it contains almost all the standard
feature information. The second relates to the
sub-categorization frame of verbs. In this case,
the kernel function aims to cluster together ver-
bal predicates which have the same syntactic
realizations. This provides the classification al-
gorithm with important clues about the possible
set of arguments suited for the target syntactic
structure.
</bodyText>
<subsectionHeader confidence="0.997634">
3.1 Predicate/Argument Feature
</subsectionHeader>
<bodyText confidence="0.871415523809524">
(PAF)
We consider the predicate argument structures
annotated in PropBank or FrameNet as our se-
mantic space. The smallest sub-structure which
includes one predicate with only one of its ar-
guments defines our structural feature. For
example, Figure 2 illustrates the parse-tree of
the sentence &amp;quot;Paul delivers a talk in formal
style&amp;quot;. The circled substructures in (a), (b)
and (c) are our semantic objects associated
with the three arguments of the verb to de-
liver, i.e. &amp;lt;deliver, Arg0&amp;gt;, &amp;lt;deliver, Arg1&amp;gt;
and &amp;lt;deliver, ArgM &amp;gt;. Note that each predi-
cate/argument pair is associated with only one
structure, i.e. Fp,a contain only one of the cir-
cled sub-trees. Other important properties are
the followings:
(1) The overall semantic feature space F con-
tains sub-structures composed of syntactic in-
formation embodied by parse-tree dependencies
and semantic information under the form of
</bodyText>
<listItem confidence="0.8698949">
predicate/argument annotation.
(2) This solution is efficient as we have to clas-
sify as many nodes as the number of predicate
arguments.
(3) A constituent cannot be part of two differ-
ent arguments of the target predicate, i.e. there
is no overlapping between the words of two ar-
guments. Thus, two semantic structures Fp1,a1
and Fp2,a2
1, associated with two different ar-
</listItem>
<page confidence="0.582483">
1
</page>
<bodyText confidence="0.566394">
Fp,a was defined as the set of features of the object
&amp;lt;p, a&amp;gt;. Since in our representations we have only one
</bodyText>
<figure confidence="0.99596985">
\x0cS
NP VP
VP VP
CC
VBD NP
flushed DT NN
the pan
and VBD NP
buckled PRP$ NN
his belt
PRP
He
Arg0
(flush and buckle)
Arg1
(flush)
Arg1 (buckle)
Predicate 1 Predicate 2
Fflush
Fbuckle
</figure>
<figureCaption confidence="0.996453">
Figure 3: Sub-Categorization Features for two
</figureCaption>
<bodyText confidence="0.9708068">
predicate argument structures.
guments, cannot be included one in the other.
This property is important because a convolu-
tion kernel would not be effective to distinguish
between an object and its sub-parts.
</bodyText>
<subsectionHeader confidence="0.999323">
3.2 Sub-Categorization Feature (SCF)
</subsectionHeader>
<bodyText confidence="0.999402083333333">
The above object space aims to capture all
the information between a predicate and one of
its arguments. Its main drawback is that im-
portant structural information related to inter-
argument dependencies is neglected. In or-
der to solve this problem we define the Sub-
Categorization Feature (SCF). This is the sub-
parse tree which includes the sub-categorization
frame of the target verbal predicate. For
example, Figure 3 shows the parse tree of
the sentence &amp;quot;He flushed the pan and buckled
his belt&amp;quot;. The solid line describes the SCF
of the predicate flush, i.e. Fflush whereas the
dashed line tailors the SCF of the predicate
buckle, i.e. Fbuckle. Note that SCFs are features
for predicates, (i.e. they describe predicates)
whereas PAF characterizes predicate/argument
pairs.
Once semantic representations are defined,
we need to design a kernel function to esti-
mate the similarity between our objects. As
suggested in Section 2 we can map them into
vectors in &amp;lt;n and evaluate implicitly the scalar
product among them.
</bodyText>
<subsectionHeader confidence="0.871968">
3.3 Predicate/Argument structure
Kernel (PAK)
</subsectionHeader>
<bodyText confidence="0.964745222222222">
Given the semantic objects defined in the previ-
ous section, we design a convolution kernel in a
way similar to the parse-tree kernel proposed
in (Collins and Duffy, 2002). We divide our
mapping in two steps: (1) from the semantic
structure space F (i.e. PAF or SCF objects)
to the set of all their possible sub-structures
element in Fp,a with an abuse of notation we use it to
indicate the objects themselves.
</bodyText>
<figure confidence="0.995670784615384">
NP
D N
a talk
NP
D N
NP
D N
a
D N
a talk
NP
D N
NP
D N
VP
V
delivers
a talk
V
delivers
NP
D N
VP
V
a talk
NP
D N
VP
V
NP
D N
VP
V
a
NP
D
VP
V
talk
N
a
NP
D N
VP
V
delivers
talk
NP
D N
VP
V
delivers
NP
D N
VP
V
delivers
NP
VP
V
NP
VP
V
delivers
talk
</figure>
<figureCaption confidence="0.99931">
Figure 4: All 17 valid fragments of the semantic
</figureCaption>
<bodyText confidence="0.48706">
structure associated with Arg 1 of Figure 2.
</bodyText>
<equation confidence="0.6188102">
F0 = {f
0
1, .., f
0
|F0|} and (2) from F0 to &amp;lt;|F0|.
</equation>
<bodyText confidence="0.995709722222222">
An example of features in F0 is given
in Figure 4 where the whole set of frag-
ments, F0
deliver,Arg1, of the argument structure
Fdeliver,Arg1, is shown (see also Figure 2).
It is worth noting that the allowed sub-trees
contain the entire (not partial) production rules.
For instance, the sub-tree [NP [D a]] is excluded
from the set of the Figure 4 since only a part of
the production NP D N is used in its gener-
ation. However, this constraint does not apply
to the production VP V NP PP along with the
fragment [VP [V NP]] as the subtree [VP [PP [...]]]
is not considered part of the semantic structure.
Thus, in step 1, an argument structure Fp,a is
mapped in a fragment set F 0
p,a. In step 2, this
latter is mapped into ~
</bodyText>
<equation confidence="0.953273142857143">
x = (x1, .., x|F0|) &amp;lt;|F0|,
where xi is equal to the number of times that
f
0
i occurs in F 0
p,a
2.
</equation>
<bodyText confidence="0.963445285714286">
In order to evaluate K((Fx), (Fz)) without
evaluating the feature vector ~
x and ~
z we de-
fine the indicator function Ii(n) = 1 if the sub-
structure i is rooted at node n and 0 otherwise.
It follows that i(Fx) =
</bodyText>
<equation confidence="0.926066333333333">
P
nNx
Ii(n), where Nx
is the set of the Fxs nodes. Therefore, the ker-
nel can be written as:
K((Fx), (Fz)) =
|F0|
X
i=1
(
X
nxNx
Ii(nx))(
X
nzNz
Ii(nz))
=
X
nxNx
X
nzNz
X
i
Ii(nx)Ii(nz)
</equation>
<bodyText confidence="0.961254666666667">
where Nx and Nz are the nodes in Fx and Fz, re-
spectively. In (Collins and Duffy, 2002), it has
been shown that
</bodyText>
<equation confidence="0.997239">
P
i Ii(nx)Ii(nz) = (nx, nz)
</equation>
<bodyText confidence="0.9101075">
can be computed in O(|Nx ||Nz|) by the fol-
lowing recursive relation:
</bodyText>
<equation confidence="0.4429695">
(1) if the productions at nx and nz are different
then (nx, nz) = 0;
</equation>
<page confidence="0.701157">
2
</page>
<bodyText confidence="0.875587">
A fragment can appear several times in a parse-tree,
thus each fragment occurrence is considered as a different
</bodyText>
<listItem confidence="0.710301285714286">
element in F 0
p,a.
\x0c(2) if the productions at nx and nz are the
same, and nx and nz are pre-terminals then
(nx, nz) = 1;
(3) if the productions at nx and nz are the same,
and nx and nz are not pre-terminals then
</listItem>
<equation confidence="0.9911202">
(nx, nz) =
nc(nx)
Y
j=1
(1 + (ch(nx, j), ch(nz, j))),
</equation>
<bodyText confidence="0.99740025">
where nc(nx) is the number of the children of nx
and ch(n, i) is the i-th child of the node n. Note
that as the productions are the same ch(nx, i) =
ch(nz, i).
This kind of kernel has the drawback of
assigning more weight to larger structures
while the argument type does not strictly
depend on the size of the argument (Moschitti
and Bejan, 2004). To overcome this prob-
lem we can scale the relative importance of
the tree fragments using a parameter for
the cases (2) and (3), i.e. (nx, nz) = and
</bodyText>
<equation confidence="0.997319333333333">
(nx, nz) =
Qnc(nx)
j=1 (1 + (ch(nx, j), ch(nz, j)))
</equation>
<bodyText confidence="0.994002153846154">
respectively.
It is worth noting that even if the above equa-
tions define a kernel function similar to the one
proposed in (Collins and Duffy, 2002), the sub-
structures on which it operates are different
from the parse-tree kernel. For example, Figure
4 shows that structures such as [VP [V] [NP]], [VP
[V delivers ] [NP]] and [VP [V] [NP [DT] [N]]] are
valid features, but these fragments (and many
others) are not generated by a complete produc-
tion, i.e. VP V NP PP. As a consequence they
would not be included in the parse-tree kernel
of the sentence.
</bodyText>
<subsectionHeader confidence="0.995244">
3.4 Comparison with Standard
Features
</subsectionHeader>
<bodyText confidence="0.973457909090909">
In this section we compare standard features
with the kernel based representation in order
to derive useful indications for their use:
First, PAK estimates a similarity between
two argument structures (i.e., PAF or SCF)
by counting the number of sub-structures that
are in common. As an example, the sim-
ilarity between the two structures in Figure
2, Fdelivers,Arg0 and Fdelivers,Arg1, is equal
to 1 since they have in common only the [V
delivers] substructure. Such low value de-
pends on the fact that different arguments tend
to appear in different structures.
On the contrary, if two structures differ only
for a few nodes (especially terminals or near
terminal nodes) the similarity remains quite
high. For example, if we change the tense of
the verb to deliver (Figure 2) in delivered, the
[VP [V delivers] [NP]] subtree will be trans-
formed in [VP [VBD delivered] [NP]], where the
NP is unchanged. Thus, the similarity with
the previous structure will be quite high as:
</bodyText>
<listItem confidence="0.7970656">
(1) the NP with all sub-parts will be matched
and (2) the small difference will not highly af-
fect the kernel norm and consequently the fi-
nal score. The above property also holds for
the SCF structures. For example, in Figure
</listItem>
<sectionHeader confidence="0.561972" genericHeader="method">
3, KP AK
</sectionHeader>
<bodyText confidence="0.992628416666667">
((Fflush), (Fbuckle)) is quite high as
the two verbs have the same syntactic realiza-
tion of their arguments. In general, flat features
do not possess this conservative property. For
example, the Parse Tree Path is very sensible
to small changes of parse-trees, e.g. two predi-
cates, expressed in different tenses, generate two
different Path features.
Second, some information contained in the
standard features is embedded in PAF: Phrase
Type, Predicate Word and Head Word explicitly
appear as structure fragments. For example, in
Figure 4 are shown fragments like [NP [DT] [N]] or
[NP [DT a] [N talk]] which explicitly encode the
Phrase Type feature NP for the Arg 1 in Fig-
ure 2.b. The Predicate Word is represented by
the fragment [V delivers] and the Head Word
is encoded in [N talk]. The same is not true for
SCF since it does not contain information about
a specific argument. SCF, in fact, aims to char-
acterize the predicate with respect to the overall
argument structures rather than a specific pair
&amp;lt;p, a&amp;gt;.
Third, Governing Category, Position and
Voice features are not explicitly contained in
both PAF and SCF. Nevertheless, SCF may
allow the learning algorithm to detect the ac-
tive/passive form of verbs.
Finally, from the above observations follows
that the PAF representation may be used with
PAK to classify arguments. On the contrary,
SCF lacks important information, thus, alone it
may be used only to classify verbs in syntactic
categories. This suggests that SCF should be
used in conjunction with standard features to
boost their classification performance.
</bodyText>
<sectionHeader confidence="0.988753" genericHeader="method">
4 The Experiments
</sectionHeader>
<bodyText confidence="0.999281888888889">
The aim of our experiments are twofold: On
the one hand, we study if the PAF represen-
tation produces an accuracy higher than stan-
dard features. On the other hand, we study if
SCF can be used to classify verbs according to
their syntactic realization. Both the above aims
can be carried out by combining PAF and SCF
\x0cwith the standard features. For this purpose
we adopted two ways to combine kernels3: (1)
</bodyText>
<equation confidence="0.560189">
K = K1 K2 and (2) K = K1 + K2. The re-
</equation>
<bodyText confidence="0.923680333333333">
sulting set of kernels used in the experiments is
the following:
Kpd is the polynomial kernel with degree d
over the standard features.
KP AF is obtained by using PAK function over
the PAF structures.
</bodyText>
<equation confidence="0.57977475">
KP AF +P
= KP AF
|KP AF  |+
Kpd
</equation>
<bodyText confidence="0.849711666666667">
|Kpd |, i.e. the sum be-
tween the normalized4 PAF-based kernel and
the normalized polynomial kernel.
</bodyText>
<equation confidence="0.754839666666667">
KP AF P =
KP AF Kpd
|KP AF ||Kpd|, i.e. the normalized
</equation>
<bodyText confidence="0.975321">
product between the PAF-based kernel and the
polynomial kernel.
</bodyText>
<equation confidence="0.70561925">
KSCF +P
= KSCF
|KSCF  |+
Kpd
</equation>
<bodyText confidence="0.982288666666667">
|Kpd |, i.e. the summa-
tion between the normalized SCF-based kernel
and the normalized polynomial kernel.
</bodyText>
<equation confidence="0.271352">
KSCF P =
KSCF Kpd
|KSCF ||Kpd |, i.e. the normal-
</equation>
<bodyText confidence="0.9107455">
ized product between SCF-based kernel and the
polynomial kernel.
</bodyText>
<subsectionHeader confidence="0.991382">
4.1 Corpora set-up
</subsectionHeader>
<bodyText confidence="0.971680368421053">
The above kernels were experimented over two
corpora: PropBank (www.cis.upenn.edu/ace)
along with Penn TreeBank5 2 (Marcus et al.,
1993) and FrameNet.
PropBank contains about 53,700 sentences
and a fixed split between training and test-
ing which has been used in other researches
e.g., (Gildea and Palmer, 2002; Surdeanu et al.,
2003; Hacioglu et al., 2003). In this split, Sec-
tions from 02 to 21 are used for training, section
23 for testing and sections 1 and 22 as devel-
oping set. We considered all PropBank argu-
ments6 from Arg0 to Arg9, ArgA and ArgM for
a total of 122,774 and 7,359 arguments in train-
ing and testing respectively. It is worth noting
that in the experiments we used the gold stan-
dard parsing from Penn TreeBank, thus our ker-
nel structures are derived with high precision.
For the FrameNet corpus (www.icsi.berkeley
</bodyText>
<page confidence="0.923581">
3
</page>
<bodyText confidence="0.904502333333333">
It can be proven that the resulting kernels still sat-
isfy Mercers conditions (Cristianini and Shawe-Taylor,
2000).
</bodyText>
<page confidence="0.900209">
4
</page>
<bodyText confidence="0.781459666666667">
To normalize a kernel K(~
x, ~
z) we can divide it by
</bodyText>
<equation confidence="0.753563166666667">
p
K(~
x, ~
x) K(~
z, ~
z).
</equation>
<page confidence="0.917286">
5
</page>
<bodyText confidence="0.999735">
We point out that we removed from Penn TreeBank
the function tags like SBJ and TMP as parsers usually
are not able to provide this information.
</bodyText>
<page confidence="0.991205">
6
</page>
<bodyText confidence="0.989525352941177">
We noted that only Arg0 to Arg4 and ArgM con-
tain enough training/testing data to affect the overall
performance.
.edu/framenet) we extracted all 24,558 sen-
tences from the 40 frames of Senseval 3 task
(www.senseval.org) for the Automatic Labeling
of Semantic Roles. We considered 18 of the
most frequent roles and we mapped together
those having the same name. Only verbs are se-
lected to be predicates in our evaluations. More-
over, as it does not exist a fixed split between
training and testing, we selected randomly 30%
of sentences for testing and 70% for training.
Additionally, 30% of training was used as a
validation-set. The sentences were processed us-
ing Collins parser (Collins, 1997) to generate
parse-trees automatically.
</bodyText>
<subsectionHeader confidence="0.965699">
4.2 Classification set-up
</subsectionHeader>
<bodyText confidence="0.998309217391304">
The classifier evaluations were carried out using
the SVM-light software (Joachims, 1999) avail-
able at svmlight.joachims.org with the default
polynomial kernel for standard feature evalu-
ations. To process PAF and SCF, we imple-
mented our own kernels and we used them in-
side SVM-light.
The classification performances were evalu-
ated using the f1 measure7 for single arguments
and the accuracy for the final multi-class clas-
sifier. This latter choice allows us to compare
the results with previous literature works, e.g.
(Gildea and Jurasfky, 2002; Surdeanu et al.,
2003; Hacioglu et al., 2003).
For the evaluation of SVMs, we used the de-
fault regularization parameter (e.g., C = 1 for
normalized kernels) and we tried a few cost-
factor values (i.e., j {0.1, 1, 2, 3, 4, 5}) to ad-
just the rate between Precision and Recall. We
chose parameters by evaluating SVM using Kp3
kernel over the validation-set. Both (see Sec-
tion 3.3) and parameters were evaluated in a
similar way by maximizing the performance of
</bodyText>
<equation confidence="0.6886354">
SVM using KP AF
and KSCF
|KSCF  |+
Kpd
|Kpd |respec-
</equation>
<bodyText confidence="0.998307">
tively. These parameters were adopted also for
all the other kernels.
</bodyText>
<subsectionHeader confidence="0.997641">
4.3 Kernel evaluations
</subsectionHeader>
<bodyText confidence="0.99894675">
To study the impact of our structural kernels we
firstly derived the maximal accuracy reachable
with standard features along with polynomial
kernels. The multi-class accuracies, for Prop-
Bank and FrameNet using Kpd with d = 1, .., 5,
are shown in Figure 5. We note that (a) the
highest performance is reached for d = 3, (b)
for PropBank our maximal accuracy (90.5%)
</bodyText>
<page confidence="0.980637">
7
</page>
<bodyText confidence="0.9640945">
f1 assigns equal importance to Precision P and Re-
call R, i.e. f1 = 2P R
</bodyText>
<equation confidence="0.7723025">
P +R
.
</equation>
<bodyText confidence="0.992069">
\x0cis substantially equal to the SVM performance
(88%) obtained in (Hacioglu et al., 2003) with
degree 2 and (c) the accuracy on FrameNet
(85.2%) is higher than the best result obtained
in literature, i.e. 82.0% in (Gildea and Palmer,
2002). This different outcome is due to a differ-
ent task (we classify different roles) and a differ-
ent classification algorithm. Moreover, we did
not use the Frame information which is very im-
</bodyText>
<figure confidence="0.9750465625">
portant8.
0.82
0.83
0.84
0.85
0.86
0.87
0.88
0.89
0.9
0.91
1 2 3 4 5
d
Accuracy
FrameNet
PropBank
</figure>
<figureCaption confidence="0.999838">
Figure 5: Multi-classifier accuracy according to dif-
</figureCaption>
<bodyText confidence="0.99709225">
ferent degrees of the polynomial kernel.
It is worth noting that the difference between
linear and polynomial kernel is about 3-4 per-
cent points for both PropBank and FrameNet.
This remarkable difference can be easily ex-
plained by considering the meaning of standard
features. For example, let us restrict the classi-
fication function CArg0 to the two features Voice
</bodyText>
<listItem confidence="0.746765333333333">
and Position. Without loss of generality we can
assume: (a) Voice=1 if active and 0 if passive,
and (b) Position=1 when the argument is af-
</listItem>
<bodyText confidence="0.997824578947368">
ter the predicate and 0 otherwise. To simplify
the example, we also assume that if an argu-
ment precedes the target predicate it is a sub-
ject, otherwise it is an object9. It follows that
a constituent is Arg0, i.e. CArg0 = 1, if only
one feature at a time is 1, otherwise it is not
an Arg0, i.e. CArg0 = 0. In other words, CArg0
= Position XOR Voice, which is the classical ex-
ample of a non-linear separable function that
becomes separable in a superlinear space (Cris-
tianini and Shawe-Taylor, 2000).
After it was established that the best ker-
nel for standard features is Kp3 , we carried out
all the other experiments using it in the kernel
combinations. Table 2 and 3 show the single
class (f1 measure) as well as multi-class classi-
fier (accuracy) performance for PropBank and
FrameNet respectively. Each column of the two
tables refers to a different kernel defined in the
</bodyText>
<page confidence="0.970899">
8
</page>
<bodyText confidence="0.696317">
Preliminary experiments indicate that SVMs can
reach 90% by using the frame feature.
</bodyText>
<page confidence="0.950011">
9
</page>
<bodyText confidence="0.99562">
Indeed, this is true in most part of the cases.
previous section. The overall meaning is dis-
cussed in the following points:
First, PAF alone has good performance, since
in PropBank evaluation it outperforms the lin-
ear kernel (Kp1 ), 88.7% vs. 86.7% whereas in
FrameNet, it shows a similar performance 79.5%
vs. 82.1% (compare tables with Figure 5). This
suggests that PAF generates the same informa-
tion as the standard features in a linear space.
However, when a degree greater than 1 is used
for standard features, PAF is outperformed10.
</bodyText>
<table confidence="0.999141444444444">
Args P 3
PAF PAF+P PAFP SCF+P SCFP
Arg0 90.8 88.3 90.6 90.5 94.6 94.7
Arg1 91.1 87.4 89.9 91.2 92.9 94.1
Arg2 80.0 68.5 77.5 74.7 77.4 82.0
Arg3 57.9 56.5 55.6 49.7 56.2 56.4
Arg4 70.5 68.7 71.2 62.7 69.6 71.1
ArgM 95.4 94.1 96.2 96.2 96.1 96.3
Acc. 90.5 88.7 90.2 90.4 92.4 93.2
</table>
<tableCaption confidence="0.964256">
Table 2: Evaluation of Kernels on PropBank.
</tableCaption>
<table confidence="0.991844">
Roles P 3
PAF PAF+P PAFP SCF+P SCFP
agent 92.0 88.5 91.7 91.3 93.1 93.9
cause 59.7 16.1 41.6 27.7 42.6 57.3
degree 74.9 68.6 71.4 57.8 68.5 60.9
depict. 52.6 29.7 51.0 28.6 46.8 37.6
durat. 45.8 52.1 40.9 29.0 31.8 41.8
goal 85.9 78.6 85.3 82.8 84.0 85.3
instr. 67.9 46.8 62.8 55.8 59.6 64.1
mann. 81.0 81.9 81.2 78.6 77.8 77.8
Acc. 85.2 79.5 84.6 81.6 83.8 84.2
18 roles
</table>
<tableCaption confidence="0.775384">
Table 3: Evaluation of Kernels on FrameNet se-
mantic roles.
</tableCaption>
<bodyText confidence="0.992133111111111">
Second, SCF improves the polynomial kernel
(d = 3), i.e. the current state-of-the-art, of
about 3 percent points on PropBank (column
SCFP). This suggests that (a) PAK can mea-
sure the similarity between two SCF structures
and (b) the sub-categorization information pro-
vides effective clues about the expected argu-
ment type. The interesting consequence is that
SCF together with PAK seems suitable to au-
tomatically cluster different verbs that have the
same syntactic realization. We note also that to
fully exploit the SCF information it is necessary
to use a kernel product (K1 K2) combination
rather than the sum (K1 + K2), e.g. column
SCF+P.
Finally, the FrameNet results are completely
different. No kernel combinations with both
PAF and SCF produce an improvement. On
</bodyText>
<page confidence="0.989866">
10
</page>
<bodyText confidence="0.991956807692308">
Unfortunately the use of a polynomial kernel on top
the tree fragments to generate the XOR functions seems
not successful.
\x0cthe contrary, the performance decreases, sug-
gesting that the classifier is confused by this
syntactic information. The main reason for the
different outcomes is that PropBank arguments
are different from semantic roles as they are
an intermediate level between syntax and se-
mantic, i.e. they are nearer to grammatical
functions. In fact, in PropBank arguments are
annotated consistently with syntactic alterna-
tions (see the Annotation guidelines for Prop-
Bank at www.cis.upenn.edu/ace). On the con-
trary FrameNet roles represent the final seman-
tic product and they are assigned according to
semantic considerations rather than syntactic
aspects. For example, Cause and Agent seman-
tic roles have identical syntactic realizations.
This prevents SCF to distinguish between them.
Another minor reason may be the use of auto-
matic parse-trees to extract PAF and SCF, even
if preliminary experiments on automatic seman-
tic shallow parsing of PropBank have shown no
important differences versus semantic parsing
which adopts Gold Standard parse-trees.
</bodyText>
<sectionHeader confidence="0.999241" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.9992028125">
In this paper, we have experimented with
SVMs using the two novel convolution kernels
PAF and SCF which are designed for the se-
mantic structures derived from PropBank and
FrameNet corpora. Moreover, we have com-
bined them with the polynomial kernel of stan-
dard features. The results have shown that:
First, SVMs using the above kernels are ap-
pealing for semantically parsing both corpora.
Second, PAF and SCF can be used to improve
automatic classification of PropBank arguments
as they provide clues about the predicate argu-
ment structure of the target verb. For example,
SCF improves (a) the classification state-of-the-
art (i.e. the polynomial kernel) of about 3 per-
cent points and (b) the best literature result of
about 5 percent points.
Third, additional work is needed to design
kernels suitable to learn the deep semantic con-
tained in FrameNet as it seems not sensible to
both PAF and SCF information.
Finally, an analysis of SVMs using poly-
nomial kernels over standard features has ex-
plained why they largely outperform linear clas-
sifiers based-on standard features.
In the future we plan to design other struc-
tures and combine them with SCF, PAF and
standard features. In this vision the learning
will be carried out on a set of structural features
instead of a set of flat features. Other studies
may relate to the use of SCF to generate verb
clusters.
</bodyText>
<sectionHeader confidence="0.98211" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.607739142857143">
This research has been sponsored by the ARDA
AQUAINT program. In addition, I would like to
thank Professor Sanda Harabagiu for her advice,
Adrian Cosmin Bejan for implementing the feature
extractor and Paul Morarescu for processing the
FrameNet data. Many thanks to the anonymous re-
viewers for their invaluable suggestions.
</bodyText>
<sectionHeader confidence="0.836129" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996223104166667">
Michael Collins and Nigel Duffy. 2002. New ranking
algorithms for parsing and tagging: Kernels over
discrete structures, and the voted perceptron. In
proceeding of ACL-02.
Michael Collins. 1997. Three generative, lexicalized
models for statistical parsing. In proceedings of
the ACL-97, pages 1623, Somerset, New Jersey.
Nello Cristianini and John Shawe-Taylor. 2000. An
introduction to Support Vector Machines. Cam-
bridge University Press.
Charles J. Fillmore. 1982. Frame semantics. In Lin-
guistics in the Morning Calm, pages 111137.
Daniel Gildea and Daniel Jurasfky. 2002. Auto-
matic labeling of semantic roles. Computational
Linguistic.
Daniel Gildea and Martha Palmer. 2002. The neces-
sity of parsing for predicate argument recognition.
In proceedings of ACL-02, Philadelphia, PA.
R. Jackendoff. 1990. Semantic Structures, Current
Studies in Linguistics series. Cambridge, Mas-
sachusetts: The MIT Press.
T. Joachims. 1999. Making large-scale SVM learn-
ing practical. In Advances in Kernel Methods -
Support Vector Learning.
Paul Kingsbury and Martha Palmer. 2002. From
treebank to propbank. In proceedings of LREC-
02, Las Palmas, Spain.
M. P. Marcus, B. Santorini, and M. A.
Marcinkiewicz. 1993. Building a large anno-
tated corpus of english: The penn treebank.
Computational Linguistics.
Alessandro Moschitti and Cosmin Adrian Bejan.
2004. A semantic kernel for predicate argu-
ment classification. In proceedings of CoNLL-04,
Boston, USA.
Kadri Hacioglu, Sameer Pradhan, Wayne Ward,
James H. Martin, and Daniel Jurafsky. 2003.
Shallow Semantic Parsing Using Support Vector
Machines. TR-CSLR-2003-03, University of Col-
orado.
Mihai Surdeanu, Sanda M. Harabagiu, John
Williams, and John Aarseth. 2003. Using
predicate-argument structures for information ex-
traction. In proceedings of ACL-03, Sapporo,
Japan.
V. Vapnik. 1995. The Nature of Statistical Learning
Theory. Springer-Verlag New York, Inc.
\x0c&apos;
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.894961">
<title confidence="0.999463">b&apos;A Study on Convolution Kernels for Shallow Semantic Parsing</title>
<author confidence="0.999908">Alessandro Moschitti</author>
<affiliation confidence="0.9999445">University of Texas at Dallas Human Language Technology Research Institute</affiliation>
<address confidence="0.998416">Richardson, TX 75083-0688, USA</address>
<email confidence="0.999671">alessandro.moschitti@utdallas.edu</email>
<abstract confidence="0.9929946">In this paper we have designed and experimented novel convolution kernels for automatic classification of predicate arguments. Their main property is the ability to process structured representations. Support Vector Machines (SVMs), using a combination of such kernels and the flat feature kernel, classify Prop- Bank predicate arguments with accuracy higher than the current argument classification stateof-the-art. Additionally, experiments on FrameNet data have shown that SVMs are appealing for the classification of semantic roles even if the proposed kernels do not produce any improvement.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Nigel Duffy</author>
</authors>
<title>New ranking algorithms for parsing and tagging: Kernels over discrete structures, and the voted perceptron. In proceeding of ACL-02.</title>
<date>2002</date>
<contexts>
<context position="13578" citStr="Collins and Duffy, 2002" startWordPosition="2284" endWordPosition="2287"> the predicate buckle, i.e. Fbuckle. Note that SCFs are features for predicates, (i.e. they describe predicates) whereas PAF characterizes predicate/argument pairs. Once semantic representations are defined, we need to design a kernel function to estimate the similarity between our objects. As suggested in Section 2 we can map them into vectors in &amp;lt;n and evaluate implicitly the scalar product among them. 3.3 Predicate/Argument structure Kernel (PAK) Given the semantic objects defined in the previous section, we design a convolution kernel in a way similar to the parse-tree kernel proposed in (Collins and Duffy, 2002). We divide our mapping in two steps: (1) from the semantic structure space F (i.e. PAF or SCF objects) to the set of all their possible sub-structures element in Fp,a with an abuse of notation we use it to indicate the objects themselves. NP D N a talk NP D N NP D N a D N a talk NP D N NP D N VP V delivers a talk V delivers NP D N VP V a talk NP D N VP V NP D N VP V a NP D VP V talk N a NP D N VP V delivers talk NP D N VP V delivers NP D N VP V delivers NP VP V NP VP V delivers talk Figure 4: All 17 valid fragments of the semantic structure associated with Arg 1 of Figure 2. F0 = {f 0 1, .., </context>
<context position="15521" citStr="Collins and Duffy, 2002" startWordPosition="2705" endWordPosition="2708">. In step 2, this latter is mapped into ~ x = (x1, .., x|F0|) &amp;lt;|F0|, where xi is equal to the number of times that f 0 i occurs in F 0 p,a 2. In order to evaluate K((Fx), (Fz)) without evaluating the feature vector ~ x and ~ z we define the indicator function Ii(n) = 1 if the substructure i is rooted at node n and 0 otherwise. It follows that i(Fx) = P nNx Ii(n), where Nx is the set of the Fxs nodes. Therefore, the kernel can be written as: K((Fx), (Fz)) = |F0| X i=1 ( X nxNx Ii(nx))( X nzNz Ii(nz)) = X nxNx X nzNz X i Ii(nx)Ii(nz) where Nx and Nz are the nodes in Fx and Fz, respectively. In (Collins and Duffy, 2002), it has been shown that P i Ii(nx)Ii(nz) = (nx, nz) can be computed in O(|Nx ||Nz|) by the following recursive relation: (1) if the productions at nx and nz are different then (nx, nz) = 0; 2 A fragment can appear several times in a parse-tree, thus each fragment occurrence is considered as a different element in F 0 p,a. \x0c(2) if the productions at nx and nz are the same, and nx and nz are pre-terminals then (nx, nz) = 1; (3) if the productions at nx and nz are the same, and nx and nz are not pre-terminals then (nx, nz) = nc(nx) Y j=1 (1 + (ch(nx, j), ch(nz, j))), where nc(nx) is the numbe</context>
<context position="16793" citStr="Collins and Duffy, 2002" startWordPosition="2952" endWordPosition="2955"> child of the node n. Note that as the productions are the same ch(nx, i) = ch(nz, i). This kind of kernel has the drawback of assigning more weight to larger structures while the argument type does not strictly depend on the size of the argument (Moschitti and Bejan, 2004). To overcome this problem we can scale the relative importance of the tree fragments using a parameter for the cases (2) and (3), i.e. (nx, nz) = and (nx, nz) = Qnc(nx) j=1 (1 + (ch(nx, j), ch(nz, j))) respectively. It is worth noting that even if the above equations define a kernel function similar to the one proposed in (Collins and Duffy, 2002), the substructures on which it operates are different from the parse-tree kernel. For example, Figure 4 shows that structures such as [VP [V] [NP]], [VP [V delivers ] [NP]] and [VP [V] [NP [DT] [N]]] are valid features, but these fragments (and many others) are not generated by a complete production, i.e. VP V NP PP. As a consequence they would not be included in the parse-tree kernel of the sentence. 3.4 Comparison with Standard Features In this section we compare standard features with the kernel based representation in order to derive useful indications for their use: First, PAK estimates </context>
</contexts>
<marker>Collins, Duffy, 2002</marker>
<rawString>Michael Collins and Nigel Duffy. 2002. New ranking algorithms for parsing and tagging: Kernels over discrete structures, and the voted perceptron. In proceeding of ACL-02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Three generative, lexicalized models for statistical parsing.</title>
<date>1997</date>
<booktitle>In proceedings of the ACL-97,</booktitle>
<pages>1623</pages>
<location>Somerset, New Jersey.</location>
<contexts>
<context position="23077" citStr="Collins, 1997" startWordPosition="4039" endWordPosition="4040">o affect the overall performance. .edu/framenet) we extracted all 24,558 sentences from the 40 frames of Senseval 3 task (www.senseval.org) for the Automatic Labeling of Semantic Roles. We considered 18 of the most frequent roles and we mapped together those having the same name. Only verbs are selected to be predicates in our evaluations. Moreover, as it does not exist a fixed split between training and testing, we selected randomly 30% of sentences for testing and 70% for training. Additionally, 30% of training was used as a validation-set. The sentences were processed using Collins parser (Collins, 1997) to generate parse-trees automatically. 4.2 Classification set-up The classifier evaluations were carried out using the SVM-light software (Joachims, 1999) available at svmlight.joachims.org with the default polynomial kernel for standard feature evaluations. To process PAF and SCF, we implemented our own kernels and we used them inside SVM-light. The classification performances were evaluated using the f1 measure7 for single arguments and the accuracy for the final multi-class classifier. This latter choice allows us to compare the results with previous literature works, e.g. (Gildea and Jura</context>
</contexts>
<marker>Collins, 1997</marker>
<rawString>Michael Collins. 1997. Three generative, lexicalized models for statistical parsing. In proceedings of the ACL-97, pages 1623, Somerset, New Jersey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nello Cristianini</author>
<author>John Shawe-Taylor</author>
</authors>
<title>An introduction to Support Vector Machines.</title>
<date>2000</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="22151" citStr="Cristianini and Shawe-Taylor, 2000" startWordPosition="3871" endWordPosition="3874">eanu et al., 2003; Hacioglu et al., 2003). In this split, Sections from 02 to 21 are used for training, section 23 for testing and sections 1 and 22 as developing set. We considered all PropBank arguments6 from Arg0 to Arg9, ArgA and ArgM for a total of 122,774 and 7,359 arguments in training and testing respectively. It is worth noting that in the experiments we used the gold standard parsing from Penn TreeBank, thus our kernel structures are derived with high precision. For the FrameNet corpus (www.icsi.berkeley 3 It can be proven that the resulting kernels still satisfy Mercers conditions (Cristianini and Shawe-Taylor, 2000). 4 To normalize a kernel K(~ x, ~ z) we can divide it by p K(~ x, ~ x) K(~ z, ~ z). 5 We point out that we removed from Penn TreeBank the function tags like SBJ and TMP as parsers usually are not able to provide this information. 6 We noted that only Arg0 to Arg4 and ArgM contain enough training/testing data to affect the overall performance. .edu/framenet) we extracted all 24,558 sentences from the 40 frames of Senseval 3 task (www.senseval.org) for the Automatic Labeling of Semantic Roles. We considered 18 of the most frequent roles and we mapped together those having the same name. Only ve</context>
<context position="26315" citStr="Cristianini and Shawe-Taylor, 2000" startWordPosition="4593" endWordPosition="4597">nd Position. Without loss of generality we can assume: (a) Voice=1 if active and 0 if passive, and (b) Position=1 when the argument is after the predicate and 0 otherwise. To simplify the example, we also assume that if an argument precedes the target predicate it is a subject, otherwise it is an object9. It follows that a constituent is Arg0, i.e. CArg0 = 1, if only one feature at a time is 1, otherwise it is not an Arg0, i.e. CArg0 = 0. In other words, CArg0 = Position XOR Voice, which is the classical example of a non-linear separable function that becomes separable in a superlinear space (Cristianini and Shawe-Taylor, 2000). After it was established that the best kernel for standard features is Kp3 , we carried out all the other experiments using it in the kernel combinations. Table 2 and 3 show the single class (f1 measure) as well as multi-class classifier (accuracy) performance for PropBank and FrameNet respectively. Each column of the two tables refers to a different kernel defined in the 8 Preliminary experiments indicate that SVMs can reach 90% by using the frame feature. 9 Indeed, this is true in most part of the cases. previous section. The overall meaning is discussed in the following points: First, PAF</context>
</contexts>
<marker>Cristianini, Shawe-Taylor, 2000</marker>
<rawString>Nello Cristianini and John Shawe-Taylor. 2000. An introduction to Support Vector Machines. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles J Fillmore</author>
</authors>
<title>Frame semantics.</title>
<date>1982</date>
<booktitle>In Linguistics in the Morning Calm,</booktitle>
<pages>111137</pages>
<contexts>
<context position="1529" citStr="Fillmore, 1982" startWordPosition="218" endWordPosition="219"> information in natural language texts is connected to syntactic structures. Hence, to deal with natural language semantics, the learning algorithm should be able to represent and process structured data. The classical solution adopted for such tasks is to convert syntax structures into flat feature representations which are suitable for a given learning model. The main drawback is that structures may not be properly represented by flat features. In particular, these problems affect the processing of predicate argument structures annotated in PropBank (Kingsbury and Palmer, 2002) or FrameNet (Fillmore, 1982). Figure 1 shows an example of a predicate annotation in PropBank for the sentence: &amp;quot;Paul gives a lecture in Rome&amp;quot;. A predicate may be a verb or a noun or an adjective and most of the time Arg 0 is the logical subject, Arg 1 is the logical object and ArgM may indicate locations, as in our example. FrameNet also describes predicate/argument structures but for this purpose it uses richer semantic structures called frames. These latter are schematic representations of situations involving various participants, properties and roles in which a word may be typically used. Frame elements or semantic </context>
</contexts>
<marker>Fillmore, 1982</marker>
<rawString>Charles J. Fillmore. 1982. Frame semantics. In Linguistics in the Morning Calm, pages 111137.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gildea</author>
<author>Daniel Jurasfky</author>
</authors>
<title>Automatic labeling of semantic roles.</title>
<date>2002</date>
<journal>Computational Linguistic.</journal>
<contexts>
<context position="2535" citStr="Gildea and Jurasfky, 2002" startWordPosition="385" endWordPosition="388"> richer semantic structures called frames. These latter are schematic representations of situations involving various participants, properties and roles in which a word may be typically used. Frame elements or semantic roles are arguments of predicates called target words. In FrameNet, the argument names are local to a particular frame. Predicate Arg. 0 Arg. M S N NP D N VP V Paul in gives a lecture PP IN N Rome Arg. 1 Figure 1: A predicate argument structure in a parse-tree representation. Several machine learning approaches for argument identification and classification have been developed (Gildea and Jurasfky, 2002; Gildea and Palmer, 2002; Surdeanu et al., 2003; Hacioglu et al., 2003). Their common characteristic is the adoption of feature spaces that model predicate-argument structures in a flat representation. On the contrary, convolution kernels aim to capture structural information in term of sub-structures, providing a viable alternative to flat features. In this paper, we select portions of syntactic trees, which include predicate/argument salient sub-structures, to define convolution kernels for the task of predicate argument classification. In particular, our kernels aim to (a) represent the re</context>
<context position="7341" citStr="Gildea and Jurasfky, 2002" startWordPosition="1190" endWordPosition="1193">r by a verb phrase, e.g. the NP associated with Arg1 is dominated by a VP. - Predicate Word: This feature consists of two components: (1) the word itself, e.g. gives for all arguments; and (2) the lemma which represents the verb normalized to lower case and infinitive form, e.g. give for all arguments. Table 1: Standard features extracted from the parse-tree in Figure 1. 2.1 Standard feature space The discovery of relevant features is, as usual, a complex task, nevertheless, there is a common consensus on the basic features that should be adopted. These standard features, firstly proposed in (Gildea and Jurasfky, 2002), refer to a flat information derived from parse trees, i.e. Phrase Type, Predicate Word, Head Word, Governing Category, Position and Voice. Table 1 presents the standard features and exemplifies how they are extracted from the parse tree in Figure 1. For example, the Parse Tree Path feature represents the path in the parse-tree between a predicate node and one of its argument nodes. It is expressed as a sequence of nonterminal labels linked by direction symbols (up or down), e.g. in Figure 1, VVPNP is the path between the predicate to give and the argument 1, a lecture. Two pairs &amp;lt;p1, a1&amp;gt; and</context>
<context position="23687" citStr="Gildea and Jurasfky, 2002" startWordPosition="4128" endWordPosition="4131">(Collins, 1997) to generate parse-trees automatically. 4.2 Classification set-up The classifier evaluations were carried out using the SVM-light software (Joachims, 1999) available at svmlight.joachims.org with the default polynomial kernel for standard feature evaluations. To process PAF and SCF, we implemented our own kernels and we used them inside SVM-light. The classification performances were evaluated using the f1 measure7 for single arguments and the accuracy for the final multi-class classifier. This latter choice allows us to compare the results with previous literature works, e.g. (Gildea and Jurasfky, 2002; Surdeanu et al., 2003; Hacioglu et al., 2003). For the evaluation of SVMs, we used the default regularization parameter (e.g., C = 1 for normalized kernels) and we tried a few costfactor values (i.e., j {0.1, 1, 2, 3, 4, 5}) to adjust the rate between Precision and Recall. We chose parameters by evaluating SVM using Kp3 kernel over the validation-set. Both (see Section 3.3) and parameters were evaluated in a similar way by maximizing the performance of SVM using KP AF and KSCF |KSCF |+ Kpd |Kpd |respectively. These parameters were adopted also for all the other kernels. 4.3 Kernel evaluation</context>
</contexts>
<marker>Gildea, Jurasfky, 2002</marker>
<rawString>Daniel Gildea and Daniel Jurasfky. 2002. Automatic labeling of semantic roles. Computational Linguistic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gildea</author>
<author>Martha Palmer</author>
</authors>
<title>The necessity of parsing for predicate argument recognition.</title>
<date>2002</date>
<booktitle>In proceedings of ACL-02,</booktitle>
<location>Philadelphia, PA.</location>
<contexts>
<context position="2560" citStr="Gildea and Palmer, 2002" startWordPosition="389" endWordPosition="392"> called frames. These latter are schematic representations of situations involving various participants, properties and roles in which a word may be typically used. Frame elements or semantic roles are arguments of predicates called target words. In FrameNet, the argument names are local to a particular frame. Predicate Arg. 0 Arg. M S N NP D N VP V Paul in gives a lecture PP IN N Rome Arg. 1 Figure 1: A predicate argument structure in a parse-tree representation. Several machine learning approaches for argument identification and classification have been developed (Gildea and Jurasfky, 2002; Gildea and Palmer, 2002; Surdeanu et al., 2003; Hacioglu et al., 2003). Their common characteristic is the adoption of feature spaces that model predicate-argument structures in a flat representation. On the contrary, convolution kernels aim to capture structural information in term of sub-structures, providing a viable alternative to flat features. In this paper, we select portions of syntactic trees, which include predicate/argument salient sub-structures, to define convolution kernels for the task of predicate argument classification. In particular, our kernels aim to (a) represent the relation between predicate </context>
<context position="21510" citStr="Gildea and Palmer, 2002" startWordPosition="3759" endWordPosition="3762"> the PAF-based kernel and the polynomial kernel. KSCF +P = KSCF |KSCF |+ Kpd |Kpd |, i.e. the summation between the normalized SCF-based kernel and the normalized polynomial kernel. KSCF P = KSCF Kpd |KSCF ||Kpd |, i.e. the normalized product between SCF-based kernel and the polynomial kernel. 4.1 Corpora set-up The above kernels were experimented over two corpora: PropBank (www.cis.upenn.edu/ace) along with Penn TreeBank5 2 (Marcus et al., 1993) and FrameNet. PropBank contains about 53,700 sentences and a fixed split between training and testing which has been used in other researches e.g., (Gildea and Palmer, 2002; Surdeanu et al., 2003; Hacioglu et al., 2003). In this split, Sections from 02 to 21 are used for training, section 23 for testing and sections 1 and 22 as developing set. We considered all PropBank arguments6 from Arg0 to Arg9, ArgA and ArgM for a total of 122,774 and 7,359 arguments in training and testing respectively. It is worth noting that in the experiments we used the gold standard parsing from Penn TreeBank, thus our kernel structures are derived with high precision. For the FrameNet corpus (www.icsi.berkeley 3 It can be proven that the resulting kernels still satisfy Mercers condit</context>
<context position="24976" citStr="Gildea and Palmer, 2002" startWordPosition="4358" endWordPosition="4361">d the maximal accuracy reachable with standard features along with polynomial kernels. The multi-class accuracies, for PropBank and FrameNet using Kpd with d = 1, .., 5, are shown in Figure 5. We note that (a) the highest performance is reached for d = 3, (b) for PropBank our maximal accuracy (90.5%) 7 f1 assigns equal importance to Precision P and Recall R, i.e. f1 = 2P R P +R . \x0cis substantially equal to the SVM performance (88%) obtained in (Hacioglu et al., 2003) with degree 2 and (c) the accuracy on FrameNet (85.2%) is higher than the best result obtained in literature, i.e. 82.0% in (Gildea and Palmer, 2002). This different outcome is due to a different task (we classify different roles) and a different classification algorithm. Moreover, we did not use the Frame information which is very important8. 0.82 0.83 0.84 0.85 0.86 0.87 0.88 0.89 0.9 0.91 1 2 3 4 5 d Accuracy FrameNet PropBank Figure 5: Multi-classifier accuracy according to different degrees of the polynomial kernel. It is worth noting that the difference between linear and polynomial kernel is about 3-4 percent points for both PropBank and FrameNet. This remarkable difference can be easily explained by considering the meaning of stand</context>
</contexts>
<marker>Gildea, Palmer, 2002</marker>
<rawString>Daniel Gildea and Martha Palmer. 2002. The necessity of parsing for predicate argument recognition. In proceedings of ACL-02, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Jackendoff</author>
</authors>
<title>Semantic Structures, Current Studies in Linguistics series.</title>
<date>1990</date>
<publisher>The MIT Press.</publisher>
<location>Cambridge, Massachusetts:</location>
<contexts>
<context position="894" citStr="Jackendoff, 1990" startWordPosition="122" endWordPosition="123">ed novel convolution kernels for automatic classification of predicate arguments. Their main property is the ability to process structured representations. Support Vector Machines (SVMs), using a combination of such kernels and the flat feature kernel, classify PropBank predicate arguments with accuracy higher than the current argument classification stateof-the-art. Additionally, experiments on FrameNet data have shown that SVMs are appealing for the classification of semantic roles even if the proposed kernels do not produce any improvement. 1 Introduction Several linguistic theories, e.g. (Jackendoff, 1990) claim that semantic information in natural language texts is connected to syntactic structures. Hence, to deal with natural language semantics, the learning algorithm should be able to represent and process structured data. The classical solution adopted for such tasks is to convert syntax structures into flat feature representations which are suitable for a given learning model. The main drawback is that structures may not be properly represented by flat features. In particular, these problems affect the processing of predicate argument structures annotated in PropBank (Kingsbury and Palmer,</context>
</contexts>
<marker>Jackendoff, 1990</marker>
<rawString>R. Jackendoff. 1990. Semantic Structures, Current Studies in Linguistics series. Cambridge, Massachusetts: The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Joachims</author>
</authors>
<title>Making large-scale SVM learning practical.</title>
<date>1999</date>
<booktitle>In Advances in Kernel Methods -Support Vector Learning.</booktitle>
<contexts>
<context position="23232" citStr="Joachims, 1999" startWordPosition="4058" endWordPosition="4059">tic Labeling of Semantic Roles. We considered 18 of the most frequent roles and we mapped together those having the same name. Only verbs are selected to be predicates in our evaluations. Moreover, as it does not exist a fixed split between training and testing, we selected randomly 30% of sentences for testing and 70% for training. Additionally, 30% of training was used as a validation-set. The sentences were processed using Collins parser (Collins, 1997) to generate parse-trees automatically. 4.2 Classification set-up The classifier evaluations were carried out using the SVM-light software (Joachims, 1999) available at svmlight.joachims.org with the default polynomial kernel for standard feature evaluations. To process PAF and SCF, we implemented our own kernels and we used them inside SVM-light. The classification performances were evaluated using the f1 measure7 for single arguments and the accuracy for the final multi-class classifier. This latter choice allows us to compare the results with previous literature works, e.g. (Gildea and Jurasfky, 2002; Surdeanu et al., 2003; Hacioglu et al., 2003). For the evaluation of SVMs, we used the default regularization parameter (e.g., C = 1 for normal</context>
</contexts>
<marker>Joachims, 1999</marker>
<rawString>T. Joachims. 1999. Making large-scale SVM learning practical. In Advances in Kernel Methods -Support Vector Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Kingsbury</author>
<author>Martha Palmer</author>
</authors>
<title>From treebank to propbank.</title>
<date>2002</date>
<booktitle>In proceedings of LREC02, Las Palmas,</booktitle>
<contexts>
<context position="1500" citStr="Kingsbury and Palmer, 2002" startWordPosition="212" endWordPosition="215">g. (Jackendoff, 1990) claim that semantic information in natural language texts is connected to syntactic structures. Hence, to deal with natural language semantics, the learning algorithm should be able to represent and process structured data. The classical solution adopted for such tasks is to convert syntax structures into flat feature representations which are suitable for a given learning model. The main drawback is that structures may not be properly represented by flat features. In particular, these problems affect the processing of predicate argument structures annotated in PropBank (Kingsbury and Palmer, 2002) or FrameNet (Fillmore, 1982). Figure 1 shows an example of a predicate annotation in PropBank for the sentence: &amp;quot;Paul gives a lecture in Rome&amp;quot;. A predicate may be a verb or a noun or an adjective and most of the time Arg 0 is the logical subject, Arg 1 is the logical object and ArgM may indicate locations, as in our example. FrameNet also describes predicate/argument structures but for this purpose it uses richer semantic structures called frames. These latter are schematic representations of situations involving various participants, properties and roles in which a word may be typically used</context>
</contexts>
<marker>Kingsbury, Palmer, 2002</marker>
<rawString>Paul Kingsbury and Martha Palmer. 2002. From treebank to propbank. In proceedings of LREC02, Las Palmas, Spain. M. P. Marcus, B. Santorini, and M. A.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of english: The penn treebank. Computational Linguistics.</title>
<date>1993</date>
<marker>Marcinkiewicz, 1993</marker>
<rawString>Marcinkiewicz. 1993. Building a large annotated corpus of english: The penn treebank. Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
<author>Cosmin Adrian Bejan</author>
</authors>
<title>A semantic kernel for predicate argument classification.</title>
<date>2004</date>
<booktitle>In proceedings of CoNLL-04,</booktitle>
<location>Boston, USA.</location>
<contexts>
<context position="16443" citStr="Moschitti and Bejan, 2004" startWordPosition="2886" endWordPosition="2889">ifferent element in F 0 p,a. \x0c(2) if the productions at nx and nz are the same, and nx and nz are pre-terminals then (nx, nz) = 1; (3) if the productions at nx and nz are the same, and nx and nz are not pre-terminals then (nx, nz) = nc(nx) Y j=1 (1 + (ch(nx, j), ch(nz, j))), where nc(nx) is the number of the children of nx and ch(n, i) is the i-th child of the node n. Note that as the productions are the same ch(nx, i) = ch(nz, i). This kind of kernel has the drawback of assigning more weight to larger structures while the argument type does not strictly depend on the size of the argument (Moschitti and Bejan, 2004). To overcome this problem we can scale the relative importance of the tree fragments using a parameter for the cases (2) and (3), i.e. (nx, nz) = and (nx, nz) = Qnc(nx) j=1 (1 + (ch(nx, j), ch(nz, j))) respectively. It is worth noting that even if the above equations define a kernel function similar to the one proposed in (Collins and Duffy, 2002), the substructures on which it operates are different from the parse-tree kernel. For example, Figure 4 shows that structures such as [VP [V] [NP]], [VP [V delivers ] [NP]] and [VP [V] [NP [DT] [N]]] are valid features, but these fragments (and many</context>
</contexts>
<marker>Moschitti, Bejan, 2004</marker>
<rawString>Alessandro Moschitti and Cosmin Adrian Bejan. 2004. A semantic kernel for predicate argument classification. In proceedings of CoNLL-04, Boston, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kadri Hacioglu</author>
<author>Sameer Pradhan</author>
<author>Wayne Ward</author>
<author>James H Martin</author>
<author>Daniel Jurafsky</author>
</authors>
<date>2003</date>
<contexts>
<context position="2607" citStr="Hacioglu et al., 2003" startWordPosition="397" endWordPosition="401">sentations of situations involving various participants, properties and roles in which a word may be typically used. Frame elements or semantic roles are arguments of predicates called target words. In FrameNet, the argument names are local to a particular frame. Predicate Arg. 0 Arg. M S N NP D N VP V Paul in gives a lecture PP IN N Rome Arg. 1 Figure 1: A predicate argument structure in a parse-tree representation. Several machine learning approaches for argument identification and classification have been developed (Gildea and Jurasfky, 2002; Gildea and Palmer, 2002; Surdeanu et al., 2003; Hacioglu et al., 2003). Their common characteristic is the adoption of feature spaces that model predicate-argument structures in a flat representation. On the contrary, convolution kernels aim to capture structural information in term of sub-structures, providing a viable alternative to flat features. In this paper, we select portions of syntactic trees, which include predicate/argument salient sub-structures, to define convolution kernels for the task of predicate argument classification. In particular, our kernels aim to (a) represent the relation between predicate and one of its arguments and (b) to capture the</context>
<context position="5540" citStr="Hacioglu et al., 2003" startWordPosition="884" endWordPosition="888"> in T (negative examples). For example, in Figure 1, for each combination of the predicate give with the nodes N, S, VP, V, NP, PP, D or IN the instances Fgive,a are generated. In case the node a exactly covers Paul, a lecture or in Rome, it will be a positive instance otherwise it will be a negative one, e.g. Fgive,IN. To learn the argument classifiers the T + set can be re-organized as positive T + argi and negative T argi examples for each argument i. In this way, an individual ONE-vs-ALL classifier for each argument i can be trained. We adopted this solution as it is simple and effective (Hacioglu et al., 2003). In the classification phase, given a sentence of the test-set, all its Fp,a are generated and classified by each individual classifier. As a final decision, we select the argument associated with the maximum value among the scores provided by the SVMs, i.e. argmaxiS Ci, where S is the target set of arguments. - Phrase Type: This feature indicates the syntactic type of the phrase labeled as a predicate argument, e.g. NP for Arg1. - Parse Tree Path: This feature contains the path in the parse tree between the predicate and the argument phrase, expressed as a sequence of nonterminal labels link</context>
<context position="21557" citStr="Hacioglu et al., 2003" startWordPosition="3767" endWordPosition="3770"> KSCF +P = KSCF |KSCF |+ Kpd |Kpd |, i.e. the summation between the normalized SCF-based kernel and the normalized polynomial kernel. KSCF P = KSCF Kpd |KSCF ||Kpd |, i.e. the normalized product between SCF-based kernel and the polynomial kernel. 4.1 Corpora set-up The above kernels were experimented over two corpora: PropBank (www.cis.upenn.edu/ace) along with Penn TreeBank5 2 (Marcus et al., 1993) and FrameNet. PropBank contains about 53,700 sentences and a fixed split between training and testing which has been used in other researches e.g., (Gildea and Palmer, 2002; Surdeanu et al., 2003; Hacioglu et al., 2003). In this split, Sections from 02 to 21 are used for training, section 23 for testing and sections 1 and 22 as developing set. We considered all PropBank arguments6 from Arg0 to Arg9, ArgA and ArgM for a total of 122,774 and 7,359 arguments in training and testing respectively. It is worth noting that in the experiments we used the gold standard parsing from Penn TreeBank, thus our kernel structures are derived with high precision. For the FrameNet corpus (www.icsi.berkeley 3 It can be proven that the resulting kernels still satisfy Mercers conditions (Cristianini and Shawe-Taylor, 2000). 4 To</context>
<context position="23734" citStr="Hacioglu et al., 2003" startWordPosition="4136" endWordPosition="4139">lly. 4.2 Classification set-up The classifier evaluations were carried out using the SVM-light software (Joachims, 1999) available at svmlight.joachims.org with the default polynomial kernel for standard feature evaluations. To process PAF and SCF, we implemented our own kernels and we used them inside SVM-light. The classification performances were evaluated using the f1 measure7 for single arguments and the accuracy for the final multi-class classifier. This latter choice allows us to compare the results with previous literature works, e.g. (Gildea and Jurasfky, 2002; Surdeanu et al., 2003; Hacioglu et al., 2003). For the evaluation of SVMs, we used the default regularization parameter (e.g., C = 1 for normalized kernels) and we tried a few costfactor values (i.e., j {0.1, 1, 2, 3, 4, 5}) to adjust the rate between Precision and Recall. We chose parameters by evaluating SVM using Kp3 kernel over the validation-set. Both (see Section 3.3) and parameters were evaluated in a similar way by maximizing the performance of SVM using KP AF and KSCF |KSCF |+ Kpd |Kpd |respectively. These parameters were adopted also for all the other kernels. 4.3 Kernel evaluations To study the impact of our structural kernels</context>
</contexts>
<marker>Hacioglu, Pradhan, Ward, Martin, Jurafsky, 2003</marker>
<rawString>Kadri Hacioglu, Sameer Pradhan, Wayne Ward, James H. Martin, and Daniel Jurafsky. 2003.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Shallow</author>
</authors>
<title>Semantic Parsing Using Support Vector Machines.</title>
<tech>TR-CSLR-2003-03,</tech>
<institution>University of Colorado.</institution>
<marker>Shallow, </marker>
<rawString>Shallow Semantic Parsing Using Support Vector Machines. TR-CSLR-2003-03, University of Colorado.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Sanda M Harabagiu</author>
<author>John Williams</author>
<author>John Aarseth</author>
</authors>
<title>Using predicate-argument structures for information extraction.</title>
<date>2003</date>
<booktitle>In proceedings of ACL-03,</booktitle>
<location>Sapporo, Japan.</location>
<contexts>
<context position="2583" citStr="Surdeanu et al., 2003" startWordPosition="393" endWordPosition="396">ter are schematic representations of situations involving various participants, properties and roles in which a word may be typically used. Frame elements or semantic roles are arguments of predicates called target words. In FrameNet, the argument names are local to a particular frame. Predicate Arg. 0 Arg. M S N NP D N VP V Paul in gives a lecture PP IN N Rome Arg. 1 Figure 1: A predicate argument structure in a parse-tree representation. Several machine learning approaches for argument identification and classification have been developed (Gildea and Jurasfky, 2002; Gildea and Palmer, 2002; Surdeanu et al., 2003; Hacioglu et al., 2003). Their common characteristic is the adoption of feature spaces that model predicate-argument structures in a flat representation. On the contrary, convolution kernels aim to capture structural information in term of sub-structures, providing a viable alternative to flat features. In this paper, we select portions of syntactic trees, which include predicate/argument salient sub-structures, to define convolution kernels for the task of predicate argument classification. In particular, our kernels aim to (a) represent the relation between predicate and one of its argument</context>
<context position="21533" citStr="Surdeanu et al., 2003" startWordPosition="3763" endWordPosition="3766"> the polynomial kernel. KSCF +P = KSCF |KSCF |+ Kpd |Kpd |, i.e. the summation between the normalized SCF-based kernel and the normalized polynomial kernel. KSCF P = KSCF Kpd |KSCF ||Kpd |, i.e. the normalized product between SCF-based kernel and the polynomial kernel. 4.1 Corpora set-up The above kernels were experimented over two corpora: PropBank (www.cis.upenn.edu/ace) along with Penn TreeBank5 2 (Marcus et al., 1993) and FrameNet. PropBank contains about 53,700 sentences and a fixed split between training and testing which has been used in other researches e.g., (Gildea and Palmer, 2002; Surdeanu et al., 2003; Hacioglu et al., 2003). In this split, Sections from 02 to 21 are used for training, section 23 for testing and sections 1 and 22 as developing set. We considered all PropBank arguments6 from Arg0 to Arg9, ArgA and ArgM for a total of 122,774 and 7,359 arguments in training and testing respectively. It is worth noting that in the experiments we used the gold standard parsing from Penn TreeBank, thus our kernel structures are derived with high precision. For the FrameNet corpus (www.icsi.berkeley 3 It can be proven that the resulting kernels still satisfy Mercers conditions (Cristianini and S</context>
<context position="23710" citStr="Surdeanu et al., 2003" startWordPosition="4132" endWordPosition="4135"> parse-trees automatically. 4.2 Classification set-up The classifier evaluations were carried out using the SVM-light software (Joachims, 1999) available at svmlight.joachims.org with the default polynomial kernel for standard feature evaluations. To process PAF and SCF, we implemented our own kernels and we used them inside SVM-light. The classification performances were evaluated using the f1 measure7 for single arguments and the accuracy for the final multi-class classifier. This latter choice allows us to compare the results with previous literature works, e.g. (Gildea and Jurasfky, 2002; Surdeanu et al., 2003; Hacioglu et al., 2003). For the evaluation of SVMs, we used the default regularization parameter (e.g., C = 1 for normalized kernels) and we tried a few costfactor values (i.e., j {0.1, 1, 2, 3, 4, 5}) to adjust the rate between Precision and Recall. We chose parameters by evaluating SVM using Kp3 kernel over the validation-set. Both (see Section 3.3) and parameters were evaluated in a similar way by maximizing the performance of SVM using KP AF and KSCF |KSCF |+ Kpd |Kpd |respectively. These parameters were adopted also for all the other kernels. 4.3 Kernel evaluations To study the impact o</context>
</contexts>
<marker>Surdeanu, Harabagiu, Williams, Aarseth, 2003</marker>
<rawString>Mihai Surdeanu, Sanda M. Harabagiu, John Williams, and John Aarseth. 2003. Using predicate-argument structures for information extraction. In proceedings of ACL-03, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Vapnik</author>
</authors>
<title>The Nature of Statistical Learning Theory.</title>
<date>1995</date>
<publisher>Springer-Verlag</publisher>
<location>New York, Inc. \x0c&apos;</location>
<contexts>
<context position="8866" citStr="Vapnik, 1995" startWordPosition="1489" endWordPosition="1490"> in delivers a talk PP IN NP jj formal N style Arg. 1 Fdeliver, ArgM c) Arg. M Figure 2: Structured features for Arg0, Arg1 and ArgM. vents the learning algorithm to generalize well on unseen data. In order to address this problem, the next section describes a novel kernel space for predicate argument classification. 2.2 Support Vector Machine approach Given a vector space in &amp;lt;n and a set of positive and negative points, SVMs classify vectors according to a separating hyperplane, H(~ x) = ~ w ~ x + b = 0, where ~ w &amp;lt;n and b &amp;lt; are learned by applying the Structural Risk Minimization principle (Vapnik, 1995). To apply the SVM algorithm to Predicate Argument Classification, we need a function : F &amp;lt;n to map our features space F = {f1, .., f|F|} and our predicate/argument pair representation, Fp,a = Fz, into &amp;lt;n, such that: Fz (Fz) = (1(Fz), .., n(Fz)) From the kernel theory we have that: H(~ x) = \x10 X i=1..l i~ xi \x11 ~ x+b = X i=1..l i~ xi ~ x+b = = X i=1..l i(Fi) (Fz) + b. where, Fi i {1, .., l} are the training instances and the product K(Fi, Fz) =&amp;lt;(Fi) (Fz)&amp;gt; is the kernel function associated with the mapping . The simplest mapping that we can apply is (Fz) = ~ z = (z1, ..., zn) where zi = 1 i</context>
</contexts>
<marker>Vapnik, 1995</marker>
<rawString>V. Vapnik. 1995. The Nature of Statistical Learning Theory. Springer-Verlag New York, Inc. \x0c&apos;</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>