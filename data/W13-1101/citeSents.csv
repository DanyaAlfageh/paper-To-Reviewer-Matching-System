Or one can train parsers on the English Web Treebank CITATION, which covers web language, including social media data, but is rather small,,
As far as we know, despite being efficient and trainable on a small amount of data, parse revision (Henestroza CITATION; Cetinoglu et al., 2011; CITATION; CITATION) has not been used for web data, or more generally for adapting a parser to out-of-domain data; an investigation of its strengths and weaknesses is thus needed,,
Also, MST offers the possibility to retrieve confidence scores for each dependency edge: We use the KDFix edge confidence scores discussed by CITATION to assist in parse revision,,
6 http://sourceforge.net/projects/ mstparser/ 4.2 Reviser #1: machine learning model We use DeSR CITATION as a machine learning model of parse revision,,
Or one can train parsers on the English Web Treebank CITATION, which covers web language, including social media data, but is rather small,,
As far as we know, despite being efficient and trainable on a small amount of data, parse revision (Henestroza CITATION; Cetinoglu et al., 2011; CITATION; CITATION) has not been used for web data, or more generally for adapting a parser to out-of-domain data; an investigation of its strengths and weaknesses is thus needed,,
ation (Foster et al., 2011; Gadde et al., 2011; CITATION), it has not teased apart which parts of the normalization are beneficial under which circumstances,,
A second problem with parsing social media data is the data situation: parsers can be trained on the standard training set, the Penn Treebank CITATION, which has a sufficient size for training a statistical parser, but has the distinct downside of modeling language that is very dissimilar 1 Taken from: http://www.youtube.com/watch? v=eHSpHCprXLA 1 \x0cfrom the target,,
Or one can train parsers on the English Web Treebank CITATION, which covers web language, including social media data, but is rather small,,
As far as we know, despite being efficient and trainable on a small amount of data, parse revision (Henestroza CITATION; Cetinoglu et al., 2011; CITATION; CITATION) has not been used for web data, or more generally for adapting a parser to out-of-domain data; an investigation of its strengths and weaknesses is thus needed,,
1) outperforms a machine learning reviser CITATION, especially when integrated with confidence scores from the parser itself,,
2 Data For our experiments, we use two main resources, the Wall Street Journal (WSJ) portion of the Penn Treebank (PTB) CITATION and the English Web Treebank (EWT) CITATION,,
The two corpora were converted from PTB constituency trees into dependency trees using the Stanford dependency converter (de Marneffe and CITATION).2 The EWT is comprised of approximately 16,000 sentences from weblogs, newsgroups, emails, reviews, and question-answers,,
2 Data For our experiments, we use two main resources, the Wall Street Journal (WSJ) portion of the Penn Treebank (PTB) CITATION and the English Web Treebank (EWT) CITATION,,
The two corpora were converted from PTB constituency trees into dependency trees using the Stanford dependency converter (de Marneffe and CITATION).2 The EWT is comprised of approximately 16,000 sentences from weblogs, newsgroups, emails, reviews, and question-answers,,
4.3 Reviser #2: simple tree anomaly model Another method we use for building parse revisions is based on a method to detect anomalies in parse structures (APS) using n-gram sequences of dependency structures (CITATION; CITATION),,
The method checks whether the same head category (e.g., verb) has a set of dependents similar to others of the same category CITATION,,
(3) s(ei) = P ngrm:eingrmn3 C(ngrm) (4) s(prep:IN) = C(det:DT NN prep:IN) + C(NN prep:IN END) + C(START det:DT NN prep:IN) + C(det:DT NN prep:IN END) + C(START det:DT NN prep:IN END) We modify the scoring slightly, incorporating bigrams (n 2), but weighing them as 0.01 of a count (C(ngrm)); this handles the issue that bigrams are not very informative, yet having some bigrams is better than none CITATION,,
The method detects non-standard parses which may result from parser error or because the text is unusual in some other way, e.g., ungrammatical CITATION,,
The revision checking algorithm in CITATION posits new labelings and attachmentsmaintaining projectivity and acyclicity, to consider only reasonable candidates8and checks whether any have,,
In the evaluation in section 5, we will find that normalization has a positive impact, although spell checking has mixed results, and that a simple tree anomaly detection method CITATION outperforms a machine learning reviser CITATION, especially when integrated with confidence scores from the parser itself,,
2 Data For our experiments, we use two main resources, the Wall Street Journal (WSJ) portion of the Penn Treebank (PTB) CITATION and the English Web Treebank (EWT) (Bi,,
4.3 Reviser #2: simple tree anomaly model Another method we use for building parse revisions is based on a method to detect anomalies in parse structures (APS) using n-gram sequences of dependency structures (CITATION; CITATION),,
The method checks whether the same head category (e.g., verb) has a set of dependents similar to others of the same category CITATION,,
The method detects non-standard parses which may result from parser error or because the text is unusual in some other way, e.g., ungrammatical CITATION,,
The revision checking algorithm in CITATION posits new labelings and attachmentsmaintaining projectivity and acyclicity, to consider only reasonable candidates8and checks whether any have a higher score.9 If so, the token is flagged as having a better revision and is more likely to be an error,,
Although data sets are hard to compare, the precision seems to outperform that of more generic (i.e., nonparser-specific) error detection methods CITATION,,
While previous research has shown the benefit of text normalization (Foster et al., 2011; Gadde et al., 2011; CITATION), it has not teased apart which parts of the normalization are beneficial under which circumstances,,
A second problem with parsing social media data is the data situation: parsers can be trained on the standard training set, the Penn Treebank CITATION, which has a sufficient size for training a statistical parser, but has the distinct downside of modeling language that is very dissimilar 1 Taken from: http://www.youtube.com/watch? v=eHSpHCprXLA 1 \x0cfrom the target,,
Or one can train parsers on the English Web Treebank CITATION, which covers web language, including soci,,
To create training and test sets, we broke the data into the following sets: WSJ training: sections 02-22 (42,009 sentences) WSJ testing: section 23 (2,416 sentences) EWT training: 80% of the data, taking the first four out of every five sentences (13,130 sentences) EWT testing: 20% of the data, taking every fifth sentence (3,282 sentences) 2 \x0c3 Text normalization Previous work has shown that accounting for variability in form (e.g., misspellings) on the web, e.g., by mapping each form to a normalized form (CITATION; Gadde et al., 2011) or by delexicalizing the parser to reduce the impact of unknown words CITATION, leads to some parser or tagger improvement,,
CITATION find that a model which posits a corrected sentence and then is POS-taggedtheir tagging after correction (TAC) modeloutperforms one which cleans POS tags in a postprocessing step,,
Or one can train parsers on the English Web Treebank CITATION, which covers web language, including social media data, but is rather small,,
As far as we know, despite being efficient and trainable on a small amount of data, parse revision (Henestroza CITATION; Cetinoglu et al., 2011; CITATION; CITATION) has not been used for web data, or more generally for adapting a parser to out-of-domain data; an investigation of its strengths and weaknesses is thus needed,,
This drop in score is consistent with previous work on non-canonical data, e.g., web data (Foster et al., 2011) and learner language CITATION,,
It is difficult to compare these results, due to different training and testing conditions, but MST (without any modifications) reaches results that are in the mid-high range of results reported by CITATION, table 4) in their overview of the SANCL shared task using the EWT data: 80.1087.62% UAS; 71.04%83.46% LAS,,
ting: 20% of the data, taking every fifth sentence (3,282 sentences) 2 \x0c3 Text normalization Previous work has shown that accounting for variability in form (e.g., misspellings) on the web, e.g., by mapping each form to a normalized form (CITATION; Gadde et al., 2011) or by delexicalizing the parser to reduce the impact of unknown words CITATION, leads to some parser or tagger improvement,,
CITATION find that a model which posits a corrected sentence and then is POS-taggedtheir tagging after correction (TAC) modeloutperforms one which cleans POS tags in a postprocessing step,,
detects non-standard parses which may result from parser error or because the text is unusual in some other way, e.g., ungrammatical CITATION,,
The revision checking algorithm in CITATION posits new labelings and attachmentsmaintaining projectivity and acyclicity, to consider only reasonable candidates8and checks whether any have a higher score.9 If so, the token is flagged as having a better revision and is more likely to be an error,,
In order to restrict Aspell from suggesting spellings that are too different from the word in question, we use Levenshtein distance CITATION to measure the degree of similarity between the original form and the suggested spelling; only words with small distances are accepted as spelling corrections,,
While previous research has shown the benefit of text normalization (Foster et al., 2011; Gadde et al., 2011; CITATION), it has not teased apart which parts of the normalization are beneficial under which circumstances,,
A second problem with parsing social media data is the data situation: parsers can be trained on the standard training set, the Penn Treebank CITATION, which has a sufficient size for training a statistical parser, but has the distinct downside of modeling language that is very dissimilar 1 Taken from: http://www.youtube.com/watch? v=eHSpHCprXLA 1 \x0cfrom the target,,
Or one can train parsers on the English Web Treebank CITATION, which covers web language, including social media data, but is rather small,,
e tree anomaly detection method CITATION outperforms a machine learning reviser CITATION, especially when integrated with confidence scores from the parser itself,,
2 Data For our experiments, we use two main resources, the Wall Street Journal (WSJ) portion of the Penn Treebank (PTB) CITATION and the English Web Treebank (EWT) CITATION,,
The two corpora were converted from PTB constituency trees into dependency trees using the Stanford dependency converter (de Marneffe and CITATION).2 The EWT is comprised of approximately 16,000 sentences from weblogs, newsgroups, emails, reviews, and question-answers,,
Various systems for parsing web data (e.g., from the SANCL shared task) have thus also explored spelling correction; CITATION, for example, used 1,057 autocorrect rules, thoughsince these did not make many changesthe system was not explored after that,,
 data CITATION, which is not a good fit for social media data,,
To perform tasks such as sentiment analysis CITATION or information extraction CITATION, it helps to perform tagging and parsing, with an eye towards providing a shallow semantic analysis,,
 4 Parser revision We use a state of the art dependency parser, MSTParser CITATION, as our main parser; and we use two parse revision methods: a machine learning model and a simple tree anomaly model,,
4.1 Basic parser MSTParser CITATION6 is a freely available parser which reaches state-of-the-art accuracy in dependency parsing for English,,
MST is a graph-based parser which optimizes its parse tree globally CITATION, using a variety of feature sets, i.e., edge, sibling, context, and nonlocal features, employing information from words and POS tags,,
Also, MST offers the possibility to retrieve confidence scores for each dependency edge: We use the KDFix edge confidence scores discussed by CITATION to assist in parse revision,,
4 Parser revision We use a state of the art dependency parser, MSTParser CITATION, as our main parser; and we use two parse revision methods: a machine learning model and a simple tree anomaly model,,
4.1 Basic parser MSTParser CITATION6 is a freely available parser which reaches state-of-the-art accuracy in dependency parsing for English,,
MST is a graph-based parser which optimizes its parse tree globally CITATION, using a variety of feature sets, i.e., edge, sibling, context, and nonlocal fe,,
MST is a graph-based parser which optimizes its parse tree globally CITATION, using a variety of feature sets, i.e., edge, sibling, context, and nonlocal features, employing information from words and POS tags,,
Also, MST offers the possibility to retrieve confidence scores for each dependency edge: We use the KDFix edge confidence scores discussed by CITATION to assist in parse revision,,
6 http://sourceforge.net/projects/ mstparser/ 4.2 Reviser #1: machine learning model We use DeSR CITATION as a machine learning model of parse revision,,
We can assist the methods by using MST confidence scores CITATION to pinpoint candidates for revision, and only pass these candidates on to the parse revisers,,
We follow CITATION and use confidence0.5 as our threshold for identifying errors,,
ifficult, as parsers are generally trained on news data CITATION, which is not a good fit for social media data,,
To perform tasks such as sentiment analysis CITATION or information extraction CITATION, it helps to perform tagging and parsing, with an eye towards providing a shallow semantic analysis,,
d test sets, we broke the data into the following sets: WSJ training: sections 02-22 (42,009 sentences) WSJ testing: section 23 (2,416 sentences) EWT training: 80% of the data, taking the first four out of every five sentences (13,130 sentences) EWT testing: 20% of the data, taking every fifth sentence (3,282 sentences) 2 \x0c3 Text normalization Previous work has shown that accounting for variability in form (e.g., misspellings) on the web, e.g., by mapping each form to a normalized form (CITATION; Gadde et al., 2011) or by delexicalizing the parser to reduce the impact of unknown words CITATION, leads to some parser or tagger improvement,,
CITATION find that a model which posits a corrected sentence and then is POS-taggedtheir tagging after correction (TAC) modeloutperforms one which cleans POS tags in a postprocessing step,,
1 Introduction and Motivation Parsing data from social media data, as well as other data from the web, is notoriously difficult, as parsers are generally trained on news data CITATION, which is not a good fit for social media data,,
To perform tasks such as sentiment analysis CITATION or information extraction CITATION, it helps ,,
This drop in score is consistent with previous work on non-canonical data, e.g., web data (Foster et al., 2011) and learner language CITATION,,
It is difficult to compare these results, due to different training and testing conditions, but MST (without any modifications) reaches results that are in the mid-high range of results reported by CITATION, table 4) in their overview of the SANCL shared task using the EWT data: 80.1087.62% UAS; 71.04%83.46% LAS,,
