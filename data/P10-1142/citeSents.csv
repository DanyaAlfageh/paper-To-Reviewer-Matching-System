It was first proposed by CITATION and McCarthy and Lehnert CITATION, and is one of the most influential learning-based coreference models,,
5.2 Scoring a Coreference Partition The MUC scorer CITATION is the first program developed for scoring coreference partitions,,
To address these problems, two coreference scoring programs have been developed: B3 CITATION and CEAF CITATION,,
To apply these scorers to automatically extracted NPs, different methods have been proposed (see Rahman and CITATION and CITATION),,
Since coreference is a clustering task, any general-purpose method for evaluating a response partition against a key partition (e.g., Kappa (Carletta, 1996)) can be used for coreference scor1403 \x0cing (see CITATION),,
Correlation clustering CITATION, which produces a partition that respects as many pairwise decisions as possible, is used by McCallum and Wellner (2004), CITATION, and Finley and Joachims (2005),,
CoRTex (Denis and Baldridge, 2008), the Illinois Coreference Package (Bengtson and Roth, 2008), CherryPicker (Rahman and CITATION), Reconcile CITATION, and Charniak and Elsners (2009) pronoun resolver,,
In particular, preprocessing tools can have a large impact on the performance of a resolver CITATION,,
To our knowledge, however, the best results on the MUC-6 and MUC-7 data sets using automatically extracted NPs are reported by CITATION (71.3 MUC F-score) and CITATIONc) (63.4 MUC F-score), respectively;8 and the best results on the ACE data sets using gold NPs can be found in CITATION (88.4 ACE-value),,
Despite its simple task definition, coreference is generally considered a difficult NLP task, typically involving the use of sophisticated knowledge sources and inference procedures CITATION,,
Computational theories of discourse, in particular focusing (see Grosz (1977) and CITATION) and centering (Grosz et al,,
CITATION), have heavily influenced coreference research in the 1970s and 1980s, leading to the development of numerous centering algorithms (see Walker et al,,
CITATION),,
6 Concluding Remarks While we have focused our discussion on supervised approaches, coreference researchers have also attempted to reduce a resolvers reliance on annotated data by combining a small amount of labeled data and a large amount of unlabeled data using general-purpose semi-supervised learning algorithms such as co-training CITATION, self-training (CITATIONa), and EM (CITATION; CITATION),,
Interestingly, recent results indicate that unsupervised approaches to coreference resolution (e.g., Haghighi and Klein (2007; 2010), CITATION) rival their supervised counterparts, casting doubts on whether supervised resolvers are making effective use of the available labeled data,,
CITATIONa) treat the two NPs involved as two bags of words, and compute their similarity using metrics commonly-used in information retrieval, such as the dot product, with each word weighted by their TF-IDF value,,
CITATION implement 1401 \x0ca Hobbs distance feature, which encodes the rank assigned to a candidate antecedent for a pronoun by Hobbss (1978) seminal syntax-based pronoun resolution algorithm,,
CITATION extract features from a parse tree for implementing Binding Constraints CITATION,,
(2006) and CITATION employ these trees directly as structured features for pronoun resolution,,
(2001)), CITATIONa) present a method for mining easy positive instances, in an attempt to avoid the inclusion of hard training instances that may complicate the acquisition of an accurate coreference model,,
Decision tree induction systems (e.g., C5 CITATION) are the first and one of the most widely used learning algorithms by coreference researchers, although rule learners (e.g., RIPPER CITATION) and memory-based learners (e.g., TiMBL (Daelemans and Van den Bosch, 2005)) are also popular choices, especially in early applications of machine learning to coreference resolution,,
CITATION and MUC-7 CITATION conferences,,
Fifteen years have passed since the first paper on learning-based coreference resolution was published CITATION,,
Note that several leading coreference researchers have published books (e.g., CITATION), written survey articles (e.g., CITATION, CITATION), and delivered tutorials (e.g., CITATION, CITATION) that provide a broad overview of coreference research,,
CITATION),,
Ranking is first applied to learning-based coreference resolution by CITATION; 1997), where a model is trained to rank two candidate antecedents,,
(2003) and the twin-candidate model by CITATION; 2008b),,
Interestingly, recent results indicate that unsupervised approaches to coreference resolution (e.g., Haghighi and Klein (2007; 2010), CITATION) rival their supervised counterparts, casting doubts on whether supervised resolvers are making effective use of the available labeled data,,
While many of the techniques discussed in this paper were originally developed for English, they have been applied to learn coreference models for other languages, such as Chinese (e.g., CITATION), Japanese (e.g., Iida (2007)), Arabic (e.g., CITATION), Dutch (e.g., Hoste (2005)), German (e.g., CITATION), Swedish (e.g., CITATION), and Czech (e.g., Ngu .CITATION),,
(2007a), Zhao and CITATION),,
As CITATION puts it, coreference resolution is a difficult, but not intractable problem, and we have been making slow, but steady progress on improving machine learning approaches t,,
For example, CITATION apply the ANY predicate to generate cluster-level features for their entity-mention model, which does not perform as well as the mention-pair model,,
CITATIONb; 2008a) also investigate the entity-mention model, which produces results that are only marginally better than those of the mention-pair model,,
For example, CITATION present a first-order logic model that determines 1400 \x0cthe probability that an arbitrary set of NPs are all co-referring,,
One of the earliest kinds of semantic knowledge employed for coreference resolution is perhaps selectional preference (CITATION; CITATIONb; CITATION; Haghighi and Klein, 2009): given a pronoun to be resolved, its governing verb, and its grammatical role, we prefer a candidate antecedent that can be governed by the same verb and be in the same role,,
Semantic knowledge has also been extracted from WordNet and unannotated corpora for computing the semantic compatibility/similarity between two common nouns (Harabagiu et al., 2001; CITATION) as well as the semantic class of a noun (CITATIONa; Huang et al., 2009),,
One of the earliest kinds of semantic knowledge employed for coreference resolution is perhaps selectional preference (CITATION; CITATIONb; CITATION; Haghighi and Klein, 2009): given a pronoun to be resolved, its governing verb, and its grammatical role, we prefer a candidate antecedent that can be governed by the same verb and be in the same role,,
Semantic knowledge has also been extracted from WordNet and unannotated corpora for computing the semantic compatibility/similarity between two common nouns (Harabagiu et al., 2001; CITATION) as well as the semantic class of a noun (CITATIONa; Huang et al., 2009),,
6 Concluding Remarks While we have focused our discussion on supervised approaches, coreference researchers have also attempted to reduce a resolvers reliance on annotated data by combining a small amount of labeled data and a large amount of unlabeled data using general-purpose semi-supervised learning algorithms such as co-training CITATION, self-training (CITATIONa), and EM (CITATION; CITATION),,
Interestingly, recent results indicate that unsupervised approaches to coreference resolution (e.g., Haghighi and Klein (2007; 2010), CITATION) rival their supervised counterparts, casting doubts on whether supervised resolvers are making effective use of the available labeled data,,
One of the earliest kinds of semantic knowledge employed for coreference resolution is perhaps selectional preference (CITATION; CITATIONb; CITATION; Haghighi and Klein, 2009): given a pronoun to be resolved, its governing verb, and its grammatical role, we prefer a candidate antecedent that can be governed by the same verb and be in the same role,,
Semantic knowledge has also been extracted from WordNet and unannotated corpora for computing the semantic compatibility/similarity between two common nouns (Harabagiu et al., 2001; CITATION) as well as the semantic class of a noun (CITATIONa; Huang et al., 2009),,
6 Concluding Remarks While we have focused our discussion on supervised approaches, coreference researchers have also attempted to reduce a resolvers reliance on annotated data by combining a small amount of labeled data and a large amount of unlabeled data using general-purpose semi-supervised learning algorithms such as co-training CITATION, self-training (CITATIONa), and EM (CITATION; CITATION),,
Interestingly, recent results indicate that unsupervised approaches to coreference resolution (e.g., Haghighi and Klein (2007; 2010), CITATION) rival their supervised counterparts, casting doubts on whether supervised resolvers are making effective use of the available labeled data,,
For example, pleonastic it has been identified using heuristic approaches (e.g., CITATION, CITATION, Kennedy and Boguraev (1996)), supervised approaches (e.g., Evans (2001), CITATION, CITATIONa)), and distributional methods (e.g., Bergsma et al,,
(2008)); and non-anaphoric definite descriptions have been identified using rule-based techniques (e.g., CITATION) and unsupervised techniques (e.g., Bean and Riloff (1999)),,
including minimum edit distance CITATION and longest common subsequence (Castano et al., 2002),,
CITATIONa) treat the two NPs involved as two bags of words, and compute their similarity using metrics commonly-used in information retrieval, such as the dot product, with each word weighted by their TF-IDF value,,
CITATION implement 1401 \x0ca Hobbs distance feature, which encodes the rank assigned to a candidate antecedent for a pronoun by Hobbss (1978) seminal syntax-based pronoun resolution algorithm,,
CITATION extract features from a parse tree for implementing Binding Constraints CITATION,,
(2006) and CITATION employ these trees directly as ,,
 approaches to coreference resolution (e.g., Haghighi and Klein (2007; 2010), CITATION) rival their supervised counterparts, casting doubts on whether supervised resolvers are making effective use of the available labeled data,,
While many of the techniques discussed in this paper were originally developed for English, they have been applied to learn coreference models for other languages, such as Chinese (e.g., CITATION), Japanese (e.g., Iida (2007)), Arabic (e.g., CITATION), Dutch (e.g., Hoste (2005)), German (e.g., CITATION), Swedish (e.g., CITATION), and Czech (e.g., Ngu .CITATION),,
(2007a), Zhao and CITATION),,
As CITATION puts it, coreference resolution is a difficult, but not intractable problem, and we have been making slow, but steady progress on improving machine learning approaches to the problem in the past fifteen years,,
For example, CITATION apply the ANY predicate to generate cluster-level features for their entity-mention model, which does not perform as well as the mention-pair model,,
CITATIONb; 2008a) also investigate the entity-mention model, which produces results that are only marginally better than those of the mention-pair model,,
For example, CITATION present a fi,,
Memorization features have been used as binary-valued features indicating the presence or absence of their words CITATION or as probabilistic features indicating the probability that the two heads are coreferent according to the training data (CITATIONb),,
An anaphoricity feature indicates whether an NP to be resolved is anaphoric, and is typically computed using an anaphoricity classifier CITATION, hand-crafted patterns (Daume III and Marcu, 2005), and automatically acquired patterns (Bean and Riloff, 1999),,
Finally, the outputs of rule-based pronoun and coreference resolvers have also been used as features for learning-based coreference resolution (CITATIONc),,
5.2 Scoring a Coreference Partition The MUC scorer CITATION is the first program developed for scoring coreference partitions,,
To address these problems, two coreference scoring programs have been developed: B3 CITATION and CEAF CITATION,,
To apply these scorers to automatically extracted NPs, different methods have been proposed (see Rahman and CITATION and CITATION),,
Since coreference is a clustering task, any general-purpose method for evaluating a response partition against a key partition (e.g., Kappa (Carletta, 1996)) can be used for coreference scor1403 \x0cing (see CITATION),,
In particular, preprocessing tools can have a large impact on the performance of a resolver CITATION,,
To our knowledge, however, the best results on the MUC-6 and MUC-7 data sets using automatically extracted NPs are reported by CITATION (71.3 MUC F-score) and CITATIONc) (63.4 MUC F-score), respectively;8 and the best results on the ACE data sets using gold NPs can be found in CITATION (88.4 ACE-value),,
These include (1) the English Penn Treebank CITATION, which is labeled with coreference links as part of the OntoNotes project (Hovy et al., 2006); (2) the Tubingen Treebank CITATION, which is a collection of German news articles consisting of 27,125 sentences; (3) the Prague Dependency Treebank (Hajic et al., 2006), which consists of 3168 news articles taken from the Czech National Corpus; (4) the NAIST Text Corpus (Iida et al., 2007b), which consists of 287 Japanese news articles; (5) the AnCora Corpus CITATION, which consists of Spanish and Catalan journalist texts; and (6) the GENIA corpus (Ohta et al., 200,,
This technique has been applied to resolve different kinds of anaphoric references, including other-anaphora (CITATION; CITATION) and bridging references (CITATIONa),,
While these patterns are typically hand-crafted (e.g., Garera and Yarowsky (2006)), they can also be learned from an annotated corpus CITATION or bootstrapped from an unannotated corpus (Bean and Riloff, 2004),,
To motivate the entity-mention model, consider an example taken from CITATION, where a document consists of three NPs: Mr,,
Fifteen years have passed since the first paper on learning-based coreference resolution was published CITATION,,
Note that several leading coreference researchers have published books (e.g., CITATION), written survey articles (e.g., CITATION, CITATION), and delivered tutorials (e.g., CITATION, CITATION) that provide a broad overview of coreference research,,
echniques discussed in this paper were originally developed for English, they have been applied to learn coreference models for other languages, such as Chinese (e.g., CITATION), Japanese (e.g., Iida (2007)), Arabic (e.g., CITATION), Dutch (e.g., Hoste (2005)), German (e.g., CITATION), Swedish (e.g., CITATION), and Czech (e.g., Ngu .CITATION),,
(2007a), Zhao and CITATION),,
As CITATION puts it, coreference resolution is a difficult, but not intractable problem, and we have been making slow, but steady progress on improving machine learning approaches to the problem in the past fifteen years,,
To ensure further progress, researchers should compare their results against a baseline that is stronger than the commonly-used CITATION system, which relies on a weak model (i.e., the mention-pair model) and a small set of linguistic features,,
nis and Baldridge, 2008), the Illinois Coreference Package (Bengtson and Roth, 2008), CherryPicker (Rahman and CITATION), Reconcile CITATION, and Charniak and Elsners (2009) pronoun resolver,,
In particular, preprocessing tools can have a large impact on the performance of a resolver CITATION,,
To our knowledge, however, the best results on the MUC-6 and MUC-7 data sets using automatically extracted NPs are reported by CITATION (71.3 MUC F-score) and CITATIONc) (63.4 MUC F-score), respectively;8 and the best results on the ACE data sets using gold NPs can be found in CITATION (88.4 ACE-value),,
Fifteen years have passed since the first paper on learning-based coreference resolution was published CITATION,,
Note that several leading coreference researchers have published books (e.g., CITATION), written survey articles (e.g., CITATION, CITATION), and delivered tutorials (e.g., CITATION, CITATION) that provide a broad overview of coreference research,,
This technique has been applied to resolve different kinds of anaphoric references, including other-anaphora (CITATION; CITATION) and bridging references (CITATIONa),,
While these patterns are typically hand-crafted (e.g., Garera and Yarowsky (2006)), they can also be learned from an annotated corpus CITATION or bootstrapped from an unannotated corpus (Bean and Riloff, 2004),,
Despite its simple task definition, coreference is generally considered a difficult NLP task, typically involving the use of sophisticated knowledge sources and inference procedures CITATION,,
Computational theories of discourse, in particular focusing (see Grosz (1977) and CITATION) and centering (Grosz et al,,
CITATION), have heavily influenced coreference research in the 1970s and 1980s, leading to the development of numerous centering algorithms (see Walker et al,,
CITATION),,
This shift can be attributed in part to the advent of the statistical NLP era, and in part to the public availability of annotated coreference corpora produced as part of the MUC-6 CITATION and MUC-7 CITATION conferences,,
It was first proposed by CITATION and McCarthy and Lehnert CITATION, and is one of the most influential learning-based coreference models,,
6 Concluding Remarks While we have focused our discussion on supervised approaches, coreference researchers have also attempted to reduce a resolvers reliance on annotated data by combining a small amount of labeled data and a large amount of unlabeled data using general-purpose semi-supervised learning algorithms such as co-training CITATION, self-training (CITATIONa), and EM (CITATION; CITATION),,
Interestingly, recent results indicate that unsupervised approaches to coreference resolution (e.g., Haghighi and Klein (2007; 2010), CITATION) rival their supervised counterparts, casting doubts on whether supervised resolvers are making effective use of the available labeled data,,
For example, pleonastic it has been identified using heuristic approaches (e.g., CITATION, CITATION, Kennedy and Boguraev (1996)), supervised approaches (e.g., Evans (2001), CITATION, CITATIONa)), and distributional methods (e.g., Bergsma et al,,
(2008)); and non-anaphoric definite descriptions have been identified using rule-based techniques (e.g., CITATION) and unsupervised techniques (e.g., Bean and Riloff (1999)),,
Recently, anaphoricity determination has been evaluated in the context of coreference resolution, with results showing that training an anaphoricity classifier to identify and filter non-anaphoric NPs prior to coreference resolution can improve a learning-based resolver (e.g., CITATIONb), CITATION, Poesio et al,,
With an eye towards improving the precision of a coreference resolver, CITATIONc) propose an instance creation method that involves a single modification to Soon et al.s method: if NPk is non-pronominal, a positive instance should be formed between NPk and its closest preceding nonpronominal antecedent instead,,
Despite their simplicity, closest-first clustering CITATION and best-first clustering (CITATIONc) are arguably the most widely used coreference clustering algorithms,,
For example, CITATIONc) report that bestfirst clustering is better than closest-first clustering,,
CITATION show that bestfirst clustering performs similarly to Bell-treebased clustering, but neither of these algorithms 5 When applying closest-first and best-first clustering, CITATION and CITATIONc) also process the NPs in a sequential manner, but since the later decisions are not dependent on the earlier ones, the order in which the NPs are processed does not affect their clustering results,,
upervised approaches (e.g., Evans (2001), CITATION, CITATIONa)), and distributional methods (e.g., Bergsma et al,,
(2008)); and non-anaphoric definite descriptions have been identified using rule-based techniques (e.g., CITATION) and unsupervised techniques (e.g., Bean and Riloff (1999)),,
Recently, anaphoricity determination has been evaluated in the context of coreference resolution, with results showing that training an anaphoricity classifier to identify and filter non-anaphoric NPs prior to coreference resolution can improve a learning-based resolver (e.g., CITATIONb), CITATION, CITATIONb)),,
Examples of such approaches have exploited techniques including integer linear programming (ILP) (Denis and Baldridge, 2007a), label propagation CITATION, and minimum cuts CITATION,,
ing the presence or absence of their words CITATION or as probabilistic features indicating the probability that the two heads are coreferent according to the training data (CITATIONb),,
An anaphoricity feature indicates whether an NP to be resolved is anaphoric, and is typically computed using an anaphoricity classifier CITATION, hand-crafted patterns (Daume III and Marcu, 2005), and automatically acquired patterns (Bean and Riloff, 1999),,
Finally, the outputs of rule-based pronoun and coreference resolvers have also been used as features for learning-based coreference resolution (CITATIONc),,
In particular, preprocessing tools can have a large impact on the performance of a resolver CITATION,,
To our knowledge, however, the best results on the MUC-6 and MUC-7 data sets using automatically extracted NPs are reported by CITATION (71.3 MUC F-score) and CITATIONc) (63.4 MUC F-score), respectively;8 and the best results on the ACE data sets using gold NPs can be found in CITATION (88.4 ACE-value),,
With an eye towards improving the precision of a coreference resolver, CITATIONc) propose an instance creation method that involves a single modification to Soon et al.s method: if NPk is non-pronominal, a positive instance should be formed between NPk and its closest preceding nonpronominal antecedent instead,,
Despite their simplicity, closest-first clustering CITATION and best-first clustering (CITATIONc) are arguably the most widely used coreference clustering algorithms,,
For example, CITATIONc) report that bestfirst clustering is better than closest-first clustering,,
CITATION show that bestfirst clustering performs similarly to Bell-treebased clustering, but neither of these algorithms 5 When applying closest-first and best-first clustering, CITATION and CITATIONc) also process the NPs in a sequential manner, but since the later decisions are not dependent on the earlier ones, the order in which the NPs are processed does not affect their clustering results,,
upervised approaches (e.g., Evans (2001), CITATION, CITATIONa)), and distributional methods (e.g., Bergsma et al,,
(2008)); and non-anaphoric definite descriptions have been identified using rule-based techniques (e.g., CITATION) and unsupervised techniques (e.g., Bean and Riloff (1999)),,
Recently, anaphoricity determination has been evaluated in the context of coreference resolution, with results showing that training an anaphoricity classifier to identify and filter non-anaphoric NPs prior to coreference resolution can improve a learning-based resolver (e.g., CITATIONb), CITATION, CITATIONb)),,
Examples of such approaches have exploited techniques including integer linear programming (ILP) (Denis and Baldridge, 2007a), label propagation CITATION, and minimum cuts CITATION,,
ing the presence or absence of their words CITATION or as probabilistic features indicating the probability that the two heads are coreferent according to the training data (CITATIONb),,
An anaphoricity feature indicates whether an NP to be resolved is anaphoric, and is typically computed using an anaphoricity classifier CITATION, hand-crafted patterns (Daume III and Marcu, 2005), and automatically acquired patterns (Bean and Riloff, 1999),,
Finally, the outputs of rule-based pronoun and coreference resolvers have also been used as features for learning-based coreference resolution (CITATIONc),,
In particular, preprocessing tools can have a large impact on the performance of a resolver CITATION,,
To our knowledge, however, the best results on the MUC-6 and MUC-7 data sets using automatically extracted NPs are reported by CITATION (71.3 MUC F-score) and CITATIONc) (63.4 MUC F-score), respectively;8 and the best results on the ACE data sets using gold NPs can be found in CITATION (88.4 ACE-value),,
With an eye towards improving the precision of a coreference resolver, CITATIONc) propose an instance creation method that involves a single modification to Soon et al.s method: if NPk is non-pronominal, a positive instance should be formed between NPk and its closest preceding nonpronominal antecedent instead,,
Despite their simplicity, closest-first clustering CITATION and best-first clustering (CITATIONc) are arguably the most widely used coreference clustering algorithms,,
For example, CITATIONc) report that bestfirst clustering is better than closest-first clustering,,
CITATION show that bestfirst clustering performs similarly to Bell-treebased clustering, but neither of these algorithms 5 When applying closest-first and best-first clustering, CITATION and CITATIONc) also process the NPs in a sequential manner, but since the later decisions are not dependent on the earlier ones, the order in which the NPs are processed does not affect their clustering results,,
upervised approaches (e.g., Evans (2001), CITATION, CITATIONa)), and distributional methods (e.g., Bergsma et al,,
(2008)); and non-anaphoric definite descriptions have been identified using rule-based techniques (e.g., CITATION) and unsupervised techniques (e.g., Bean and Riloff (1999)),,
Recently, anaphoricity determination has been evaluated in the context of coreference resolution, with results showing that training an anaphoricity classifier to identify and filter non-anaphoric NPs prior to coreference resolution can improve a learning-based resolver (e.g., CITATIONb), CITATION, CITATIONb)),,
Examples of such approaches have exploited techniques including integer linear programming (ILP) (Denis and Baldridge, 2007a), label propagation CITATION, and minimum cuts CITATION,,
ing the presence or absence of their words CITATION or as probabilistic features indicating the probability that the two heads are coreferent according to the training data (CITATIONb),,
An anaphoricity feature indicates whether an NP to be resolved is anaphoric, and is typically computed using an anaphoricity classifier CITATION, hand-crafted patterns (Daume III and Marcu, 2005), and automatically acquired patterns (Bean and Riloff, 1999),,
Finally, the outputs of rule-based pronoun and coreference resolvers have also been used as features for learning-based coreference resolution (CITATIONc),,
In particular, preprocessing tools can have a large impact on the performance of a resolver CITATION,,
To our knowledge, however, the best results on the MUC-6 and MUC-7 data sets using automatically extracted NPs are reported by CITATION (71.3 MUC F-score) and CITATIONc) (63.4 MUC F-score), respectively;8 and the best results on the ACE data sets using gold NPs can be found in CITATION (88.4 ACE-value),,
Memorization features have been used as binary-valued features indicating the presence or absence of their words CITATION or as probabilistic features indicating the probability that the two heads are coreferent according to the training data (CITATIONb),,
An anaphoricity feature indicates whether an NP to be resolved is anaphoric, and is typically computed using an anaphoricity classifier CITATION, hand-crafted patterns (Daume III and Marcu, 2005), and automatically acquired patterns (Bean and Riloff, 1999),,
Finally, the outputs of rule-based pronoun and coreference resolvers have also been used as features for learning-based coreference resolution (CITATIONc),,
inds of semantic knowledge employed for coreference resolution is perhaps selectional preference (CITATION; CITATIONb; CITATION; Haghighi and Klein, 2009): given a pronoun to be resolved, its governing verb, and its grammatical role, we prefer a candidate antecedent that can be governed by the same verb and be in the same role,,
Semantic knowledge has also been extracted from WordNet and unannotated corpora for computing the semantic compatibility/similarity between two common nouns (Harabagiu et al., 2001; CITATION) as well as the semantic class of a noun (CITATIONa; Huang et al., 2009),,
Some researchers simply use the first sense CITATION or all possible senses (CITATIONa), while others overcome this problem with word sense disambiguation CITATION,,
Memorization features have been used as binary-valued features indicating the presence or absence of their words CITATION or as probabilistic features indicating the probability that the two heads are coreferent according to the training data (CITATIONb),,
An anaphoricity feature indicates whether an NP to be resolved is anaphoric, and is typically computed using an anaphoricity classifier CITATION, hand-crafted patterns (Daume III and Marcu, 2005), and automatically acquired patterns (Bean and Riloff, 1999),,
Finally, the outputs of rule-based pronoun and coreference resolvers have also been used as features for learning-based coreference resolution (CITATIONc),,
e many of the techniques discussed in this paper were originally developed for English, they have been applied to learn coreference models for other languages, such as Chinese (e.g., CITATION), Japanese (e.g., Iida (2007)), Arabic (e.g., CITATION), Dutch (e.g., Hoste (2005)), German (e.g., CITATION), Swedish (e.g., CITATION), and Czech (e.g., Ngu .CITATION),,
(2007a), Zhao and CITATION),,
As CITATION puts it, coreference resolution is a difficult, but not intractable problem, and we have been making slow, but steady progress on improving machine learning approaches to the problem in the past fifteen years,,
To ensure further progress, researchers should compare their results against a baseline that is stronger than the commonly-used CITATION system, which relies on a weak model (i.e., the mention-pair model) and a small set of linguistic features,,
inds of semantic knowledge employed for coreference resolution is perhaps selectional preference (CITATION; CITATIONb; CITATION; Haghighi and Klein, 2009): given a pronoun to be resolved, its governing verb, and its grammatical role, we prefer a candidate antecedent that can be governed by the same verb and be in the same role,,
Semantic knowledge has also been extracted from WordNet and unannotated corpora for computing the semantic compatibility/similarity between two common nouns (Harabagiu et al., 2001; CITATION) as well as the semantic class of a noun (CITATIONa; Huang et al., 2009),,
Some researchers simply use the first sense CITATION or all possible senses (CITATIONa), while others overcome this problem with word sense disambiguation CITATION,,
Memorization features have been used as binary-valued features indicating the presence or absence of their words CITATION or as probabilistic features indicating the probability that the two heads are coreferent according to the training data (CITATIONb),,
An anaphoricity feature indicates whether an NP to be resolved is anaphoric, and is typically computed using an anaphoricity classifier CITATION, hand-crafted patterns (Daume III and Marcu, 2005), and automatically acquired patterns (Bean and Riloff, 1999),,
Finally, the outputs of rule-based pronoun and coreference resolvers have also been used as features for learning-based coreference resolution (CITATIONc),,
e many of the techniques discussed in this paper were originally developed for English, they have been applied to learn coreference models for other languages, such as Chinese (e.g., CITATION), Japanese (e.g., Iida (2007)), Arabic (e.g., CITATION), Dutch (e.g., Hoste (2005)), German (e.g., CITATION), Swedish (e.g., CITATION), and Czech (e.g., Ngu .CITATION),,
(2007a), Zhao and CITATION),,
As CITATION puts it, coreference resolution is a difficult, but not intractable problem, and we have been making slow, but steady progress on improving machine learning approaches to the problem in the past fifteen years,,
To ensure further progress, researchers should compare their results against a baseline that is stronger than the commonly-used CITATION system, which relies on a weak model (i.e., the mention-pair model) and a small set of linguistic features,,
6 Concluding Remarks While we have focused our discussion on supervised approaches, coreference researchers have also attempted to reduce a resolvers reliance on annotated data by combining a small amount of labeled data and a large amount of unlabeled data using general-purpose semi-supervised learning algorithms such as co-training CITATION, self-training (CITATIONa), and EM (CITATION; CITATION),,
Interestingly, recent results indicate that unsupervised approaches to coreference resolution (e.g., Haghighi and Klein (2007; 2010), CITATION) rival their supervised counterparts, casting doubts on whether supervised resolvers are making effective use of the available labeled data,,
lassifier to identify and filter non-anaphoric NPs prior to coreference resolution can improve a learning-based resolver (e.g., CITATIONb), CITATION, CITATIONb)),,
Examples of such approaches have exploited techniques including integer linear programming (ILP) (Denis and Baldridge, 2007a), label propagation CITATION, and minimum cuts CITATION,,
While mention rankers have consistently outperformed the mention-pair model (CITATION; Denis and Baldridge, 2007b), they are not more expressive than the mention-pair model, as they are unable to exploit cluster-level features, unlike the entitymention model,,
To enable rankers to employ cluster-level features, Rahman and CITATION propose the cluster-ranking model, which ranks preceding clusters, rather than candidate antecedents, for an NP to be resolved,,
To address these problems, two coreference scoring programs have been developed: B3 CITATION and CEAF CITATION,,
To apply these scorers to automatically extracted NPs, different methods have been proposed (see Rahman and CITATION and CITATION),,
Since coreference is a clustering task, any general-purpose method for evaluating a response partition against a key partition (e.g., Kappa (Carletta, 1996)) can be used for coreference scor1403 \x0cing (see CITATION),,
 is stronger than the commonly-used CITATION system, which relies on a weak model (i.e., the mention-pair model) and a small set of linguistic features,,
Publicly available coreference systems currently include JavaRAP CITATION, GuiTaR CITATION, BART (CITATIONb), CoRTex (Denis and Baldridge, 2008), the Illinois Coreference Package (Bengtson and Roth, 2008), CherryPicker (Rahman and CITATION), Reconcile CITATION, and Charniak and Elsners (2009) pronoun resolver,,
In particular, preprocessing tools can have a large impact on the performance of a resolver CITATION,,
While many of the techniques discussed in this paper were originally developed for English, they have been applied to learn coreference models for other languages, such as Chinese (e.g., CITATION), Japanese (e.g., Iida (2007)), Arabic (e.g., CITATION), Dutch (e.g., Hoste (2005)), German (e.g., CITATION), Swedish (e.g., CITATION), and Czech (e.g., Ngu .CITATION),,
(2007a), Zhao and CITATION),,
As CITATION puts it, coreference resolution is a difficult, but not intractable problem, and we have been making slow, but steady progress on improving machine learning approaches to the problem in the past fifteen years,,
To ensure further progress, researchers should compare their results against a baseline that is stronger than the commonly-used CITATION system, whi,,
For example, CITATIONc) report that bestfirst clustering is better than closest-first clustering,,
CITATION show that bestfirst clustering performs similarly to Bell-treebased clustering, but neither of these algorithms 5 When applying closest-first and best-first clustering, CITATION and CITATIONc) also process the NPs in a sequential manner, but since the later decisions are not dependent on the earlier ones, the order in which the NPs are processed does not affect their clustering results,,
Semantic knowledge has also been extracted from WordNet and unannotated corpora for computing the semantic compatibility/similarity between two common nouns (Harabagiu et al., 2001; CITATION) as well as the semantic class of a noun (CITATIONa; Huang et al., 2009),,
Some researchers simply use the first sense CITATION or all possible senses (CITATIONa), while others overcome this problem with word sense disambiguation CITATION,,
Knowledge has also been mined from Wikipedia for measuring the semantic relatedness of two NPs, NPj and NPk (Ponzetto and Strube (2006a; 2007)), such as: whether NPj/k appears in the first paragraph of the Wiki page that has NPk/j as the title or in the list of categories to which this page belongs, and the degree of overlap between the two pages that have the two NPs as their titles (see CITATION for other uses of encyclopedic knowledge for coreference resolution),,
Owing in large part to the difference in the number of NPs extracted by these three methods, a coreference resolver can produce substantially different results when applied to the resulting three sets of NPs, with gold NPs yielding the best results and NPs extracted from a parser yielding the worst CITATION,,
While researchers who evaluate their resolvers on gold NPs point out that the results can more accurately reflect the performance of their coreference algorithm, CITATION argue that such evaluations are unrealistic, as NP extraction is an integral part of an end-to-end fully-automatic resolver,,
While many of the techniques discussed in this paper were originally developed for English, they have been applied to learn coreference models for other languages, such as Chinese (e.g., CITATION), Japanese (e.g., Iida (2007)), Arabic (e.g., CITATION), Dutch (e.g., Hoste (2005)), German (e.g., CITATION), Swedish (e.g., CITATION), and Czech (e.g., Ngu .CITATION),,
(2007a), Zhao and CITATION),,
As CITATION puts it, coreference resolution is a difficult, but not intractable problem, and we have been making slow, but steady progress on improving machine learning approaches to the problem in the past fifteen years,,
us et al., 1993), which is labeled with coreference links as part of the OntoNotes project (Hovy et al., 2006); (2) the Tubingen Treebank CITATION, which is a collection of German news articles consisting of 27,125 sentences; (3) the Prague Dependency Treebank (Hajic et al., 2006), which consists of 3168 news articles taken from the Czech National Corpus; (4) the NAIST Text Corpus (Iida et al., 2007b), which consists of 287 Japanese news articles; (5) the AnCora Corpus CITATION, which consists of Spanish and Catalan journalist texts; and (6) the GENIA corpus CITATION, which contains 2000 MEDLINE abstracts,,
Other publicly available coreference corpora of interest include two annotated by Ruslan Mitkovs research group: (1) a 55,000-word corpus in the domain of security/terrorism (Hasler et al., 2006); and (2) training data released as part of the 2007 Anaphora Resolution Exercise CITATION, a coreference resolution shared task,,
edia for measuring the semantic relatedness of two NPs, NPj and NPk (Ponzetto and Strube (2006a; 2007)), such as: whether NPj/k appears in the first paragraph of the Wiki page that has NPk/j as the title or in the list of categories to which this page belongs, and the degree of overlap between the two pages that have the two NPs as their titles (see CITATION for other uses of encyclopedic knowledge for coreference resolution),,
Contextual roles (Bean and Riloff, 2004), semantic relations (Ji et al., 2005), semantic roles (CITATIONb; Kong et al., 2009), and animacy CITATION have also been exploited to improve coreference resolution,,
taken from the Czech National Corpus; (4) the NAIST Text Corpus (Iida et al., 2007b), which consists of 287 Japanese news articles; (5) the AnCora Corpus CITATION, which consists of Spanish and Catalan journalist texts; and (6) the GENIA corpus CITATION, which contains 2000 MEDLINE abstracts,,
Other publicly available coreference corpora of interest include two annotated by Ruslan Mitkovs research group: (1) a 55,000-word corpus in the domain of security/terrorism (Hasler et al., 2006); and (2) training data released as part of the 2007 Anaphora Resolution Exercise CITATION, a coreference resolution shared task,,
For instance, the SemEval-2010 shared task on Coreference Resolution in Multiple Languages CITATION has promised to release coreference data in six languages,,
For example, pleonastic it has been identified using heuristic approaches (e.g., CITATION, CITATION, Kennedy and Boguraev (1996)), supervised approaches (e.g., Evans (2001), CITATION, CITATIONa)), and distributional methods (e.g., Bergsma et al,,
(2008)); and non-anaphoric definite descriptions have been identified using rule-based techniques (e.g., CITATION) and unsupervised techniques (e.g., Bean and Riloff (1999)),,
To ensure further progress, researchers should compare their results against a baseline that is stronger than the commonly-used CITATION system, which relies on a weak model (i.e., the mention-pair model) and a small set of linguistic features,,
Publicly available coreference systems currently include JavaRAP CITATION, GuiTaR CITATION, BART (CITATIONb), CoRTex (Denis and Baldridge, 2008), the Illinois Coreference Package (Bengtson and Roth, 2008), CherryPicker (Rahman and CITATION), Reconcile CITATION, and Charniak and Elsners (2009) pronoun resolver,,
, CITATION, CITATIONa)), and distributional methods (e.g., Bergsma et al,,
(2008)); and non-anaphoric definite descriptions have been identified using rule-based techniques (e.g., CITATION) and unsupervised techniques (e.g., Bean and Riloff (1999)),,
Recently, anaphoricity determination has been evaluated in the context of coreference resolution, with results showing that training an anaphoricity classifier to identify and filter non-anaphoric NPs prior to coreference resolution can improve a learning-based resolver (e.g., CITATIONb), CITATION, CITATIONb)),,
Examples of such approaches have exploited techniques including integer linear programming (ILP) (Denis and Baldridge, 2007a), label propagation CITATION, and minimum cuts CITATION,,
This technique has been applied to resolve different kinds of anaphoric references, including other-anaphora (CITATION; CITATION) and bridging references (CITATIONa),,
While these patterns are typically hand-crafted (e.g., Garera and Yarowsky (2006)), they can also be learned from an annotated corpus CITATION or bootstrapped from an unannotated corpus (Bean and Riloff, 2004),,
 researchers simply use the first sense CITATION or all possible senses (CITATIONa), while others overcome this problem with word sense disambiguation CITATION,,
Knowledge has also been mined from Wikipedia for measuring the semantic relatedness of two NPs, NPj and NPk (Ponzetto and Strube (2006a; 2007)), such as: whether NPj/k appears in the first paragraph of the Wiki page that has NPk/j as the title or in the list of categories to which this page belongs, and the degree of overlap between the two pages that have the two NPs as their titles (see CITATION for other uses of encyclopedic knowledge for coreference resolution),,
Contextual roles (Bean and Riloff, 2004), semantic relations (Ji et al., 2005), semantic roles (CITATIONb; Kong et al., 2009), and animacy CITATION have also been exploited to improve coreference resolution,,
e passed since the first paper on learning-based coreference resolution was published CITATION,,
Note that several leading coreference researchers have published books (e.g., CITATION), written survey articles (e.g., CITATION, CITATION), and delivered tutorials (e.g., CITATION, CITATION) that provide a broad overview of coreference research,,
Semantic knowledge has also been extracted from WordNet and unannotated corpora for computing the semantic compatibility/similarity between two common nouns (Harabagiu et al., 2001; CITATION) as well as the semantic class of a noun (CITATIONa; Huang et al., 2009),,
Some researchers simply use the first sense CITATION or all possible senses (CITATIONa), while others overcome this problem with word sense disambiguation CITATION,,
Knowledge has also been mined from Wikipedia for measuring the semantic relatedness of two NPs, NPj and NPk (Ponzetto and Strube (2006a; 2007)), such as: whether NPj/k appears in the first paragraph of the Wiki page that has NPk/j as the title or in the list of categories to which this page belongs, and the degree of overlap between the two pages that have the two NPs as their titles (see CITATION for other uses of encyclopedic knowledge for coreference resolution),,
Semantic knowledge has also been extracted from WordNet and unannotated corpora for computing the semantic compatibility/similarity between two common nouns (Harabagiu et al., 2001; CITATION) as well as the semantic class of a noun (CITATIONa; Huang et al., 2009),,
Some researchers simply use the first sense CITATION or all possible senses (CITATIONa), while others overcome this problem with word sense disambiguation CITATION,,
Knowledge has also been mined from Wikipedia for measuring the semantic relatedness of two NPs, NPj and NPk (Ponzetto and Strube (2006a; 2007)), such as: whether NPj/k appears in the first paragraph of the Wiki page that has NPk/j as the title or in the list of categories to which this page belongs, and the degree of overlap between the two pages that have the two NPs as their titles (see CITATION for other uses of encyclopedic knowledge for coreference resolution),,
6 Concluding Remarks While we have focused our discussion on supervised approaches, coreference researchers have also attempted to reduce a resolvers reliance on annotated data by combining a small amount of labeled data and a large amount of unlabeled data using general-purpose semi-supervised learning algorithms such as co-training CITATION, self-training (CITATIONa), and EM (CITATION; CITATION),,
Interestingly, recent results indicate that unsupervised approaches to coreference resolution (e.g., Haghighi and Klein (2007; 2010), CITATION) rival their supervised counterparts, casting doubts on whether supervised resolvers are making effective use of the available labeled data,,
While many of the techniques discussed in this paper were originally developed for English, they have been applied to learn coreference models for other languages, such as Chinese (e.g., CITATION), Japanese (e.g., Iida (2007)), Arabic (e.g., CITATION), Dutch (e.g., Hoste (2005)), German (e.g., CITATION), Swedish (e.g., Nils,,
lems, two coreference scoring programs have been developed: B3 CITATION and CEAF CITATION,,
To apply these scorers to automatically extracted NPs, different methods have been proposed (see Rahman and CITATION and CITATION),,
Since coreference is a clustering task, any general-purpose method for evaluating a response partition against a key partition (e.g., Kappa (Carletta, 1996)) can be used for coreference scor1403 \x0cing (see CITATION),,
To ensure further progress, researchers should compare their results against a baseline that is stronger than the commonly-used CITATION system, which relies on a weak model (i.e., the mention-pair model) and a small set of linguistic features,,
Publicly available coreference systems currently include JavaRAP CITATION, GuiTaR CITATION, BART (CITATIONb), CoRTex (Denis and Baldridge, 2008), the Illinois Coreference Package (Bengtson and Roth, 2008), CherryPicker (Rahman and CITATION), Reconcile CITATION, and Charniak and Elsners (2009) pronoun resolver,,
(2001)), CITATIONa) present a method for mining easy positive instances, in an attempt to avoid the inclusion of hard training instances that may complicate the acquisition of an accurate coreference model,,
Decision tree induction systems (e.g., C5 CITATION) are the first and one of the most widely used learning algorithms by coreference researchers, although rule learners (e.g., RIPPER CITATION) and memory-based learners (e.g., TiMBL (Daelemans and Van den Bosch, 2005)) are also popular choices, especially in early applications of machine learning to coreference resolution,,
While mention rankers have consistently outperformed the mention-pair model (CITATION; Denis and Baldridge, 2007b), they are not more expressive than the mention-pair model, as they are unable to exploit cluster-level features, unlike the entitymention model,,
To enable rankers to employ cluster-level features, Rahman and CITATION propose the cluster-ranking model, which ranks preceding clusters, rather than candidate antecedents, for an NP to be resolved,,
To address these problems, two coreference scoring programs have been developed: B3 CITATION and CEAF CITATION,,
To apply these scorers to automatically extracted NPs, different methods have been proposed (see Rahman and CITATION and CITATION),,
Since coreference is a clustering task, any general-purpose method for evaluating a response partition against a key partition (e.g., Kappa (Carletta, 1996)) can be used for coreference scor1403 \x0cing (see CITATION),,
seline that is stronger than the commonly-used CITATION system, which relies on a weak model (i.e., the mention-pair model) and a small set of linguistic features,,
Publicly available coreference systems currently include JavaRAP CITATION, GuiTaR CITATION, BART (CITATIONb), CoRTex (Denis and Baldridge, 2008), the Illinois Coreference Package (Bengtson and Roth, 2008), CherryPicker (Rahman and CITATION), Reconcile CITATION, and Charniak and Elsners (2009) pronoun resolver,,
In particular, preprocessing tools can have a large impact on the performance of a resolver CITATION,,
These include (1) the English Penn Treebank CITATION, which is labeled with coreference links as part of the OntoNotes project (Hovy et al., 2006); (2) the Tubingen Treebank CITATION, which is a collection of German news articles consisting of 27,125 sentences; (3) the Prague Dependency Treebank (Hajic et al., 2006), which consists of 3168 news articles taken from the Czech National Corpus; (4) the NAIST Text Corpus (Iida et al., 2007b), which consists of 287 Japanese news articles; (5) the AnCora Corpus CITATION, which consists of Spanish and Catalan journalist texts; and (6) the GENIA corpus CITATION, which contains 2000 MEDLINE abstracts,,
Other publicly available coreference corpora of interest include two annotated by Ruslan Mitkovs research group: (1) a 55,000-word corpus in the domain of security/terrorism (Hasler et al., 2006); and (2) training data released as part of the 2007 Anaphora Resolution Exercise CITATION, a coreference resolution shared task,,
erest include two annotated by Ruslan Mitkovs research group: (1) a 55,000-word corpus in the domain of security/terrorism (Hasler et al., 2006); and (2) training data released as part of the 2007 Anaphora Resolution Exercise CITATION, a coreference resolution shared task,,
For instance, the SemEval-2010 shared task on Coreference Resolution in Multiple Languages CITATION has promised to release coreference data in six languages,,
Despite its simple task definition, coreference is generally considered a difficult NLP task, typically involving the use of sophisticated knowledge sources and inference procedures CITATION,,
Computational theories of discourse, in particular focusing (see Grosz (1977) and CITATION) and centering (Grosz et al,,
CITATION), have heavily influenced coreference research in the 1970s and 1980s, leading to the development of numerous centering algorithms (see Walker et al,,
CITATION),,
This shift can be attributed in part to the advent of the statistical NLP era, and in part to the public availability of annotated coreference corpora produced as part of the MUC-6 CITATION and MUC-7 CITATION conferences,,
Despite their simplicity, closest-first clustering CITATION and best-first clustering (CITATIONc) are arguably the most widely used coreference clustering algorithms,,
For example, CITATIONc) report that bestfirst clustering is better than closest-first clustering,,
CITATION show that bestfirst clustering performs similarly to Bell-treebased clustering, but neither of these algorithms 5 When applying closest-first and best-first clustering, CITATION and CITATIONc) also process the NPs in a sequential manner, but since the later decisions are not dependent on the earlier ones, the order in which the NPs are processed does not affect their clustering results,,
Semantic knowledge has also been extracted from WordNet and unannotated corpora for computing the semantic compatibility/similarity between two common nouns (Harabagiu et al., 2001; CITATION) as well as the semantic class of a noun (CITATIONa; Huang et al., 2009),,
Some researchers simply use the first sense CITATION or all possible senses (CITATIONa), while others overcome this problem with word sense disambiguation CITATION,,
Knowledge has also been mined from Wikipedia for measuring the semantic relatedness of two NPs, NPj and NPk (Ponzetto and Strube (2006a; 2007)), such as: whether NPj/k appears in the first paragraph of the Wiki page that has NPk/j as the title or in the list of categories to which this page belongs, and the degree of overlap between the two pages that have the two NPs as their titles (see CITATION for other uses of encyclopedic knowled,,
ch (e.g., Ngu .CITATION),,
(2007a), Zhao and CITATION),,
As CITATION puts it, coreference resolution is a difficult, but not intractable problem, and we have been making slow, but steady progress on improving machine learning approaches to the problem in the past fifteen years,,
To ensure further progress, researchers should compare their results against a baseline that is stronger than the commonly-used CITATION system, which relies on a weak model (i.e., the mention-pair model) and a small set of linguistic features,,
Publicly available coreference systems currently include JavaRAP CITATION, GuiTaR CITATION, BART (CITATIONb), CoRTex (Denis and Baldridge, 2008), the Illinois Coreference Package (Bengtson and Roth, 2008), CherryPicker (Rahman and CITATION), Reconcile CITATION, and Char,,
Owing in large part to the difference in the number of NPs extracted by these three methods, a coreference resolver can produce substantially different results when applied to the resulting three sets of NPs, with gold NPs yielding the best results and NPs extracted from a parser yielding the worst CITATION,,
While researchers who evaluate their resolvers on gold NPs point out that the results can more accurately reflect the performance of their coreference algorithm, CITATION argue that such evaluations are unrealistic, as NP extraction is an integral part of an end-to-end fully-automatic resolver,,
5.2 Scoring a Coreference Partition The MUC scorer CITATION is the first program developed for scoring coreference partitions,,
commonly-used CITATION system, which relies on a weak model (i.e., the mention-pair model) and a small set of linguistic features,,
Publicly available coreference systems currently include JavaRAP CITATION, GuiTaR CITATION, BART (CITATIONb), CoRTex (Denis and Baldridge, 2008), the Illinois Coreference Package (Bengtson and Roth, 2008), CherryPicker (Rahman and CITATION), Reconcile CITATION, and Charniak and Elsners (2009) pronoun resolver,,
In particular, preprocessing tools can have a large impact on the performance of a resolver CITATION,,
To further reduce class skewness, some researchers employ a filtering mechanism on top of an instance creation method, thereby disallowing the creation of training instances from NP pairs that are unlikely to be coreferent, such as NP pairs that violate gender and number agreement (e.g., CITATION, CITATION),,
While many instance creation methods are heuristic in nature (see CITATION and Hoste and Daelemans (2005)), some are learning-based,,
(2001)), CITATIONa) present a method for mining easy positive instances, in an attempt to avoid the inclusion of hard training instances that may complicate the acquisition of an accurate coreference model,,
Besides simple string-matching operations such as exact string match, substring match, and head noun match for different kinds of NPs (see Daume III and Marcu (2005)), slightly more sophisticated stringmatching facilities have been attempted, including minimum edit distance CITATION and longest common subsequence (Castano et al., 2002),,
CITATIONa) treat the two NPs involved as two bags of words, and compute their similarity using metrics commonly-used in information retrieval, such as the dot product, with each word weighted by their TF-IDF value,,
CITATION implement 1401 \x0ca Hobbs distance feature, which encodes the rank assigned to a candidate antecedent for a pronoun by Hobbss (1978) seminal syntax-based pronoun resolution algorithm,,
CITATION extract features from a parse ,,
fteen years have passed since the first paper on learning-based coreference resolution was published CITATION,,
Note that several leading coreference researchers have published books (e.g., CITATION), written survey articles (e.g., CITATION, CITATION), and delivered tutorials (e.g., CITATION, CITATION) that provide a broad overview of coreference research,,
Fifteen years have passed since the first paper on learning-based coreference resolution was published CITATION,,
Note that several leading coreference researchers have published books (e.g., CITATION), written survey articles (e.g., CITATION, CITATION), and delivered tutorials (e.g., CITATION, CITATION) that provide a broad overview of coreference research,,
These include (1) the English Penn Treebank CITATION, which is labeled with coreference links as part of the OntoNotes project (Hovy et al., 2006); (2) the Tubingen Treebank CITATION, which is a collection of German news articles consisting of 27,125 sentences; (3) the Prague Dependency Treebank (Hajic et al., 2006), which consists of 3168 news articles taken from the Czech National Corpus; (4) the NAIST Text Corpus (Iida et al., 2007b), which consists of 287 Japanese news articles; (5) the AnCora Corpus CITATION, which consists of Spanish and Catalan journalist texts; and (6) the GENIA corpus CITATION, which contains 2000 MEDLINE abstracts,,
It is worth noting that CITATION has employed Grosz and Sidners (1986) discourse theory and Veins Theory (Ide and Cristea, 2000) to identify and remove candidate antecedents that are not referentially accessible to an anaphoric pronoun in his heuristic pronoun resolvers,,
.g., Evans (2001), CITATION, CITATIONa)), and distributional methods (e.g., Bergsma et al,,
(2008)); and non-anaphoric definite descriptions have been identified using rule-based techniques (e.g., CITATION) and unsupervised techniques (e.g., Bean and Riloff (1999)),,
Recently, anaphoricity determination has been evaluated in the context of coreference resolution, with results showing that training an anaphoricity classifier to identify and filter non-anaphoric NPs prior to coreference resolution can improve a learning-based resolver (e.g., CITATIONb), CITATION, CITATIONb)),,
Examples of such approaches have exploited techniques including integer linear programming (ILP) (Denis and Baldridge, 2007a), label propagation CITATION, and minimum cuts CITATION,,
To further reduce class skewness, some researchers employ a filtering mechanism on top of an instance creation method, thereby disallowing the creation of training instances from NP pairs that are unlikely to be coreferent, such as NP pairs that violate gender and number agreement (e.g., CITATION, CITATION),,
While many instance creation methods are heuristic in nature (see CITATION and Hoste and Daelemans (2005)), some are learning-based,,
(2001)), CITATIONa) present a method for mining easy positive instances, in an attempt to avoid the inclusion of hard training instances that may complicate the acquisition of an accurate coreference model,,
For example, pleonastic it has been identified using heuristic approaches (e.g., CITATION, CITATION, Kennedy and Boguraev (1996)), supervised approaches (e.g., Evans (2001), CITATION, CITATIONa)), and distributional methods (e.g., Bergsma et al,,
(2008)); and non-anaphoric definite descriptions have been identified using rule-based techniques (e.g., CITATION) and unsupervised techniques (e.g., Bean and Riloff (1999)),,
Recently, anaphoricity determination has been evaluated in the context of coreference resolution, with results showing that training an anaphoricity classifier to identify and filter non-anaphoric NPs prior to coreference resolution can improve a learning-based resolver (e.g., CITATIONb), CITATION, CITATIONb)),,
To ensure further progress, researchers should compare their results against a baseline that is stronger than the commonly-used CITATION system, which relies on a weak model (i.e., the mention-pair model) and a small set of linguistic features,,
Publicly available coreference systems currently include JavaRAP CITATION, GuiTaR CITATION, BART (CITATIONb), CoRTex (Denis and Baldridge, 2008), the Illinois Coreference Package (Bengtson and Roth, 2008), CherryPicker (Rahman and CITATION), Reconcile CITATION, and Charniak and Elsners (2009) pronoun resolver,,
For example, pleonastic it has been identified using heuristic approaches (e.g., CITATION, CITATION, Kennedy and Boguraev (1996)), supervised approaches (e.g., Evans (2001), CITATION, CITATIONa)), and distributional methods (e.g., Bergsma et al,,
(2008)); and non-anaphoric definite descriptions have been identified using rule-based techniques (e.g., CITATION) and unsupervised techniques (e.g., Bean and Riloff (1999)),,
Recently, anaphoricity determination has been evaluated in the context of coreference resolution, with results showing that training an anaphoricity classifier to identify and filter non-anaphoric NPs prior to coreference resolution can improve a learning-based resolver (e.g., CITATIONb), CITATION, CITATIONb)),,
To ensure further progress, researchers should compare their results against a baseline that is stronger than the commonly-used CITATION system, which relies on a weak model (i.e., the mention-pair model) and a small set of linguistic features,,
Publicly available coreference systems currently include JavaRAP CITATION, GuiTaR CITATION, BART (CITATIONb), CoRTex (Denis and Baldridge, 2008), the Illinois Coreference Package (Bengtson and Roth, 2008), CherryPicker (Rahman and CITATION), Reconcile CITATION, and Charniak and Elsners (2009) pronoun resolver,,
(2003) and the twin-candidate model by CITATION; 2008b),,
While mention rankers have consistently outperformed the mention-pair model (CITATION; Denis and Baldridge, 2007b), they are not more expressive than the mention-pair model, as they are unable to exploit cluster-level features, unlike the entitymention model,,
To enable rankers to employ cluster-level features, Rahman and CITATION propose the cluster-ranking model, which ranks preceding clusters, rather than candidate antecedents, for an NP to be resolved,,
One of the earliest kinds of semantic knowledge employed for coreference resolution is perhaps selectional preference (CITATION; CITATIONb; CITATION; Haghighi and Klein, 2009): given a pronoun to be resolved, its governing verb, and its grammatical role, we prefer a candidate antecedent that can be governed by the same verb and be in the same role,,
Semantic knowledge has also been extracted from WordNet and unannotated corpora for computing the semantic compatibility/similarity between two common nouns (Harabagiu et al., 2001; CITATION) as well as the semantic class of a noun (CITATIONa; Huang et al., 2009),,
Some researchers simply use the first sense CITATION or all possible senses (CITATIONa), while others overcome this problem with word sense disambiguation CITATION,,
For example, pleonastic it has been identified using heuristic approaches (e.g., CITATION, CITATION, Kennedy and Boguraev (1996)), supervised approaches (e.g., Evans (2001), CITATION, CITATIONa)), and distributional methods (e.g., Bergsma et al,,
(2008)); and non-anaphoric definite descriptions have been identified using rule-based techniques (e.g., CITATION) and unsupervised techniques (e.g., Bean and Riloff (1999)),,
Recently, anaphoricity determination has been evaluated in the context of coreference resolution, with results showing that training an anaphoricity classifier to identify and filter non-anaphoric NPs prior to coreference resolution can improve a learning-based resolver (e.g., CITATIONb), CITATION, CITATIONb)),,
While researchers who evaluate their resolvers on gold NPs point out that the results can more accurately reflect the performance of their coreference algorithm, CITATION argue that such evaluations are unrealistic, as NP extraction is an integral part of an end-to-end fully-automatic resolver,,
5.2 Scoring a Coreference Partition The MUC scorer CITATION is the first program developed for scoring coreference partitions,,
To address these problems, two coreference scoring programs have been developed: B3 CITATION and CEAF CITATION,,
Despite its simple task definition, coreference is generally considered a difficult NLP task, typically involving the use of sophisticated knowledge sources and inference procedures CITATION,,
Computational theories of discourse, in particular focusing (see Grosz (1977) and CITATION) and centering (Grosz et al,,
CITATION), have heavily influenced coreference research in the 1970s and 1980s, leading to the development of numerous centering algorithms (see Walker et al,,
CITATION),,
This shift can be attributed in part to the advent of the statistical NLP era, and in part to the public availability of annotated coreference corpora produced as part of the MUC-6 CITATION and MUC-7 CITATION conferences,,
CITATION),,
Ranking is first applied to learning-based coreference resolution by CITATION; 1997), where a model is trained to rank two candidate antecedents,,
(2003) and the twin-candidate model by CITATION; 2008b),,
xact string match, substring match, and head noun match for different kinds of NPs (see Daume III and Marcu (2005)), slightly more sophisticated stringmatching facilities have been attempted, including minimum edit distance CITATION and longest common subsequence (Castano et al., 2002),,
CITATIONa) treat the two NPs involved as two bags of words, and compute their similarity using metrics commonly-used in information retrieval, such as the dot product, with each word weighted by their TF-IDF value,,
CITATION implement 1401 \x0ca Hobbs distance feature, which encodes the rank assigned to a candidate antecedent for a pronoun by Hobbss (1978) seminal syntax-based pronoun resolution algorithm,,
CITATION extract features from a parse tree for implementing Binding Constraints CITATION,,
07; 2010), CITATION) rival their supervised counterparts, casting doubts on whether supervised resolvers are making effective use of the available labeled data,,
While many of the techniques discussed in this paper were originally developed for English, they have been applied to learn coreference models for other languages, such as Chinese (e.g., CITATION), Japanese (e.g., Iida (2007)), Arabic (e.g., CITATION), Dutch (e.g., Hoste (2005)), German (e.g., CITATION), Swedish (e.g., CITATION), and Czech (e.g., Ngu .CITATION),,
(2007a), Zhao and CITATION),,
As CITATION puts it, coreference resolution is a difficult, but not intractable problem, and we have been making slow, but steady progress on improving machine learning approaches to the problem in the past fifteen years,,
This technique has been applied to resolve different kinds of anaphoric references, including other-anaphora (CITATION; CITATION) and bridging references (CITATIONa),,
While these patterns are typically hand-crafted (e.g., Garera and Yarowsky (2006)), they can also be learned from an annotated corpus CITATION or bootstrapped from an unannotated corpus (Bean and Riloff, 2004),,
To further reduce class skewness, some researchers employ a filtering mechanism on top of an instance creation method, thereby disallowing the creation of training instances from NP pairs that are unlikely to be coreferent, such as NP pairs that violate gender and number agreement (e.g., CITATION, CITATION),,
While many instance creation methods are heuristic in nature (see CITATION and Hoste and Daelemans (2005)), some are learning-based,,
(2001)), CITATIONa) present a method for mining easy positive instances, in an attempt to avoid the inclusion of hard training instances that may complicate the acquisition of an accurate coreference model,,
CITATION),,
Ranking is first applied to learning-based coreference resolution by CITATION; 1997), where a model is trained to rank two candidate antecedents,,
(2003) and the twin-candidate model by CITATION; 2008b),,
While mention rankers have consistently outperformed the mention-pair model (CITATION; Denis and Baldridge, 2007b), they are not more expressive than the mention-pair model, as they are unable to exploit cluster-level features, unlike t,,
In particular, preprocessing tools can have a large impact on the performance of a resolver CITATION,,
To our knowledge, however, the best results on the MUC-6 and MUC-7 data sets using automatically extracted NPs are reported by CITATION (71.3 MUC F-score) and CITATIONc) (63.4 MUC F-score), respectively;8 and the best results on the ACE data sets using gold NPs can be found in CITATION (88.4 ACE-value),,
For example, CITATION apply the ANY predicate to generate cluster-level features for their entity-mention model, which does not perform as well as the mention-pair model,,
CITATIONb; 2008a) also investigate the entity-mention model, which produces results that are only marginally better than those of the mention-pair model,,
For example, CITATION present a first-order logic model that determines 1400 \x0cthe probability that an arbitrary set of NPs are all co-referring,,
Besides simple string-matching operations such as exact string match, substring match, and head noun match for different kinds of NPs (see Daume III and Marcu (2005)), slightly more sophisticated stringmatching facilities have been attempted, including minimum edit distance CITATION and longest common subsequence (Castano et al., 2002),,
CITATIONa) treat the two NPs involved as two bags of words, and compute their similarity using metrics commonly-used in information retrieval, such as the dot product, with each word weighted by their TF-IDF value,,
CITATION implement 1401 \x0ca Hobbs distance feature, which encodes the rank assigned to a candidate antecedent for a pronoun by Hobbss (1978) seminal syntax-based pronoun resolution algorithm,,
CITATION extract features from a parse tree for implementing Binding Constraints CITATION,,
For example, CITATION apply the ANY predicate to generate cluster-level features for their entity-mention model, which does not perform as well as the mention-pair model,,
CITATIONb; 2008a) also investigate the entity-mention model, which produces results that are only marginally better than those of the mention-pair model,,
For example, CITATION present a first-order logic model that determines 1400 \x0cthe probability that an arbitrary set of NPs are all co-referring,,
Besides simple string-matching operations such as exact string match, substring match, and head noun match for different kinds of NPs (see Daume III and Marcu (2005)), slightly more sophisticated stringmatching facilities have been attempted, including minimum edit distance CITATION and longest common subsequence (Castano et al., 2002),,
CITATIONa) treat the two NPs involved as two bags of words, and compute their similarity using metrics commonly-used in information retrieval, such as the dot product, with each word weighted by their TF-IDF value,,
CITATION implement 1401 \x0ca Hobbs distance feature, which encodes the rank assigned to a candidate antecedent for a pronoun by Hobbss (1978) seminal syntax-based pronoun resolution algorithm,,
CITATION extract features from a parse tree for implementing Binding Constraints CITATION,,
One of the earliest kinds of semantic knowledge employed for coreference resolution is perhaps selectional preference (CITATION; CITATIONb; CITATION; Haghighi and Klein, 2009): given a pronoun to be resolved, its governing verb, and its grammatical role, we prefer a candidate antecedent that can be governed by the same verb and be in the same role,,
Semantic knowledge has also been extracted from WordNet and unannotated corpora for computing the semantic compatibility/similarity between two common nouns (Harabagiu et al., 2001; CITATION) as well as the semantic class of a noun (CITATIONa; Huang et al., 2009),,
CITATION extract features from a parse tree for implementing Binding Constraints CITATION,,
(2006) and CITATION employ these trees directly as structured features for pronoun resolution,,
Correlation clustering CITATION, which produces a partition that respects as many pairwise decisions as possible, is used by McCallum and Wellner (2004), CITATION, and Finley and Joachims (2005),,
While many of the techniques discussed in this paper were originally developed for English, they have been applied to learn coreference models for other languages, such as Chinese (e.g., CITATION), Japanese (e.g., Iida (2007)), Arabic (e.g., CITATION), Dutch (e.g., Hoste (2005)), German (e.g., CITATION), Swedish (e.g., CITATION), and Czech (e.g., Ngu .CITATION),,
(2007a), Zhao and CITATION),,
As CITATION puts it, coreference resolution is a difficult, but not intractable problem, and we have been making slow, but steady progress on improving machine learning approaches to the problem in the past fifteen years,,
To ensure further progress, researchers should compare their results against a baseline that is stronger than the commonly-used CITATION system, which relies on a weak model (i.e., the mention-pair model) and a small set of linguistic features,,
 showing that training an anaphoricity classifier to identify and filter non-anaphoric NPs prior to coreference resolution can improve a learning-based resolver (e.g., CITATIONb), CITATION, CITATIONb)),,
Examples of such approaches have exploited techniques including integer linear programming (ILP) (Denis and Baldridge, 2007a), label propagation CITATION, and minimum cuts CITATION,,
