<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<bodyText confidence="0.428808">
b&apos;Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 13961411,
Uppsala, Sweden, 11-16 July 2010. c
</bodyText>
<sectionHeader confidence="0.340309" genericHeader="abstract">
2010 Association for Computational Linguistics
</sectionHeader>
<title confidence="0.805443">
Supervised Noun Phrase Coreference Research: The First Fifteen Years
</title>
<author confidence="0.895593">
Vincent Ng
</author>
<affiliation confidence="0.8767915">
Human Language Technology Research Institute
University of Texas at Dallas
</affiliation>
<address confidence="0.961849">
Richardson, TX 75083-0688
</address>
<email confidence="0.996647">
vince@hlt.utdallas.edu
</email>
<sectionHeader confidence="0.99071" genericHeader="keywords">
Abstract
</sectionHeader>
<bodyText confidence="0.999401428571429">
The research focus of computational
coreference resolution has exhibited a
shift from heuristic approaches to machine
learning approaches in the past decade.
This paper surveys the major milestones in
supervised coreference research since its
inception fifteen years ago.
</bodyText>
<sectionHeader confidence="0.998084" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998587515151515">
Noun phrase (NP) coreference resolution, the task
of determining which NPs in a text or dialogue re-
fer to the same real-world entity, has been at the
core of natural language processing (NLP) since
the 1960s. NP coreference is related to the task
of anaphora resolution, whose goal is to identify
an antecedent for an anaphoric NP (i.e., an NP
that depends on another NP, specifically its an-
tecedent, for its interpretation) [see van Deemter
and Kibble (2000) for a detailed discussion of the
difference between the two tasks]. Despite its sim-
ple task definition, coreference is generally con-
sidered a difficult NLP task, typically involving
the use of sophisticated knowledge sources and
inference procedures (Charniak, 1972). Compu-
tational theories of discourse, in particular focus-
ing (see Grosz (1977) and Sidner (1979)) and cen-
tering (Grosz et al. (1983; 1995)), have heavily
influenced coreference research in the 1970s and
1980s, leading to the development of numerous
centering algorithms (see Walker et al. (1998)).
The focus of coreference research underwent a
gradual shift from heuristic approaches to machine
learning approaches in the 1990s. This shift can
be attributed in part to the advent of the statisti-
cal NLP era, and in part to the public availability
of annotated coreference corpora produced as part
of the MUC-6 (1995) and MUC-7 (1998) confer-
ences. Learning-based coreference research has
remained vibrant since then, with results regularly
published not only in general NLP conferences,
but also in specialized conferences (e.g., the bien-
nial Discourse Anaphora and Anaphor Resolution
Colloquium (DAARC)) and workshops (e.g., the
series of Bergen Workshop on Anaphora Resolu-
tion (WAR)). Being inherently a clustering task,
coreference has also received a lot of attention in
the machine learning community.
Fifteen years have passed since the first paper
on learning-based coreference resolution was pub-
lished (Connolly et al., 1994). Our goal in this
paper is to provide NLP researchers with a sur-
vey of the major milestones in supervised coref-
erence research, focusing on the computational
models, the linguistic features, the annotated cor-
pora, and the evaluation metrics that were devel-
oped in the past fifteen years. Note that several
leading coreference researchers have published
books (e.g., Mitkov (2002)), written survey arti-
cles (e.g., Mitkov (1999), Strube (2009)), and de-
livered tutorials (e.g., Strube (2002), Ponzetto and
Poesio (2009)) that provide a broad overview of
coreference research. This survey paper aims to
complement, rather than supersede, these previ-
ously published materials. In particular, while ex-
isting survey papers discuss learning-based coref-
erence research primarily in the context of the in-
fluential mention-pair model, we additionally sur-
vey recently proposed learning-based coreference
models, which attempt to address the weaknesses
of the mention-pair model. Due to space limita-
tions, however, we will restrict our discussion to
the most commonly investigated kind of corefer-
ence relation: the identity relation for NPs, exclud-
ing coreference among clauses and bridging refer-
ences (e.g., part/whole and set/subset relations).
</bodyText>
<sectionHeader confidence="0.992656" genericHeader="method">
2 Annotated Corpora
</sectionHeader>
<bodyText confidence="0.996724">
The widespread popularity of machine learning
approaches to coreference resolution can be at-
tributed in part to the public availability of an-
</bodyText>
<page confidence="0.959493">
1396
</page>
<bodyText confidence="0.991656">
\x0cnotated coreference corpora. The MUC-6 and
MUC-7 corpora, though relatively small (60 doc-
uments each) and homogeneous w.r.t. document
type (newswire articles only), have been exten-
sively used for training and evaluating coreference
models. Equally popular are the corpora produced
by the Automatic Content Extraction (ACE1) eval-
uations in the past decade: while the earlier ACE
corpora (e.g., ACE-2) consist of solely English
newswire and broadcast news articles, the later
ones (e.g., ACE 2005) have also included Chi-
nese and Arabic documents taken from additional
sources such as broadcast conversations, webblog,
usenet, and conversational telephone speech.
Coreference annotations are also publicly avail-
able in treebanks. These include (1) the English
Penn Treebank (Marcus et al., 1993), which is la-
beled with coreference links as part of the Onto-
Notes project (Hovy et al., 2006); (2) the Tubingen
Treebank (Telljohann et al., 2004), which is a
collection of German news articles consisting of
27,125 sentences; (3) the Prague Dependency
Treebank (Hajic et al., 2006), which consists of
3168 news articles taken from the Czech National
Corpus; (4) the NAIST Text Corpus (Iida et al.,
2007b), which consists of 287 Japanese news arti-
cles; (5) the AnCora Corpus (Recasens and Mart,
2009), which consists of Spanish and Catalan jour-
nalist texts; and (6) the GENIA corpus (Ohta et al.,
2002), which contains 2000 MEDLINE abstracts.
Other publicly available coreference corpora of
interest include two annotated by Ruslan Mitkovs
research group: (1) a 55,000-word corpus in
the domain of security/terrorism (Hasler et al.,
2006); and (2) training data released as part of the
2007 Anaphora Resolution Exercise (Orasan et al.,
2008), a coreference resolution shared task. There
are also two that consist of spoken dialogues: the
TRAINS93 corpus (Heeman and Allen, 1995) and
the Switchboard data set (Calhoun et al., in press).
Additional coreference data will be available in
the near future. For instance, the SemEval-2010
shared task on Coreference Resolution in Multiple
Languages (Recasens et al., 2009) has promised to
release coreference data in six languages. In addi-
tion, Massimo Poesio and his colleagues are lead-
ing an annotation project that aims to collect large
amounts of coreference data for English via a Web
Collaboration game called Phrase Detectives2.
</bodyText>
<footnote confidence="0.50276375">
1
http://www.itl.nist.gov/iad/mig/tests/ace/
2
http://www.phrasedetectives.org
</footnote>
<sectionHeader confidence="0.820044" genericHeader="method">
3 Learning-Based Coreference Models
</sectionHeader>
<bodyText confidence="0.9905845">
In this section, we examine three important classes
of coreference models that were developed in the
past fifteen years, namely, the mention-pair model,
the entity-mention model, and ranking models.
</bodyText>
<subsectionHeader confidence="0.806007">
3.1 Mention-Pair Model
</subsectionHeader>
<bodyText confidence="0.999722378378378">
The mention-pair model is a classifier that deter-
mines whether two NPs are coreferent. It was
first proposed by Aone and Bennett (1995) and
McCarthy and Lehnert (1995), and is one of the
most influential learning-based coreference mod-
els. Despite its popularity, this binary classifica-
tion approach to coreference is somewhat undesir-
able: the transitivity property inherent in the coref-
erence relation cannot be enforced, as it is possible
for the model to determine that A and B are coref-
erent, B and C are coreferent, but A and C are not
coreferent. Hence, a separate clustering mecha-
nism is needed to coordinate the pairwise classifi-
cation decisions made by the model and construct
a coreference partition.
Another issue that surrounds the acquisition of
the mention-pair model concerns the way train-
ing instances are created. Specifically, to deter-
mine whether a pair of NPs is coreferent or not,
the mention-pair model needs to be trained on a
data set where each instance represents two NPs
and possesses a class value that indicates whether
the two NPs are coreferent. Hence, a natural way
to assemble a training set is to create one instance
from each pair of NPs appearing in a training doc-
ument. However, this instance creation method is
rarely employed: as most NP pairs in a text are not
coreferent, this method yields a training set with a
skewed class distribution, where the negative in-
stances significantly outnumber the positives.
As a result, in practical implementations of the
mention-pair model, one needs to specify not only
the learning algorithm for training the model and
the linguistic features for representing an instance,
but also the training instance creation method for
reducing class skewness and the clustering algo-
rithm for constructing a coreference partition.
</bodyText>
<subsubsectionHeader confidence="0.828419">
3.1.1 Creating Training Instances
</subsubsectionHeader>
<bodyText confidence="0.99653">
As noted above, the primary purpose of train-
ing instance creation is to reduce class skewness.
Many heuristic instance creation methods have
been proposed, among which Soon et al.s (1999;
2001) is arguably the most popular choice. Given
</bodyText>
<page confidence="0.95595">
1397
</page>
<bodyText confidence="0.998425787878788">
\x0can anaphoric noun phrase3, NPk, Soon et al.s
method creates a positive instance between NPk
and its closest preceding antecedent, NPj, and a
negative instance by pairing NPk with each of the
intervening NPs, NPj+1, . . ., NPk1.
With an eye towards improving the precision of
a coreference resolver, Ng and Cardie (2002c) pro-
pose an instance creation method that involves a
single modification to Soon et al.s method: if NPk
is non-pronominal, a positive instance should be
formed between NPk and its closest preceding non-
pronominal antecedent instead. This modification
is motivated by the observation that it is not easy
for a human, let alone a machine learner, to learn
from a positive instance where the antecedent of a
non-pronominal NP is a pronoun.
To further reduce class skewness, some re-
searchers employ a filtering mechanism on top of
an instance creation method, thereby disallowing
the creation of training instances from NP pairs
that are unlikely to be coreferent, such as NP pairs
that violate gender and number agreement (e.g.,
Strube et al. (2002), Yang et al. (2003)).
While many instance creation methods are
heuristic in nature (see Uryupina (2004) and Hoste
and Daelemans (2005)), some are learning-based.
For example, motivated by the fact that some
coreference relations are harder to identify than
the others (see Harabagiu et al. (2001)), Ng and
Cardie (2002a) present a method for mining easy
positive instances, in an attempt to avoid the inclu-
sion of hard training instances that may complicate
the acquisition of an accurate coreference model.
</bodyText>
<subsectionHeader confidence="0.704243">
3.1.2 Training a Coreference Classifier
</subsectionHeader>
<bodyText confidence="0.994565307692308">
Once a training set is created, we can train a coref-
erence model using an off-the-shelf learning algo-
rithm. Decision tree induction systems (e.g., C5
(Quinlan, 1993)) are the first and one of the most
widely used learning algorithms by coreference
researchers, although rule learners (e.g., RIPPER
(Cohen, 1995)) and memory-based learners (e.g.,
TiMBL (Daelemans and Van den Bosch, 2005))
are also popular choices, especially in early appli-
cations of machine learning to coreference resolu-
tion. In recent years, statistical learners such as
maximum entropy models (Berger et al., 1996),
voted perceptrons (Freund and Schapire, 1999),
</bodyText>
<page confidence="0.990978">
3
</page>
<bodyText confidence="0.999779909090909">
In this paper, we use the term anaphoric to describe any
NP that is part of a coreference chain but is not the head of
the chain. Hence, proper names can be anaphoric under this
overloaded definition, but linguistically, they are not.
and support vector machines (Joachims, 1999)
have been increasingly used, in part due to their
ability to provide a confidence value (e.g., in the
form of a probability) associated with a classifica-
tion, and in part due to the fact that they can be
easily adapted to train recently proposed ranking-
based coreference models (see Section 3.3).
</bodyText>
<subsubsectionHeader confidence="0.452957">
3.1.3 Generating an NP Partition
</subsubsectionHeader>
<bodyText confidence="0.999271634146341">
After training, we can apply the resulting model
to a test text, using a clustering algorithm to co-
ordinate the pairwise classification decisions and
impose an NP partition. Below we describe some
commonly used coreference clustering algorithms.
Despite their simplicity, closest-first cluster-
ing (Soon et al., 2001) and best-first clustering
(Ng and Cardie, 2002c) are arguably the most
widely used coreference clustering algorithms.
The closest-first clustering algorithm selects as the
antecedent for an NP, NPk, the closest preceding
noun phrase that is classified as coreferent with it.4
However, if no such preceding noun phrase exists,
no antecedent is selected for NPk. The best-first
clustering algorithm aims to improve the precision
of closest-first clustering, specifically by selecting
as the antecedent of NPk the most probable preced-
ing NP that is classified as coreferent with it.
One criticism of the closest-first and best-first
clustering algorithms is that they are too greedy.
In particular, clusters are formed based on a small
subset of the pairwise decisions made by the
model. Moreover, positive pairwise decisions are
unjustifiably favored over their negative counter-
parts. For example, three NPs are likely to end up
in the same cluster in the resulting partition even if
there is strong evidence that A and C are not coref-
erent, as long as the other two pairs (i.e., (A,B) and
(B,C)) are classified as positive.
Several algorithms that address one or both of
these problems have been used for coreference
clustering. Correlation clustering (Bansal et al.,
2002), which produces a partition that respects
as many pairwise decisions as possible, is used
by McCallum and Wellner (2004), Zelenko et al.
(2004), and Finley and Joachims (2005). Graph
partitioning algorithms are applied on a weighted,
undirected graph where a vertex corresponds to
an NP and an edge is weighted by the pairwise
coreference scores between two NPs (e.g., Mc-
Callum and Wellner (2004), Nicolae and Nico-
</bodyText>
<page confidence="0.988048">
4
</page>
<bodyText confidence="0.9995905">
If a probabilistic model is used, we can define a threshold
above which a pair of NPs is considered coreferent.
</bodyText>
<page confidence="0.975831">
1398
</page>
<bodyText confidence="0.997009446808511">
\x0clae (2006)). The Dempster-Shafer rule (Dempster,
1968), which combines the positive and negative
pairwise decisions to score a partition, is used by
Kehler (1997) and Bean and Riloff (2004) to iden-
tify the most probable NP partition.
Some clustering algorithms bear a closer resem-
blance to the way a human creates coreference
clusters. In these algorithms, not only are the NPs
in a text processed in a left-to-right manner, the
later coreference decisions are dependent on the
earlier ones (Cardie and Wagstaff, 1999; Klenner
and Ailloud, 2008).5 For example, to resolve an
NP, NPk, Cardie and Wagstaffs algorithm consid-
ers each preceding NP, NPj, as a candidate an-
tecedent in a right-to-left order. If NPk and NPj
are likely to be coreferent, the algorithm imposes
an additional check that NPk does not violate any
constraint on coreference (e.g., gender agreement)
with any NP in the cluster containing NPj before
positing that the two NPs are coreferent.
Luo et al.s (2004) Bell-tree-based algorithm is
another clustering algorithm where the later coref-
erence decisions are dependent on the earlier ones.
A Bell tree provides an elegant way of organizing
the space of NP partitions. Informally, a node in
the ith level of a Bell tree corresponds to an ith-
order partial partition (i.e., a partition of the first
i NPs of the given document), and the ith level of
the tree contains all possible ith-order partial parti-
tions. Hence, a leaf node contains a complete par-
tition of the NPs, and the goal is to search for the
leaf node that contains the most probable partition.
The search starts at the root, and a partitioning of
the NPs is incrementally constructed as we move
down the tree. Specifically, based on the corefer-
ence decisions it has made in the first i1 levels of
the tree, the algorithm determines at the ith level
whether the ith NP should start a new cluster, or to
which preceding cluster it should be assigned.
While many coreference clustering algorithms
have been developed, there have only been a few
attempts to compare their effectiveness. For ex-
ample, Ng and Cardie (2002c) report that best-
first clustering is better than closest-first cluster-
ing. Nicolae and Nicolae (2006) show that best-
first clustering performs similarly to Bell-tree-
based clustering, but neither of these algorithms
</bodyText>
<page confidence="0.980474">
5
</page>
<bodyText confidence="0.995767428571429">
When applying closest-first and best-first clustering,
Soon et al. (2001) and Ng and Cardie (2002c) also process
the NPs in a sequential manner, but since the later decisions
are not dependent on the earlier ones, the order in which the
NPs are processed does not affect their clustering results.
performs as well as their proposed minimum-cut-
based graph partitioning algorithm.
</bodyText>
<subsubsectionHeader confidence="0.403986">
3.1.4 Determining NP Anaphoricity
</subsubsectionHeader>
<bodyText confidence="0.999366828571429">
While coreference clustering algorithms attempt
to resolve each NP encountered in a document,
only a subset of the NPs are anaphoric and there-
fore need to be resolved. Hence, knowledge of the
anaphoricity of an NP can potentially improve the
precision of a coreference resolver.
Traditionally, the task of anaphoricity determi-
nation has been tackled independently of corefer-
ence resolution using a variety of techniques. For
example, pleonastic it has been identified using
heuristic approaches (e.g., Paice and Husk (1987),
Lappin and Leass (1994), Kennedy and Bogu-
raev (1996)), supervised approaches (e.g., Evans
(2001), Muller (2006), Versley et al. (2008a)),
and distributional methods (e.g., Bergsma et al.
(2008)); and non-anaphoric definite descriptions
have been identified using rule-based techniques
(e.g., Vieira and Poesio (2000)) and unsupervised
techniques (e.g., Bean and Riloff (1999)).
Recently, anaphoricity determination has been
evaluated in the context of coreference resolution,
with results showing that training an anaphoric-
ity classifier to identify and filter non-anaphoric
NPs prior to coreference resolution can improve
a learning-based resolver (e.g., Ng and Cardie
(2002b), Uryupina (2003), Poesio et al. (2004b)).
Compared to earlier work on anaphoricity deter-
mination, recently proposed approaches are more
global in nature, taking into account the pair-
wise decisions made by the mention-pair model
when making anaphoricity decisions. Examples
of such approaches have exploited techniques in-
cluding integer linear programming (ILP) (Denis
and Baldridge, 2007a), label propagation (Zhou
and Kong, 2009), and minimum cuts (Ng, 2009).
</bodyText>
<subsubsectionHeader confidence="0.818288">
3.1.5 Combining Classification &amp; Clustering
</subsubsectionHeader>
<bodyText confidence="0.996907272727273">
From a learning perspective, a two-step approach
to coreference classification and clustering
is undesirable. Since the classification model
is trained independently of the clustering algo-
rithm, improvements in classification accuracy
do not guarantee corresponding improvements in
clustering-level accuracy. That is, overall perfor-
mance on the coreference task might not improve.
To address this problem, McCallum and Well-
ner (2004) and Finley and Joachims (2005) elimi-
nate the classification step entirely, treating coref-
</bodyText>
<page confidence="0.971538">
1399
</page>
<bodyText confidence="0.984274">
\x0cerence as a supervised clustering task where a sim-
ilarity metric is learned to directly maximize clus-
tering accuracy. Klenner (2007) and Finkel and
Manning (2008) use ILP to ensure that the pair-
wise classification decisions satisfy transitivity.6
</bodyText>
<subsubsectionHeader confidence="0.451396">
3.1.6 Weaknesses of the Mention-Pair Model
</subsubsectionHeader>
<bodyText confidence="0.999458086956522">
While many of the aforementioned algorithms
for clustering and anaphoricity determination have
been shown to improve coreference performance,
the underlying model with which they are used
in combination the mention-pair model re-
mains fundamentally weak. The model has two
commonly-cited weaknesses. First, since each
candidate antecedent for an anaphoric NP to be
resolved is considered independently of the oth-
ers, the model only determines how good a candi-
date antecedent is relative to the anaphoric NP, but
not how good a candidate antecedent is relative to
other candidates. In other words, it fails to answer
the question of which candidate antecedent is most
probable. Second, it has limitations in its expres-
siveness: the information extracted from the two
NPs alone may not be sufficient for making an in-
formed coreference decision, especially if the can-
didate antecedent is a pronoun (which is semanti-
cally empty) or a mention that lacks descriptive in-
formation such as gender (e.g., Clinton). Below
we discuss how these weaknesses are addressed by
the entity-mention model and ranking models.
</bodyText>
<subsectionHeader confidence="0.907742">
3.2 Entity-Mention Model
</subsectionHeader>
<bodyText confidence="0.9994685">
The entity-mention model addresses the expres-
siveness problem with the mention-pair model.
To motivate the entity-mention model, consider
an example taken from McCallum and Wellner
(2003), where a document consists of three NPs:
Mr. Clinton, Clinton, and she. The mention-
pair model may determine that Mr. Clinton and
Clinton are coreferent using string-matching
features, and that Clinton and she are coref-
erent based on proximity and lack of evidence for
gender and number disagreement. However, these
two pairwise decisions together with transitivity
imply that Mr. Clinton and she will end up in
the same cluster, which is incorrect due to gen-
der mismatch. This kind of error arises in part
because the later coreference decisions are not de-
pendent on the earlier ones. In particular, had the
model taken into consideration that Mr. Clinton
</bodyText>
<page confidence="0.993222">
6
</page>
<bodyText confidence="0.998423981132076">
Recently, however, Klenner and Ailloud (2009) have be-
come less optimistic about ILP approaches to coreference.
and Clinton were in the same cluster, it proba-
bly would not have posited that she and Clin-
ton are coreferent. The aforementioned Cardie
and Wagstaff algorithm attempts to address this
problem in a heuristic manner. It would be de-
sirable to learn a model that can classify whether
an NP to be resolved is coreferent with a preced-
ing, possibly partially-formed, cluster. This model
is commonly known as the entity-mention model.
Since the entity-mention model aims to classify
whether an NP is coreferent with a preceding clus-
ter, each of its training instances (1) corresponds
to an NP, NPk, and a preceding cluster, Cj, and
(2) is labeled with either POSITIVE or NEGATIVE,
depending on whether NPk should be assigned to
Cj. Consequently, we can represent each instance
by a set of cluster-level features (i.e., features that
are defined over an arbitrary subset of the NPs in
Cj). A cluster-level feature can be computed from
a feature employed by the mention-pair model by
applying a logical predicate. For example, given
the NUMBER AGREEMENT feature, which deter-
mines whether two NPs agree in number, we can
apply the ALL predicate to create a cluster-level
feature, which has the value YES if NPk agrees in
number with all of the NPs in Cj and NO other-
wise. Other commonly-used logical predicates for
creating cluster-level features include relaxed ver-
sions of the ALL predicate, such as MOST, which
is true if NPk agrees in number with more than half
of the NPs in Cj, and ANY, which is true as long as
NPk agrees in number with just one of the NPs in
Cj. The ability of the entity-mention model to em-
ploy cluster-level features makes it more expres-
sive than its mention-pair counterpart.
Despite its improved expressiveness, the entity-
mention model has not yielded particularly en-
couraging results. For example, Luo et al. (2004)
apply the ANY predicate to generate cluster-level
features for their entity-mention model, which
does not perform as well as the mention-pair
model. Yang et al. (2004b; 2008a) also investi-
gate the entity-mention model, which produces re-
sults that are only marginally better than those of
the mention-pair model. However, it appears that
they are not fully exploiting the expressiveness of
the entity-mention model, as cluster-level features
only comprise a small fraction of their features.
Variants of the entity-mention model have been
investigated. For example, Culotta et al. (2007)
present a first-order logic model that determines
</bodyText>
<page confidence="0.913316">
1400
</page>
<bodyText confidence="0.994341222222222">
\x0cthe probability that an arbitrary set of NPs are all
co-referring. Their model resembles the entity-
mention model in that it enables the use of cluster-
level features. Daume III and Marcu (2005) pro-
pose an online learning model for constructing
coreference chains in an incremental fashion, al-
lowing later coreference decisions to be made by
exploiting cluster-level features that are computed
over the coreference chains created thus far.
</bodyText>
<subsectionHeader confidence="0.99132">
3.3 Ranking Models
</subsectionHeader>
<bodyText confidence="0.999442666666667">
While the entity-mention model addresses the
expressiveness problem with the mention-pair
model, it does not address the other problem: fail-
ure to identify the most probable candidate an-
tecedent. Ranking models, on the other hand, al-
low us to determine which candidate antecedent
is most probable given an NP to be resolved.
Ranking is arguably a more natural reformula-
tion of coreference resolution than classification,
as a ranker allows all candidate antecedents to be
considered simultaneously and therefore directly
captures the competition among them. Another
desirable consequence is that there exists a nat-
ural resolution strategy for a ranking approach:
an anaphoric NP is resolved to the candidate an-
tecedent that has the highest rank. This contrasts
with classification-based approaches, where many
clustering algorithms have been employed to co-
ordinate the pairwise classification decisions, and
it is still not clear which of them is the best.
The notion of ranking candidate antecedents
can be traced back to centering algorithms, many
of which use grammatical roles to rank forward-
looking centers (see Walker et al. (1998)). Rank-
ing is first applied to learning-based coreference
resolution by Connolly et al. (1994; 1997), where
a model is trained to rank two candidate an-
tecedents. Each training instance corresponds to
the NP to be resolved, NPk, as well as two candi-
date antecedents, NPi and NPj, one of which is an
antecedent of NPk and the other is not. Its class
value indicates which of the two candidates is bet-
ter. This model is referred to as the tournament
model by Iida et al. (2003) and the twin-candidate
model by Yang et al. (2003; 2008b). To resolve an
NP during testing, one way is to apply the model to
each pair of its candidate antecedents, and the can-
didate that is classified as better the largest number
of times is selected as its antecedent.
Advances in machine learning have made it pos-
sible to train a mention ranker that ranks all of
the candidate antecedents simultaneously. While
mention rankers have consistently outperformed
the mention-pair model (Versley, 2006; Denis and
Baldridge, 2007b), they are not more expressive
than the mention-pair model, as they are unable
to exploit cluster-level features, unlike the entity-
mention model. To enable rankers to employ
cluster-level features, Rahman and Ng (2009) pro-
pose the cluster-ranking model, which ranks pre-
ceding clusters, rather than candidate antecedents,
for an NP to be resolved. Cluster rankers there-
fore address both weaknesses of the mention-pair
model, and have been shown to improve mention
rankers. Cluster rankers are conceptually similar
to Lappin and Leasss (1994) heuristic pronoun re-
solver, which resolves an anaphoric pronoun to the
most salient preceding cluster.
An important issue with ranking models that
we have eluded so far concerns the identification
of non-anaphoric NPs. As a ranker simply im-
poses a ranking on candidate antecedents or pre-
ceding clusters, it cannot determine whether an NP
is anaphoric (and hence should be resolved). To
address this problem, Denis and Baldridge (2008)
apply an independently trained anaphoricity clas-
sifier to identify non-anaphoric NPs prior to rank-
ing, and Rahman and Ng (2009) propose a model
that jointly learns coreference and anaphoricity.
</bodyText>
<sectionHeader confidence="0.980188" genericHeader="method">
4 Knowledge Sources
</sectionHeader>
<bodyText confidence="0.9997505">
Another thread of supervised coreference research
concerns the development of linguistic features.
Below we give an overview of these features.
String-matching features can be computed ro-
bustly and typically contribute a lot to the per-
formance of a coreference system. Besides sim-
ple string-matching operations such as exact string
match, substring match, and head noun match
for different kinds of NPs (see Daume III and
Marcu (2005)), slightly more sophisticated string-
matching facilities have been attempted, includ-
ing minimum edit distance (Strube et al., 2002)
and longest common subsequence (Castano et al.,
2002). Yang et al. (2004a) treat the two NPs in-
volved as two bags of words, and compute their
similarity using metrics commonly-used in infor-
mation retrieval, such as the dot product, with each
word weighted by their TF-IDF value.
Syntactic features are computed based on a
syntactic parse tree. Ge et al. (1998) implement
</bodyText>
<page confidence="0.874999">
1401
</page>
<bodyText confidence="0.997809656862745">
\x0ca Hobbs distance feature, which encodes the rank
assigned to a candidate antecedent for a pronoun
by Hobbss (1978) seminal syntax-based pronoun
resolution algorithm. Luo and Zitouni (2005) ex-
tract features from a parse tree for implement-
ing Binding Constraints (Chomsky, 1988). Given
an automatically parsed corpus, Bergsma and Lin
(2006) extract from each parse tree a dependency
path, which is represented as a sequence of nodes
and dependency labels connecting a pronoun and
a candidate antecedent, and collect statistical in-
formation from these paths to determine the like-
lihood that a pronoun and a candidate antecedent
connected by a given path are coreferent. Rather
than deriving features from parse trees, Iida et al.
(2006) and Yang et al. (2006) employ these trees
directly as structured features for pronoun resolu-
tion. Specifically, Yang et al. define tree kernels
for efficiently computing the similarity between
two parse trees, and Iida et al. use a boosting-based
algorithm to compute the usefulness of a subtree.
Grammatical features encode the grammati-
cal properties of one or both NPs involved in an
instance. For example, Ng and Cardies (2002c)
resolver employs 34 grammatical features. Some
features determine NP type (e.g., are both NPs def-
inite or pronouns?). Some determine the grammat-
ical role of one or both of the NPs. Some encode
traditional linguistic (hard) constraints on corefer-
ence. For example, coreferent NPs have to agree
in number and gender and cannot span one an-
other (e.g., Google and Google employees).
There are also features that encode general linguis-
tic preferences either for or against coreference.
For example, an indefinite NP (that is not in ap-
position to an anaphoric NP) is not likely to be
coreferent with any NP that precedes it.
There has been an increasing amount of work on
investigating semantic features for coreference
resolution. One of the earliest kinds of seman-
tic knowledge employed for coreference resolu-
tion is perhaps selectional preference (Dagan and
Itai, 1990; Kehler et al., 2004b; Yang et al., 2005;
Haghighi and Klein, 2009): given a pronoun to be
resolved, its governing verb, and its grammatical
role, we prefer a candidate antecedent that can be
governed by the same verb and be in the same role.
Semantic knowledge has also been extracted from
WordNet and unannotated corpora for computing
the semantic compatibility/similarity between two
common nouns (Harabagiu et al., 2001; Versley,
2007) as well as the semantic class of a noun (Ng,
2007a; Huang et al., 2009). One difficulty with
deriving knowledge from WordNet is that one has
to determine which sense of a given word to use.
Some researchers simply use the first sense (Soon
et al., 2001) or all possible senses (Ponzetto and
Strube, 2006a), while others overcome this prob-
lem with word sense disambiguation (Nicolae and
Nicolae, 2006). Knowledge has also been mined
from Wikipedia for measuring the semantic relat-
edness of two NPs, NPj and NPk (Ponzetto and
Strube (2006a; 2007)), such as: whether NPj/k ap-
pears in the first paragraph of the Wiki page that
has NPk/j as the title or in the list of categories to
which this page belongs, and the degree of overlap
between the two pages that have the two NPs as
their titles (see Poesio et al. (2007) for other uses
of encyclopedic knowledge for coreference reso-
lution). Contextual roles (Bean and Riloff, 2004),
semantic relations (Ji et al., 2005), semantic roles
(Ponzetto and Strube, 2006b; Kong et al., 2009),
and animacy (Orasan and Evans, 2007) have also
been exploited to improve coreference resolution.
Lexico-syntactic patterns have been used to
capture the semantic relatedness between two NPs
and hence the likelihood that they are coreferent.
For instance, given the pattern X is a Y (which is
highly indicative that X and Y are coreferent), we
can instantiate it with a pair of NPs and search
for the instantiated pattern in a large corpus or
the Web (Daume III and Marcu, 2005; Haghighi
and Klein, 2009). The more frequently the pat-
tern occurs, the more likely they are coreferent.
This technique has been applied to resolve dif-
ferent kinds of anaphoric references, including
other-anaphora (Modjeska et al., 2003; Markert
and Nissim, 2005) and bridging references (Poesio
et al., 2004a). While these patterns are typically
hand-crafted (e.g., Garera and Yarowsky (2006)),
they can also be learned from an annotated cor-
pus (Yang and Su, 2007) or bootstrapped from an
unannotated corpus (Bean and Riloff, 2004).
Despite the large amount of work on discourse-
based anaphora resolution in the 1970s and
1980s (see Hirst (1981)), learning-based resolvers
have only exploited shallow discourse-based fea-
tures, which primarily involve characterizing the
salience of a candidate antecedent by measuring
its distance from the anaphoric NP to be resolved
or determining whether it is in a prominent gram-
matical role (e.g., subject). A notable exception
</bodyText>
<page confidence="0.906218">
1402
</page>
<bodyText confidence="0.99836196875">
\x0cis Iida et al. (2009), who train a ranker to rank
the candidate antecedents for an anaphoric pro-
noun by their salience. It is worth noting that
Tetreault (2005) has employed Grosz and Sid-
ners (1986) discourse theory and Veins Theory
(Ide and Cristea, 2000) to identify and remove
candidate antecedents that are not referentially ac-
cessible to an anaphoric pronoun in his heuristic
pronoun resolvers. It would be interesting to in-
corporate this idea into a learning-based resolver.
There are also features that do not fall into any
of the preceding categories. For example, a mem-
orization feature is a word pair composed of the
head nouns of the two NPs involved in an in-
stance (Bengtson and Roth, 2008). Memoriza-
tion features have been used as binary-valued fea-
tures indicating the presence or absence of their
words (Luo et al., 2004) or as probabilistic fea-
tures indicating the probability that the two heads
are coreferent according to the training data (Ng,
2007b). An anaphoricity feature indicates whether
an NP to be resolved is anaphoric, and is typ-
ically computed using an anaphoricity classifier
(Ng, 2004), hand-crafted patterns (Daume III and
Marcu, 2005), and automatically acquired pat-
terns (Bean and Riloff, 1999). Finally, the outputs
of rule-based pronoun and coreference resolvers
have also been used as features for learning-based
coreference resolution (Ng and Cardie, 2002c).
For an empirical evaluation of the contribution
of a subset of these features to the mention-pair
model, see Bengtson and Roth (2008).
</bodyText>
<sectionHeader confidence="0.982502" genericHeader="evaluation">
5 Evaluation Issues
</sectionHeader>
<bodyText confidence="0.9901875">
Two important issues surround the evaluation of a
coreference resolver. First, how do we obtain the
set of NPs that a resolver will partition? Second,
how do we score the partition it produces?
</bodyText>
<subsectionHeader confidence="0.997154">
5.1 Extracting Candidate Noun Phrases
</subsectionHeader>
<bodyText confidence="0.998544444444444">
To obtain the set of NPs to be partitioned by a re-
solver, three methods are typically used. In the
first method, the NPs are extracted automatically
from a syntactic parser. The second method in-
volves extracting the NPs directly from the gold
standard. In the third method, a mention detec-
tor is first trained on the gold-standard NPs in the
training texts, and is then applied to automatically
extract system mentions in a test text.7 Note that
</bodyText>
<page confidence="0.989967">
7
</page>
<bodyText confidence="0.999380064516129">
An exception is Daume III and Marcu (2005), whose
model jointly learns to extract NPs and perform coreference.
these three extraction methods typically produce
different numbers of NPs: the NPs extracted from
a parser tend to significantly outnumber the system
mentions, which in turn outnumber the gold NPs.
The reasons are two-fold. First, in some corefer-
ence corpora (e.g., MUC-6 and MUC-7), the NPs
that are not part of any coreference chain are not
annotated. Second, in corpora such as those pro-
duced by the ACE evaluations, only the NPs that
belong to one of the ACE entity types (e.g., PER-
SON, ORGANIZATION, LOCATION) are annotated.
Owing in large part to the difference in the num-
ber of NPs extracted by these three methods, a
coreference resolver can produce substantially dif-
ferent results when applied to the resulting three
sets of NPs, with gold NPs yielding the best results
and NPs extracted from a parser yielding the worst
(Nicolae and Nicolae, 2006). While researchers
who evaluate their resolvers on gold NPs point out
that the results can more accurately reflect the per-
formance of their coreference algorithm, Stoyanov
et al. (2009) argue that such evaluations are unre-
alistic, as NP extraction is an integral part of an
end-to-end fully-automatic resolver.
Whichever NP extraction method is employed,
it is clear that the use of gold NPs can considerably
simplify the coreference task, and hence resolvers
employing different extraction methods should not
be compared against each other.
</bodyText>
<subsectionHeader confidence="0.999856">
5.2 Scoring a Coreference Partition
</subsectionHeader>
<bodyText confidence="0.9988437">
The MUC scorer (Vilain et al., 1995) is the first
program developed for scoring coreference parti-
tions. It has two often-cited weaknesses. As a link-
based measure, it does not reward correctly iden-
tified singleton clusters since there is no corefer-
ence link in these clusters. Also, it tends to under-
penalize partitions with overly large clusters.
To address these problems, two coreference
scoring programs have been developed: B3
(Bagga and Baldwin, 1998) and CEAF (Luo,
2005). Note that both scorers have only been de-
fined for the case where the key partition has the
same set of NPs as the response partition. To apply
these scorers to automatically extracted NPs, dif-
ferent methods have been proposed (see Rahman
and Ng (2009) and Stoyanov et al. (2009)).
Since coreference is a clustering task, any
general-purpose method for evaluating a response
partition against a key partition (e.g., Kappa (Car-
letta, 1996)) can be used for coreference scor-
</bodyText>
<page confidence="0.767294">
1403
</page>
<bodyText confidence="0.989755888888889">
\x0cing (see Popescu-Belis et al. (2004)). In practice,
these general-purpose methods are typically used
to provide scores that complement those obtained
via the three coreference scorers discussed above.
It is worth mentioning that there is a trend to-
wards evaluating a resolver against multiple scor-
ers, which can indirectly help to counteract the
bias inherent in a particular scorer. For further dis-
cussion on evaluation issues, see Byron (2001).
</bodyText>
<sectionHeader confidence="0.943367" genericHeader="conclusions">
6 Concluding Remarks
</sectionHeader>
<bodyText confidence="0.972503055555555">
While we have focused our discussion on super-
vised approaches, coreference researchers have
also attempted to reduce a resolvers reliance on
annotated data by combining a small amount of
labeled data and a large amount of unlabeled
data using general-purpose semi-supervised learn-
ing algorithms such as co-training (Muller et al.,
2002), self-training (Kehler et al., 2004a), and EM
(Cherry and Bergsma, 2005; Ng, 2008). Interest-
ingly, recent results indicate that unsupervised ap-
proaches to coreference resolution (e.g., Haghighi
and Klein (2007; 2010), Poon and Domingos
(2008)) rival their supervised counterparts, casting
doubts on whether supervised resolvers are mak-
ing effective use of the available labeled data.
Another issue that we have not focused on but
which is becoming increasingly important is mul-
tilinguality. While many of the techniques dis-
cussed in this paper were originally developed for
English, they have been applied to learn coref-
erence models for other languages, such as Chi-
nese (e.g., Converse (2006)), Japanese (e.g., Iida
(2007)), Arabic (e.g., Luo and Zitouni (2005)),
Dutch (e.g., Hoste (2005)), German (e.g., Wun-
sch (2010)), Swedish (e.g., Nilsson (2010)), and
Czech (e.g., Ngu
.y et al. (2009)). In addition, re-
searchers have developed approaches that are tar-
geted at handling certain kinds of anaphora present
in non-English languages, such as zero anaphora
(e.g., Iida et al. (2007a), Zhao and Ng (2007)).
As Mitkov (2001) puts it, coreference resolution
is a difficult, but not intractable problem, and
we have been making slow, but steady progress
on improving machine learning approaches to the
problem in the past fifteen years. To ensure fur-
ther progress, researchers should compare their re-
sults against a baseline that is stronger than the
commonly-used Soon et al. (2001) system, which
relies on a weak model (i.e., the mention-pair
model) and a small set of linguistic features. As re-
cent systems are becoming more sophisticated, we
suggest that researchers make their systems pub-
licly available in order to facilitate performance
comparisons. Publicly available coreference sys-
tems currently include JavaRAP (Qiu et al., 2004),
GuiTaR (Poesio and Kabadjov, 2004), BART (Ver-
sley et al., 2008b), CoRTex (Denis and Baldridge,
2008), the Illinois Coreference Package (Bengt-
son and Roth, 2008), CherryPicker (Rahman and
Ng, 2009), Reconcile (Stoyanov et al., 2010), and
Charniak and Elsners (2009) pronoun resolver.
We conclude with a discussion of two ques-
tions regarding supervised coreference research.
First, what is the state of the art? This is not an
easy question, as researchers have been evaluat-
ing their resolvers on different corpora using dif-
ferent evaluation metrics and preprocessing tools.
In particular, preprocessing tools can have a large
impact on the performance of a resolver (Barbu
and Mitkov, 2001). Worse still, assumptions about
whether gold or automatically extracted NPs are
used are sometimes not explicitly stated, poten-
tially causing results to be interpreted incorrectly.
To our knowledge, however, the best results on the
MUC-6 and MUC-7 data sets using automatically
extracted NPs are reported by Yang et al. (2003)
(71.3 MUC F-score) and Ng and Cardie (2002c)
(63.4 MUC F-score), respectively;8 and the best
results on the ACE data sets using gold NPs can
be found in Luo (2007) (88.4 ACE-value).
Second, what lessons can we learn from fifteen
years of learning-based coreference research?
The mention-pair model is weak because it makes
coreference decisions based on local informa-
tion (i.e., information extracted from two NPs).
Expressive models (e.g., those that can exploit
cluster-level features) generally offer better perfor-
mance, and so are models that are global in na-
ture. Global coreference models may refer to any
kind of models that can exploit non-local infor-
mation, including models that can consider mul-
tiple candidate antecedents simultaneously (e.g.,
ranking models), models that allow joint learning
for coreference resolution and related tasks (e.g.,
anaphoricity determination), models that can di-
rectly optimize clustering-level (rather than classi-
fication) accuracy, and models that can coordinate
with other components of a resolver, such as train-
ing instance creation and clustering.
</bodyText>
<page confidence="0.993108">
8
</page>
<bodyText confidence="0.998937666666667">
These results by no means suggest that no progress has
been made since 2003: most of the recently proposed coref-
erence models were evaluated on the ACE data sets.
</bodyText>
<page confidence="0.902549">
1404
</page>
<bodyText confidence="0.973281222222222">
\x0cAcknowledgments
We thank the three anonymous reviewers for their
invaluable comments on an earlier draft of the pa-
per. This work was supported in part by NSF
Grant IIS-0812261. Any opinions, findings, and
conclusions or recommendations expressed are
those of the author and do not necessarily reflect
the views or official policies, either expressed or
implied, of the NSF.
</bodyText>
<sectionHeader confidence="0.917543" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.856792857142857">
Chinatsu Aone and Scott William Bennett. 1995.
Evaluating automated and manual acquisition of
anaphora resolution strategies. In Proceedings of the
33rd Annual Meeting of the Association for Compu-
tational Linguistics, pages 122129.
Amit Bagga and Breck Baldwin. 1998. Algorithms for
scoring coreference chains. In Proceedings of the
LREC Workshop on Linguistic Coreference, pages
563566.
Nikhil Bansal, Avrim Blum, and Shuchi Chawla. 2002.
Correlation clustering. In Proceedings of the 43rd
Annual IEEE Symposium on Foundations of Com-
puter Science, pages 238247.
Catalina Barbu and Ruslan Mitkov. 2001. Evaluation
</reference>
<bodyText confidence="0.909781327586207">
tool for rule-based anaphora resolution methods. In
Proceedings of the 39th Annual Meeting of the Asso-
ciation for Computational Linguistics, pages 3441.
David Bean and Ellen Riloff. 1999. Corpus-based
identification of non-anaphoric noun phrases. In
Proceedings of the 37th Annual Meeting of the As-
sociation for Computational Linguistics, pages 373
380.
David Bean and Ellen Riloff. 2004. Unsupervised
learning of contextual role knowledge for corefer-
ence resolution. In Human Language Technologies
2004: The Conference of the North American Chap-
ter of the Association for Computational Linguistics;
Proceedings of the Main Conference, pages 297
304.
Eric Bengtson and Dan Roth. 2008. Understanding the
values of features for coreference resolution. In Pro-
ceedings of the 2008 Conference on Empirical Meth-
ods in Natural Language Processing, pages 294
303.
Adam L. Berger, Stephen A. Della Pietra, and Vin-
cent J. Della Pietra. 1996. A maximum entropy
approach to natural language processing. Compu-
tational Linguistics, 22(1):3971.
Shane Bergsma and Dekang Lin. 2006. Bootstrapping
path-based pronoun resolution. In Proceedings of
the 21st International Conference on Computational
Linguistics and the 44th Annual Meeting of the Asso-
ciation for Computational Linguistics, pages 3340.
Shane Bergsma, Dekang Lin, and Randy Goebel.
2008. Distributional identification of non-referential
pronouns. In Proceedings of ACL-08: HLT, pages
1018.
Donna Byron. 2001. The uncommon denominator: A
proposal for consistent reporting of pronoun resolu-
tion results. Computational Linguistics, 27(4):569
578.
Sasha Calhoun, Jean Carletta, Jason Brenier, Neil
Mayo, Dan Jurafsky, Mark Steedman, and David
Beaver. (in press). The NXT-format Switchboard
corpus: A rich resource for investigating the syn-
tax, semantics, pragmatics and prosody of dialogue.
Language Resources and Evaluation.
Claire Cardie and Kiri Wagstaff. 1999. Noun phrase
coreference as clustering. In Proceedings of the
1999 Joint SIGDAT Conference on Empirical Meth-
ods in Natural Language Processing and Very Large
Corpora, pages 8289.
Jean Carletta. 1996. Assessing agreement on classi-
fication tasks: the kappa statistic. Computational
Linguistics, 22(2):249254.
Jose Castano, Jason Zhang, and James Pustejovsky.
2002. Anaphora resolution in biomedical literature.
In Proceedings of the 2002 International Symposium
on Reference Resolution.
Eugene Charniak and Micha Elsner. 2009. EM works
for pronoun anaphora resolution. In Proceedings of
the 12th Conference of the European Chapter of the
</bodyText>
<reference confidence="0.869455346153846">
Association for Computational Linguistics, pages
148156.
Eugene Charniak. 1972. Towards a Model of Chil-
drens Story Comphrension. AI-TR 266, Artificial
Intelligence Laboratory, Massachusetts Institute of
Technology, USA.
Colin Cherry and Shane Bergsma. 2005. An expecta-
tion maximization approach to pronoun resolution.
In Proceedings of the Ninth Conference on Compu-
tational Natural Language Learning, pages 8895.
Noam Chomsky. 1988. Language and Problems of
Knowledge. The Managua Lectures. MIT Press,
Cambridge, Massachusetts.
William Cohen. 1995. Fast effective rule induction. In
Proceedings of the 12th International Conference on
Machine Learning, pages 115123.
Dennis Connolly, John D. Burger, and David S. Day.
1994. A machine learning approach to anaphoric
reference. In Proceedings of International Con-
ference on New Methods in Language Processing,
pages 255261.
Dennis Connolly, John D. Burger, and David S. Day.
1997. A machine learning approach to anaphoric
reference. In D. Jones and H. Somers, editors, New
Methods in Language Processing, pages 133144.
UCL Press.
</reference>
<page confidence="0.915801">
1405
</page>
<reference confidence="0.479961384615385">
\x0cSusan Converse. 2006. Pronominal Anaphora Resolu-
tion in Chinese. Ph.D. thesis, University of Pennsyl-
vania, USA.
Aron Culotta, Michael Wick, and Andrew McCallum.
2007. First-order probabilistic models for corefer-
ence resolution. In Human Language Technologies
2007: The Conference of the North American Chap-
ter of the Association for Computational Linguistics;
Proceedings of the Main Conference, pages 8188.
Walter Daelemans and Antal Van den Bosch. 2005.
Memory-Based Language Processing. Cambridge
University Press, Cambridge, UK.
Ido Dagan and Alon Itai. 1990. Automatic processing
</reference>
<bodyText confidence="0.896637712765957">
of large corpora for the resolution of anaphora ref-
erences. In Proceedings of the 13th International
Conference on Computational Linguistics, pages
330332.
Hal Daume III and Daniel Marcu. 2005. A large-
scale exploration of effective global features for a
joint entity detection and tracking model. In Pro-
ceedings of the Human Language Technology Con-
ference and the Conference on Empirical Methods
in Natural Language Processing, pages 97104.
Arthur Dempster. 1968. A generalization of Bayesian
inference. Journal of the Royal Statistical Society,
30:205247.
Pascal Denis and Jason Baldridge. 2007a. Global,
joint determination of anaphoricity and coreference
resolution using integer programming. In Human
Language Technologies 2007: The Conference of
the North American Chapter of the Association for
Computational Linguistics; Proceedings of the Main
Conference, pages 236243.
Pascal Denis and Jason Baldridge. 2007b. A ranking
approach to pronoun resolution. In Proceedings of
the Twentieth International Conference on Artificial
Intelligence, pages 15881593.
Pascal Denis and Jason Baldridge. 2008. Special-
ized models and ranking for coreference resolution.
In Proceedings of the 2008 Conference on Empiri-
cal Methods in Natural Language Processing, pages
660669.
Richard Evans. 2001. Applying machine learning to-
ward an automatic classification of it. Literary and
Linguistic Computing, 16(1):4557.
Jenny Rose Finkel and Christopher Manning. 2008.
Enforcing transitivity in coreference resolution. In
Proceedings of ACL-08: HLT, Short Papers, pages
4548.
Thomas Finley and Thorsten Joachims. 2005. Super-
vised clustering with support vector machines. In
Proceedings of the 22nd International Conference
on Machine Learning, pages 217224.
Yoav Freund and Robert E. Schapire. 1999. Large
margin classification using the perceptron algorithm.
Machine Learning, 37(3):277296.
Nikesh Garera and David Yarowsky. 2006. Resolving
and generating definite anaphora by modeling hy-
pernymy using unlabeled corpora. In Proceedings
of the Tenth Conference on Computational Natural
Language Learning, pages 3744.
Niyu Ge, John Hale, and Eugene Charniak. 1998. A
statistical approach to anaphora resolution. In Pro-
ceedings of the Sixth Workshop on Very Large Cor-
pora, pages 161170.
Barbara J. Grosz and Candace L. Sidner. 1986. Atten-
tion, intentions, and the structure of discourse. Com-
putational Linguistics, 12(3):175204.
Barbara J. Grosz, Aravind K. Joshi, and Scott Wein-
stein. 1983. Providing a unified account of definite
noun phrases in discourse. In Proceedings of the
21st Annual Meeting of the Association for Compu-
tational Linguistics, pages 4450.
Barbara J. Grosz, Aravind K. Joshi, and Scott Wein-
stein. 1995. Centering: A framework for model-
ing the local coherence of discourse. Computational
Linguistics, 21(2):203226.
Barbara J. Grosz. 1977. The representation and use of
focus in a system for understanding dialogs. In Pro-
ceedings of the Fifth International Joint Conference
on Artificial Intelligence, pages 6776.
Aria Haghighi and Dan Klein. 2007. Unsupervised
coreference resolution in a nonparametric bayesian
model. In Proceedings of the 45th Annual Meet-
ing of the Association of Computational Linguistics,
pages 848855.
Aria Haghighi and Dan Klein. 2009. Simple coref-
erence resolution with rich syntactic and semantic
features. In Proceedings of the 2009 Conference on
Empirical Methods in Natural Language Process-
ing, pages 11521161.
Aria Haghighi and Dan Klein. 2010. Coreference
resolution in a modular, entity-centered model. In
Proceedings of Human Language Technologies: The
2010 Annual Conference of the North American
Chapter of the Association for Computational Lin-
guistics.
Jan Hajic, Jarmila Panevova, Eva Hajicova, Jarmila
Panevova, Petr Sgall, Petr Pajas, Jan Stepanek, Jir
Havelka, and Marie Mikulova. 2006. The Prague
Dependency Treebank 2.0. In Linguistic Data Con-
sortium.
Sanda Harabagiu, Razvan Bunescu, and Steven Maio-
rano. 2001. Text and knowledge mining for corefer-
ence resolution. In Proceedings of the 2nd Meeting
of the North American Chapter of the Association
for Computational Linguistics, pages 5562.
</bodyText>
<page confidence="0.915871">
1406
</page>
<bodyText confidence="0.980466625">
\x0cLaura Hasler, Constantin Orasan, and Karin Naumann.
2006. NPs for events: Experiments in coreference
annotation. In Proceedings of the 5th International
Conference on Language Resources and Evaluation,
pages 11671172.
Peter Heeman and James Allen. 1995. The TRAINS
spoken dialog corpus. CD-ROM, Linguistic Data
Consortium.
Graeme Hirst. 1981. Discourse-oriented anaphora
resolution in natural language understanding: A re-
view. American Journal of Computational Linguis-
tics, 7(2):8598.
Jerry Hobbs. 1978. Resolving pronoun references.
Lingua, 44:311338.
Veronique Hoste and Walter Daelemans. 2005. Com-
paring learning approaches to coreference resolu-
tion. There is more to it than bias. In Proceedings
of the ICML Workshop on Meta-Learning.
Veronique Hoste. 2005. Optimization Issues in Ma-
chine Learning of Coreference Resolution. Ph.D.
thesis, University of Antewerp, Belgium.
Eduard Hovy, Mitchell Marcus, Martha Palmer, Lance
Ramshaw, and Ralph Weischedel. 2006. Ontonotes:
The 90% solution. In Proceedings of the Human
</bodyText>
<subsectionHeader confidence="0.555207">
Language Technology Conference of the NAACL,
</subsectionHeader>
<bodyText confidence="0.767134485714286">
Companion Volume: Short Papers, pages 5760.
Zhiheng Huang, Guangping Zeng, Weiqun Xu, and
Asli Celikyilmaz. 2009. Accurate semantic class
classifier for coreference resolution. In Proceedings
of the 2009 Conference on Empirical Methods in
Natural Language Processing, pages 12321240.
Nancy Ide and Dan Cristea. 2000. A hierarchical ac-
count of referential accessibility. In Proceedings of
the 38th Annual Meeting of the Association for Com-
putational Linguistics, pages 416424.
Ryu Iida, Kentaro Inui, Hiroya Takamura, and Yuji
Matsumoto. 2003. Incorporating contextual cues
in trainable models for coreference resolution. In
Proceedings of the EACL Workshop on The Compu-
tational Treatment of Anaphora.
Ryu Iida, Kentaro Inui, and Yuji Matsumoto. 2006.
Exploting syntactic patterns as clues in zero-
anaphora resolution. In Proceedings of the 21st In-
ternational Conference on Computational Linguis-
tics and the 44th Annual Meeting of the Association
for Computational Linguistics, pages 625632.
Ryu Iida, Kentaro Inui, and Yuji Matsumoto. 2007a.
Zero-anaphora resolution by learning rich syntactic
pattern features. ACM Transactions on Asian Lan-
guage Information Processing, 6(4).
Ryu Iida, Mamoru Komachi, Kentaro Inui, and Yuji
Matsumoto. 2007b. Annotating a Japanese text cor-
pus with predicate-argument and coreference rela-
tions. In Proceedings of the ACL Workshop Lin-
guistic Annotation Workshop, pages 132139.
Ryu Iida, Kentaro Inui, and Yuji Matsumoto. 2009.
Capturing salience with a trainable cache model for
zero-anaphora resolution. In Proceedings of the
Joint Conference of the 47th Annual Meeting of the
ACL and the 4th International Joint Conference on
</bodyText>
<footnote confidence="0.9120265">
Natural Language Processing of the AFNLP, pages
647655.
Ryu Iida. 2007. Combining Linguistic Knowledge and
Machine Learning for Anaphora Resolution. Ph.D.
thesis, Nara Institute of Science and Technology,
Japan.
Heng Ji, David Westbrook, and Ralph Grishman. 2005.
Using semantic relations to refine coreference deci-
sions. In Proceedings of the Human Language Tech-
nology Conference and the Conference on Empiri-
cal Methods in Natural Language Processing, pages
1724.
</footnote>
<reference confidence="0.702645636363636">
Thorsten Joachims. 1999. Making large-scale SVM
learning practical. In Bernhard Scholkopf and
Alexander Smola, editors, Advances in Kernel Meth-
ods - Support Vector Learning, pages 4456. MIT
Press.
Andrew Kehler, Douglas Appelt, Lara Taylor, and
Aleksandr Simma. 2004a. Competitive self-trained
pronoun interpretation. In Proceedings of HLT-
NAACL 2004: Short Papers, pages 3336.
Andrew Kehler, Douglas Appelt, Lara Taylor, and
Aleksandr Simma. 2004b. The (non)utility of
</reference>
<bodyText confidence="0.899149777777778">
predicate-argument frequencies for pronoun inter-
pretation. In Human Language Technologies 2004:
The Conference of the North American Chapter of
the Association for Computational Linguistics; Pro-
ceedings of the Main Conference, pages 289296.
Andrew Kehler. 1997. Probabilistic coreference in in-
formation extraction. In Proceedings of the Second
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 163173.
Christopher Kennedy and Branimir Boguraev. 1996.
Anaphor for everyone: Pronominal anaphora resolu-
tion without a parser. In Proceedings of the 16th In-
ternational Conference on Computational Linguis-
tics, pages 113118.
Manfred Klenner and Etienne Ailloud. 2008. Enhanc-
ing coreference clustering. In Proceedings of the
Second Workshop on Anaphora Resolution, pages
3140.
Manfred Klenner and Etienne Ailloud. 2009. Op-
timization in coreference resolution is not needed:
A nearly-optimal algorithm with intensional con-
straints. In Proceedings of the 12th Conference of
the European Chapter of the Association for Com-
putational Linguistics, pages 442450.
Manfred Klenner. 2007. Enforcing consistency on
coreference sets. In Proceedings of Recent Ad-
vances in Natural Language Processing.
</bodyText>
<page confidence="0.896503">
1407
</page>
<reference confidence="0.916483666666667">
\x0cFang Kong, GuoDong Zhou, and Qiaoming Zhu. 2009.
Employing the centering theory in pronoun resolu-
tion from the semantic perspective. In Proceedings
of the 2009 Conference on Empirical Methods in
Natural Language Processing, pages 987996.
Shalom Lappin and Herbert Leass. 1994. An algo-
rithm for pronominal anaphora resolution. Compu-
tational Linguistics, 20(4):535562.
Xiaoqiang Luo and Imed Zitouni. 2005. Multi-lingual
coreference resolution with syntactic features. In
Proceedings of the Human Language Technology
Conference and the Conference on Empirical Meth-
ods in Natural Language Processing, pages 660
667.
Xiaoqiang Luo, Abe Ittycheriah, Hongyan Jing, Nanda
Kambhatla, and Salim Roukos. 2004. A mention-
synchronous coreference resolution algorithm based
on the Bell tree. In Proceedings of the 42nd Annual
Meeting of the Association for Computational Lin-
guistics, pages 135142.
Xiaoqiang Luo. 2005. On coreference resolution per-
formance metrics. In Proceedings of the Human
Language Technology Conference and the Confer-
ence on Empirical Methods in Natural Language
Processing, pages 2532.
Xiaoqiang Luo. 2007. Coreference or not: A twin
model for coreference resolution. In Human Lan-
guage Technologies 2007: The Conference of the
North American Chapter of the Association for
Computational Linguistics; Proceedings of the Main
Conference, pages 7380.
Mitchell P. Marcus, Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1993. Building a large annotated
corpus of English: The Penn Treebank. Computa-
tional Linguistics, 19(2):313330.
Katja Markert and Malvina Nissim. 2005. Comparing
knowledge sources for nominal anaphora resolution.
Computational Linguistics, 31(3):367402.
Andrew McCallum and Ben Wellner. 2003. Toward
</reference>
<bodyText confidence="0.917645454545455">
conditional models of identity uncertainty with ap-
plication to proper noun coreference. In Proceed-
ings of the IJCAI Workshop on Information Integra-
tion on the Web.
Andrew McCallum and Ben Wellner. 2004. Condi-
tional models of identity uncertainty with applica-
tion to noun coreference. In Advances in Neural In-
formation Proceesing Systems.
Joseph McCarthy and Wendy Lehnert. 1995. Using
decision trees for coreference resolution. In Pro-
ceedings of the Fourteenth International Conference
</bodyText>
<reference confidence="0.87764625862069">
on Artificial Intelligence, pages 10501055.
Ruslan Mitkov. 1999. Anaphora resolution: The
state of the art. Technical Report (Based on the
COLING/ACL-98 tutorial on anaphora resolution),
University of Wolverhampton, Wolverhampton.
Ruslan Mitkov. 2001. Outstanding issues in anaphora
resolution. In Al. Gelbukh, editor, Computational
Linguistics and Intelligent Text Processing, pages
110125. Springer.
Ruslan Mitkov. 2002. Anaphora Resolution. Long-
man.
Natalia N. Modjeska, Katja Markert, and Malvina Nis-
sim. 2003. Using the web in machine learning
for other-anaphora resolution. In Proceedings of the
2003 Conference on Empirical Methods in Natural
Language Processing, pages 176183.
MUC-6. 1995. Proceedings of the Sixth Message Un-
derstanding Conference.
MUC-7. 1998. Proceedings of the Seventh Message
Understanding Conference.
Christoph Muller, Stefan Rapp, and Michael Strube.
2002. Applying co-training to reference resolution.
In Proceedings of the 40th Annual Meeting of the As-
sociation for Computational Linguistics, pages 352
359.
Christoph Muller. 2006. Automatic detection of non-
referential it in spoken multi-party dialog. In Pro-
ceedings of the 11th Conference of the European
Chapter of the Association for Computational Lin-
guistics, pages 4956.
Vincent Ng and Claire Cardie. 2002a. Combining
sample selection and error-driven pruning for ma-
chine learning of coreference rules. In Proceedings
of the 2002 Conference on Empirical Methods in
Natural Language Processing, pages 5562.
Vincent Ng and Claire Cardie. 2002b. Identifying
anaphoric and non-anaphoric noun phrases to im-
prove coreference resolution. In Proceedings of
the 19th International Conference on Computational
Linguistics, pages 730736.
Vincent Ng and Claire Cardie. 2002c. Improving ma-
chine learning approaches to coreference resolution.
In Proceedings of the 40th Annual Meeting of the As-
sociation for Computational Linguistics, pages 104
111.
Vincent Ng. 2004. Learning noun phrase anaphoricity
to improve conference resolution: Issues in repre-
sentation and optimization. In Proceedings of the
42nd Annual Meeting of the Association for Compu-
tational Linguistics, pages 151158.
Vincent Ng. 2007a. Semantic class induction and
coreference resolution. In Proceedings of the 45th
Annual Meeting of the Association of Computational
Linguistics, pages 536543.
Vincent Ng. 2007b. Shallow semantics for coreference
resolution. In Proceedings of the Twentieth Inter-
national Joint Conference on Artificial Intelligence,
pages 16891694.
</reference>
<page confidence="0.552366">
1408
</page>
<reference confidence="0.990157258992806">
\x0cVincent Ng. 2008. Unsupervised models for corefer-
ence resolution. In Proceedings of the 2008 Con-
ference on Empirical Methods in Natural Language
Processing, pages 640649.
Vincent Ng. 2009. Graph-cut-based anaphoricity de-
termination for coreference resolution. In Proceed-
ings of Human Language Technologies: The 2009
Annual Conference of the North American Chap-
ter of the Association for Computational Linguistics,
pages 575583.
Giang Linh Ngu
.y, Vaclav Novak, and Zdenek
Zabokrtsky. 2009. Comparison of classification and
ranking approaches to pronominal anaphora resolu-
tion in Czech. In Proceedings of the SIGDIAL 2009
Conference, pages 276285.
Cristina Nicolae and Gabriel Nicolae. 2006. Best-
Cut: A graph algorithm for coreference resolution.
In Proceedings of the 2006 Conference on Empiri-
cal Methods in Natural Language Processing, pages
275283.
Kristina Nilsson. 2010. Hybrid Methods for Coref-
erence Resolution in Swedish. Ph.D. thesis, Stock-
holm University, Sweden.
Tomoko Ohta, Yuka Tateisi, and Jin-Dong Kim. 2002.
The GENIA corpus: An annotated research abstract
corpus in molecular biology domain. In Proceed-
ings of the Second International Conference on Hu-
man Language Technology Research, pages 8286.
Constantin Orasan and Richard Evans. 2007. NP ani-
macy identification for anaphora resolution. Journal
of Artificial Intelligence Research, 29:79 103.
Constantin Orasan, Dan Cristea, Ruslan Mitkov, and
Antonio H. Branco. 2008. Anaphora Resolution
Exercise: An overview. In Proceedings of the 6th
Language Resources and Evaluation Conference,
pages 28012805.
Chris Paice and Gareth Husk. 1987. Towards the au-
tomatic recognition of anaphoric features in English
text: the impersonal pronoun it. Computer Speech
and Language, 2:109132.
Massimo Poesio and Mijail A. Kabadjov. 2004. A
general-purpose, off-the-shelf anaphora resolution
module: Implementation and preliminary evalua-
tion. In Proceedings of the 4th International Confer-
ence on Language Resources and Evaluation, pages
663668.
Massimo Poesio, Rahul Mehta, Axel Maroudas, and
Janet Hitzeman. 2004a. Learning to resolve bridg-
ing references. In Proceedings of the 42nd Annual
Meeting of the Association for Computational Lin-
guistics, pages 143150.
Massimo Poesio, Olga Uryupina, Renata Vieira, Mijail
Alexandrov-Kabadjov,and Rodrigo Goulart. 2004b.
Discourse-new detectors for definite description res-
olution: A survey and a preliminary proposal. In
Proeedings of the ACL Workshop on Reference Res-
olution.
Massimo Poesio, David Day, Ron Artstein, Jason Dun-
can, Vladimir Eidelman, Claudio Giuliano, Rob
Hall, Janet Hitzeman, Alan Jern, Mijail Kabadjov,
Stanley Yong Wai Keong, Gideon Mann, Alessan-
dro Moschitti, Simone Ponzetto, Jason Smith, Josef
Steinberger, Michael Strube, Jian Su, Yannick Vers-
ley, Xiaofeng Yang, and Michael Wick. 2007. EL-
ERFED: Final report of the research group on Ex-
ploiting Lexical and Encyclopedic Resources For
Entity Disambiguation. Technical report, Summer
Workshop on Language Engineering, Center for
Language and Speech Processing, Johns Hopkins
University, Baltimore, MD.
Simone Paolo Ponzetto and Massimo Poesio. 2009.
State-of-the-art NLP approaches to coreference res-
olution: Theory and practical recipes. In Tutorial
Abstracts of ACL-IJCNLP 2009, page 6.
Simone Paolo Ponzetto and Michael Strube. 2006a.
Exploiting semantic role labeling, WordNet and
Wikipedia for coreference resolution. In Human
Language Technologies 2006: The Conference of
the North American Chapter of the Association for
Computational Linguistics; Proceedings of the Main
Conference, pages 192199.
Simone Paolo Ponzetto and Michael Strube. 2006b.
Semantic role labeling for coreference resolution. In
Proceedings of the 11th Conference of the European
Chapter of the Association for Computational Lin-
guistics, pages 143146.
Simone Paolo Ponzetto and Michael Strube. 2007.
Knowledge derived from Wikipedia for computing
semantic relatedness. Journal of Artificial Intelli-
gence Research, 30:181212.
Hoifung Poon and Pedro Domingos. 2008. Joint unsu-
pervised coreference resolution with Markov Logic.
In Proceedings of the 2008 Conference on Empiri-
cal Methods in Natural Language Processing, pages
650659.
Andrei Popescu-Belis, Los Rigouste, Susanne
Salmon-Alt, and Laurent Romary. 2004. Online
evaluation of coreference resolution. In Proceedings
of the 4th International Conference on Language
Resources and Evaluation, pages 15071510.
Long Qiu, Min-Yen Kan, and Tat-Seng Chua. 2004.
A public reference implementation of the RAP
anaphora resolution algorithm. In Proceedings of
the 4th International Conference on Language Re-
sources and Evaluation, pages 291294.
John Ross Quinlan. 1993. C4.5: Programs for Ma-
chine Learning. Morgan Kaufmann, San Mateo,
CA.
Altaf Rahman and Vincent Ng. 2009. Supervised mod-
els for coreference resolution. In Proceedings of the
2009 Conference on Empirical Methods in Natural
Language Processing, pages 968977.
1409
\x0cMarta Recasens and M. Antonia Mart. 2009. AnCora-
CO: Coreferentially annotated corpora for Spanish
and Catalan. Language Resources and Evaluation,
43(4).
Marta Recasens, Toni Mart, Mariona Taule, Llus
Marquez, and Emili Sapena. 2009. SemEval-
2010 Task 1: Coreference resolution in multiple lan-
guages. In Proceedings of the Workshop on Seman-
tic Evaluations: Recent Achievements and Future
Directions (SEW-2009), pages 7075.
Candace Sidner. 1979. Towards a Computational The-
ory of Definite Anaphora Comprehension in English
Discourse. Ph.D. thesis, Massachusetts Institute of
Technology, USA.
Wee Meng Soon, Hwee Tou Ng, and Chung Yong Lim.
1999. Corpus-based learning for noun phrase coref-
erence resolution. In Proceedings of the 1999 Joint
SIGDAT Conference on Empirical Methods in Nat-
ural Language Processing and Very Large Corpora,
pages 285291.
Wee Meng Soon, Hwee Tou Ng, and Daniel
Chung Yong Lim. 2001. A machine learning ap-
proach to coreference resolution of noun phrases.
Computational Linguistics, 27(4):521544.
Veselin Stoyanov, Nathan Gilbert, Claire Cardie, and
Ellen Riloff. 2009. Conundrums in noun phrase
coreference resolution: Making sense of the state-
of-the-art. In Proceedings of the Joint Conference of
the 47th Annual Meeting of the ACL and the 4th In-
ternational Joint Conference on Natural Language
Processing of the AFNLP, pages 656664.
Veselin Stoyanov, Claire Cardie, Nathan Gilbert, Ellen
Riloff, David Buttler, and David Hysom. 2010.
Coreference resolution with Reconcile. In Proceed-
ings of the ACL 2010 Conference Short Papers.
Michael Strube, Stefan Rapp, and Christoph Muller.
2002. The influence of minimum edit distance on
reference resolution. In Proceedings of the 2002
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 312319.
Michael Strube. 2002. NLP approaches to reference
resolution. In Tutorial Abstracts of ACL 2002, page
124.
Michael Strube. 2009. Anaphernresolution. In Com-
puterlinguistik und Sprachtechnologie. Eine Ein-
fuhrung. Springer, Heidelberg, Germany, 3rd edi-
tion.
Heike Telljohann, Erhard Hinrichs, and Sandra Kubler.
2004. The tuba-d/z treebank: Annotating German
with a context-free backbone. In Proceedings of
the 4th International Conference on Language Re-
sources and Evaluation, pages 22292235.
Joel Tetreault. 2005. Empirical Evaluations of
Pronoun Resolution. Ph.D. thesis, University of
Rochester, USA.
Olga Uryupina. 2003. High-precision identification of
discourse new and unique noun phrases. In Proceed-
ings of the ACL Student Research Workshop, pages
8086.
Olga Uryupina. 2004. Linguistically motivated sample
selection for coreference resolution. In Proceedings
of the 5th Discourse Anaphora and Anaphor Reso-
lution Colloquium.
Kees van Deemter and Rodger Kibble. 2000. On core-
ferring: Coreference in MUC and related annotation
schemes. Computational Linguistics, 26(4):629
637.
Yannick Versley, Alessandro Moschitti, Massimo Poe-
sio, and Xiaofeng Yang. 2008a. Coreference sys-
tems based on kernels methods. In Proceedings
of the 22nd International Conference on Computa-
tional Linguistics, pages 961968.
Yannick Versley, Simone Paolo Ponzetto, Massimo
Poesio, Vladimir Eidelman, Alan Jern, Jason Smith,
Xiaofeng Yang, and Alessandro Moschitti. 2008b.
BART: A modular toolkit for coreference resolution.
In Proceedings of the ACL-08: HLT Demo Session,
pages 912.
Yannick Versley. 2006. A constraint-based approach
to noun phrase coreference resolution in German
newspaper text. In Konferenz zur Verarbeitung
Naturlicher Sprache.
Yannick Versley. 2007. Antecedent selection tech-
niques for high-recall coreference resolution. In
Proceedings of the 2007 Joint Conference on Empir-
ical Methods in Natural Language Processing and
Computational Natural Language Learning, pages
496505.
Renata Vieira and Massimo Poesio. 2000. Process-
ing definite descriptions in corpora. In S. Botley
and A. McEnery, editors, Corpus-based and Compu-
tational Approaches to Discourse Anaphora, pages
189212. UCL Press.
Marc Vilain, John Burger, John Aberdeen, Dennis Con-
nolly, and Lynette Hirschman. 1995. A model-
theoretic coreference scoring scheme. In Proceed-
ings of the Sixth Message Understanding Confer-
ence, pages 4552.
Marilyn Walker, Aravind Joshi, and Ellen Prince, edi-
tors. 1998. Centering Theory in Discourse. Oxford
University Press.
Holger Wunsch. 2010. Rule-based and Memory-based
Pronoun Resolution for German: A Comparison and
Assessment of Data Sources. Ph.D. thesis, Univer-
sity of Tubingen, Germany.
Xiaofeng Yang and Jian Su. 2007. Coreference reso-
lution using semantic relatedness information from
automatically discovered patterns. In Proceedings
of the 45th Annual Meeting of the Association for
Computational Linguistics, pages 528535.
1410
\x0cXiaofeng Yang, Guodong Zhou, Jian Su, and
Chew Lim Tan. 2003. Coreference resolution us-
ing competitive learning approach. In Proceedings
of the 41st Annual Meeting of the Association for
Computational Linguistics, pages 176183.
Xiaofeng Yang, Jian Su, and Chew Lim Tan. 2004a.
Improving noun phrase coreference resolution by
matching strings. In Proceedings of the First In-
ternational Joint Conference on Natural Language
Processing, pages 2231.
Xiaofeng Yang, Jian Su, GuoDong Zhou, and
Chew Lim Tan. 2004b. An NP-cluster based ap-
proach to coreference resolution. In Proceedings of
the 20th International Conference on Computational
Linguistics, pages 226232.
Xiaofeng Yang, Jian Su, and Chew Lim Tan. 2005.
Improving pronoun resolution using statistics-based
semantic compatibility information. In Proceedings
of the 43rd Annual Meeting of the Association for
Computational Linguistics, pages 165172.
Xiaofeng Yang, Jian Su, and Chew Lim Tan. 2006.
Kernel based pronoun resolution with structured
syntactic knowledge. In Proceedings of the 21st In-
ternational Conference on Computational Linguis-
tics and the 44th Annual Meeting of the Association
for Computational Linguistics, pages 4148.
Xiaofeng Yang, Jian Su, Jun Lang, Chew Lim Tan,
and Sheng Li. 2008a. An entity-mention model
for coreference resolution with inductive logic pro-
gramming. In Proceedings of ACL-08: HLT, pages
843851.
Xiaofeng Yang, Jian Su, and Chew Lim Tan. 2008b. A
twin-candidate model for learning-based anaphora
resolution. Computational Linguistics, 34(3):327
356.
Dmitry Zelenko, Chinatsu Aone, and Jason Tibbetts.
2004. Coreference resolution for information ex-
traction. In Proceedings of the ACL Workshop on
Reference Resolution and its Applications, pages 9
16.
Shanheng Zhao and Hwee Tou Ng. 2007. Identifica-
tion and resolution of Chinese zero pronouns: A ma-
chine learning approach. In Proceedings of the 2007
Joint Conference on Empirical Methods on Natu-
ral Language Processing and Computational Natu-
ral Language Learning, pages 541550.
GuoDong Zhou and Fang Kong. 2009. Global learn-
ing of noun phrase anaphoricity in coreference res-
olution via label propagation. In Proceedings of the
2009 Conference on Empirical Methods in Natural
Language Processing, pages 978986.
1411
\x0c&apos;
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.464265">
<note confidence="0.882457333333333">b&apos;Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 13961411, Uppsala, Sweden, 11-16 July 2010. c 2010 Association for Computational Linguistics</note>
<title confidence="0.752559">Supervised Noun Phrase Coreference Research: The First Fifteen Years</title>
<author confidence="0.996048">Vincent Ng</author>
<affiliation confidence="0.999653">Human Language Technology Research Institute University of Texas at Dallas</affiliation>
<address confidence="0.948131">Richardson, TX 75083-0688</address>
<email confidence="0.999669">vince@hlt.utdallas.edu</email>
<abstract confidence="0.96924525">The research focus of computational coreference resolution has exhibited a shift from heuristic approaches to machine learning approaches in the past decade. This paper surveys the major milestones in supervised coreference research since its inception fifteen years ago.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Chinatsu Aone</author>
<author>Scott William Bennett</author>
</authors>
<title>Evaluating automated and manual acquisition of anaphora resolution strategies.</title>
<date>1995</date>
<booktitle>In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>122129</pages>
<contexts>
<context position="6898" citStr="Aone and Bennett (1995)" startWordPosition="1031" endWordPosition="1034">ading an annotation project that aims to collect large amounts of coreference data for English via a Web Collaboration game called Phrase Detectives2. 1 http://www.itl.nist.gov/iad/mig/tests/ace/ 2 http://www.phrasedetectives.org 3 Learning-Based Coreference Models In this section, we examine three important classes of coreference models that were developed in the past fifteen years, namely, the mention-pair model, the entity-mention model, and ranking models. 3.1 Mention-Pair Model The mention-pair model is a classifier that determines whether two NPs are coreferent. It was first proposed by Aone and Bennett (1995) and McCarthy and Lehnert (1995), and is one of the most influential learning-based coreference models. Despite its popularity, this binary classification approach to coreference is somewhat undesirable: the transitivity property inherent in the coreference relation cannot be enforced, as it is possible for the model to determine that A and B are coreferent, B and C are coreferent, but A and C are not coreferent. Hence, a separate clustering mechanism is needed to coordinate the pairwise classification decisions made by the model and construct a coreference partition. Another issue that surrou</context>
</contexts>
<marker>Aone, Bennett, 1995</marker>
<rawString>Chinatsu Aone and Scott William Bennett. 1995. Evaluating automated and manual acquisition of anaphora resolution strategies. In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics, pages 122129.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amit Bagga</author>
<author>Breck Baldwin</author>
</authors>
<title>Algorithms for scoring coreference chains.</title>
<date>1998</date>
<booktitle>In Proceedings of the LREC Workshop on Linguistic Coreference,</booktitle>
<pages>563566</pages>
<contexts>
<context position="37571" citStr="Bagga and Baldwin, 1998" startWordPosition="5931" endWordPosition="5934">implify the coreference task, and hence resolvers employing different extraction methods should not be compared against each other. 5.2 Scoring a Coreference Partition The MUC scorer (Vilain et al., 1995) is the first program developed for scoring coreference partitions. It has two often-cited weaknesses. As a linkbased measure, it does not reward correctly identified singleton clusters since there is no coreference link in these clusters. Also, it tends to underpenalize partitions with overly large clusters. To address these problems, two coreference scoring programs have been developed: B3 (Bagga and Baldwin, 1998) and CEAF (Luo, 2005). Note that both scorers have only been defined for the case where the key partition has the same set of NPs as the response partition. To apply these scorers to automatically extracted NPs, different methods have been proposed (see Rahman and Ng (2009) and Stoyanov et al. (2009)). Since coreference is a clustering task, any general-purpose method for evaluating a response partition against a key partition (e.g., Kappa (Carletta, 1996)) can be used for coreference scor1403 \x0cing (see Popescu-Belis et al. (2004)). In practice, these general-purpose methods are typically u</context>
</contexts>
<marker>Bagga, Baldwin, 1998</marker>
<rawString>Amit Bagga and Breck Baldwin. 1998. Algorithms for scoring coreference chains. In Proceedings of the LREC Workshop on Linguistic Coreference, pages 563566.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nikhil Bansal</author>
<author>Avrim Blum</author>
<author>Shuchi Chawla</author>
</authors>
<title>Correlation clustering.</title>
<date>2002</date>
<booktitle>In Proceedings of the 43rd Annual IEEE Symposium on Foundations of Computer Science,</booktitle>
<pages>238247</pages>
<contexts>
<context position="13289" citStr="Bansal et al., 2002" startWordPosition="2053" endWordPosition="2056">is that they are too greedy. In particular, clusters are formed based on a small subset of the pairwise decisions made by the model. Moreover, positive pairwise decisions are unjustifiably favored over their negative counterparts. For example, three NPs are likely to end up in the same cluster in the resulting partition even if there is strong evidence that A and C are not coreferent, as long as the other two pairs (i.e., (A,B) and (B,C)) are classified as positive. Several algorithms that address one or both of these problems have been used for coreference clustering. Correlation clustering (Bansal et al., 2002), which produces a partition that respects as many pairwise decisions as possible, is used by McCallum and Wellner (2004), Zelenko et al. (2004), and Finley and Joachims (2005). Graph partitioning algorithms are applied on a weighted, undirected graph where a vertex corresponds to an NP and an edge is weighted by the pairwise coreference scores between two NPs (e.g., McCallum and Wellner (2004), Nicolae and Nico4 If a probabilistic model is used, we can define a threshold above which a pair of NPs is considered coreferent. 1398 \x0clae (2006)). The Dempster-Shafer rule (Dempster, 1968), which </context>
</contexts>
<marker>Bansal, Blum, Chawla, 2002</marker>
<rawString>Nikhil Bansal, Avrim Blum, and Shuchi Chawla. 2002. Correlation clustering. In Proceedings of the 43rd Annual IEEE Symposium on Foundations of Computer Science, pages 238247.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Catalina Barbu</author>
<author>Ruslan Mitkov</author>
</authors>
<title>Evaluation Association for Computational Linguistics,</title>
<date>2001</date>
<pages>148156</pages>
<contexts>
<context position="41407" citStr="Barbu and Mitkov, 2001" startWordPosition="6530" endWordPosition="6533">CoRTex (Denis and Baldridge, 2008), the Illinois Coreference Package (Bengtson and Roth, 2008), CherryPicker (Rahman and Ng, 2009), Reconcile (Stoyanov et al., 2010), and Charniak and Elsners (2009) pronoun resolver. We conclude with a discussion of two questions regarding supervised coreference research. First, what is the state of the art? This is not an easy question, as researchers have been evaluating their resolvers on different corpora using different evaluation metrics and preprocessing tools. In particular, preprocessing tools can have a large impact on the performance of a resolver (Barbu and Mitkov, 2001). Worse still, assumptions about whether gold or automatically extracted NPs are used are sometimes not explicitly stated, potentially causing results to be interpreted incorrectly. To our knowledge, however, the best results on the MUC-6 and MUC-7 data sets using automatically extracted NPs are reported by Yang et al. (2003) (71.3 MUC F-score) and Ng and Cardie (2002c) (63.4 MUC F-score), respectively;8 and the best results on the ACE data sets using gold NPs can be found in Luo (2007) (88.4 ACE-value). Second, what lessons can we learn from fifteen years of learning-based coreference researc</context>
</contexts>
<marker>Barbu, Mitkov, 2001</marker>
<rawString>Catalina Barbu and Ruslan Mitkov. 2001. Evaluation Association for Computational Linguistics, pages 148156.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
</authors>
<title>Towards a Model of Childrens Story Comphrension.</title>
<date>1972</date>
<tech>AI-TR 266,</tech>
<institution>Artificial Intelligence Laboratory, Massachusetts Institute of Technology, USA.</institution>
<contexts>
<context position="1416" citStr="Charniak, 1972" startWordPosition="206" endWordPosition="207">ame real-world entity, has been at the core of natural language processing (NLP) since the 1960s. NP coreference is related to the task of anaphora resolution, whose goal is to identify an antecedent for an anaphoric NP (i.e., an NP that depends on another NP, specifically its antecedent, for its interpretation) [see van Deemter and Kibble (2000) for a detailed discussion of the difference between the two tasks]. Despite its simple task definition, coreference is generally considered a difficult NLP task, typically involving the use of sophisticated knowledge sources and inference procedures (Charniak, 1972). Computational theories of discourse, in particular focusing (see Grosz (1977) and Sidner (1979)) and centering (Grosz et al. (1983; 1995)), have heavily influenced coreference research in the 1970s and 1980s, leading to the development of numerous centering algorithms (see Walker et al. (1998)). The focus of coreference research underwent a gradual shift from heuristic approaches to machine learning approaches in the 1990s. This shift can be attributed in part to the advent of the statistical NLP era, and in part to the public availability of annotated coreference corpora produced as part of</context>
</contexts>
<marker>Charniak, 1972</marker>
<rawString>Eugene Charniak. 1972. Towards a Model of Childrens Story Comphrension. AI-TR 266, Artificial Intelligence Laboratory, Massachusetts Institute of Technology, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Cherry</author>
<author>Shane Bergsma</author>
</authors>
<title>An expectation maximization approach to pronoun resolution.</title>
<date>2005</date>
<booktitle>In Proceedings of the Ninth Conference on Computational Natural Language Learning,</booktitle>
<pages>8895</pages>
<contexts>
<context position="38950" citStr="Cherry and Bergsma, 2005" startWordPosition="6149" endWordPosition="6152">s evaluating a resolver against multiple scorers, which can indirectly help to counteract the bias inherent in a particular scorer. For further discussion on evaluation issues, see Byron (2001). 6 Concluding Remarks While we have focused our discussion on supervised approaches, coreference researchers have also attempted to reduce a resolvers reliance on annotated data by combining a small amount of labeled data and a large amount of unlabeled data using general-purpose semi-supervised learning algorithms such as co-training (Muller et al., 2002), self-training (Kehler et al., 2004a), and EM (Cherry and Bergsma, 2005; Ng, 2008). Interestingly, recent results indicate that unsupervised approaches to coreference resolution (e.g., Haghighi and Klein (2007; 2010), Poon and Domingos (2008)) rival their supervised counterparts, casting doubts on whether supervised resolvers are making effective use of the available labeled data. Another issue that we have not focused on but which is becoming increasingly important is multilinguality. While many of the techniques discussed in this paper were originally developed for English, they have been applied to learn coreference models for other languages, such as Chinese </context>
</contexts>
<marker>Cherry, Bergsma, 2005</marker>
<rawString>Colin Cherry and Shane Bergsma. 2005. An expectation maximization approach to pronoun resolution. In Proceedings of the Ninth Conference on Computational Natural Language Learning, pages 8895.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noam Chomsky</author>
</authors>
<title>Language and Problems of Knowledge. The Managua Lectures.</title>
<date>1988</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, Massachusetts.</location>
<contexts>
<context position="28659" citStr="Chomsky, 1988" startWordPosition="4482" endWordPosition="4483"> al., 2002). Yang et al. (2004a) treat the two NPs involved as two bags of words, and compute their similarity using metrics commonly-used in information retrieval, such as the dot product, with each word weighted by their TF-IDF value. Syntactic features are computed based on a syntactic parse tree. Ge et al. (1998) implement 1401 \x0ca Hobbs distance feature, which encodes the rank assigned to a candidate antecedent for a pronoun by Hobbss (1978) seminal syntax-based pronoun resolution algorithm. Luo and Zitouni (2005) extract features from a parse tree for implementing Binding Constraints (Chomsky, 1988). Given an automatically parsed corpus, Bergsma and Lin (2006) extract from each parse tree a dependency path, which is represented as a sequence of nodes and dependency labels connecting a pronoun and a candidate antecedent, and collect statistical information from these paths to determine the likelihood that a pronoun and a candidate antecedent connected by a given path are coreferent. Rather than deriving features from parse trees, Iida et al. (2006) and Yang et al. (2006) employ these trees directly as structured features for pronoun resolution. Specifically, Yang et al. define tree kernel</context>
</contexts>
<marker>Chomsky, 1988</marker>
<rawString>Noam Chomsky. 1988. Language and Problems of Knowledge. The Managua Lectures. MIT Press, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Cohen</author>
</authors>
<title>Fast effective rule induction.</title>
<date>1995</date>
<booktitle>In Proceedings of the 12th International Conference on Machine Learning,</booktitle>
<pages>115123</pages>
<contexts>
<context position="10765" citStr="Cohen, 1995" startWordPosition="1656" endWordPosition="1657">tify than the others (see Harabagiu et al. (2001)), Ng and Cardie (2002a) present a method for mining easy positive instances, in an attempt to avoid the inclusion of hard training instances that may complicate the acquisition of an accurate coreference model. 3.1.2 Training a Coreference Classifier Once a training set is created, we can train a coreference model using an off-the-shelf learning algorithm. Decision tree induction systems (e.g., C5 (Quinlan, 1993)) are the first and one of the most widely used learning algorithms by coreference researchers, although rule learners (e.g., RIPPER (Cohen, 1995)) and memory-based learners (e.g., TiMBL (Daelemans and Van den Bosch, 2005)) are also popular choices, especially in early applications of machine learning to coreference resolution. In recent years, statistical learners such as maximum entropy models (Berger et al., 1996), voted perceptrons (Freund and Schapire, 1999), 3 In this paper, we use the term anaphoric to describe any NP that is part of a coreference chain but is not the head of the chain. Hence, proper names can be anaphoric under this overloaded definition, but linguistically, they are not. and support vector machines (Joachims, 1</context>
</contexts>
<marker>Cohen, 1995</marker>
<rawString>William Cohen. 1995. Fast effective rule induction. In Proceedings of the 12th International Conference on Machine Learning, pages 115123.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dennis Connolly</author>
<author>John D Burger</author>
<author>David S Day</author>
</authors>
<title>A machine learning approach to anaphoric reference.</title>
<date>1994</date>
<booktitle>In Proceedings of International Conference on New Methods in Language Processing,</booktitle>
<pages>255261</pages>
<contexts>
<context position="2649" citStr="Connolly et al., 1994" startWordPosition="392" endWordPosition="395">(1995) and MUC-7 (1998) conferences. Learning-based coreference research has remained vibrant since then, with results regularly published not only in general NLP conferences, but also in specialized conferences (e.g., the biennial Discourse Anaphora and Anaphor Resolution Colloquium (DAARC)) and workshops (e.g., the series of Bergen Workshop on Anaphora Resolution (WAR)). Being inherently a clustering task, coreference has also received a lot of attention in the machine learning community. Fifteen years have passed since the first paper on learning-based coreference resolution was published (Connolly et al., 1994). Our goal in this paper is to provide NLP researchers with a survey of the major milestones in supervised coreference research, focusing on the computational models, the linguistic features, the annotated corpora, and the evaluation metrics that were developed in the past fifteen years. Note that several leading coreference researchers have published books (e.g., Mitkov (2002)), written survey articles (e.g., Mitkov (1999), Strube (2009)), and delivered tutorials (e.g., Strube (2002), Ponzetto and Poesio (2009)) that provide a broad overview of coreference research. This survey paper aims to </context>
<context position="25338" citStr="Connolly et al. (1994" startWordPosition="3949" endWordPosition="3952">a natural resolution strategy for a ranking approach: an anaphoric NP is resolved to the candidate antecedent that has the highest rank. This contrasts with classification-based approaches, where many clustering algorithms have been employed to coordinate the pairwise classification decisions, and it is still not clear which of them is the best. The notion of ranking candidate antecedents can be traced back to centering algorithms, many of which use grammatical roles to rank forwardlooking centers (see Walker et al. (1998)). Ranking is first applied to learning-based coreference resolution by Connolly et al. (1994; 1997), where a model is trained to rank two candidate antecedents. Each training instance corresponds to the NP to be resolved, NPk, as well as two candidate antecedents, NPi and NPj, one of which is an antecedent of NPk and the other is not. Its class value indicates which of the two candidates is better. This model is referred to as the tournament model by Iida et al. (2003) and the twin-candidate model by Yang et al. (2003; 2008b). To resolve an NP during testing, one way is to apply the model to each pair of its candidate antecedents, and the candidate that is classified as better the la</context>
</contexts>
<marker>Connolly, Burger, Day, 1994</marker>
<rawString>Dennis Connolly, John D. Burger, and David S. Day. 1994. A machine learning approach to anaphoric reference. In Proceedings of International Conference on New Methods in Language Processing, pages 255261.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dennis Connolly</author>
<author>John D Burger</author>
<author>David S Day</author>
</authors>
<title>A machine learning approach to anaphoric reference.</title>
<date>1997</date>
<booktitle>New Methods in Language Processing,</booktitle>
<pages>133144</pages>
<editor>In D. Jones and H. Somers, editors,</editor>
<publisher>UCL Press.</publisher>
<marker>Connolly, Burger, Day, 1997</marker>
<rawString>Dennis Connolly, John D. Burger, and David S. Day. 1997. A machine learning approach to anaphoric reference. In D. Jones and H. Somers, editors, New Methods in Language Processing, pages 133144. UCL Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>\x0cSusan Converse</author>
</authors>
<title>Pronominal Anaphora Resolution in Chinese.</title>
<date>2006</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania, USA.</institution>
<contexts>
<context position="39572" citStr="Converse (2006)" startWordPosition="6246" endWordPosition="6247">008). Interestingly, recent results indicate that unsupervised approaches to coreference resolution (e.g., Haghighi and Klein (2007; 2010), Poon and Domingos (2008)) rival their supervised counterparts, casting doubts on whether supervised resolvers are making effective use of the available labeled data. Another issue that we have not focused on but which is becoming increasingly important is multilinguality. While many of the techniques discussed in this paper were originally developed for English, they have been applied to learn coreference models for other languages, such as Chinese (e.g., Converse (2006)), Japanese (e.g., Iida (2007)), Arabic (e.g., Luo and Zitouni (2005)), Dutch (e.g., Hoste (2005)), German (e.g., Wunsch (2010)), Swedish (e.g., Nilsson (2010)), and Czech (e.g., Ngu .y et al. (2009)). In addition, researchers have developed approaches that are targeted at handling certain kinds of anaphora present in non-English languages, such as zero anaphora (e.g., Iida et al. (2007a), Zhao and Ng (2007)). As Mitkov (2001) puts it, coreference resolution is a difficult, but not intractable problem, and we have been making slow, but steady progress on improving machine learning approaches t</context>
</contexts>
<marker>Converse, 2006</marker>
<rawString>\x0cSusan Converse. 2006. Pronominal Anaphora Resolution in Chinese. Ph.D. thesis, University of Pennsylvania, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aron Culotta</author>
<author>Michael Wick</author>
<author>Andrew McCallum</author>
</authors>
<title>First-order probabilistic models for coreference resolution.</title>
<date>2007</date>
<booktitle>In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference,</booktitle>
<pages>8188</pages>
<contexts>
<context position="23591" citStr="Culotta et al. (2007)" startWordPosition="3680" endWordPosition="3683">ts. For example, Luo et al. (2004) apply the ANY predicate to generate cluster-level features for their entity-mention model, which does not perform as well as the mention-pair model. Yang et al. (2004b; 2008a) also investigate the entity-mention model, which produces results that are only marginally better than those of the mention-pair model. However, it appears that they are not fully exploiting the expressiveness of the entity-mention model, as cluster-level features only comprise a small fraction of their features. Variants of the entity-mention model have been investigated. For example, Culotta et al. (2007) present a first-order logic model that determines 1400 \x0cthe probability that an arbitrary set of NPs are all co-referring. Their model resembles the entitymention model in that it enables the use of clusterlevel features. Daume III and Marcu (2005) propose an online learning model for constructing coreference chains in an incremental fashion, allowing later coreference decisions to be made by exploiting cluster-level features that are computed over the coreference chains created thus far. 3.3 Ranking Models While the entity-mention model addresses the expressiveness problem with the mentio</context>
</contexts>
<marker>Culotta, Wick, McCallum, 2007</marker>
<rawString>Aron Culotta, Michael Wick, and Andrew McCallum. 2007. First-order probabilistic models for coreference resolution. In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference, pages 8188.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter Daelemans</author>
<author>Antal Van den Bosch</author>
</authors>
<title>Memory-Based Language Processing.</title>
<date>2005</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge, UK.</location>
<marker>Daelemans, Van den Bosch, 2005</marker>
<rawString>Walter Daelemans and Antal Van den Bosch. 2005. Memory-Based Language Processing. Cambridge University Press, Cambridge, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Alon Itai</author>
</authors>
<title>Automatic processing Thorsten Joachims.</title>
<date>1990</date>
<booktitle>In Bernhard Scholkopf and Alexander Smola, editors, Advances in Kernel Methods - Support Vector Learning,</booktitle>
<pages>4456</pages>
<publisher>MIT Press.</publisher>
<contexts>
<context position="30414" citStr="Dagan and Itai, 1990" startWordPosition="4763" endWordPosition="4766">ence. For example, coreferent NPs have to agree in number and gender and cannot span one another (e.g., Google and Google employees). There are also features that encode general linguistic preferences either for or against coreference. For example, an indefinite NP (that is not in apposition to an anaphoric NP) is not likely to be coreferent with any NP that precedes it. There has been an increasing amount of work on investigating semantic features for coreference resolution. One of the earliest kinds of semantic knowledge employed for coreference resolution is perhaps selectional preference (Dagan and Itai, 1990; Kehler et al., 2004b; Yang et al., 2005; Haghighi and Klein, 2009): given a pronoun to be resolved, its governing verb, and its grammatical role, we prefer a candidate antecedent that can be governed by the same verb and be in the same role. Semantic knowledge has also been extracted from WordNet and unannotated corpora for computing the semantic compatibility/similarity between two common nouns (Harabagiu et al., 2001; Versley, 2007) as well as the semantic class of a noun (Ng, 2007a; Huang et al., 2009). One difficulty with deriving knowledge from WordNet is that one has to determine which</context>
</contexts>
<marker>Dagan, Itai, 1990</marker>
<rawString>Ido Dagan and Alon Itai. 1990. Automatic processing Thorsten Joachims. 1999. Making large-scale SVM learning practical. In Bernhard Scholkopf and Alexander Smola, editors, Advances in Kernel Methods - Support Vector Learning, pages 4456. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Kehler</author>
<author>Douglas Appelt</author>
<author>Lara Taylor</author>
<author>Aleksandr Simma</author>
</authors>
<title>Competitive self-trained pronoun interpretation.</title>
<date>2004</date>
<booktitle>In Proceedings of HLTNAACL 2004: Short Papers,</booktitle>
<pages>3336</pages>
<contexts>
<context position="30435" citStr="Kehler et al., 2004" startWordPosition="4767" endWordPosition="4770">eferent NPs have to agree in number and gender and cannot span one another (e.g., Google and Google employees). There are also features that encode general linguistic preferences either for or against coreference. For example, an indefinite NP (that is not in apposition to an anaphoric NP) is not likely to be coreferent with any NP that precedes it. There has been an increasing amount of work on investigating semantic features for coreference resolution. One of the earliest kinds of semantic knowledge employed for coreference resolution is perhaps selectional preference (Dagan and Itai, 1990; Kehler et al., 2004b; Yang et al., 2005; Haghighi and Klein, 2009): given a pronoun to be resolved, its governing verb, and its grammatical role, we prefer a candidate antecedent that can be governed by the same verb and be in the same role. Semantic knowledge has also been extracted from WordNet and unannotated corpora for computing the semantic compatibility/similarity between two common nouns (Harabagiu et al., 2001; Versley, 2007) as well as the semantic class of a noun (Ng, 2007a; Huang et al., 2009). One difficulty with deriving knowledge from WordNet is that one has to determine which sense of a given wor</context>
<context position="38914" citStr="Kehler et al., 2004" startWordPosition="6143" endWordPosition="6146">ng that there is a trend towards evaluating a resolver against multiple scorers, which can indirectly help to counteract the bias inherent in a particular scorer. For further discussion on evaluation issues, see Byron (2001). 6 Concluding Remarks While we have focused our discussion on supervised approaches, coreference researchers have also attempted to reduce a resolvers reliance on annotated data by combining a small amount of labeled data and a large amount of unlabeled data using general-purpose semi-supervised learning algorithms such as co-training (Muller et al., 2002), self-training (Kehler et al., 2004a), and EM (Cherry and Bergsma, 2005; Ng, 2008). Interestingly, recent results indicate that unsupervised approaches to coreference resolution (e.g., Haghighi and Klein (2007; 2010), Poon and Domingos (2008)) rival their supervised counterparts, casting doubts on whether supervised resolvers are making effective use of the available labeled data. Another issue that we have not focused on but which is becoming increasingly important is multilinguality. While many of the techniques discussed in this paper were originally developed for English, they have been applied to learn coreference models f</context>
</contexts>
<marker>Kehler, Appelt, Taylor, Simma, 2004</marker>
<rawString>Andrew Kehler, Douglas Appelt, Lara Taylor, and Aleksandr Simma. 2004a. Competitive self-trained pronoun interpretation. In Proceedings of HLTNAACL 2004: Short Papers, pages 3336.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Kehler</author>
<author>Douglas Appelt</author>
<author>Lara Taylor</author>
<author>Aleksandr Simma</author>
</authors>
<title>The (non)utility of \x0cFang Kong, GuoDong Zhou, and Qiaoming Zhu.</title>
<date>2004</date>
<contexts>
<context position="30435" citStr="Kehler et al., 2004" startWordPosition="4767" endWordPosition="4770">eferent NPs have to agree in number and gender and cannot span one another (e.g., Google and Google employees). There are also features that encode general linguistic preferences either for or against coreference. For example, an indefinite NP (that is not in apposition to an anaphoric NP) is not likely to be coreferent with any NP that precedes it. There has been an increasing amount of work on investigating semantic features for coreference resolution. One of the earliest kinds of semantic knowledge employed for coreference resolution is perhaps selectional preference (Dagan and Itai, 1990; Kehler et al., 2004b; Yang et al., 2005; Haghighi and Klein, 2009): given a pronoun to be resolved, its governing verb, and its grammatical role, we prefer a candidate antecedent that can be governed by the same verb and be in the same role. Semantic knowledge has also been extracted from WordNet and unannotated corpora for computing the semantic compatibility/similarity between two common nouns (Harabagiu et al., 2001; Versley, 2007) as well as the semantic class of a noun (Ng, 2007a; Huang et al., 2009). One difficulty with deriving knowledge from WordNet is that one has to determine which sense of a given wor</context>
<context position="38914" citStr="Kehler et al., 2004" startWordPosition="6143" endWordPosition="6146">ng that there is a trend towards evaluating a resolver against multiple scorers, which can indirectly help to counteract the bias inherent in a particular scorer. For further discussion on evaluation issues, see Byron (2001). 6 Concluding Remarks While we have focused our discussion on supervised approaches, coreference researchers have also attempted to reduce a resolvers reliance on annotated data by combining a small amount of labeled data and a large amount of unlabeled data using general-purpose semi-supervised learning algorithms such as co-training (Muller et al., 2002), self-training (Kehler et al., 2004a), and EM (Cherry and Bergsma, 2005; Ng, 2008). Interestingly, recent results indicate that unsupervised approaches to coreference resolution (e.g., Haghighi and Klein (2007; 2010), Poon and Domingos (2008)) rival their supervised counterparts, casting doubts on whether supervised resolvers are making effective use of the available labeled data. Another issue that we have not focused on but which is becoming increasingly important is multilinguality. While many of the techniques discussed in this paper were originally developed for English, they have been applied to learn coreference models f</context>
</contexts>
<marker>Kehler, Appelt, Taylor, Simma, 2004</marker>
<rawString>Andrew Kehler, Douglas Appelt, Lara Taylor, and Aleksandr Simma. 2004b. The (non)utility of \x0cFang Kong, GuoDong Zhou, and Qiaoming Zhu. 2009.</rawString>
</citation>
<citation valid="false">
<title>Employing the centering theory in pronoun resolution from the semantic perspective.</title>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>987996</pages>
<marker></marker>
<rawString>Employing the centering theory in pronoun resolution from the semantic perspective. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 987996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shalom Lappin</author>
<author>Herbert Leass</author>
</authors>
<title>An algorithm for pronominal anaphora resolution.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>20</volume>
<issue>4</issue>
<contexts>
<context position="17102" citStr="Lappin and Leass (1994)" startWordPosition="2676" endWordPosition="2679">m-cutbased graph partitioning algorithm. 3.1.4 Determining NP Anaphoricity While coreference clustering algorithms attempt to resolve each NP encountered in a document, only a subset of the NPs are anaphoric and therefore need to be resolved. Hence, knowledge of the anaphoricity of an NP can potentially improve the precision of a coreference resolver. Traditionally, the task of anaphoricity determination has been tackled independently of coreference resolution using a variety of techniques. For example, pleonastic it has been identified using heuristic approaches (e.g., Paice and Husk (1987), Lappin and Leass (1994), Kennedy and Boguraev (1996)), supervised approaches (e.g., Evans (2001), Muller (2006), Versley et al. (2008a)), and distributional methods (e.g., Bergsma et al. (2008)); and non-anaphoric definite descriptions have been identified using rule-based techniques (e.g., Vieira and Poesio (2000)) and unsupervised techniques (e.g., Bean and Riloff (1999)). Recently, anaphoricity determination has been evaluated in the context of coreference resolution, with results showing that training an anaphoricity classifier to identify and filter non-anaphoric NPs prior to coreference resolution can improve </context>
</contexts>
<marker>Lappin, Leass, 1994</marker>
<rawString>Shalom Lappin and Herbert Leass. 1994. An algorithm for pronominal anaphora resolution. Computational Linguistics, 20(4):535562.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaoqiang Luo</author>
<author>Imed Zitouni</author>
</authors>
<title>Multi-lingual coreference resolution with syntactic features.</title>
<date>2005</date>
<booktitle>In Proceedings of the Human Language Technology Conference and the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>660--667</pages>
<contexts>
<context position="28571" citStr="Luo and Zitouni (2005)" startWordPosition="4466" endWordPosition="4469">including minimum edit distance (Strube et al., 2002) and longest common subsequence (Castano et al., 2002). Yang et al. (2004a) treat the two NPs involved as two bags of words, and compute their similarity using metrics commonly-used in information retrieval, such as the dot product, with each word weighted by their TF-IDF value. Syntactic features are computed based on a syntactic parse tree. Ge et al. (1998) implement 1401 \x0ca Hobbs distance feature, which encodes the rank assigned to a candidate antecedent for a pronoun by Hobbss (1978) seminal syntax-based pronoun resolution algorithm. Luo and Zitouni (2005) extract features from a parse tree for implementing Binding Constraints (Chomsky, 1988). Given an automatically parsed corpus, Bergsma and Lin (2006) extract from each parse tree a dependency path, which is represented as a sequence of nodes and dependency labels connecting a pronoun and a candidate antecedent, and collect statistical information from these paths to determine the likelihood that a pronoun and a candidate antecedent connected by a given path are coreferent. Rather than deriving features from parse trees, Iida et al. (2006) and Yang et al. (2006) employ these trees directly as </context>
<context position="39641" citStr="Luo and Zitouni (2005)" startWordPosition="6254" endWordPosition="6257"> approaches to coreference resolution (e.g., Haghighi and Klein (2007; 2010), Poon and Domingos (2008)) rival their supervised counterparts, casting doubts on whether supervised resolvers are making effective use of the available labeled data. Another issue that we have not focused on but which is becoming increasingly important is multilinguality. While many of the techniques discussed in this paper were originally developed for English, they have been applied to learn coreference models for other languages, such as Chinese (e.g., Converse (2006)), Japanese (e.g., Iida (2007)), Arabic (e.g., Luo and Zitouni (2005)), Dutch (e.g., Hoste (2005)), German (e.g., Wunsch (2010)), Swedish (e.g., Nilsson (2010)), and Czech (e.g., Ngu .y et al. (2009)). In addition, researchers have developed approaches that are targeted at handling certain kinds of anaphora present in non-English languages, such as zero anaphora (e.g., Iida et al. (2007a), Zhao and Ng (2007)). As Mitkov (2001) puts it, coreference resolution is a difficult, but not intractable problem, and we have been making slow, but steady progress on improving machine learning approaches to the problem in the past fifteen years. To ensure further progress, </context>
</contexts>
<marker>Luo, Zitouni, 2005</marker>
<rawString>Xiaoqiang Luo and Imed Zitouni. 2005. Multi-lingual coreference resolution with syntactic features. In Proceedings of the Human Language Technology Conference and the Conference on Empirical Methods in Natural Language Processing, pages 660 667.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaoqiang Luo</author>
<author>Abe Ittycheriah</author>
<author>Hongyan Jing</author>
<author>Nanda Kambhatla</author>
<author>Salim Roukos</author>
</authors>
<title>A mentionsynchronous coreference resolution algorithm based on the Bell tree.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>135142</pages>
<contexts>
<context position="23004" citStr="Luo et al. (2004)" startWordPosition="3592" endWordPosition="3595">with all of the NPs in Cj and NO otherwise. Other commonly-used logical predicates for creating cluster-level features include relaxed versions of the ALL predicate, such as MOST, which is true if NPk agrees in number with more than half of the NPs in Cj, and ANY, which is true as long as NPk agrees in number with just one of the NPs in Cj. The ability of the entity-mention model to employ cluster-level features makes it more expressive than its mention-pair counterpart. Despite its improved expressiveness, the entitymention model has not yielded particularly encouraging results. For example, Luo et al. (2004) apply the ANY predicate to generate cluster-level features for their entity-mention model, which does not perform as well as the mention-pair model. Yang et al. (2004b; 2008a) also investigate the entity-mention model, which produces results that are only marginally better than those of the mention-pair model. However, it appears that they are not fully exploiting the expressiveness of the entity-mention model, as cluster-level features only comprise a small fraction of their features. Variants of the entity-mention model have been investigated. For example, Culotta et al. (2007) present a fi</context>
<context position="34171" citStr="Luo et al., 2004" startWordPosition="5383" endWordPosition="5386">d Veins Theory (Ide and Cristea, 2000) to identify and remove candidate antecedents that are not referentially accessible to an anaphoric pronoun in his heuristic pronoun resolvers. It would be interesting to incorporate this idea into a learning-based resolver. There are also features that do not fall into any of the preceding categories. For example, a memorization feature is a word pair composed of the head nouns of the two NPs involved in an instance (Bengtson and Roth, 2008). Memorization features have been used as binary-valued features indicating the presence or absence of their words (Luo et al., 2004) or as probabilistic features indicating the probability that the two heads are coreferent according to the training data (Ng, 2007b). An anaphoricity feature indicates whether an NP to be resolved is anaphoric, and is typically computed using an anaphoricity classifier (Ng, 2004), hand-crafted patterns (Daume III and Marcu, 2005), and automatically acquired patterns (Bean and Riloff, 1999). Finally, the outputs of rule-based pronoun and coreference resolvers have also been used as features for learning-based coreference resolution (Ng and Cardie, 2002c). For an empirical evaluation of the con</context>
</contexts>
<marker>Luo, Ittycheriah, Jing, Kambhatla, Roukos, 2004</marker>
<rawString>Xiaoqiang Luo, Abe Ittycheriah, Hongyan Jing, Nanda Kambhatla, and Salim Roukos. 2004. A mentionsynchronous coreference resolution algorithm based on the Bell tree. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics, pages 135142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaoqiang Luo</author>
</authors>
<title>On coreference resolution performance metrics.</title>
<date>2005</date>
<booktitle>In Proceedings of the Human Language Technology Conference and the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>2532</pages>
<contexts>
<context position="37592" citStr="Luo, 2005" startWordPosition="5937" endWordPosition="5938">ence resolvers employing different extraction methods should not be compared against each other. 5.2 Scoring a Coreference Partition The MUC scorer (Vilain et al., 1995) is the first program developed for scoring coreference partitions. It has two often-cited weaknesses. As a linkbased measure, it does not reward correctly identified singleton clusters since there is no coreference link in these clusters. Also, it tends to underpenalize partitions with overly large clusters. To address these problems, two coreference scoring programs have been developed: B3 (Bagga and Baldwin, 1998) and CEAF (Luo, 2005). Note that both scorers have only been defined for the case where the key partition has the same set of NPs as the response partition. To apply these scorers to automatically extracted NPs, different methods have been proposed (see Rahman and Ng (2009) and Stoyanov et al. (2009)). Since coreference is a clustering task, any general-purpose method for evaluating a response partition against a key partition (e.g., Kappa (Carletta, 1996)) can be used for coreference scor1403 \x0cing (see Popescu-Belis et al. (2004)). In practice, these general-purpose methods are typically used to provide scores</context>
</contexts>
<marker>Luo, 2005</marker>
<rawString>Xiaoqiang Luo. 2005. On coreference resolution performance metrics. In Proceedings of the Human Language Technology Conference and the Conference on Empirical Methods in Natural Language Processing, pages 2532.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaoqiang Luo</author>
</authors>
<title>Coreference or not: A twin model for coreference resolution.</title>
<date>2007</date>
<booktitle>In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference,</booktitle>
<pages>7380</pages>
<contexts>
<context position="41898" citStr="Luo (2007)" startWordPosition="6612" endWordPosition="6613">s. In particular, preprocessing tools can have a large impact on the performance of a resolver (Barbu and Mitkov, 2001). Worse still, assumptions about whether gold or automatically extracted NPs are used are sometimes not explicitly stated, potentially causing results to be interpreted incorrectly. To our knowledge, however, the best results on the MUC-6 and MUC-7 data sets using automatically extracted NPs are reported by Yang et al. (2003) (71.3 MUC F-score) and Ng and Cardie (2002c) (63.4 MUC F-score), respectively;8 and the best results on the ACE data sets using gold NPs can be found in Luo (2007) (88.4 ACE-value). Second, what lessons can we learn from fifteen years of learning-based coreference research? The mention-pair model is weak because it makes coreference decisions based on local information (i.e., information extracted from two NPs). Expressive models (e.g., those that can exploit cluster-level features) generally offer better performance, and so are models that are global in nature. Global coreference models may refer to any kind of models that can exploit non-local information, including models that can consider multiple candidate antecedents simultaneously (e.g., ranking </context>
</contexts>
<marker>Luo, 2007</marker>
<rawString>Xiaoqiang Luo. 2007. Coreference or not: A twin model for coreference resolution. In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference, pages 7380.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: The Penn Treebank. Computational Linguistics,</title>
<date>1993</date>
<contexts>
<context position="4846" citStr="Marcus et al., 1993" startWordPosition="717" endWordPosition="720">en extensively used for training and evaluating coreference models. Equally popular are the corpora produced by the Automatic Content Extraction (ACE1) evaluations in the past decade: while the earlier ACE corpora (e.g., ACE-2) consist of solely English newswire and broadcast news articles, the later ones (e.g., ACE 2005) have also included Chinese and Arabic documents taken from additional sources such as broadcast conversations, webblog, usenet, and conversational telephone speech. Coreference annotations are also publicly available in treebanks. These include (1) the English Penn Treebank (Marcus et al., 1993), which is labeled with coreference links as part of the OntoNotes project (Hovy et al., 2006); (2) the Tubingen Treebank (Telljohann et al., 2004), which is a collection of German news articles consisting of 27,125 sentences; (3) the Prague Dependency Treebank (Hajic et al., 2006), which consists of 3168 news articles taken from the Czech National Corpus; (4) the NAIST Text Corpus (Iida et al., 2007b), which consists of 287 Japanese news articles; (5) the AnCora Corpus (Recasens and Mart, 2009), which consists of Spanish and Catalan journalist texts; and (6) the GENIA corpus (Ohta et al., 200</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>Mitchell P. Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1993. Building a large annotated corpus of English: The Penn Treebank. Computational Linguistics, 19(2):313330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katja Markert</author>
<author>Malvina Nissim</author>
</authors>
<title>Comparing knowledge sources for nominal anaphora resolution.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>3</issue>
<contexts>
<context position="32624" citStr="Markert and Nissim, 2005" startWordPosition="5132" endWordPosition="5135">atterns have been used to capture the semantic relatedness between two NPs and hence the likelihood that they are coreferent. For instance, given the pattern X is a Y (which is highly indicative that X and Y are coreferent), we can instantiate it with a pair of NPs and search for the instantiated pattern in a large corpus or the Web (Daume III and Marcu, 2005; Haghighi and Klein, 2009). The more frequently the pattern occurs, the more likely they are coreferent. This technique has been applied to resolve different kinds of anaphoric references, including other-anaphora (Modjeska et al., 2003; Markert and Nissim, 2005) and bridging references (Poesio et al., 2004a). While these patterns are typically hand-crafted (e.g., Garera and Yarowsky (2006)), they can also be learned from an annotated corpus (Yang and Su, 2007) or bootstrapped from an unannotated corpus (Bean and Riloff, 2004). Despite the large amount of work on discoursebased anaphora resolution in the 1970s and 1980s (see Hirst (1981)), learning-based resolvers have only exploited shallow discourse-based features, which primarily involve characterizing the salience of a candidate antecedent by measuring its distance from the anaphoric NP to be reso</context>
</contexts>
<marker>Markert, Nissim, 2005</marker>
<rawString>Katja Markert and Malvina Nissim. 2005. Comparing knowledge sources for nominal anaphora resolution. Computational Linguistics, 31(3):367402.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew McCallum</author>
<author>Ben Wellner</author>
</authors>
<date>2003</date>
<journal>Toward on Artificial Intelligence,</journal>
<pages>10501055</pages>
<contexts>
<context position="20400" citStr="McCallum and Wellner (2003)" startWordPosition="3154" endWordPosition="3157">s limitations in its expressiveness: the information extracted from the two NPs alone may not be sufficient for making an informed coreference decision, especially if the candidate antecedent is a pronoun (which is semantically empty) or a mention that lacks descriptive information such as gender (e.g., Clinton). Below we discuss how these weaknesses are addressed by the entity-mention model and ranking models. 3.2 Entity-Mention Model The entity-mention model addresses the expressiveness problem with the mention-pair model. To motivate the entity-mention model, consider an example taken from McCallum and Wellner (2003), where a document consists of three NPs: Mr. Clinton, Clinton, and she. The mentionpair model may determine that Mr. Clinton and Clinton are coreferent using string-matching features, and that Clinton and she are coreferent based on proximity and lack of evidence for gender and number disagreement. However, these two pairwise decisions together with transitivity imply that Mr. Clinton and she will end up in the same cluster, which is incorrect due to gender mismatch. This kind of error arises in part because the later coreference decisions are not dependent on the earlier ones. In particular,</context>
</contexts>
<marker>McCallum, Wellner, 2003</marker>
<rawString>Andrew McCallum and Ben Wellner. 2003. Toward on Artificial Intelligence, pages 10501055.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruslan Mitkov</author>
</authors>
<title>Anaphora resolution: The state of the art. Technical Report (Based on the COLING/ACL-98 tutorial on anaphora resolution),</title>
<date>1999</date>
<institution>University of Wolverhampton,</institution>
<location>Wolverhampton.</location>
<contexts>
<context position="3076" citStr="Mitkov (1999)" startWordPosition="461" endWordPosition="462">eived a lot of attention in the machine learning community. Fifteen years have passed since the first paper on learning-based coreference resolution was published (Connolly et al., 1994). Our goal in this paper is to provide NLP researchers with a survey of the major milestones in supervised coreference research, focusing on the computational models, the linguistic features, the annotated corpora, and the evaluation metrics that were developed in the past fifteen years. Note that several leading coreference researchers have published books (e.g., Mitkov (2002)), written survey articles (e.g., Mitkov (1999), Strube (2009)), and delivered tutorials (e.g., Strube (2002), Ponzetto and Poesio (2009)) that provide a broad overview of coreference research. This survey paper aims to complement, rather than supersede, these previously published materials. In particular, while existing survey papers discuss learning-based coreference research primarily in the context of the influential mention-pair model, we additionally survey recently proposed learning-based coreference models, which attempt to address the weaknesses of the mention-pair model. Due to space limitations, however, we will restrict our dis</context>
</contexts>
<marker>Mitkov, 1999</marker>
<rawString>Ruslan Mitkov. 1999. Anaphora resolution: The state of the art. Technical Report (Based on the COLING/ACL-98 tutorial on anaphora resolution), University of Wolverhampton, Wolverhampton.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruslan Mitkov</author>
</authors>
<title>Outstanding issues in anaphora resolution.</title>
<date>2001</date>
<booktitle>Computational Linguistics and Intelligent Text Processing,</booktitle>
<pages>110125</pages>
<editor>In Al. Gelbukh, editor,</editor>
<publisher>Springer.</publisher>
<contexts>
<context position="40002" citStr="Mitkov (2001)" startWordPosition="6314" endWordPosition="6315">echniques discussed in this paper were originally developed for English, they have been applied to learn coreference models for other languages, such as Chinese (e.g., Converse (2006)), Japanese (e.g., Iida (2007)), Arabic (e.g., Luo and Zitouni (2005)), Dutch (e.g., Hoste (2005)), German (e.g., Wunsch (2010)), Swedish (e.g., Nilsson (2010)), and Czech (e.g., Ngu .y et al. (2009)). In addition, researchers have developed approaches that are targeted at handling certain kinds of anaphora present in non-English languages, such as zero anaphora (e.g., Iida et al. (2007a), Zhao and Ng (2007)). As Mitkov (2001) puts it, coreference resolution is a difficult, but not intractable problem, and we have been making slow, but steady progress on improving machine learning approaches to the problem in the past fifteen years. To ensure further progress, researchers should compare their results against a baseline that is stronger than the commonly-used Soon et al. (2001) system, which relies on a weak model (i.e., the mention-pair model) and a small set of linguistic features. As recent systems are becoming more sophisticated, we suggest that researchers make their systems publicly available in order to facil</context>
<context position="41407" citStr="Mitkov, 2001" startWordPosition="6532" endWordPosition="6533">nis and Baldridge, 2008), the Illinois Coreference Package (Bengtson and Roth, 2008), CherryPicker (Rahman and Ng, 2009), Reconcile (Stoyanov et al., 2010), and Charniak and Elsners (2009) pronoun resolver. We conclude with a discussion of two questions regarding supervised coreference research. First, what is the state of the art? This is not an easy question, as researchers have been evaluating their resolvers on different corpora using different evaluation metrics and preprocessing tools. In particular, preprocessing tools can have a large impact on the performance of a resolver (Barbu and Mitkov, 2001). Worse still, assumptions about whether gold or automatically extracted NPs are used are sometimes not explicitly stated, potentially causing results to be interpreted incorrectly. To our knowledge, however, the best results on the MUC-6 and MUC-7 data sets using automatically extracted NPs are reported by Yang et al. (2003) (71.3 MUC F-score) and Ng and Cardie (2002c) (63.4 MUC F-score), respectively;8 and the best results on the ACE data sets using gold NPs can be found in Luo (2007) (88.4 ACE-value). Second, what lessons can we learn from fifteen years of learning-based coreference researc</context>
</contexts>
<marker>Mitkov, 2001</marker>
<rawString>Ruslan Mitkov. 2001. Outstanding issues in anaphora resolution. In Al. Gelbukh, editor, Computational Linguistics and Intelligent Text Processing, pages 110125. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruslan Mitkov</author>
</authors>
<title>Anaphora Resolution.</title>
<date>2002</date>
<publisher>Longman.</publisher>
<contexts>
<context position="3029" citStr="Mitkov (2002)" startWordPosition="454" endWordPosition="455">tly a clustering task, coreference has also received a lot of attention in the machine learning community. Fifteen years have passed since the first paper on learning-based coreference resolution was published (Connolly et al., 1994). Our goal in this paper is to provide NLP researchers with a survey of the major milestones in supervised coreference research, focusing on the computational models, the linguistic features, the annotated corpora, and the evaluation metrics that were developed in the past fifteen years. Note that several leading coreference researchers have published books (e.g., Mitkov (2002)), written survey articles (e.g., Mitkov (1999), Strube (2009)), and delivered tutorials (e.g., Strube (2002), Ponzetto and Poesio (2009)) that provide a broad overview of coreference research. This survey paper aims to complement, rather than supersede, these previously published materials. In particular, while existing survey papers discuss learning-based coreference research primarily in the context of the influential mention-pair model, we additionally survey recently proposed learning-based coreference models, which attempt to address the weaknesses of the mention-pair model. Due to space</context>
</contexts>
<marker>Mitkov, 2002</marker>
<rawString>Ruslan Mitkov. 2002. Anaphora Resolution. Longman.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Natalia N Modjeska</author>
<author>Katja Markert</author>
<author>Malvina Nissim</author>
</authors>
<title>Using the web in machine learning for other-anaphora resolution.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>176183</pages>
<contexts>
<context position="32597" citStr="Modjeska et al., 2003" startWordPosition="5128" endWordPosition="5131">ion. Lexico-syntactic patterns have been used to capture the semantic relatedness between two NPs and hence the likelihood that they are coreferent. For instance, given the pattern X is a Y (which is highly indicative that X and Y are coreferent), we can instantiate it with a pair of NPs and search for the instantiated pattern in a large corpus or the Web (Daume III and Marcu, 2005; Haghighi and Klein, 2009). The more frequently the pattern occurs, the more likely they are coreferent. This technique has been applied to resolve different kinds of anaphoric references, including other-anaphora (Modjeska et al., 2003; Markert and Nissim, 2005) and bridging references (Poesio et al., 2004a). While these patterns are typically hand-crafted (e.g., Garera and Yarowsky (2006)), they can also be learned from an annotated corpus (Yang and Su, 2007) or bootstrapped from an unannotated corpus (Bean and Riloff, 2004). Despite the large amount of work on discoursebased anaphora resolution in the 1970s and 1980s (see Hirst (1981)), learning-based resolvers have only exploited shallow discourse-based features, which primarily involve characterizing the salience of a candidate antecedent by measuring its distance from </context>
</contexts>
<marker>Modjeska, Markert, Nissim, 2003</marker>
<rawString>Natalia N. Modjeska, Katja Markert, and Malvina Nissim. 2003. Using the web in machine learning for other-anaphora resolution. In Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing, pages 176183.</rawString>
</citation>
<citation valid="true">
<date>1995</date>
<booktitle>Proceedings of the Sixth Message Understanding Conference.</booktitle>
<contexts>
<context position="1555" citStr="(1983; 1995)" startWordPosition="229" endWordPosition="230">phora resolution, whose goal is to identify an antecedent for an anaphoric NP (i.e., an NP that depends on another NP, specifically its antecedent, for its interpretation) [see van Deemter and Kibble (2000) for a detailed discussion of the difference between the two tasks]. Despite its simple task definition, coreference is generally considered a difficult NLP task, typically involving the use of sophisticated knowledge sources and inference procedures (Charniak, 1972). Computational theories of discourse, in particular focusing (see Grosz (1977) and Sidner (1979)) and centering (Grosz et al. (1983; 1995)), have heavily influenced coreference research in the 1970s and 1980s, leading to the development of numerous centering algorithms (see Walker et al. (1998)). The focus of coreference research underwent a gradual shift from heuristic approaches to machine learning approaches in the 1990s. This shift can be attributed in part to the advent of the statistical NLP era, and in part to the public availability of annotated coreference corpora produced as part of the MUC-6 (1995) and MUC-7 (1998) conferences. Learning-based coreference research has remained vibrant since then, with results regularly</context>
<context position="6898" citStr="(1995)" startWordPosition="1034" endWordPosition="1034">on project that aims to collect large amounts of coreference data for English via a Web Collaboration game called Phrase Detectives2. 1 http://www.itl.nist.gov/iad/mig/tests/ace/ 2 http://www.phrasedetectives.org 3 Learning-Based Coreference Models In this section, we examine three important classes of coreference models that were developed in the past fifteen years, namely, the mention-pair model, the entity-mention model, and ranking models. 3.1 Mention-Pair Model The mention-pair model is a classifier that determines whether two NPs are coreferent. It was first proposed by Aone and Bennett (1995) and McCarthy and Lehnert (1995), and is one of the most influential learning-based coreference models. Despite its popularity, this binary classification approach to coreference is somewhat undesirable: the transitivity property inherent in the coreference relation cannot be enforced, as it is possible for the model to determine that A and B are coreferent, B and C are coreferent, but A and C are not coreferent. Hence, a separate clustering mechanism is needed to coordinate the pairwise classification decisions made by the model and construct a coreference partition. Another issue that surrou</context>
</contexts>
<marker>1995</marker>
<rawString>MUC-6. 1995. Proceedings of the Sixth Message Understanding Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>MUC-7</author>
</authors>
<date>1998</date>
<booktitle>Proceedings of the Seventh Message Understanding Conference.</booktitle>
<marker>MUC-7, 1998</marker>
<rawString>MUC-7. 1998. Proceedings of the Seventh Message Understanding Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christoph Muller</author>
<author>Stefan Rapp</author>
<author>Michael Strube</author>
</authors>
<title>Applying co-training to reference resolution.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>352--359</pages>
<contexts>
<context position="38878" citStr="Muller et al., 2002" startWordPosition="6138" endWordPosition="6141">discussed above. It is worth mentioning that there is a trend towards evaluating a resolver against multiple scorers, which can indirectly help to counteract the bias inherent in a particular scorer. For further discussion on evaluation issues, see Byron (2001). 6 Concluding Remarks While we have focused our discussion on supervised approaches, coreference researchers have also attempted to reduce a resolvers reliance on annotated data by combining a small amount of labeled data and a large amount of unlabeled data using general-purpose semi-supervised learning algorithms such as co-training (Muller et al., 2002), self-training (Kehler et al., 2004a), and EM (Cherry and Bergsma, 2005; Ng, 2008). Interestingly, recent results indicate that unsupervised approaches to coreference resolution (e.g., Haghighi and Klein (2007; 2010), Poon and Domingos (2008)) rival their supervised counterparts, casting doubts on whether supervised resolvers are making effective use of the available labeled data. Another issue that we have not focused on but which is becoming increasingly important is multilinguality. While many of the techniques discussed in this paper were originally developed for English, they have been a</context>
</contexts>
<marker>Muller, Rapp, Strube, 2002</marker>
<rawString>Christoph Muller, Stefan Rapp, and Michael Strube. 2002. Applying co-training to reference resolution. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 352 359.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christoph Muller</author>
</authors>
<title>Automatic detection of nonreferential it in spoken multi-party dialog.</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>4956</pages>
<contexts>
<context position="17190" citStr="Muller (2006)" startWordPosition="2690" endWordPosition="2691">ering algorithms attempt to resolve each NP encountered in a document, only a subset of the NPs are anaphoric and therefore need to be resolved. Hence, knowledge of the anaphoricity of an NP can potentially improve the precision of a coreference resolver. Traditionally, the task of anaphoricity determination has been tackled independently of coreference resolution using a variety of techniques. For example, pleonastic it has been identified using heuristic approaches (e.g., Paice and Husk (1987), Lappin and Leass (1994), Kennedy and Boguraev (1996)), supervised approaches (e.g., Evans (2001), Muller (2006), Versley et al. (2008a)), and distributional methods (e.g., Bergsma et al. (2008)); and non-anaphoric definite descriptions have been identified using rule-based techniques (e.g., Vieira and Poesio (2000)) and unsupervised techniques (e.g., Bean and Riloff (1999)). Recently, anaphoricity determination has been evaluated in the context of coreference resolution, with results showing that training an anaphoricity classifier to identify and filter non-anaphoric NPs prior to coreference resolution can improve a learning-based resolver (e.g., Ng and Cardie (2002b), Uryupina (2003), Poesio et al. (</context>
</contexts>
<marker>Muller, 2006</marker>
<rawString>Christoph Muller. 2006. Automatic detection of nonreferential it in spoken multi-party dialog. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics, pages 4956.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vincent Ng</author>
<author>Claire Cardie</author>
</authors>
<title>Combining sample selection and error-driven pruning for machine learning of coreference rules.</title>
<date>2002</date>
<booktitle>In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>5562</pages>
<contexts>
<context position="9158" citStr="Ng and Cardie (2002" startWordPosition="1398" endWordPosition="1401">reference partition. 3.1.1 Creating Training Instances As noted above, the primary purpose of training instance creation is to reduce class skewness. Many heuristic instance creation methods have been proposed, among which Soon et al.s (1999; 2001) is arguably the most popular choice. Given 1397 \x0can anaphoric noun phrase3, NPk, Soon et al.s method creates a positive instance between NPk and its closest preceding antecedent, NPj, and a negative instance by pairing NPk with each of the intervening NPs, NPj+1, . . ., NPk1. With an eye towards improving the precision of a coreference resolver, Ng and Cardie (2002c) propose an instance creation method that involves a single modification to Soon et al.s method: if NPk is non-pronominal, a positive instance should be formed between NPk and its closest preceding nonpronominal antecedent instead. This modification is motivated by the observation that it is not easy for a human, let alone a machine learner, to learn from a positive instance where the antecedent of a non-pronominal NP is a pronoun. To further reduce class skewness, some researchers employ a filtering mechanism on top of an instance creation method, thereby disallowing the creation of trainin</context>
<context position="12063" citStr="Ng and Cardie, 2002" startWordPosition="1860" endWordPosition="1863">fidence value (e.g., in the form of a probability) associated with a classification, and in part due to the fact that they can be easily adapted to train recently proposed rankingbased coreference models (see Section 3.3). 3.1.3 Generating an NP Partition After training, we can apply the resulting model to a test text, using a clustering algorithm to coordinate the pairwise classification decisions and impose an NP partition. Below we describe some commonly used coreference clustering algorithms. Despite their simplicity, closest-first clustering (Soon et al., 2001) and best-first clustering (Ng and Cardie, 2002c) are arguably the most widely used coreference clustering algorithms. The closest-first clustering algorithm selects as the antecedent for an NP, NPk, the closest preceding noun phrase that is classified as coreferent with it.4 However, if no such preceding noun phrase exists, no antecedent is selected for NPk. The best-first clustering algorithm aims to improve the precision of closest-first clustering, specifically by selecting as the antecedent of NPk the most probable preceding NP that is classified as coreferent with it. One criticism of the closest-first and best-first clustering algor</context>
<context position="15923" citStr="Ng and Cardie (2002" startWordPosition="2496" endWordPosition="2499">f the NPs, and the goal is to search for the leaf node that contains the most probable partition. The search starts at the root, and a partitioning of the NPs is incrementally constructed as we move down the tree. Specifically, based on the coreference decisions it has made in the first i1 levels of the tree, the algorithm determines at the ith level whether the ith NP should start a new cluster, or to which preceding cluster it should be assigned. While many coreference clustering algorithms have been developed, there have only been a few attempts to compare their effectiveness. For example, Ng and Cardie (2002c) report that bestfirst clustering is better than closest-first clustering. Nicolae and Nicolae (2006) show that bestfirst clustering performs similarly to Bell-treebased clustering, but neither of these algorithms 5 When applying closest-first and best-first clustering, Soon et al. (2001) and Ng and Cardie (2002c) also process the NPs in a sequential manner, but since the later decisions are not dependent on the earlier ones, the order in which the NPs are processed does not affect their clustering results. performs as well as their proposed minimum-cutbased graph partitioning algorithm. 3.1</context>
<context position="17754" citStr="Ng and Cardie (2002" startWordPosition="2764" endWordPosition="2767">upervised approaches (e.g., Evans (2001), Muller (2006), Versley et al. (2008a)), and distributional methods (e.g., Bergsma et al. (2008)); and non-anaphoric definite descriptions have been identified using rule-based techniques (e.g., Vieira and Poesio (2000)) and unsupervised techniques (e.g., Bean and Riloff (1999)). Recently, anaphoricity determination has been evaluated in the context of coreference resolution, with results showing that training an anaphoricity classifier to identify and filter non-anaphoric NPs prior to coreference resolution can improve a learning-based resolver (e.g., Ng and Cardie (2002b), Uryupina (2003), Poesio et al. (2004b)). Compared to earlier work on anaphoricity determination, recently proposed approaches are more global in nature, taking into account the pairwise decisions made by the mention-pair model when making anaphoricity decisions. Examples of such approaches have exploited techniques including integer linear programming (ILP) (Denis and Baldridge, 2007a), label propagation (Zhou and Kong, 2009), and minimum cuts (Ng, 2009). 3.1.5 Combining Classification &amp; Clustering From a learning perspective, a two-step approach to coreference classification and clusterin</context>
<context position="34729" citStr="Ng and Cardie, 2002" startWordPosition="5466" endWordPosition="5469">ing the presence or absence of their words (Luo et al., 2004) or as probabilistic features indicating the probability that the two heads are coreferent according to the training data (Ng, 2007b). An anaphoricity feature indicates whether an NP to be resolved is anaphoric, and is typically computed using an anaphoricity classifier (Ng, 2004), hand-crafted patterns (Daume III and Marcu, 2005), and automatically acquired patterns (Bean and Riloff, 1999). Finally, the outputs of rule-based pronoun and coreference resolvers have also been used as features for learning-based coreference resolution (Ng and Cardie, 2002c). For an empirical evaluation of the contribution of a subset of these features to the mention-pair model, see Bengtson and Roth (2008). 5 Evaluation Issues Two important issues surround the evaluation of a coreference resolver. First, how do we obtain the set of NPs that a resolver will partition? Second, how do we score the partition it produces? 5.1 Extracting Candidate Noun Phrases To obtain the set of NPs to be partitioned by a resolver, three methods are typically used. In the first method, the NPs are extracted automatically from a syntactic parser. The second method involves extracti</context>
<context position="41777" citStr="Ng and Cardie (2002" startWordPosition="6588" endWordPosition="6591">as researchers have been evaluating their resolvers on different corpora using different evaluation metrics and preprocessing tools. In particular, preprocessing tools can have a large impact on the performance of a resolver (Barbu and Mitkov, 2001). Worse still, assumptions about whether gold or automatically extracted NPs are used are sometimes not explicitly stated, potentially causing results to be interpreted incorrectly. To our knowledge, however, the best results on the MUC-6 and MUC-7 data sets using automatically extracted NPs are reported by Yang et al. (2003) (71.3 MUC F-score) and Ng and Cardie (2002c) (63.4 MUC F-score), respectively;8 and the best results on the ACE data sets using gold NPs can be found in Luo (2007) (88.4 ACE-value). Second, what lessons can we learn from fifteen years of learning-based coreference research? The mention-pair model is weak because it makes coreference decisions based on local information (i.e., information extracted from two NPs). Expressive models (e.g., those that can exploit cluster-level features) generally offer better performance, and so are models that are global in nature. Global coreference models may refer to any kind of models that can exploi</context>
</contexts>
<marker>Ng, Cardie, 2002</marker>
<rawString>Vincent Ng and Claire Cardie. 2002a. Combining sample selection and error-driven pruning for machine learning of coreference rules. In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing, pages 5562.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vincent Ng</author>
<author>Claire Cardie</author>
</authors>
<title>Identifying anaphoric and non-anaphoric noun phrases to improve coreference resolution.</title>
<date>2002</date>
<booktitle>In Proceedings of the 19th International Conference on Computational Linguistics,</booktitle>
<pages>730736</pages>
<contexts>
<context position="9158" citStr="Ng and Cardie (2002" startWordPosition="1398" endWordPosition="1401">reference partition. 3.1.1 Creating Training Instances As noted above, the primary purpose of training instance creation is to reduce class skewness. Many heuristic instance creation methods have been proposed, among which Soon et al.s (1999; 2001) is arguably the most popular choice. Given 1397 \x0can anaphoric noun phrase3, NPk, Soon et al.s method creates a positive instance between NPk and its closest preceding antecedent, NPj, and a negative instance by pairing NPk with each of the intervening NPs, NPj+1, . . ., NPk1. With an eye towards improving the precision of a coreference resolver, Ng and Cardie (2002c) propose an instance creation method that involves a single modification to Soon et al.s method: if NPk is non-pronominal, a positive instance should be formed between NPk and its closest preceding nonpronominal antecedent instead. This modification is motivated by the observation that it is not easy for a human, let alone a machine learner, to learn from a positive instance where the antecedent of a non-pronominal NP is a pronoun. To further reduce class skewness, some researchers employ a filtering mechanism on top of an instance creation method, thereby disallowing the creation of trainin</context>
<context position="12063" citStr="Ng and Cardie, 2002" startWordPosition="1860" endWordPosition="1863">fidence value (e.g., in the form of a probability) associated with a classification, and in part due to the fact that they can be easily adapted to train recently proposed rankingbased coreference models (see Section 3.3). 3.1.3 Generating an NP Partition After training, we can apply the resulting model to a test text, using a clustering algorithm to coordinate the pairwise classification decisions and impose an NP partition. Below we describe some commonly used coreference clustering algorithms. Despite their simplicity, closest-first clustering (Soon et al., 2001) and best-first clustering (Ng and Cardie, 2002c) are arguably the most widely used coreference clustering algorithms. The closest-first clustering algorithm selects as the antecedent for an NP, NPk, the closest preceding noun phrase that is classified as coreferent with it.4 However, if no such preceding noun phrase exists, no antecedent is selected for NPk. The best-first clustering algorithm aims to improve the precision of closest-first clustering, specifically by selecting as the antecedent of NPk the most probable preceding NP that is classified as coreferent with it. One criticism of the closest-first and best-first clustering algor</context>
<context position="15923" citStr="Ng and Cardie (2002" startWordPosition="2496" endWordPosition="2499">f the NPs, and the goal is to search for the leaf node that contains the most probable partition. The search starts at the root, and a partitioning of the NPs is incrementally constructed as we move down the tree. Specifically, based on the coreference decisions it has made in the first i1 levels of the tree, the algorithm determines at the ith level whether the ith NP should start a new cluster, or to which preceding cluster it should be assigned. While many coreference clustering algorithms have been developed, there have only been a few attempts to compare their effectiveness. For example, Ng and Cardie (2002c) report that bestfirst clustering is better than closest-first clustering. Nicolae and Nicolae (2006) show that bestfirst clustering performs similarly to Bell-treebased clustering, but neither of these algorithms 5 When applying closest-first and best-first clustering, Soon et al. (2001) and Ng and Cardie (2002c) also process the NPs in a sequential manner, but since the later decisions are not dependent on the earlier ones, the order in which the NPs are processed does not affect their clustering results. performs as well as their proposed minimum-cutbased graph partitioning algorithm. 3.1</context>
<context position="17754" citStr="Ng and Cardie (2002" startWordPosition="2764" endWordPosition="2767">upervised approaches (e.g., Evans (2001), Muller (2006), Versley et al. (2008a)), and distributional methods (e.g., Bergsma et al. (2008)); and non-anaphoric definite descriptions have been identified using rule-based techniques (e.g., Vieira and Poesio (2000)) and unsupervised techniques (e.g., Bean and Riloff (1999)). Recently, anaphoricity determination has been evaluated in the context of coreference resolution, with results showing that training an anaphoricity classifier to identify and filter non-anaphoric NPs prior to coreference resolution can improve a learning-based resolver (e.g., Ng and Cardie (2002b), Uryupina (2003), Poesio et al. (2004b)). Compared to earlier work on anaphoricity determination, recently proposed approaches are more global in nature, taking into account the pairwise decisions made by the mention-pair model when making anaphoricity decisions. Examples of such approaches have exploited techniques including integer linear programming (ILP) (Denis and Baldridge, 2007a), label propagation (Zhou and Kong, 2009), and minimum cuts (Ng, 2009). 3.1.5 Combining Classification &amp; Clustering From a learning perspective, a two-step approach to coreference classification and clusterin</context>
<context position="34729" citStr="Ng and Cardie, 2002" startWordPosition="5466" endWordPosition="5469">ing the presence or absence of their words (Luo et al., 2004) or as probabilistic features indicating the probability that the two heads are coreferent according to the training data (Ng, 2007b). An anaphoricity feature indicates whether an NP to be resolved is anaphoric, and is typically computed using an anaphoricity classifier (Ng, 2004), hand-crafted patterns (Daume III and Marcu, 2005), and automatically acquired patterns (Bean and Riloff, 1999). Finally, the outputs of rule-based pronoun and coreference resolvers have also been used as features for learning-based coreference resolution (Ng and Cardie, 2002c). For an empirical evaluation of the contribution of a subset of these features to the mention-pair model, see Bengtson and Roth (2008). 5 Evaluation Issues Two important issues surround the evaluation of a coreference resolver. First, how do we obtain the set of NPs that a resolver will partition? Second, how do we score the partition it produces? 5.1 Extracting Candidate Noun Phrases To obtain the set of NPs to be partitioned by a resolver, three methods are typically used. In the first method, the NPs are extracted automatically from a syntactic parser. The second method involves extracti</context>
<context position="41777" citStr="Ng and Cardie (2002" startWordPosition="6588" endWordPosition="6591">as researchers have been evaluating their resolvers on different corpora using different evaluation metrics and preprocessing tools. In particular, preprocessing tools can have a large impact on the performance of a resolver (Barbu and Mitkov, 2001). Worse still, assumptions about whether gold or automatically extracted NPs are used are sometimes not explicitly stated, potentially causing results to be interpreted incorrectly. To our knowledge, however, the best results on the MUC-6 and MUC-7 data sets using automatically extracted NPs are reported by Yang et al. (2003) (71.3 MUC F-score) and Ng and Cardie (2002c) (63.4 MUC F-score), respectively;8 and the best results on the ACE data sets using gold NPs can be found in Luo (2007) (88.4 ACE-value). Second, what lessons can we learn from fifteen years of learning-based coreference research? The mention-pair model is weak because it makes coreference decisions based on local information (i.e., information extracted from two NPs). Expressive models (e.g., those that can exploit cluster-level features) generally offer better performance, and so are models that are global in nature. Global coreference models may refer to any kind of models that can exploi</context>
</contexts>
<marker>Ng, Cardie, 2002</marker>
<rawString>Vincent Ng and Claire Cardie. 2002b. Identifying anaphoric and non-anaphoric noun phrases to improve coreference resolution. In Proceedings of the 19th International Conference on Computational Linguistics, pages 730736.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vincent Ng</author>
<author>Claire Cardie</author>
</authors>
<title>Improving machine learning approaches to coreference resolution.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>104--111</pages>
<contexts>
<context position="9158" citStr="Ng and Cardie (2002" startWordPosition="1398" endWordPosition="1401">reference partition. 3.1.1 Creating Training Instances As noted above, the primary purpose of training instance creation is to reduce class skewness. Many heuristic instance creation methods have been proposed, among which Soon et al.s (1999; 2001) is arguably the most popular choice. Given 1397 \x0can anaphoric noun phrase3, NPk, Soon et al.s method creates a positive instance between NPk and its closest preceding antecedent, NPj, and a negative instance by pairing NPk with each of the intervening NPs, NPj+1, . . ., NPk1. With an eye towards improving the precision of a coreference resolver, Ng and Cardie (2002c) propose an instance creation method that involves a single modification to Soon et al.s method: if NPk is non-pronominal, a positive instance should be formed between NPk and its closest preceding nonpronominal antecedent instead. This modification is motivated by the observation that it is not easy for a human, let alone a machine learner, to learn from a positive instance where the antecedent of a non-pronominal NP is a pronoun. To further reduce class skewness, some researchers employ a filtering mechanism on top of an instance creation method, thereby disallowing the creation of trainin</context>
<context position="12063" citStr="Ng and Cardie, 2002" startWordPosition="1860" endWordPosition="1863">fidence value (e.g., in the form of a probability) associated with a classification, and in part due to the fact that they can be easily adapted to train recently proposed rankingbased coreference models (see Section 3.3). 3.1.3 Generating an NP Partition After training, we can apply the resulting model to a test text, using a clustering algorithm to coordinate the pairwise classification decisions and impose an NP partition. Below we describe some commonly used coreference clustering algorithms. Despite their simplicity, closest-first clustering (Soon et al., 2001) and best-first clustering (Ng and Cardie, 2002c) are arguably the most widely used coreference clustering algorithms. The closest-first clustering algorithm selects as the antecedent for an NP, NPk, the closest preceding noun phrase that is classified as coreferent with it.4 However, if no such preceding noun phrase exists, no antecedent is selected for NPk. The best-first clustering algorithm aims to improve the precision of closest-first clustering, specifically by selecting as the antecedent of NPk the most probable preceding NP that is classified as coreferent with it. One criticism of the closest-first and best-first clustering algor</context>
<context position="15923" citStr="Ng and Cardie (2002" startWordPosition="2496" endWordPosition="2499">f the NPs, and the goal is to search for the leaf node that contains the most probable partition. The search starts at the root, and a partitioning of the NPs is incrementally constructed as we move down the tree. Specifically, based on the coreference decisions it has made in the first i1 levels of the tree, the algorithm determines at the ith level whether the ith NP should start a new cluster, or to which preceding cluster it should be assigned. While many coreference clustering algorithms have been developed, there have only been a few attempts to compare their effectiveness. For example, Ng and Cardie (2002c) report that bestfirst clustering is better than closest-first clustering. Nicolae and Nicolae (2006) show that bestfirst clustering performs similarly to Bell-treebased clustering, but neither of these algorithms 5 When applying closest-first and best-first clustering, Soon et al. (2001) and Ng and Cardie (2002c) also process the NPs in a sequential manner, but since the later decisions are not dependent on the earlier ones, the order in which the NPs are processed does not affect their clustering results. performs as well as their proposed minimum-cutbased graph partitioning algorithm. 3.1</context>
<context position="17754" citStr="Ng and Cardie (2002" startWordPosition="2764" endWordPosition="2767">upervised approaches (e.g., Evans (2001), Muller (2006), Versley et al. (2008a)), and distributional methods (e.g., Bergsma et al. (2008)); and non-anaphoric definite descriptions have been identified using rule-based techniques (e.g., Vieira and Poesio (2000)) and unsupervised techniques (e.g., Bean and Riloff (1999)). Recently, anaphoricity determination has been evaluated in the context of coreference resolution, with results showing that training an anaphoricity classifier to identify and filter non-anaphoric NPs prior to coreference resolution can improve a learning-based resolver (e.g., Ng and Cardie (2002b), Uryupina (2003), Poesio et al. (2004b)). Compared to earlier work on anaphoricity determination, recently proposed approaches are more global in nature, taking into account the pairwise decisions made by the mention-pair model when making anaphoricity decisions. Examples of such approaches have exploited techniques including integer linear programming (ILP) (Denis and Baldridge, 2007a), label propagation (Zhou and Kong, 2009), and minimum cuts (Ng, 2009). 3.1.5 Combining Classification &amp; Clustering From a learning perspective, a two-step approach to coreference classification and clusterin</context>
<context position="34729" citStr="Ng and Cardie, 2002" startWordPosition="5466" endWordPosition="5469">ing the presence or absence of their words (Luo et al., 2004) or as probabilistic features indicating the probability that the two heads are coreferent according to the training data (Ng, 2007b). An anaphoricity feature indicates whether an NP to be resolved is anaphoric, and is typically computed using an anaphoricity classifier (Ng, 2004), hand-crafted patterns (Daume III and Marcu, 2005), and automatically acquired patterns (Bean and Riloff, 1999). Finally, the outputs of rule-based pronoun and coreference resolvers have also been used as features for learning-based coreference resolution (Ng and Cardie, 2002c). For an empirical evaluation of the contribution of a subset of these features to the mention-pair model, see Bengtson and Roth (2008). 5 Evaluation Issues Two important issues surround the evaluation of a coreference resolver. First, how do we obtain the set of NPs that a resolver will partition? Second, how do we score the partition it produces? 5.1 Extracting Candidate Noun Phrases To obtain the set of NPs to be partitioned by a resolver, three methods are typically used. In the first method, the NPs are extracted automatically from a syntactic parser. The second method involves extracti</context>
<context position="41777" citStr="Ng and Cardie (2002" startWordPosition="6588" endWordPosition="6591">as researchers have been evaluating their resolvers on different corpora using different evaluation metrics and preprocessing tools. In particular, preprocessing tools can have a large impact on the performance of a resolver (Barbu and Mitkov, 2001). Worse still, assumptions about whether gold or automatically extracted NPs are used are sometimes not explicitly stated, potentially causing results to be interpreted incorrectly. To our knowledge, however, the best results on the MUC-6 and MUC-7 data sets using automatically extracted NPs are reported by Yang et al. (2003) (71.3 MUC F-score) and Ng and Cardie (2002c) (63.4 MUC F-score), respectively;8 and the best results on the ACE data sets using gold NPs can be found in Luo (2007) (88.4 ACE-value). Second, what lessons can we learn from fifteen years of learning-based coreference research? The mention-pair model is weak because it makes coreference decisions based on local information (i.e., information extracted from two NPs). Expressive models (e.g., those that can exploit cluster-level features) generally offer better performance, and so are models that are global in nature. Global coreference models may refer to any kind of models that can exploi</context>
</contexts>
<marker>Ng, Cardie, 2002</marker>
<rawString>Vincent Ng and Claire Cardie. 2002c. Improving machine learning approaches to coreference resolution. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 104 111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vincent Ng</author>
</authors>
<title>Learning noun phrase anaphoricity to improve conference resolution: Issues in representation and optimization.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>151158</pages>
<contexts>
<context position="34452" citStr="Ng, 2004" startWordPosition="5429" endWordPosition="5430">at do not fall into any of the preceding categories. For example, a memorization feature is a word pair composed of the head nouns of the two NPs involved in an instance (Bengtson and Roth, 2008). Memorization features have been used as binary-valued features indicating the presence or absence of their words (Luo et al., 2004) or as probabilistic features indicating the probability that the two heads are coreferent according to the training data (Ng, 2007b). An anaphoricity feature indicates whether an NP to be resolved is anaphoric, and is typically computed using an anaphoricity classifier (Ng, 2004), hand-crafted patterns (Daume III and Marcu, 2005), and automatically acquired patterns (Bean and Riloff, 1999). Finally, the outputs of rule-based pronoun and coreference resolvers have also been used as features for learning-based coreference resolution (Ng and Cardie, 2002c). For an empirical evaluation of the contribution of a subset of these features to the mention-pair model, see Bengtson and Roth (2008). 5 Evaluation Issues Two important issues surround the evaluation of a coreference resolver. First, how do we obtain the set of NPs that a resolver will partition? Second, how do we sco</context>
</contexts>
<marker>Ng, 2004</marker>
<rawString>Vincent Ng. 2004. Learning noun phrase anaphoricity to improve conference resolution: Issues in representation and optimization. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics, pages 151158.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vincent Ng</author>
</authors>
<title>Semantic class induction and coreference resolution.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>536543</pages>
<contexts>
<context position="30904" citStr="Ng, 2007" startWordPosition="4846" endWordPosition="4847">inds of semantic knowledge employed for coreference resolution is perhaps selectional preference (Dagan and Itai, 1990; Kehler et al., 2004b; Yang et al., 2005; Haghighi and Klein, 2009): given a pronoun to be resolved, its governing verb, and its grammatical role, we prefer a candidate antecedent that can be governed by the same verb and be in the same role. Semantic knowledge has also been extracted from WordNet and unannotated corpora for computing the semantic compatibility/similarity between two common nouns (Harabagiu et al., 2001; Versley, 2007) as well as the semantic class of a noun (Ng, 2007a; Huang et al., 2009). One difficulty with deriving knowledge from WordNet is that one has to determine which sense of a given word to use. Some researchers simply use the first sense (Soon et al., 2001) or all possible senses (Ponzetto and Strube, 2006a), while others overcome this problem with word sense disambiguation (Nicolae and Nicolae, 2006). Knowledge has also been mined from Wikipedia for measuring the semantic relatedness of two NPs, NPj and NPk (Ponzetto and Strube (2006a; 2007)), such as: whether NPj/k appears in the first paragraph of the Wiki page that has NPk/j as the title or </context>
<context position="34302" citStr="Ng, 2007" startWordPosition="5406" endWordPosition="5407">onoun in his heuristic pronoun resolvers. It would be interesting to incorporate this idea into a learning-based resolver. There are also features that do not fall into any of the preceding categories. For example, a memorization feature is a word pair composed of the head nouns of the two NPs involved in an instance (Bengtson and Roth, 2008). Memorization features have been used as binary-valued features indicating the presence or absence of their words (Luo et al., 2004) or as probabilistic features indicating the probability that the two heads are coreferent according to the training data (Ng, 2007b). An anaphoricity feature indicates whether an NP to be resolved is anaphoric, and is typically computed using an anaphoricity classifier (Ng, 2004), hand-crafted patterns (Daume III and Marcu, 2005), and automatically acquired patterns (Bean and Riloff, 1999). Finally, the outputs of rule-based pronoun and coreference resolvers have also been used as features for learning-based coreference resolution (Ng and Cardie, 2002c). For an empirical evaluation of the contribution of a subset of these features to the mention-pair model, see Bengtson and Roth (2008). 5 Evaluation Issues Two important </context>
<context position="39983" citStr="Ng (2007)" startWordPosition="6311" endWordPosition="6312">e many of the techniques discussed in this paper were originally developed for English, they have been applied to learn coreference models for other languages, such as Chinese (e.g., Converse (2006)), Japanese (e.g., Iida (2007)), Arabic (e.g., Luo and Zitouni (2005)), Dutch (e.g., Hoste (2005)), German (e.g., Wunsch (2010)), Swedish (e.g., Nilsson (2010)), and Czech (e.g., Ngu .y et al. (2009)). In addition, researchers have developed approaches that are targeted at handling certain kinds of anaphora present in non-English languages, such as zero anaphora (e.g., Iida et al. (2007a), Zhao and Ng (2007)). As Mitkov (2001) puts it, coreference resolution is a difficult, but not intractable problem, and we have been making slow, but steady progress on improving machine learning approaches to the problem in the past fifteen years. To ensure further progress, researchers should compare their results against a baseline that is stronger than the commonly-used Soon et al. (2001) system, which relies on a weak model (i.e., the mention-pair model) and a small set of linguistic features. As recent systems are becoming more sophisticated, we suggest that researchers make their systems publicly availabl</context>
</contexts>
<marker>Ng, 2007</marker>
<rawString>Vincent Ng. 2007a. Semantic class induction and coreference resolution. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 536543.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vincent Ng</author>
</authors>
<title>Shallow semantics for coreference resolution.</title>
<date>2007</date>
<booktitle>In Proceedings of the Twentieth International Joint Conference on Artificial Intelligence,</booktitle>
<pages>16891694</pages>
<contexts>
<context position="30904" citStr="Ng, 2007" startWordPosition="4846" endWordPosition="4847">inds of semantic knowledge employed for coreference resolution is perhaps selectional preference (Dagan and Itai, 1990; Kehler et al., 2004b; Yang et al., 2005; Haghighi and Klein, 2009): given a pronoun to be resolved, its governing verb, and its grammatical role, we prefer a candidate antecedent that can be governed by the same verb and be in the same role. Semantic knowledge has also been extracted from WordNet and unannotated corpora for computing the semantic compatibility/similarity between two common nouns (Harabagiu et al., 2001; Versley, 2007) as well as the semantic class of a noun (Ng, 2007a; Huang et al., 2009). One difficulty with deriving knowledge from WordNet is that one has to determine which sense of a given word to use. Some researchers simply use the first sense (Soon et al., 2001) or all possible senses (Ponzetto and Strube, 2006a), while others overcome this problem with word sense disambiguation (Nicolae and Nicolae, 2006). Knowledge has also been mined from Wikipedia for measuring the semantic relatedness of two NPs, NPj and NPk (Ponzetto and Strube (2006a; 2007)), such as: whether NPj/k appears in the first paragraph of the Wiki page that has NPk/j as the title or </context>
<context position="34302" citStr="Ng, 2007" startWordPosition="5406" endWordPosition="5407">onoun in his heuristic pronoun resolvers. It would be interesting to incorporate this idea into a learning-based resolver. There are also features that do not fall into any of the preceding categories. For example, a memorization feature is a word pair composed of the head nouns of the two NPs involved in an instance (Bengtson and Roth, 2008). Memorization features have been used as binary-valued features indicating the presence or absence of their words (Luo et al., 2004) or as probabilistic features indicating the probability that the two heads are coreferent according to the training data (Ng, 2007b). An anaphoricity feature indicates whether an NP to be resolved is anaphoric, and is typically computed using an anaphoricity classifier (Ng, 2004), hand-crafted patterns (Daume III and Marcu, 2005), and automatically acquired patterns (Bean and Riloff, 1999). Finally, the outputs of rule-based pronoun and coreference resolvers have also been used as features for learning-based coreference resolution (Ng and Cardie, 2002c). For an empirical evaluation of the contribution of a subset of these features to the mention-pair model, see Bengtson and Roth (2008). 5 Evaluation Issues Two important </context>
<context position="39983" citStr="Ng (2007)" startWordPosition="6311" endWordPosition="6312">e many of the techniques discussed in this paper were originally developed for English, they have been applied to learn coreference models for other languages, such as Chinese (e.g., Converse (2006)), Japanese (e.g., Iida (2007)), Arabic (e.g., Luo and Zitouni (2005)), Dutch (e.g., Hoste (2005)), German (e.g., Wunsch (2010)), Swedish (e.g., Nilsson (2010)), and Czech (e.g., Ngu .y et al. (2009)). In addition, researchers have developed approaches that are targeted at handling certain kinds of anaphora present in non-English languages, such as zero anaphora (e.g., Iida et al. (2007a), Zhao and Ng (2007)). As Mitkov (2001) puts it, coreference resolution is a difficult, but not intractable problem, and we have been making slow, but steady progress on improving machine learning approaches to the problem in the past fifteen years. To ensure further progress, researchers should compare their results against a baseline that is stronger than the commonly-used Soon et al. (2001) system, which relies on a weak model (i.e., the mention-pair model) and a small set of linguistic features. As recent systems are becoming more sophisticated, we suggest that researchers make their systems publicly availabl</context>
</contexts>
<marker>Ng, 2007</marker>
<rawString>Vincent Ng. 2007b. Shallow semantics for coreference resolution. In Proceedings of the Twentieth International Joint Conference on Artificial Intelligence, pages 16891694.</rawString>
</citation>
<citation valid="true">
<authors>
<author>\x0cVincent Ng</author>
</authors>
<title>Unsupervised models for coreference resolution.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>640649</pages>
<contexts>
<context position="38961" citStr="Ng, 2008" startWordPosition="6153" endWordPosition="6154">ainst multiple scorers, which can indirectly help to counteract the bias inherent in a particular scorer. For further discussion on evaluation issues, see Byron (2001). 6 Concluding Remarks While we have focused our discussion on supervised approaches, coreference researchers have also attempted to reduce a resolvers reliance on annotated data by combining a small amount of labeled data and a large amount of unlabeled data using general-purpose semi-supervised learning algorithms such as co-training (Muller et al., 2002), self-training (Kehler et al., 2004a), and EM (Cherry and Bergsma, 2005; Ng, 2008). Interestingly, recent results indicate that unsupervised approaches to coreference resolution (e.g., Haghighi and Klein (2007; 2010), Poon and Domingos (2008)) rival their supervised counterparts, casting doubts on whether supervised resolvers are making effective use of the available labeled data. Another issue that we have not focused on but which is becoming increasingly important is multilinguality. While many of the techniques discussed in this paper were originally developed for English, they have been applied to learn coreference models for other languages, such as Chinese (e.g., Conv</context>
</contexts>
<marker>Ng, 2008</marker>
<rawString>\x0cVincent Ng. 2008. Unsupervised models for coreference resolution. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 640649.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vincent Ng</author>
</authors>
<title>Graph-cut-based anaphoricity determination for coreference resolution.</title>
<date>2009</date>
<booktitle>In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>575583</pages>
<contexts>
<context position="18216" citStr="Ng, 2009" startWordPosition="2832" endWordPosition="2833">lassifier to identify and filter non-anaphoric NPs prior to coreference resolution can improve a learning-based resolver (e.g., Ng and Cardie (2002b), Uryupina (2003), Poesio et al. (2004b)). Compared to earlier work on anaphoricity determination, recently proposed approaches are more global in nature, taking into account the pairwise decisions made by the mention-pair model when making anaphoricity decisions. Examples of such approaches have exploited techniques including integer linear programming (ILP) (Denis and Baldridge, 2007a), label propagation (Zhou and Kong, 2009), and minimum cuts (Ng, 2009). 3.1.5 Combining Classification &amp; Clustering From a learning perspective, a two-step approach to coreference classification and clustering is undesirable. Since the classification model is trained independently of the clustering algorithm, improvements in classification accuracy do not guarantee corresponding improvements in clustering-level accuracy. That is, overall performance on the coreference task might not improve. To address this problem, McCallum and Wellner (2004) and Finley and Joachims (2005) eliminate the classification step entirely, treating coref1399 \x0cerence as a supervised</context>
<context position="26465" citStr="Ng (2009)" startWordPosition="4142" endWordPosition="4143">f its candidate antecedents, and the candidate that is classified as better the largest number of times is selected as its antecedent. Advances in machine learning have made it possible to train a mention ranker that ranks all of the candidate antecedents simultaneously. While mention rankers have consistently outperformed the mention-pair model (Versley, 2006; Denis and Baldridge, 2007b), they are not more expressive than the mention-pair model, as they are unable to exploit cluster-level features, unlike the entitymention model. To enable rankers to employ cluster-level features, Rahman and Ng (2009) propose the cluster-ranking model, which ranks preceding clusters, rather than candidate antecedents, for an NP to be resolved. Cluster rankers therefore address both weaknesses of the mention-pair model, and have been shown to improve mention rankers. Cluster rankers are conceptually similar to Lappin and Leasss (1994) heuristic pronoun resolver, which resolves an anaphoric pronoun to the most salient preceding cluster. An important issue with ranking models that we have eluded so far concerns the identification of non-anaphoric NPs. As a ranker simply imposes a ranking on candidate antecede</context>
<context position="37845" citStr="Ng (2009)" startWordPosition="5982" endWordPosition="5983">cited weaknesses. As a linkbased measure, it does not reward correctly identified singleton clusters since there is no coreference link in these clusters. Also, it tends to underpenalize partitions with overly large clusters. To address these problems, two coreference scoring programs have been developed: B3 (Bagga and Baldwin, 1998) and CEAF (Luo, 2005). Note that both scorers have only been defined for the case where the key partition has the same set of NPs as the response partition. To apply these scorers to automatically extracted NPs, different methods have been proposed (see Rahman and Ng (2009) and Stoyanov et al. (2009)). Since coreference is a clustering task, any general-purpose method for evaluating a response partition against a key partition (e.g., Kappa (Carletta, 1996)) can be used for coreference scor1403 \x0cing (see Popescu-Belis et al. (2004)). In practice, these general-purpose methods are typically used to provide scores that complement those obtained via the three coreference scorers discussed above. It is worth mentioning that there is a trend towards evaluating a resolver against multiple scorers, which can indirectly help to counteract the bias inherent in a partic</context>
<context position="40914" citStr="Ng, 2009" startWordPosition="6455" endWordPosition="6456"> is stronger than the commonly-used Soon et al. (2001) system, which relies on a weak model (i.e., the mention-pair model) and a small set of linguistic features. As recent systems are becoming more sophisticated, we suggest that researchers make their systems publicly available in order to facilitate performance comparisons. Publicly available coreference systems currently include JavaRAP (Qiu et al., 2004), GuiTaR (Poesio and Kabadjov, 2004), BART (Versley et al., 2008b), CoRTex (Denis and Baldridge, 2008), the Illinois Coreference Package (Bengtson and Roth, 2008), CherryPicker (Rahman and Ng, 2009), Reconcile (Stoyanov et al., 2010), and Charniak and Elsners (2009) pronoun resolver. We conclude with a discussion of two questions regarding supervised coreference research. First, what is the state of the art? This is not an easy question, as researchers have been evaluating their resolvers on different corpora using different evaluation metrics and preprocessing tools. In particular, preprocessing tools can have a large impact on the performance of a resolver (Barbu and Mitkov, 2001). Worse still, assumptions about whether gold or automatically extracted NPs are used are sometimes not exp</context>
</contexts>
<marker>Ng, 2009</marker>
<rawString>Vincent Ng. 2009. Graph-cut-based anaphoricity determination for coreference resolution. In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 575583.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Giang Linh Ngu y</author>
<author>Vaclav Novak</author>
<author>Zdenek Zabokrtsky</author>
</authors>
<title>Comparison of classification and ranking approaches to pronominal anaphora resolution in Czech.</title>
<date>2009</date>
<booktitle>In Proceedings of the SIGDIAL 2009 Conference,</booktitle>
<pages>276285</pages>
<contexts>
<context position="39771" citStr="y et al. (2009)" startWordPosition="6275" endWordPosition="6278">ts, casting doubts on whether supervised resolvers are making effective use of the available labeled data. Another issue that we have not focused on but which is becoming increasingly important is multilinguality. While many of the techniques discussed in this paper were originally developed for English, they have been applied to learn coreference models for other languages, such as Chinese (e.g., Converse (2006)), Japanese (e.g., Iida (2007)), Arabic (e.g., Luo and Zitouni (2005)), Dutch (e.g., Hoste (2005)), German (e.g., Wunsch (2010)), Swedish (e.g., Nilsson (2010)), and Czech (e.g., Ngu .y et al. (2009)). In addition, researchers have developed approaches that are targeted at handling certain kinds of anaphora present in non-English languages, such as zero anaphora (e.g., Iida et al. (2007a), Zhao and Ng (2007)). As Mitkov (2001) puts it, coreference resolution is a difficult, but not intractable problem, and we have been making slow, but steady progress on improving machine learning approaches to the problem in the past fifteen years. To ensure further progress, researchers should compare their results against a baseline that is stronger than the commonly-used Soon et al. (2001) system, whi</context>
</contexts>
<marker>y, Novak, Zabokrtsky, 2009</marker>
<rawString>Giang Linh Ngu .y, Vaclav Novak, and Zdenek Zabokrtsky. 2009. Comparison of classification and ranking approaches to pronominal anaphora resolution in Czech. In Proceedings of the SIGDIAL 2009 Conference, pages 276285.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cristina Nicolae</author>
<author>Gabriel Nicolae</author>
</authors>
<title>BestCut: A graph algorithm for coreference resolution.</title>
<date>2006</date>
<contexts>
<context position="16026" citStr="Nicolae and Nicolae (2006)" startWordPosition="2511" endWordPosition="2514">. The search starts at the root, and a partitioning of the NPs is incrementally constructed as we move down the tree. Specifically, based on the coreference decisions it has made in the first i1 levels of the tree, the algorithm determines at the ith level whether the ith NP should start a new cluster, or to which preceding cluster it should be assigned. While many coreference clustering algorithms have been developed, there have only been a few attempts to compare their effectiveness. For example, Ng and Cardie (2002c) report that bestfirst clustering is better than closest-first clustering. Nicolae and Nicolae (2006) show that bestfirst clustering performs similarly to Bell-treebased clustering, but neither of these algorithms 5 When applying closest-first and best-first clustering, Soon et al. (2001) and Ng and Cardie (2002c) also process the NPs in a sequential manner, but since the later decisions are not dependent on the earlier ones, the order in which the NPs are processed does not affect their clustering results. performs as well as their proposed minimum-cutbased graph partitioning algorithm. 3.1.4 Determining NP Anaphoricity While coreference clustering algorithms attempt to resolve each NP encou</context>
<context position="31255" citStr="Nicolae and Nicolae, 2006" startWordPosition="4902" endWordPosition="4905">erb and be in the same role. Semantic knowledge has also been extracted from WordNet and unannotated corpora for computing the semantic compatibility/similarity between two common nouns (Harabagiu et al., 2001; Versley, 2007) as well as the semantic class of a noun (Ng, 2007a; Huang et al., 2009). One difficulty with deriving knowledge from WordNet is that one has to determine which sense of a given word to use. Some researchers simply use the first sense (Soon et al., 2001) or all possible senses (Ponzetto and Strube, 2006a), while others overcome this problem with word sense disambiguation (Nicolae and Nicolae, 2006). Knowledge has also been mined from Wikipedia for measuring the semantic relatedness of two NPs, NPj and NPk (Ponzetto and Strube (2006a; 2007)), such as: whether NPj/k appears in the first paragraph of the Wiki page that has NPk/j as the title or in the list of categories to which this page belongs, and the degree of overlap between the two pages that have the two NPs as their titles (see Poesio et al. (2007) for other uses of encyclopedic knowledge for coreference resolution). Contextual roles (Bean and Riloff, 2004), semantic relations (Ji et al., 2005), semantic roles (Ponzetto and Strube</context>
<context position="36536" citStr="Nicolae and Nicolae, 2006" startWordPosition="5770" endWordPosition="5773">in some coreference corpora (e.g., MUC-6 and MUC-7), the NPs that are not part of any coreference chain are not annotated. Second, in corpora such as those produced by the ACE evaluations, only the NPs that belong to one of the ACE entity types (e.g., PERSON, ORGANIZATION, LOCATION) are annotated. Owing in large part to the difference in the number of NPs extracted by these three methods, a coreference resolver can produce substantially different results when applied to the resulting three sets of NPs, with gold NPs yielding the best results and NPs extracted from a parser yielding the worst (Nicolae and Nicolae, 2006). While researchers who evaluate their resolvers on gold NPs point out that the results can more accurately reflect the performance of their coreference algorithm, Stoyanov et al. (2009) argue that such evaluations are unrealistic, as NP extraction is an integral part of an end-to-end fully-automatic resolver. Whichever NP extraction method is employed, it is clear that the use of gold NPs can considerably simplify the coreference task, and hence resolvers employing different extraction methods should not be compared against each other. 5.2 Scoring a Coreference Partition The MUC scorer (Vilai</context>
</contexts>
<marker>Nicolae, Nicolae, 2006</marker>
<rawString>Cristina Nicolae and Gabriel Nicolae. 2006. BestCut: A graph algorithm for coreference resolution.</rawString>
</citation>
<citation valid="false">
<booktitle>In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>275283</pages>
<marker></marker>
<rawString>In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, pages 275283.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Nilsson</author>
</authors>
<title>Hybrid Methods for Coreference Resolution in Swedish.</title>
<date>2010</date>
<tech>Ph.D. thesis,</tech>
<institution>Stockholm University, Sweden.</institution>
<contexts>
<context position="39731" citStr="Nilsson (2010)" startWordPosition="6269" endWordPosition="6270">008)) rival their supervised counterparts, casting doubts on whether supervised resolvers are making effective use of the available labeled data. Another issue that we have not focused on but which is becoming increasingly important is multilinguality. While many of the techniques discussed in this paper were originally developed for English, they have been applied to learn coreference models for other languages, such as Chinese (e.g., Converse (2006)), Japanese (e.g., Iida (2007)), Arabic (e.g., Luo and Zitouni (2005)), Dutch (e.g., Hoste (2005)), German (e.g., Wunsch (2010)), Swedish (e.g., Nilsson (2010)), and Czech (e.g., Ngu .y et al. (2009)). In addition, researchers have developed approaches that are targeted at handling certain kinds of anaphora present in non-English languages, such as zero anaphora (e.g., Iida et al. (2007a), Zhao and Ng (2007)). As Mitkov (2001) puts it, coreference resolution is a difficult, but not intractable problem, and we have been making slow, but steady progress on improving machine learning approaches to the problem in the past fifteen years. To ensure further progress, researchers should compare their results against a baseline that is stronger than the comm</context>
</contexts>
<marker>Nilsson, 2010</marker>
<rawString>Kristina Nilsson. 2010. Hybrid Methods for Coreference Resolution in Swedish. Ph.D. thesis, Stockholm University, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomoko Ohta</author>
<author>Yuka Tateisi</author>
<author>Jin-Dong Kim</author>
</authors>
<title>The GENIA corpus: An annotated research abstract corpus in molecular biology domain.</title>
<date>2002</date>
<booktitle>In Proceedings of the Second International Conference on Human Language Technology Research,</booktitle>
<pages>8286</pages>
<contexts>
<context position="5448" citStr="Ohta et al., 2002" startWordPosition="819" endWordPosition="822">us et al., 1993), which is labeled with coreference links as part of the OntoNotes project (Hovy et al., 2006); (2) the Tubingen Treebank (Telljohann et al., 2004), which is a collection of German news articles consisting of 27,125 sentences; (3) the Prague Dependency Treebank (Hajic et al., 2006), which consists of 3168 news articles taken from the Czech National Corpus; (4) the NAIST Text Corpus (Iida et al., 2007b), which consists of 287 Japanese news articles; (5) the AnCora Corpus (Recasens and Mart, 2009), which consists of Spanish and Catalan journalist texts; and (6) the GENIA corpus (Ohta et al., 2002), which contains 2000 MEDLINE abstracts. Other publicly available coreference corpora of interest include two annotated by Ruslan Mitkovs research group: (1) a 55,000-word corpus in the domain of security/terrorism (Hasler et al., 2006); and (2) training data released as part of the 2007 Anaphora Resolution Exercise (Orasan et al., 2008), a coreference resolution shared task. There are also two that consist of spoken dialogues: the TRAINS93 corpus (Heeman and Allen, 1995) and the Switchboard data set (Calhoun et al., in press). Additional coreference data will be available in the near future. </context>
</contexts>
<marker>Ohta, Tateisi, Kim, 2002</marker>
<rawString>Tomoko Ohta, Yuka Tateisi, and Jin-Dong Kim. 2002. The GENIA corpus: An annotated research abstract corpus in molecular biology domain. In Proceedings of the Second International Conference on Human Language Technology Research, pages 8286.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Constantin Orasan</author>
<author>Richard Evans</author>
</authors>
<title>NP animacy identification for anaphora resolution.</title>
<date>2007</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<volume>29</volume>
<pages>103</pages>
<contexts>
<context position="31920" citStr="Orasan and Evans, 2007" startWordPosition="5017" endWordPosition="5020">edia for measuring the semantic relatedness of two NPs, NPj and NPk (Ponzetto and Strube (2006a; 2007)), such as: whether NPj/k appears in the first paragraph of the Wiki page that has NPk/j as the title or in the list of categories to which this page belongs, and the degree of overlap between the two pages that have the two NPs as their titles (see Poesio et al. (2007) for other uses of encyclopedic knowledge for coreference resolution). Contextual roles (Bean and Riloff, 2004), semantic relations (Ji et al., 2005), semantic roles (Ponzetto and Strube, 2006b; Kong et al., 2009), and animacy (Orasan and Evans, 2007) have also been exploited to improve coreference resolution. Lexico-syntactic patterns have been used to capture the semantic relatedness between two NPs and hence the likelihood that they are coreferent. For instance, given the pattern X is a Y (which is highly indicative that X and Y are coreferent), we can instantiate it with a pair of NPs and search for the instantiated pattern in a large corpus or the Web (Daume III and Marcu, 2005; Haghighi and Klein, 2009). The more frequently the pattern occurs, the more likely they are coreferent. This technique has been applied to resolve different k</context>
</contexts>
<marker>Orasan, Evans, 2007</marker>
<rawString>Constantin Orasan and Richard Evans. 2007. NP animacy identification for anaphora resolution. Journal of Artificial Intelligence Research, 29:79 103.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Constantin Orasan</author>
<author>Dan Cristea</author>
<author>Ruslan Mitkov</author>
<author>Antonio H Branco</author>
</authors>
<title>Anaphora Resolution Exercise: An overview.</title>
<date>2008</date>
<booktitle>In Proceedings of the 6th Language Resources and Evaluation Conference,</booktitle>
<pages>28012805</pages>
<contexts>
<context position="5787" citStr="Orasan et al., 2008" startWordPosition="869" endWordPosition="872">taken from the Czech National Corpus; (4) the NAIST Text Corpus (Iida et al., 2007b), which consists of 287 Japanese news articles; (5) the AnCora Corpus (Recasens and Mart, 2009), which consists of Spanish and Catalan journalist texts; and (6) the GENIA corpus (Ohta et al., 2002), which contains 2000 MEDLINE abstracts. Other publicly available coreference corpora of interest include two annotated by Ruslan Mitkovs research group: (1) a 55,000-word corpus in the domain of security/terrorism (Hasler et al., 2006); and (2) training data released as part of the 2007 Anaphora Resolution Exercise (Orasan et al., 2008), a coreference resolution shared task. There are also two that consist of spoken dialogues: the TRAINS93 corpus (Heeman and Allen, 1995) and the Switchboard data set (Calhoun et al., in press). Additional coreference data will be available in the near future. For instance, the SemEval-2010 shared task on Coreference Resolution in Multiple Languages (Recasens et al., 2009) has promised to release coreference data in six languages. In addition, Massimo Poesio and his colleagues are leading an annotation project that aims to collect large amounts of coreference data for English via a Web Collabo</context>
</contexts>
<marker>Orasan, Cristea, Mitkov, Branco, 2008</marker>
<rawString>Constantin Orasan, Dan Cristea, Ruslan Mitkov, and Antonio H. Branco. 2008. Anaphora Resolution Exercise: An overview. In Proceedings of the 6th Language Resources and Evaluation Conference, pages 28012805.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Paice</author>
<author>Gareth Husk</author>
</authors>
<title>Towards the automatic recognition of anaphoric features in English text: the impersonal pronoun it. Computer Speech and Language,</title>
<date>1987</date>
<pages>2--109132</pages>
<contexts>
<context position="17077" citStr="Paice and Husk (1987)" startWordPosition="2672" endWordPosition="2675">s their proposed minimum-cutbased graph partitioning algorithm. 3.1.4 Determining NP Anaphoricity While coreference clustering algorithms attempt to resolve each NP encountered in a document, only a subset of the NPs are anaphoric and therefore need to be resolved. Hence, knowledge of the anaphoricity of an NP can potentially improve the precision of a coreference resolver. Traditionally, the task of anaphoricity determination has been tackled independently of coreference resolution using a variety of techniques. For example, pleonastic it has been identified using heuristic approaches (e.g., Paice and Husk (1987), Lappin and Leass (1994), Kennedy and Boguraev (1996)), supervised approaches (e.g., Evans (2001), Muller (2006), Versley et al. (2008a)), and distributional methods (e.g., Bergsma et al. (2008)); and non-anaphoric definite descriptions have been identified using rule-based techniques (e.g., Vieira and Poesio (2000)) and unsupervised techniques (e.g., Bean and Riloff (1999)). Recently, anaphoricity determination has been evaluated in the context of coreference resolution, with results showing that training an anaphoricity classifier to identify and filter non-anaphoric NPs prior to coreferenc</context>
</contexts>
<marker>Paice, Husk, 1987</marker>
<rawString>Chris Paice and Gareth Husk. 1987. Towards the automatic recognition of anaphoric features in English text: the impersonal pronoun it. Computer Speech and Language, 2:109132.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Massimo Poesio</author>
<author>Mijail A Kabadjov</author>
</authors>
<title>A general-purpose, off-the-shelf anaphora resolution module: Implementation and preliminary evaluation.</title>
<date>2004</date>
<booktitle>In Proceedings of the 4th International Conference on Language Resources and Evaluation,</booktitle>
<pages>663668</pages>
<contexts>
<context position="40752" citStr="Poesio and Kabadjov, 2004" startWordPosition="6428" endWordPosition="6431">ess on improving machine learning approaches to the problem in the past fifteen years. To ensure further progress, researchers should compare their results against a baseline that is stronger than the commonly-used Soon et al. (2001) system, which relies on a weak model (i.e., the mention-pair model) and a small set of linguistic features. As recent systems are becoming more sophisticated, we suggest that researchers make their systems publicly available in order to facilitate performance comparisons. Publicly available coreference systems currently include JavaRAP (Qiu et al., 2004), GuiTaR (Poesio and Kabadjov, 2004), BART (Versley et al., 2008b), CoRTex (Denis and Baldridge, 2008), the Illinois Coreference Package (Bengtson and Roth, 2008), CherryPicker (Rahman and Ng, 2009), Reconcile (Stoyanov et al., 2010), and Charniak and Elsners (2009) pronoun resolver. We conclude with a discussion of two questions regarding supervised coreference research. First, what is the state of the art? This is not an easy question, as researchers have been evaluating their resolvers on different corpora using different evaluation metrics and preprocessing tools. In particular, preprocessing tools can have a large impact on</context>
</contexts>
<marker>Poesio, Kabadjov, 2004</marker>
<rawString>Massimo Poesio and Mijail A. Kabadjov. 2004. A general-purpose, off-the-shelf anaphora resolution module: Implementation and preliminary evaluation. In Proceedings of the 4th International Conference on Language Resources and Evaluation, pages 663668.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Massimo Poesio</author>
<author>Rahul Mehta</author>
<author>Axel Maroudas</author>
<author>Janet Hitzeman</author>
</authors>
<title>Learning to resolve bridging references.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>143150</pages>
<contexts>
<context position="17794" citStr="Poesio et al. (2004" startWordPosition="2770" endWordPosition="2773">, Muller (2006), Versley et al. (2008a)), and distributional methods (e.g., Bergsma et al. (2008)); and non-anaphoric definite descriptions have been identified using rule-based techniques (e.g., Vieira and Poesio (2000)) and unsupervised techniques (e.g., Bean and Riloff (1999)). Recently, anaphoricity determination has been evaluated in the context of coreference resolution, with results showing that training an anaphoricity classifier to identify and filter non-anaphoric NPs prior to coreference resolution can improve a learning-based resolver (e.g., Ng and Cardie (2002b), Uryupina (2003), Poesio et al. (2004b)). Compared to earlier work on anaphoricity determination, recently proposed approaches are more global in nature, taking into account the pairwise decisions made by the mention-pair model when making anaphoricity decisions. Examples of such approaches have exploited techniques including integer linear programming (ILP) (Denis and Baldridge, 2007a), label propagation (Zhou and Kong, 2009), and minimum cuts (Ng, 2009). 3.1.5 Combining Classification &amp; Clustering From a learning perspective, a two-step approach to coreference classification and clustering is undesirable. Since the classificati</context>
<context position="32669" citStr="Poesio et al., 2004" startWordPosition="5139" endWordPosition="5142">tedness between two NPs and hence the likelihood that they are coreferent. For instance, given the pattern X is a Y (which is highly indicative that X and Y are coreferent), we can instantiate it with a pair of NPs and search for the instantiated pattern in a large corpus or the Web (Daume III and Marcu, 2005; Haghighi and Klein, 2009). The more frequently the pattern occurs, the more likely they are coreferent. This technique has been applied to resolve different kinds of anaphoric references, including other-anaphora (Modjeska et al., 2003; Markert and Nissim, 2005) and bridging references (Poesio et al., 2004a). While these patterns are typically hand-crafted (e.g., Garera and Yarowsky (2006)), they can also be learned from an annotated corpus (Yang and Su, 2007) or bootstrapped from an unannotated corpus (Bean and Riloff, 2004). Despite the large amount of work on discoursebased anaphora resolution in the 1970s and 1980s (see Hirst (1981)), learning-based resolvers have only exploited shallow discourse-based features, which primarily involve characterizing the salience of a candidate antecedent by measuring its distance from the anaphoric NP to be resolved or determining whether it is in a promin</context>
</contexts>
<marker>Poesio, Mehta, Maroudas, Hitzeman, 2004</marker>
<rawString>Massimo Poesio, Rahul Mehta, Axel Maroudas, and Janet Hitzeman. 2004a. Learning to resolve bridging references. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics, pages 143150.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Massimo Poesio</author>
<author>Olga Uryupina</author>
<author>Renata Vieira</author>
</authors>
<title>Mijail Alexandrov-Kabadjov,and Rodrigo Goulart. 2004b. Discourse-new detectors for definite description resolution: A survey and a preliminary proposal.</title>
<booktitle>In Proeedings of the ACL Workshop on Reference Resolution.</booktitle>
<marker>Poesio, Uryupina, Vieira, </marker>
<rawString>Massimo Poesio, Olga Uryupina, Renata Vieira, Mijail Alexandrov-Kabadjov,and Rodrigo Goulart. 2004b. Discourse-new detectors for definite description resolution: A survey and a preliminary proposal. In Proeedings of the ACL Workshop on Reference Resolution.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Massimo Poesio</author>
<author>David Day</author>
<author>Ron Artstein</author>
<author>Jason Duncan</author>
<author>Vladimir Eidelman</author>
<author>Claudio Giuliano</author>
<author>Rob Hall</author>
<author>Janet Hitzeman</author>
<author>Alan Jern</author>
<author>Mijail Kabadjov</author>
<author>Stanley Yong Wai Keong</author>
<author>Gideon Mann</author>
<author>Alessandro Moschitti</author>
<author>Simone Ponzetto</author>
<author>Jason Smith</author>
<author>Josef Steinberger</author>
<author>Michael Strube</author>
<author>Jian Su</author>
<author>Yannick Versley</author>
<author>Xiaofeng Yang</author>
<author>Michael Wick</author>
</authors>
<date>2007</date>
<booktitle>ELERFED: Final report of the research group on Exploiting Lexical and Encyclopedic Resources For Entity Disambiguation. Technical report, Summer Workshop on Language Engineering,</booktitle>
<institution>Center for Language and Speech Processing, Johns Hopkins University,</institution>
<location>Baltimore, MD.</location>
<contexts>
<context position="31669" citStr="Poesio et al. (2007)" startWordPosition="4979" endWordPosition="4982"> researchers simply use the first sense (Soon et al., 2001) or all possible senses (Ponzetto and Strube, 2006a), while others overcome this problem with word sense disambiguation (Nicolae and Nicolae, 2006). Knowledge has also been mined from Wikipedia for measuring the semantic relatedness of two NPs, NPj and NPk (Ponzetto and Strube (2006a; 2007)), such as: whether NPj/k appears in the first paragraph of the Wiki page that has NPk/j as the title or in the list of categories to which this page belongs, and the degree of overlap between the two pages that have the two NPs as their titles (see Poesio et al. (2007) for other uses of encyclopedic knowledge for coreference resolution). Contextual roles (Bean and Riloff, 2004), semantic relations (Ji et al., 2005), semantic roles (Ponzetto and Strube, 2006b; Kong et al., 2009), and animacy (Orasan and Evans, 2007) have also been exploited to improve coreference resolution. Lexico-syntactic patterns have been used to capture the semantic relatedness between two NPs and hence the likelihood that they are coreferent. For instance, given the pattern X is a Y (which is highly indicative that X and Y are coreferent), we can instantiate it with a pair of NPs and </context>
</contexts>
<marker>Poesio, Day, Artstein, Duncan, Eidelman, Giuliano, Hall, Hitzeman, Jern, Kabadjov, Keong, Mann, Moschitti, Ponzetto, Smith, Steinberger, Strube, Su, Versley, Yang, Wick, 2007</marker>
<rawString>Massimo Poesio, David Day, Ron Artstein, Jason Duncan, Vladimir Eidelman, Claudio Giuliano, Rob Hall, Janet Hitzeman, Alan Jern, Mijail Kabadjov, Stanley Yong Wai Keong, Gideon Mann, Alessandro Moschitti, Simone Ponzetto, Jason Smith, Josef Steinberger, Michael Strube, Jian Su, Yannick Versley, Xiaofeng Yang, and Michael Wick. 2007. ELERFED: Final report of the research group on Exploiting Lexical and Encyclopedic Resources For Entity Disambiguation. Technical report, Summer Workshop on Language Engineering, Center for Language and Speech Processing, Johns Hopkins University, Baltimore, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simone Paolo Ponzetto</author>
<author>Massimo Poesio</author>
</authors>
<date>2009</date>
<contexts>
<context position="3166" citStr="Ponzetto and Poesio (2009)" startWordPosition="472" endWordPosition="475">e passed since the first paper on learning-based coreference resolution was published (Connolly et al., 1994). Our goal in this paper is to provide NLP researchers with a survey of the major milestones in supervised coreference research, focusing on the computational models, the linguistic features, the annotated corpora, and the evaluation metrics that were developed in the past fifteen years. Note that several leading coreference researchers have published books (e.g., Mitkov (2002)), written survey articles (e.g., Mitkov (1999), Strube (2009)), and delivered tutorials (e.g., Strube (2002), Ponzetto and Poesio (2009)) that provide a broad overview of coreference research. This survey paper aims to complement, rather than supersede, these previously published materials. In particular, while existing survey papers discuss learning-based coreference research primarily in the context of the influential mention-pair model, we additionally survey recently proposed learning-based coreference models, which attempt to address the weaknesses of the mention-pair model. Due to space limitations, however, we will restrict our discussion to the most commonly investigated kind of coreference relation: the identity relat</context>
</contexts>
<marker>Ponzetto, Poesio, 2009</marker>
<rawString>Simone Paolo Ponzetto and Massimo Poesio. 2009.</rawString>
</citation>
<citation valid="false">
<authors>
<author>State-of-the-art NLP</author>
</authors>
<title>approaches to coreference resolution: Theory and practical recipes.</title>
<booktitle>In Tutorial Abstracts of ACL-IJCNLP 2009,</booktitle>
<pages>6</pages>
<marker>NLP, </marker>
<rawString>State-of-the-art NLP approaches to coreference resolution: Theory and practical recipes. In Tutorial Abstracts of ACL-IJCNLP 2009, page 6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simone Paolo Ponzetto</author>
<author>Michael Strube</author>
</authors>
<date>2006</date>
<contexts>
<context position="31158" citStr="Ponzetto and Strube, 2006" startWordPosition="4888" endWordPosition="4891">b, and its grammatical role, we prefer a candidate antecedent that can be governed by the same verb and be in the same role. Semantic knowledge has also been extracted from WordNet and unannotated corpora for computing the semantic compatibility/similarity between two common nouns (Harabagiu et al., 2001; Versley, 2007) as well as the semantic class of a noun (Ng, 2007a; Huang et al., 2009). One difficulty with deriving knowledge from WordNet is that one has to determine which sense of a given word to use. Some researchers simply use the first sense (Soon et al., 2001) or all possible senses (Ponzetto and Strube, 2006a), while others overcome this problem with word sense disambiguation (Nicolae and Nicolae, 2006). Knowledge has also been mined from Wikipedia for measuring the semantic relatedness of two NPs, NPj and NPk (Ponzetto and Strube (2006a; 2007)), such as: whether NPj/k appears in the first paragraph of the Wiki page that has NPk/j as the title or in the list of categories to which this page belongs, and the degree of overlap between the two pages that have the two NPs as their titles (see Poesio et al. (2007) for other uses of encyclopedic knowledge for coreference resolution). Contextual roles (</context>
</contexts>
<marker>Ponzetto, Strube, 2006</marker>
<rawString>Simone Paolo Ponzetto and Michael Strube. 2006a.</rawString>
</citation>
<citation valid="false">
<title>Exploiting semantic role labeling, WordNet and Wikipedia for coreference resolution.</title>
<booktitle>In Human Language Technologies 2006: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference,</booktitle>
<pages>192199</pages>
<marker></marker>
<rawString>Exploiting semantic role labeling, WordNet and Wikipedia for coreference resolution. In Human Language Technologies 2006: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference, pages 192199.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simone Paolo Ponzetto</author>
<author>Michael Strube</author>
</authors>
<title>Semantic role labeling for coreference resolution.</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>143146</pages>
<contexts>
<context position="31158" citStr="Ponzetto and Strube, 2006" startWordPosition="4888" endWordPosition="4891">b, and its grammatical role, we prefer a candidate antecedent that can be governed by the same verb and be in the same role. Semantic knowledge has also been extracted from WordNet and unannotated corpora for computing the semantic compatibility/similarity between two common nouns (Harabagiu et al., 2001; Versley, 2007) as well as the semantic class of a noun (Ng, 2007a; Huang et al., 2009). One difficulty with deriving knowledge from WordNet is that one has to determine which sense of a given word to use. Some researchers simply use the first sense (Soon et al., 2001) or all possible senses (Ponzetto and Strube, 2006a), while others overcome this problem with word sense disambiguation (Nicolae and Nicolae, 2006). Knowledge has also been mined from Wikipedia for measuring the semantic relatedness of two NPs, NPj and NPk (Ponzetto and Strube (2006a; 2007)), such as: whether NPj/k appears in the first paragraph of the Wiki page that has NPk/j as the title or in the list of categories to which this page belongs, and the degree of overlap between the two pages that have the two NPs as their titles (see Poesio et al. (2007) for other uses of encyclopedic knowledge for coreference resolution). Contextual roles (</context>
</contexts>
<marker>Ponzetto, Strube, 2006</marker>
<rawString>Simone Paolo Ponzetto and Michael Strube. 2006b. Semantic role labeling for coreference resolution. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics, pages 143146.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simone Paolo Ponzetto</author>
<author>Michael Strube</author>
</authors>
<title>Knowledge derived from Wikipedia for computing semantic relatedness.</title>
<date>2007</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>30--181212</pages>
<marker>Ponzetto, Strube, 2007</marker>
<rawString>Simone Paolo Ponzetto and Michael Strube. 2007. Knowledge derived from Wikipedia for computing semantic relatedness. Journal of Artificial Intelligence Research, 30:181212.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hoifung Poon</author>
<author>Pedro Domingos</author>
</authors>
<title>Joint unsupervised coreference resolution with Markov Logic.</title>
<date>2008</date>
<contexts>
<context position="39121" citStr="Poon and Domingos (2008)" startWordPosition="6173" endWordPosition="6176">sues, see Byron (2001). 6 Concluding Remarks While we have focused our discussion on supervised approaches, coreference researchers have also attempted to reduce a resolvers reliance on annotated data by combining a small amount of labeled data and a large amount of unlabeled data using general-purpose semi-supervised learning algorithms such as co-training (Muller et al., 2002), self-training (Kehler et al., 2004a), and EM (Cherry and Bergsma, 2005; Ng, 2008). Interestingly, recent results indicate that unsupervised approaches to coreference resolution (e.g., Haghighi and Klein (2007; 2010), Poon and Domingos (2008)) rival their supervised counterparts, casting doubts on whether supervised resolvers are making effective use of the available labeled data. Another issue that we have not focused on but which is becoming increasingly important is multilinguality. While many of the techniques discussed in this paper were originally developed for English, they have been applied to learn coreference models for other languages, such as Chinese (e.g., Converse (2006)), Japanese (e.g., Iida (2007)), Arabic (e.g., Luo and Zitouni (2005)), Dutch (e.g., Hoste (2005)), German (e.g., Wunsch (2010)), Swedish (e.g., Nils</context>
</contexts>
<marker>Poon, Domingos, 2008</marker>
<rawString>Hoifung Poon and Pedro Domingos. 2008. Joint unsupervised coreference resolution with Markov Logic.</rawString>
</citation>
<citation valid="false">
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>650659</pages>
<marker></marker>
<rawString>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 650659.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrei Popescu-Belis</author>
<author>Los Rigouste</author>
<author>Susanne Salmon-Alt</author>
<author>Laurent Romary</author>
</authors>
<title>Online evaluation of coreference resolution.</title>
<date>2004</date>
<booktitle>In Proceedings of the 4th International Conference on Language Resources and Evaluation,</booktitle>
<pages>15071510</pages>
<contexts>
<context position="38110" citStr="Popescu-Belis et al. (2004)" startWordPosition="6021" endWordPosition="6024">lems, two coreference scoring programs have been developed: B3 (Bagga and Baldwin, 1998) and CEAF (Luo, 2005). Note that both scorers have only been defined for the case where the key partition has the same set of NPs as the response partition. To apply these scorers to automatically extracted NPs, different methods have been proposed (see Rahman and Ng (2009) and Stoyanov et al. (2009)). Since coreference is a clustering task, any general-purpose method for evaluating a response partition against a key partition (e.g., Kappa (Carletta, 1996)) can be used for coreference scor1403 \x0cing (see Popescu-Belis et al. (2004)). In practice, these general-purpose methods are typically used to provide scores that complement those obtained via the three coreference scorers discussed above. It is worth mentioning that there is a trend towards evaluating a resolver against multiple scorers, which can indirectly help to counteract the bias inherent in a particular scorer. For further discussion on evaluation issues, see Byron (2001). 6 Concluding Remarks While we have focused our discussion on supervised approaches, coreference researchers have also attempted to reduce a resolvers reliance on annotated data by combining</context>
</contexts>
<marker>Popescu-Belis, Rigouste, Salmon-Alt, Romary, 2004</marker>
<rawString>Andrei Popescu-Belis, Los Rigouste, Susanne Salmon-Alt, and Laurent Romary. 2004. Online evaluation of coreference resolution. In Proceedings of the 4th International Conference on Language Resources and Evaluation, pages 15071510.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Long Qiu</author>
<author>Min-Yen Kan</author>
<author>Tat-Seng Chua</author>
</authors>
<title>A public reference implementation of the RAP anaphora resolution algorithm.</title>
<date>2004</date>
<booktitle>In Proceedings of the 4th International Conference on Language Resources and Evaluation,</booktitle>
<pages>291294</pages>
<contexts>
<context position="40716" citStr="Qiu et al., 2004" startWordPosition="6423" endWordPosition="6426">king slow, but steady progress on improving machine learning approaches to the problem in the past fifteen years. To ensure further progress, researchers should compare their results against a baseline that is stronger than the commonly-used Soon et al. (2001) system, which relies on a weak model (i.e., the mention-pair model) and a small set of linguistic features. As recent systems are becoming more sophisticated, we suggest that researchers make their systems publicly available in order to facilitate performance comparisons. Publicly available coreference systems currently include JavaRAP (Qiu et al., 2004), GuiTaR (Poesio and Kabadjov, 2004), BART (Versley et al., 2008b), CoRTex (Denis and Baldridge, 2008), the Illinois Coreference Package (Bengtson and Roth, 2008), CherryPicker (Rahman and Ng, 2009), Reconcile (Stoyanov et al., 2010), and Charniak and Elsners (2009) pronoun resolver. We conclude with a discussion of two questions regarding supervised coreference research. First, what is the state of the art? This is not an easy question, as researchers have been evaluating their resolvers on different corpora using different evaluation metrics and preprocessing tools. In particular, preprocess</context>
</contexts>
<marker>Qiu, Kan, Chua, 2004</marker>
<rawString>Long Qiu, Min-Yen Kan, and Tat-Seng Chua. 2004. A public reference implementation of the RAP anaphora resolution algorithm. In Proceedings of the 4th International Conference on Language Resources and Evaluation, pages 291294.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Ross Quinlan</author>
</authors>
<title>C4.5: Programs for Machine Learning.</title>
<date>1993</date>
<publisher>Morgan Kaufmann,</publisher>
<location>San Mateo, CA.</location>
<contexts>
<context position="10619" citStr="Quinlan, 1993" startWordPosition="1634" endWordPosition="1635">004) and Hoste and Daelemans (2005)), some are learning-based. For example, motivated by the fact that some coreference relations are harder to identify than the others (see Harabagiu et al. (2001)), Ng and Cardie (2002a) present a method for mining easy positive instances, in an attempt to avoid the inclusion of hard training instances that may complicate the acquisition of an accurate coreference model. 3.1.2 Training a Coreference Classifier Once a training set is created, we can train a coreference model using an off-the-shelf learning algorithm. Decision tree induction systems (e.g., C5 (Quinlan, 1993)) are the first and one of the most widely used learning algorithms by coreference researchers, although rule learners (e.g., RIPPER (Cohen, 1995)) and memory-based learners (e.g., TiMBL (Daelemans and Van den Bosch, 2005)) are also popular choices, especially in early applications of machine learning to coreference resolution. In recent years, statistical learners such as maximum entropy models (Berger et al., 1996), voted perceptrons (Freund and Schapire, 1999), 3 In this paper, we use the term anaphoric to describe any NP that is part of a coreference chain but is not the head of the chain.</context>
</contexts>
<marker>Quinlan, 1993</marker>
<rawString>John Ross Quinlan. 1993. C4.5: Programs for Machine Learning. Morgan Kaufmann, San Mateo, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Altaf Rahman</author>
<author>Vincent Ng</author>
</authors>
<title>Supervised models for coreference resolution.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>968977</pages>
<contexts>
<context position="26465" citStr="Rahman and Ng (2009)" startWordPosition="4140" endWordPosition="4143">each pair of its candidate antecedents, and the candidate that is classified as better the largest number of times is selected as its antecedent. Advances in machine learning have made it possible to train a mention ranker that ranks all of the candidate antecedents simultaneously. While mention rankers have consistently outperformed the mention-pair model (Versley, 2006; Denis and Baldridge, 2007b), they are not more expressive than the mention-pair model, as they are unable to exploit cluster-level features, unlike the entitymention model. To enable rankers to employ cluster-level features, Rahman and Ng (2009) propose the cluster-ranking model, which ranks preceding clusters, rather than candidate antecedents, for an NP to be resolved. Cluster rankers therefore address both weaknesses of the mention-pair model, and have been shown to improve mention rankers. Cluster rankers are conceptually similar to Lappin and Leasss (1994) heuristic pronoun resolver, which resolves an anaphoric pronoun to the most salient preceding cluster. An important issue with ranking models that we have eluded so far concerns the identification of non-anaphoric NPs. As a ranker simply imposes a ranking on candidate antecede</context>
<context position="37845" citStr="Rahman and Ng (2009)" startWordPosition="5980" endWordPosition="5983"> two often-cited weaknesses. As a linkbased measure, it does not reward correctly identified singleton clusters since there is no coreference link in these clusters. Also, it tends to underpenalize partitions with overly large clusters. To address these problems, two coreference scoring programs have been developed: B3 (Bagga and Baldwin, 1998) and CEAF (Luo, 2005). Note that both scorers have only been defined for the case where the key partition has the same set of NPs as the response partition. To apply these scorers to automatically extracted NPs, different methods have been proposed (see Rahman and Ng (2009) and Stoyanov et al. (2009)). Since coreference is a clustering task, any general-purpose method for evaluating a response partition against a key partition (e.g., Kappa (Carletta, 1996)) can be used for coreference scor1403 \x0cing (see Popescu-Belis et al. (2004)). In practice, these general-purpose methods are typically used to provide scores that complement those obtained via the three coreference scorers discussed above. It is worth mentioning that there is a trend towards evaluating a resolver against multiple scorers, which can indirectly help to counteract the bias inherent in a partic</context>
<context position="40914" citStr="Rahman and Ng, 2009" startWordPosition="6453" endWordPosition="6456">seline that is stronger than the commonly-used Soon et al. (2001) system, which relies on a weak model (i.e., the mention-pair model) and a small set of linguistic features. As recent systems are becoming more sophisticated, we suggest that researchers make their systems publicly available in order to facilitate performance comparisons. Publicly available coreference systems currently include JavaRAP (Qiu et al., 2004), GuiTaR (Poesio and Kabadjov, 2004), BART (Versley et al., 2008b), CoRTex (Denis and Baldridge, 2008), the Illinois Coreference Package (Bengtson and Roth, 2008), CherryPicker (Rahman and Ng, 2009), Reconcile (Stoyanov et al., 2010), and Charniak and Elsners (2009) pronoun resolver. We conclude with a discussion of two questions regarding supervised coreference research. First, what is the state of the art? This is not an easy question, as researchers have been evaluating their resolvers on different corpora using different evaluation metrics and preprocessing tools. In particular, preprocessing tools can have a large impact on the performance of a resolver (Barbu and Mitkov, 2001). Worse still, assumptions about whether gold or automatically extracted NPs are used are sometimes not exp</context>
</contexts>
<marker>Rahman, Ng, 2009</marker>
<rawString>Altaf Rahman and Vincent Ng. 2009. Supervised models for coreference resolution. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 968977.</rawString>
</citation>
<citation valid="true">
<authors>
<author>\x0cMarta Recasens</author>
<author>M Antonia Mart</author>
</authors>
<title>AnCoraCO: Coreferentially annotated corpora for Spanish and Catalan. Language Resources and Evaluation,</title>
<date>2009</date>
<volume>43</volume>
<issue>4</issue>
<contexts>
<context position="5346" citStr="Recasens and Mart, 2009" startWordPosition="801" endWordPosition="804">ence annotations are also publicly available in treebanks. These include (1) the English Penn Treebank (Marcus et al., 1993), which is labeled with coreference links as part of the OntoNotes project (Hovy et al., 2006); (2) the Tubingen Treebank (Telljohann et al., 2004), which is a collection of German news articles consisting of 27,125 sentences; (3) the Prague Dependency Treebank (Hajic et al., 2006), which consists of 3168 news articles taken from the Czech National Corpus; (4) the NAIST Text Corpus (Iida et al., 2007b), which consists of 287 Japanese news articles; (5) the AnCora Corpus (Recasens and Mart, 2009), which consists of Spanish and Catalan journalist texts; and (6) the GENIA corpus (Ohta et al., 2002), which contains 2000 MEDLINE abstracts. Other publicly available coreference corpora of interest include two annotated by Ruslan Mitkovs research group: (1) a 55,000-word corpus in the domain of security/terrorism (Hasler et al., 2006); and (2) training data released as part of the 2007 Anaphora Resolution Exercise (Orasan et al., 2008), a coreference resolution shared task. There are also two that consist of spoken dialogues: the TRAINS93 corpus (Heeman and Allen, 1995) and the Switchboard d</context>
</contexts>
<marker>Recasens, Mart, 2009</marker>
<rawString>\x0cMarta Recasens and M. Antonia Mart. 2009. AnCoraCO: Coreferentially annotated corpora for Spanish and Catalan. Language Resources and Evaluation, 43(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marta Recasens</author>
<author>Toni Mart</author>
<author>Mariona Taule</author>
<author>Llus Marquez</author>
<author>Emili Sapena</author>
</authors>
<title>SemEval2010 Task 1: Coreference resolution in multiple languages.</title>
<date>2009</date>
<booktitle>In Proceedings of the Workshop on Semantic Evaluations: Recent Achievements and Future Directions (SEW-2009),</booktitle>
<pages>7075</pages>
<contexts>
<context position="6162" citStr="Recasens et al., 2009" startWordPosition="926" endWordPosition="929">erest include two annotated by Ruslan Mitkovs research group: (1) a 55,000-word corpus in the domain of security/terrorism (Hasler et al., 2006); and (2) training data released as part of the 2007 Anaphora Resolution Exercise (Orasan et al., 2008), a coreference resolution shared task. There are also two that consist of spoken dialogues: the TRAINS93 corpus (Heeman and Allen, 1995) and the Switchboard data set (Calhoun et al., in press). Additional coreference data will be available in the near future. For instance, the SemEval-2010 shared task on Coreference Resolution in Multiple Languages (Recasens et al., 2009) has promised to release coreference data in six languages. In addition, Massimo Poesio and his colleagues are leading an annotation project that aims to collect large amounts of coreference data for English via a Web Collaboration game called Phrase Detectives2. 1 http://www.itl.nist.gov/iad/mig/tests/ace/ 2 http://www.phrasedetectives.org 3 Learning-Based Coreference Models In this section, we examine three important classes of coreference models that were developed in the past fifteen years, namely, the mention-pair model, the entity-mention model, and ranking models. 3.1 Mention-Pair Model</context>
</contexts>
<marker>Recasens, Mart, Taule, Marquez, Sapena, 2009</marker>
<rawString>Marta Recasens, Toni Mart, Mariona Taule, Llus Marquez, and Emili Sapena. 2009. SemEval2010 Task 1: Coreference resolution in multiple languages. In Proceedings of the Workshop on Semantic Evaluations: Recent Achievements and Future Directions (SEW-2009), pages 7075.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Candace Sidner</author>
</authors>
<title>Towards a Computational Theory of Definite Anaphora Comprehension in English Discourse.</title>
<date>1979</date>
<tech>Ph.D. thesis,</tech>
<institution>Massachusetts Institute of Technology, USA.</institution>
<contexts>
<context position="1513" citStr="Sidner (1979)" startWordPosition="221" endWordPosition="222">P coreference is related to the task of anaphora resolution, whose goal is to identify an antecedent for an anaphoric NP (i.e., an NP that depends on another NP, specifically its antecedent, for its interpretation) [see van Deemter and Kibble (2000) for a detailed discussion of the difference between the two tasks]. Despite its simple task definition, coreference is generally considered a difficult NLP task, typically involving the use of sophisticated knowledge sources and inference procedures (Charniak, 1972). Computational theories of discourse, in particular focusing (see Grosz (1977) and Sidner (1979)) and centering (Grosz et al. (1983; 1995)), have heavily influenced coreference research in the 1970s and 1980s, leading to the development of numerous centering algorithms (see Walker et al. (1998)). The focus of coreference research underwent a gradual shift from heuristic approaches to machine learning approaches in the 1990s. This shift can be attributed in part to the advent of the statistical NLP era, and in part to the public availability of annotated coreference corpora produced as part of the MUC-6 (1995) and MUC-7 (1998) conferences. Learning-based coreference research has remained </context>
</contexts>
<marker>Sidner, 1979</marker>
<rawString>Candace Sidner. 1979. Towards a Computational Theory of Definite Anaphora Comprehension in English Discourse. Ph.D. thesis, Massachusetts Institute of Technology, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wee Meng Soon</author>
<author>Hwee Tou Ng</author>
<author>Chung Yong Lim</author>
</authors>
<title>Corpus-based learning for noun phrase coreference resolution.</title>
<date>1999</date>
<booktitle>In Proceedings of the 1999 Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora,</booktitle>
<pages>285291</pages>
<marker>Soon, Ng, Lim, 1999</marker>
<rawString>Wee Meng Soon, Hwee Tou Ng, and Chung Yong Lim. 1999. Corpus-based learning for noun phrase coreference resolution. In Proceedings of the 1999 Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora, pages 285291.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wee Meng Soon</author>
<author>Hwee Tou Ng</author>
<author>Daniel Chung Yong Lim</author>
</authors>
<title>A machine learning approach to coreference resolution of noun phrases.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<volume>27</volume>
<issue>4</issue>
<contexts>
<context position="12016" citStr="Soon et al., 2001" startWordPosition="1853" endWordPosition="1856"> in part due to their ability to provide a confidence value (e.g., in the form of a probability) associated with a classification, and in part due to the fact that they can be easily adapted to train recently proposed rankingbased coreference models (see Section 3.3). 3.1.3 Generating an NP Partition After training, we can apply the resulting model to a test text, using a clustering algorithm to coordinate the pairwise classification decisions and impose an NP partition. Below we describe some commonly used coreference clustering algorithms. Despite their simplicity, closest-first clustering (Soon et al., 2001) and best-first clustering (Ng and Cardie, 2002c) are arguably the most widely used coreference clustering algorithms. The closest-first clustering algorithm selects as the antecedent for an NP, NPk, the closest preceding noun phrase that is classified as coreferent with it.4 However, if no such preceding noun phrase exists, no antecedent is selected for NPk. The best-first clustering algorithm aims to improve the precision of closest-first clustering, specifically by selecting as the antecedent of NPk the most probable preceding NP that is classified as coreferent with it. One criticism of th</context>
<context position="16214" citStr="Soon et al. (2001)" startWordPosition="2538" endWordPosition="2541">evels of the tree, the algorithm determines at the ith level whether the ith NP should start a new cluster, or to which preceding cluster it should be assigned. While many coreference clustering algorithms have been developed, there have only been a few attempts to compare their effectiveness. For example, Ng and Cardie (2002c) report that bestfirst clustering is better than closest-first clustering. Nicolae and Nicolae (2006) show that bestfirst clustering performs similarly to Bell-treebased clustering, but neither of these algorithms 5 When applying closest-first and best-first clustering, Soon et al. (2001) and Ng and Cardie (2002c) also process the NPs in a sequential manner, but since the later decisions are not dependent on the earlier ones, the order in which the NPs are processed does not affect their clustering results. performs as well as their proposed minimum-cutbased graph partitioning algorithm. 3.1.4 Determining NP Anaphoricity While coreference clustering algorithms attempt to resolve each NP encountered in a document, only a subset of the NPs are anaphoric and therefore need to be resolved. Hence, knowledge of the anaphoricity of an NP can potentially improve the precision of a cor</context>
<context position="31108" citStr="Soon et al., 2001" startWordPosition="4880" endWordPosition="4883">a pronoun to be resolved, its governing verb, and its grammatical role, we prefer a candidate antecedent that can be governed by the same verb and be in the same role. Semantic knowledge has also been extracted from WordNet and unannotated corpora for computing the semantic compatibility/similarity between two common nouns (Harabagiu et al., 2001; Versley, 2007) as well as the semantic class of a noun (Ng, 2007a; Huang et al., 2009). One difficulty with deriving knowledge from WordNet is that one has to determine which sense of a given word to use. Some researchers simply use the first sense (Soon et al., 2001) or all possible senses (Ponzetto and Strube, 2006a), while others overcome this problem with word sense disambiguation (Nicolae and Nicolae, 2006). Knowledge has also been mined from Wikipedia for measuring the semantic relatedness of two NPs, NPj and NPk (Ponzetto and Strube (2006a; 2007)), such as: whether NPj/k appears in the first paragraph of the Wiki page that has NPk/j as the title or in the list of categories to which this page belongs, and the degree of overlap between the two pages that have the two NPs as their titles (see Poesio et al. (2007) for other uses of encyclopedic knowled</context>
<context position="40359" citStr="Soon et al. (2001)" startWordPosition="6369" endWordPosition="6372">ch (e.g., Ngu .y et al. (2009)). In addition, researchers have developed approaches that are targeted at handling certain kinds of anaphora present in non-English languages, such as zero anaphora (e.g., Iida et al. (2007a), Zhao and Ng (2007)). As Mitkov (2001) puts it, coreference resolution is a difficult, but not intractable problem, and we have been making slow, but steady progress on improving machine learning approaches to the problem in the past fifteen years. To ensure further progress, researchers should compare their results against a baseline that is stronger than the commonly-used Soon et al. (2001) system, which relies on a weak model (i.e., the mention-pair model) and a small set of linguistic features. As recent systems are becoming more sophisticated, we suggest that researchers make their systems publicly available in order to facilitate performance comparisons. Publicly available coreference systems currently include JavaRAP (Qiu et al., 2004), GuiTaR (Poesio and Kabadjov, 2004), BART (Versley et al., 2008b), CoRTex (Denis and Baldridge, 2008), the Illinois Coreference Package (Bengtson and Roth, 2008), CherryPicker (Rahman and Ng, 2009), Reconcile (Stoyanov et al., 2010), and Char</context>
</contexts>
<marker>Soon, Ng, Lim, 2001</marker>
<rawString>Wee Meng Soon, Hwee Tou Ng, and Daniel Chung Yong Lim. 2001. A machine learning approach to coreference resolution of noun phrases. Computational Linguistics, 27(4):521544.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Veselin Stoyanov</author>
<author>Nathan Gilbert</author>
<author>Claire Cardie</author>
<author>Ellen Riloff</author>
</authors>
<title>Conundrums in noun phrase coreference resolution: Making sense of the stateof-the-art.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP,</booktitle>
<pages>656664</pages>
<contexts>
<context position="36722" citStr="Stoyanov et al. (2009)" startWordPosition="5799" endWordPosition="5802">nly the NPs that belong to one of the ACE entity types (e.g., PERSON, ORGANIZATION, LOCATION) are annotated. Owing in large part to the difference in the number of NPs extracted by these three methods, a coreference resolver can produce substantially different results when applied to the resulting three sets of NPs, with gold NPs yielding the best results and NPs extracted from a parser yielding the worst (Nicolae and Nicolae, 2006). While researchers who evaluate their resolvers on gold NPs point out that the results can more accurately reflect the performance of their coreference algorithm, Stoyanov et al. (2009) argue that such evaluations are unrealistic, as NP extraction is an integral part of an end-to-end fully-automatic resolver. Whichever NP extraction method is employed, it is clear that the use of gold NPs can considerably simplify the coreference task, and hence resolvers employing different extraction methods should not be compared against each other. 5.2 Scoring a Coreference Partition The MUC scorer (Vilain et al., 1995) is the first program developed for scoring coreference partitions. It has two often-cited weaknesses. As a linkbased measure, it does not reward correctly identified sing</context>
</contexts>
<marker>Stoyanov, Gilbert, Cardie, Riloff, 2009</marker>
<rawString>Veselin Stoyanov, Nathan Gilbert, Claire Cardie, and Ellen Riloff. 2009. Conundrums in noun phrase coreference resolution: Making sense of the stateof-the-art. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, pages 656664.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Veselin Stoyanov</author>
<author>Claire Cardie</author>
<author>Nathan Gilbert</author>
<author>Ellen Riloff</author>
<author>David Buttler</author>
<author>David Hysom</author>
</authors>
<date>2010</date>
<contexts>
<context position="40949" citStr="Stoyanov et al., 2010" startWordPosition="6458" endWordPosition="6461">commonly-used Soon et al. (2001) system, which relies on a weak model (i.e., the mention-pair model) and a small set of linguistic features. As recent systems are becoming more sophisticated, we suggest that researchers make their systems publicly available in order to facilitate performance comparisons. Publicly available coreference systems currently include JavaRAP (Qiu et al., 2004), GuiTaR (Poesio and Kabadjov, 2004), BART (Versley et al., 2008b), CoRTex (Denis and Baldridge, 2008), the Illinois Coreference Package (Bengtson and Roth, 2008), CherryPicker (Rahman and Ng, 2009), Reconcile (Stoyanov et al., 2010), and Charniak and Elsners (2009) pronoun resolver. We conclude with a discussion of two questions regarding supervised coreference research. First, what is the state of the art? This is not an easy question, as researchers have been evaluating their resolvers on different corpora using different evaluation metrics and preprocessing tools. In particular, preprocessing tools can have a large impact on the performance of a resolver (Barbu and Mitkov, 2001). Worse still, assumptions about whether gold or automatically extracted NPs are used are sometimes not explicitly stated, potentially causing</context>
</contexts>
<marker>Stoyanov, Cardie, Gilbert, Riloff, Buttler, Hysom, 2010</marker>
<rawString>Veselin Stoyanov, Claire Cardie, Nathan Gilbert, Ellen Riloff, David Buttler, and David Hysom. 2010.</rawString>
</citation>
<citation valid="false">
<title>Coreference resolution with Reconcile.</title>
<booktitle>In Proceedings of the ACL 2010 Conference Short Papers.</booktitle>
<marker></marker>
<rawString>Coreference resolution with Reconcile. In Proceedings of the ACL 2010 Conference Short Papers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Strube</author>
<author>Stefan Rapp</author>
<author>Christoph Muller</author>
</authors>
<title>The influence of minimum edit distance on reference resolution.</title>
<date>2002</date>
<booktitle>In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>312319</pages>
<contexts>
<context position="9905" citStr="Strube et al. (2002)" startWordPosition="1520" endWordPosition="1523">positive instance should be formed between NPk and its closest preceding nonpronominal antecedent instead. This modification is motivated by the observation that it is not easy for a human, let alone a machine learner, to learn from a positive instance where the antecedent of a non-pronominal NP is a pronoun. To further reduce class skewness, some researchers employ a filtering mechanism on top of an instance creation method, thereby disallowing the creation of training instances from NP pairs that are unlikely to be coreferent, such as NP pairs that violate gender and number agreement (e.g., Strube et al. (2002), Yang et al. (2003)). While many instance creation methods are heuristic in nature (see Uryupina (2004) and Hoste and Daelemans (2005)), some are learning-based. For example, motivated by the fact that some coreference relations are harder to identify than the others (see Harabagiu et al. (2001)), Ng and Cardie (2002a) present a method for mining easy positive instances, in an attempt to avoid the inclusion of hard training instances that may complicate the acquisition of an accurate coreference model. 3.1.2 Training a Coreference Classifier Once a training set is created, we can train a core</context>
<context position="28002" citStr="Strube et al., 2002" startWordPosition="4375" endWordPosition="4378">arns coreference and anaphoricity. 4 Knowledge Sources Another thread of supervised coreference research concerns the development of linguistic features. Below we give an overview of these features. String-matching features can be computed robustly and typically contribute a lot to the performance of a coreference system. Besides simple string-matching operations such as exact string match, substring match, and head noun match for different kinds of NPs (see Daume III and Marcu (2005)), slightly more sophisticated stringmatching facilities have been attempted, including minimum edit distance (Strube et al., 2002) and longest common subsequence (Castano et al., 2002). Yang et al. (2004a) treat the two NPs involved as two bags of words, and compute their similarity using metrics commonly-used in information retrieval, such as the dot product, with each word weighted by their TF-IDF value. Syntactic features are computed based on a syntactic parse tree. Ge et al. (1998) implement 1401 \x0ca Hobbs distance feature, which encodes the rank assigned to a candidate antecedent for a pronoun by Hobbss (1978) seminal syntax-based pronoun resolution algorithm. Luo and Zitouni (2005) extract features from a parse </context>
</contexts>
<marker>Strube, Rapp, Muller, 2002</marker>
<rawString>Michael Strube, Stefan Rapp, and Christoph Muller. 2002. The influence of minimum edit distance on reference resolution. In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing, pages 312319.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Strube</author>
</authors>
<title>NLP approaches to reference resolution.</title>
<date>2002</date>
<booktitle>In Tutorial Abstracts of ACL 2002,</booktitle>
<pages>124</pages>
<contexts>
<context position="3138" citStr="Strube (2002)" startWordPosition="470" endWordPosition="471">fteen years have passed since the first paper on learning-based coreference resolution was published (Connolly et al., 1994). Our goal in this paper is to provide NLP researchers with a survey of the major milestones in supervised coreference research, focusing on the computational models, the linguistic features, the annotated corpora, and the evaluation metrics that were developed in the past fifteen years. Note that several leading coreference researchers have published books (e.g., Mitkov (2002)), written survey articles (e.g., Mitkov (1999), Strube (2009)), and delivered tutorials (e.g., Strube (2002), Ponzetto and Poesio (2009)) that provide a broad overview of coreference research. This survey paper aims to complement, rather than supersede, these previously published materials. In particular, while existing survey papers discuss learning-based coreference research primarily in the context of the influential mention-pair model, we additionally survey recently proposed learning-based coreference models, which attempt to address the weaknesses of the mention-pair model. Due to space limitations, however, we will restrict our discussion to the most commonly investigated kind of coreference </context>
</contexts>
<marker>Strube, 2002</marker>
<rawString>Michael Strube. 2002. NLP approaches to reference resolution. In Tutorial Abstracts of ACL 2002, page 124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Strube</author>
</authors>
<title>edition.</title>
<date>2009</date>
<booktitle>Anaphernresolution. In Computerlinguistik und Sprachtechnologie. Eine Einfuhrung.</booktitle>
<publisher>Springer,</publisher>
<location>Heidelberg,</location>
<contexts>
<context position="3091" citStr="Strube (2009)" startWordPosition="463" endWordPosition="464">attention in the machine learning community. Fifteen years have passed since the first paper on learning-based coreference resolution was published (Connolly et al., 1994). Our goal in this paper is to provide NLP researchers with a survey of the major milestones in supervised coreference research, focusing on the computational models, the linguistic features, the annotated corpora, and the evaluation metrics that were developed in the past fifteen years. Note that several leading coreference researchers have published books (e.g., Mitkov (2002)), written survey articles (e.g., Mitkov (1999), Strube (2009)), and delivered tutorials (e.g., Strube (2002), Ponzetto and Poesio (2009)) that provide a broad overview of coreference research. This survey paper aims to complement, rather than supersede, these previously published materials. In particular, while existing survey papers discuss learning-based coreference research primarily in the context of the influential mention-pair model, we additionally survey recently proposed learning-based coreference models, which attempt to address the weaknesses of the mention-pair model. Due to space limitations, however, we will restrict our discussion to the </context>
</contexts>
<marker>Strube, 2009</marker>
<rawString>Michael Strube. 2009. Anaphernresolution. In Computerlinguistik und Sprachtechnologie. Eine Einfuhrung. Springer, Heidelberg, Germany, 3rd edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heike Telljohann</author>
<author>Erhard Hinrichs</author>
<author>Sandra Kubler</author>
</authors>
<title>The tuba-d/z treebank: Annotating German with a context-free backbone.</title>
<date>2004</date>
<booktitle>In Proceedings of the 4th International Conference on Language Resources and Evaluation,</booktitle>
<pages>22292235</pages>
<contexts>
<context position="4993" citStr="Telljohann et al., 2004" startWordPosition="743" endWordPosition="746">n (ACE1) evaluations in the past decade: while the earlier ACE corpora (e.g., ACE-2) consist of solely English newswire and broadcast news articles, the later ones (e.g., ACE 2005) have also included Chinese and Arabic documents taken from additional sources such as broadcast conversations, webblog, usenet, and conversational telephone speech. Coreference annotations are also publicly available in treebanks. These include (1) the English Penn Treebank (Marcus et al., 1993), which is labeled with coreference links as part of the OntoNotes project (Hovy et al., 2006); (2) the Tubingen Treebank (Telljohann et al., 2004), which is a collection of German news articles consisting of 27,125 sentences; (3) the Prague Dependency Treebank (Hajic et al., 2006), which consists of 3168 news articles taken from the Czech National Corpus; (4) the NAIST Text Corpus (Iida et al., 2007b), which consists of 287 Japanese news articles; (5) the AnCora Corpus (Recasens and Mart, 2009), which consists of Spanish and Catalan journalist texts; and (6) the GENIA corpus (Ohta et al., 2002), which contains 2000 MEDLINE abstracts. Other publicly available coreference corpora of interest include two annotated by Ruslan Mitkovs researc</context>
</contexts>
<marker>Telljohann, Hinrichs, Kubler, 2004</marker>
<rawString>Heike Telljohann, Erhard Hinrichs, and Sandra Kubler. 2004. The tuba-d/z treebank: Annotating German with a context-free backbone. In Proceedings of the 4th International Conference on Language Resources and Evaluation, pages 22292235.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joel Tetreault</author>
</authors>
<title>Empirical Evaluations of Pronoun Resolution.</title>
<date>2005</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Rochester, USA.</institution>
<contexts>
<context position="33496" citStr="Tetreault (2005)" startWordPosition="5271" endWordPosition="5272">Riloff, 2004). Despite the large amount of work on discoursebased anaphora resolution in the 1970s and 1980s (see Hirst (1981)), learning-based resolvers have only exploited shallow discourse-based features, which primarily involve characterizing the salience of a candidate antecedent by measuring its distance from the anaphoric NP to be resolved or determining whether it is in a prominent grammatical role (e.g., subject). A notable exception 1402 \x0cis Iida et al. (2009), who train a ranker to rank the candidate antecedents for an anaphoric pronoun by their salience. It is worth noting that Tetreault (2005) has employed Grosz and Sidners (1986) discourse theory and Veins Theory (Ide and Cristea, 2000) to identify and remove candidate antecedents that are not referentially accessible to an anaphoric pronoun in his heuristic pronoun resolvers. It would be interesting to incorporate this idea into a learning-based resolver. There are also features that do not fall into any of the preceding categories. For example, a memorization feature is a word pair composed of the head nouns of the two NPs involved in an instance (Bengtson and Roth, 2008). Memorization features have been used as binary-valued fe</context>
</contexts>
<marker>Tetreault, 2005</marker>
<rawString>Joel Tetreault. 2005. Empirical Evaluations of Pronoun Resolution. Ph.D. thesis, University of Rochester, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Olga Uryupina</author>
</authors>
<title>High-precision identification of discourse new and unique noun phrases.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL Student Research Workshop,</booktitle>
<pages>8086</pages>
<contexts>
<context position="17773" citStr="Uryupina (2003)" startWordPosition="2768" endWordPosition="2769">.g., Evans (2001), Muller (2006), Versley et al. (2008a)), and distributional methods (e.g., Bergsma et al. (2008)); and non-anaphoric definite descriptions have been identified using rule-based techniques (e.g., Vieira and Poesio (2000)) and unsupervised techniques (e.g., Bean and Riloff (1999)). Recently, anaphoricity determination has been evaluated in the context of coreference resolution, with results showing that training an anaphoricity classifier to identify and filter non-anaphoric NPs prior to coreference resolution can improve a learning-based resolver (e.g., Ng and Cardie (2002b), Uryupina (2003), Poesio et al. (2004b)). Compared to earlier work on anaphoricity determination, recently proposed approaches are more global in nature, taking into account the pairwise decisions made by the mention-pair model when making anaphoricity decisions. Examples of such approaches have exploited techniques including integer linear programming (ILP) (Denis and Baldridge, 2007a), label propagation (Zhou and Kong, 2009), and minimum cuts (Ng, 2009). 3.1.5 Combining Classification &amp; Clustering From a learning perspective, a two-step approach to coreference classification and clustering is undesirable. S</context>
</contexts>
<marker>Uryupina, 2003</marker>
<rawString>Olga Uryupina. 2003. High-precision identification of discourse new and unique noun phrases. In Proceedings of the ACL Student Research Workshop, pages 8086.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Olga Uryupina</author>
</authors>
<title>Linguistically motivated sample selection for coreference resolution.</title>
<date>2004</date>
<booktitle>In Proceedings of the 5th Discourse Anaphora and Anaphor Resolution Colloquium.</booktitle>
<contexts>
<context position="10009" citStr="Uryupina (2004)" startWordPosition="1538" endWordPosition="1539">is modification is motivated by the observation that it is not easy for a human, let alone a machine learner, to learn from a positive instance where the antecedent of a non-pronominal NP is a pronoun. To further reduce class skewness, some researchers employ a filtering mechanism on top of an instance creation method, thereby disallowing the creation of training instances from NP pairs that are unlikely to be coreferent, such as NP pairs that violate gender and number agreement (e.g., Strube et al. (2002), Yang et al. (2003)). While many instance creation methods are heuristic in nature (see Uryupina (2004) and Hoste and Daelemans (2005)), some are learning-based. For example, motivated by the fact that some coreference relations are harder to identify than the others (see Harabagiu et al. (2001)), Ng and Cardie (2002a) present a method for mining easy positive instances, in an attempt to avoid the inclusion of hard training instances that may complicate the acquisition of an accurate coreference model. 3.1.2 Training a Coreference Classifier Once a training set is created, we can train a coreference model using an off-the-shelf learning algorithm. Decision tree induction systems (e.g., C5 (Quin</context>
</contexts>
<marker>Uryupina, 2004</marker>
<rawString>Olga Uryupina. 2004. Linguistically motivated sample selection for coreference resolution. In Proceedings of the 5th Discourse Anaphora and Anaphor Resolution Colloquium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kees van Deemter</author>
<author>Rodger Kibble</author>
</authors>
<title>On coreferring: Coreference in MUC and related annotation schemes.</title>
<date>2000</date>
<journal>Computational Linguistics,</journal>
<volume>26</volume>
<issue>4</issue>
<pages>637</pages>
<marker>van Deemter, Kibble, 2000</marker>
<rawString>Kees van Deemter and Rodger Kibble. 2000. On coreferring: Coreference in MUC and related annotation schemes. Computational Linguistics, 26(4):629 637.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yannick Versley</author>
<author>Alessandro Moschitti</author>
<author>Massimo Poesio</author>
<author>Xiaofeng Yang</author>
</authors>
<title>Coreference systems based on kernels methods.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics,</booktitle>
<pages>961968</pages>
<contexts>
<context position="17212" citStr="Versley et al. (2008" startWordPosition="2692" endWordPosition="2695">s attempt to resolve each NP encountered in a document, only a subset of the NPs are anaphoric and therefore need to be resolved. Hence, knowledge of the anaphoricity of an NP can potentially improve the precision of a coreference resolver. Traditionally, the task of anaphoricity determination has been tackled independently of coreference resolution using a variety of techniques. For example, pleonastic it has been identified using heuristic approaches (e.g., Paice and Husk (1987), Lappin and Leass (1994), Kennedy and Boguraev (1996)), supervised approaches (e.g., Evans (2001), Muller (2006), Versley et al. (2008a)), and distributional methods (e.g., Bergsma et al. (2008)); and non-anaphoric definite descriptions have been identified using rule-based techniques (e.g., Vieira and Poesio (2000)) and unsupervised techniques (e.g., Bean and Riloff (1999)). Recently, anaphoricity determination has been evaluated in the context of coreference resolution, with results showing that training an anaphoricity classifier to identify and filter non-anaphoric NPs prior to coreference resolution can improve a learning-based resolver (e.g., Ng and Cardie (2002b), Uryupina (2003), Poesio et al. (2004b)). Compared to e</context>
<context position="40780" citStr="Versley et al., 2008" startWordPosition="6433" endWordPosition="6437">approaches to the problem in the past fifteen years. To ensure further progress, researchers should compare their results against a baseline that is stronger than the commonly-used Soon et al. (2001) system, which relies on a weak model (i.e., the mention-pair model) and a small set of linguistic features. As recent systems are becoming more sophisticated, we suggest that researchers make their systems publicly available in order to facilitate performance comparisons. Publicly available coreference systems currently include JavaRAP (Qiu et al., 2004), GuiTaR (Poesio and Kabadjov, 2004), BART (Versley et al., 2008b), CoRTex (Denis and Baldridge, 2008), the Illinois Coreference Package (Bengtson and Roth, 2008), CherryPicker (Rahman and Ng, 2009), Reconcile (Stoyanov et al., 2010), and Charniak and Elsners (2009) pronoun resolver. We conclude with a discussion of two questions regarding supervised coreference research. First, what is the state of the art? This is not an easy question, as researchers have been evaluating their resolvers on different corpora using different evaluation metrics and preprocessing tools. In particular, preprocessing tools can have a large impact on the performance of a resolv</context>
</contexts>
<marker>Versley, Moschitti, Poesio, Yang, 2008</marker>
<rawString>Yannick Versley, Alessandro Moschitti, Massimo Poesio, and Xiaofeng Yang. 2008a. Coreference systems based on kernels methods. In Proceedings of the 22nd International Conference on Computational Linguistics, pages 961968.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yannick Versley</author>
<author>Simone Paolo Ponzetto</author>
<author>Massimo Poesio</author>
<author>Vladimir Eidelman</author>
<author>Alan Jern</author>
<author>Jason Smith</author>
</authors>
<title>Xiaofeng Yang, and Alessandro Moschitti.</title>
<date>2008</date>
<booktitle>In Proceedings of the ACL-08: HLT Demo Session,</booktitle>
<pages>912</pages>
<contexts>
<context position="17212" citStr="Versley et al. (2008" startWordPosition="2692" endWordPosition="2695">s attempt to resolve each NP encountered in a document, only a subset of the NPs are anaphoric and therefore need to be resolved. Hence, knowledge of the anaphoricity of an NP can potentially improve the precision of a coreference resolver. Traditionally, the task of anaphoricity determination has been tackled independently of coreference resolution using a variety of techniques. For example, pleonastic it has been identified using heuristic approaches (e.g., Paice and Husk (1987), Lappin and Leass (1994), Kennedy and Boguraev (1996)), supervised approaches (e.g., Evans (2001), Muller (2006), Versley et al. (2008a)), and distributional methods (e.g., Bergsma et al. (2008)); and non-anaphoric definite descriptions have been identified using rule-based techniques (e.g., Vieira and Poesio (2000)) and unsupervised techniques (e.g., Bean and Riloff (1999)). Recently, anaphoricity determination has been evaluated in the context of coreference resolution, with results showing that training an anaphoricity classifier to identify and filter non-anaphoric NPs prior to coreference resolution can improve a learning-based resolver (e.g., Ng and Cardie (2002b), Uryupina (2003), Poesio et al. (2004b)). Compared to e</context>
<context position="40780" citStr="Versley et al., 2008" startWordPosition="6433" endWordPosition="6437">approaches to the problem in the past fifteen years. To ensure further progress, researchers should compare their results against a baseline that is stronger than the commonly-used Soon et al. (2001) system, which relies on a weak model (i.e., the mention-pair model) and a small set of linguistic features. As recent systems are becoming more sophisticated, we suggest that researchers make their systems publicly available in order to facilitate performance comparisons. Publicly available coreference systems currently include JavaRAP (Qiu et al., 2004), GuiTaR (Poesio and Kabadjov, 2004), BART (Versley et al., 2008b), CoRTex (Denis and Baldridge, 2008), the Illinois Coreference Package (Bengtson and Roth, 2008), CherryPicker (Rahman and Ng, 2009), Reconcile (Stoyanov et al., 2010), and Charniak and Elsners (2009) pronoun resolver. We conclude with a discussion of two questions regarding supervised coreference research. First, what is the state of the art? This is not an easy question, as researchers have been evaluating their resolvers on different corpora using different evaluation metrics and preprocessing tools. In particular, preprocessing tools can have a large impact on the performance of a resolv</context>
</contexts>
<marker>Versley, Ponzetto, Poesio, Eidelman, Jern, Smith, 2008</marker>
<rawString>Yannick Versley, Simone Paolo Ponzetto, Massimo Poesio, Vladimir Eidelman, Alan Jern, Jason Smith, Xiaofeng Yang, and Alessandro Moschitti. 2008b. BART: A modular toolkit for coreference resolution. In Proceedings of the ACL-08: HLT Demo Session, pages 912.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yannick Versley</author>
</authors>
<title>A constraint-based approach to noun phrase coreference resolution in German newspaper text.</title>
<date>2006</date>
<booktitle>In Konferenz zur Verarbeitung Naturlicher Sprache.</booktitle>
<contexts>
<context position="26218" citStr="Versley, 2006" startWordPosition="4105" endWordPosition="4106">tes which of the two candidates is better. This model is referred to as the tournament model by Iida et al. (2003) and the twin-candidate model by Yang et al. (2003; 2008b). To resolve an NP during testing, one way is to apply the model to each pair of its candidate antecedents, and the candidate that is classified as better the largest number of times is selected as its antecedent. Advances in machine learning have made it possible to train a mention ranker that ranks all of the candidate antecedents simultaneously. While mention rankers have consistently outperformed the mention-pair model (Versley, 2006; Denis and Baldridge, 2007b), they are not more expressive than the mention-pair model, as they are unable to exploit cluster-level features, unlike the entitymention model. To enable rankers to employ cluster-level features, Rahman and Ng (2009) propose the cluster-ranking model, which ranks preceding clusters, rather than candidate antecedents, for an NP to be resolved. Cluster rankers therefore address both weaknesses of the mention-pair model, and have been shown to improve mention rankers. Cluster rankers are conceptually similar to Lappin and Leasss (1994) heuristic pronoun resolver, wh</context>
</contexts>
<marker>Versley, 2006</marker>
<rawString>Yannick Versley. 2006. A constraint-based approach to noun phrase coreference resolution in German newspaper text. In Konferenz zur Verarbeitung Naturlicher Sprache.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yannick Versley</author>
</authors>
<title>Antecedent selection techniques for high-recall coreference resolution.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>496505</pages>
<contexts>
<context position="30854" citStr="Versley, 2007" startWordPosition="4835" endWordPosition="4836">atures for coreference resolution. One of the earliest kinds of semantic knowledge employed for coreference resolution is perhaps selectional preference (Dagan and Itai, 1990; Kehler et al., 2004b; Yang et al., 2005; Haghighi and Klein, 2009): given a pronoun to be resolved, its governing verb, and its grammatical role, we prefer a candidate antecedent that can be governed by the same verb and be in the same role. Semantic knowledge has also been extracted from WordNet and unannotated corpora for computing the semantic compatibility/similarity between two common nouns (Harabagiu et al., 2001; Versley, 2007) as well as the semantic class of a noun (Ng, 2007a; Huang et al., 2009). One difficulty with deriving knowledge from WordNet is that one has to determine which sense of a given word to use. Some researchers simply use the first sense (Soon et al., 2001) or all possible senses (Ponzetto and Strube, 2006a), while others overcome this problem with word sense disambiguation (Nicolae and Nicolae, 2006). Knowledge has also been mined from Wikipedia for measuring the semantic relatedness of two NPs, NPj and NPk (Ponzetto and Strube (2006a; 2007)), such as: whether NPj/k appears in the first paragrap</context>
</contexts>
<marker>Versley, 2007</marker>
<rawString>Yannick Versley. 2007. Antecedent selection techniques for high-recall coreference resolution. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 496505.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Renata Vieira</author>
<author>Massimo Poesio</author>
</authors>
<title>Processing definite descriptions in corpora.</title>
<date>2000</date>
<booktitle>Corpus-based and Computational Approaches to Discourse Anaphora,</booktitle>
<pages>189212</pages>
<editor>In S. Botley and A. McEnery, editors,</editor>
<publisher>UCL Press.</publisher>
<contexts>
<context position="17395" citStr="Vieira and Poesio (2000)" startWordPosition="2715" endWordPosition="2718"> potentially improve the precision of a coreference resolver. Traditionally, the task of anaphoricity determination has been tackled independently of coreference resolution using a variety of techniques. For example, pleonastic it has been identified using heuristic approaches (e.g., Paice and Husk (1987), Lappin and Leass (1994), Kennedy and Boguraev (1996)), supervised approaches (e.g., Evans (2001), Muller (2006), Versley et al. (2008a)), and distributional methods (e.g., Bergsma et al. (2008)); and non-anaphoric definite descriptions have been identified using rule-based techniques (e.g., Vieira and Poesio (2000)) and unsupervised techniques (e.g., Bean and Riloff (1999)). Recently, anaphoricity determination has been evaluated in the context of coreference resolution, with results showing that training an anaphoricity classifier to identify and filter non-anaphoric NPs prior to coreference resolution can improve a learning-based resolver (e.g., Ng and Cardie (2002b), Uryupina (2003), Poesio et al. (2004b)). Compared to earlier work on anaphoricity determination, recently proposed approaches are more global in nature, taking into account the pairwise decisions made by the mention-pair model when makin</context>
</contexts>
<marker>Vieira, Poesio, 2000</marker>
<rawString>Renata Vieira and Massimo Poesio. 2000. Processing definite descriptions in corpora. In S. Botley and A. McEnery, editors, Corpus-based and Computational Approaches to Discourse Anaphora, pages 189212. UCL Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Vilain</author>
<author>John Burger</author>
<author>John Aberdeen</author>
<author>Dennis Connolly</author>
<author>Lynette Hirschman</author>
</authors>
<title>A modeltheoretic coreference scoring scheme.</title>
<date>1995</date>
<booktitle>In Proceedings of the Sixth Message Understanding Conference,</booktitle>
<pages>4552</pages>
<contexts>
<context position="37151" citStr="Vilain et al., 1995" startWordPosition="5865" endWordPosition="5868">2006). While researchers who evaluate their resolvers on gold NPs point out that the results can more accurately reflect the performance of their coreference algorithm, Stoyanov et al. (2009) argue that such evaluations are unrealistic, as NP extraction is an integral part of an end-to-end fully-automatic resolver. Whichever NP extraction method is employed, it is clear that the use of gold NPs can considerably simplify the coreference task, and hence resolvers employing different extraction methods should not be compared against each other. 5.2 Scoring a Coreference Partition The MUC scorer (Vilain et al., 1995) is the first program developed for scoring coreference partitions. It has two often-cited weaknesses. As a linkbased measure, it does not reward correctly identified singleton clusters since there is no coreference link in these clusters. Also, it tends to underpenalize partitions with overly large clusters. To address these problems, two coreference scoring programs have been developed: B3 (Bagga and Baldwin, 1998) and CEAF (Luo, 2005). Note that both scorers have only been defined for the case where the key partition has the same set of NPs as the response partition. To apply these scorers </context>
</contexts>
<marker>Vilain, Burger, Aberdeen, Connolly, Hirschman, 1995</marker>
<rawString>Marc Vilain, John Burger, John Aberdeen, Dennis Connolly, and Lynette Hirschman. 1995. A modeltheoretic coreference scoring scheme. In Proceedings of the Sixth Message Understanding Conference, pages 4552.</rawString>
</citation>
<citation valid="true">
<title>Centering Theory in Discourse.</title>
<date>1998</date>
<editor>Marilyn Walker, Aravind Joshi, and Ellen Prince, editors.</editor>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="1712" citStr="(1998)" startWordPosition="253" endWordPosition="253">etation) [see van Deemter and Kibble (2000) for a detailed discussion of the difference between the two tasks]. Despite its simple task definition, coreference is generally considered a difficult NLP task, typically involving the use of sophisticated knowledge sources and inference procedures (Charniak, 1972). Computational theories of discourse, in particular focusing (see Grosz (1977) and Sidner (1979)) and centering (Grosz et al. (1983; 1995)), have heavily influenced coreference research in the 1970s and 1980s, leading to the development of numerous centering algorithms (see Walker et al. (1998)). The focus of coreference research underwent a gradual shift from heuristic approaches to machine learning approaches in the 1990s. This shift can be attributed in part to the advent of the statistical NLP era, and in part to the public availability of annotated coreference corpora produced as part of the MUC-6 (1995) and MUC-7 (1998) conferences. Learning-based coreference research has remained vibrant since then, with results regularly published not only in general NLP conferences, but also in specialized conferences (e.g., the biennial Discourse Anaphora and Anaphor Resolution Colloquium </context>
<context position="25245" citStr="(1998)" startWordPosition="3938" endWordPosition="3938">he competition among them. Another desirable consequence is that there exists a natural resolution strategy for a ranking approach: an anaphoric NP is resolved to the candidate antecedent that has the highest rank. This contrasts with classification-based approaches, where many clustering algorithms have been employed to coordinate the pairwise classification decisions, and it is still not clear which of them is the best. The notion of ranking candidate antecedents can be traced back to centering algorithms, many of which use grammatical roles to rank forwardlooking centers (see Walker et al. (1998)). Ranking is first applied to learning-based coreference resolution by Connolly et al. (1994; 1997), where a model is trained to rank two candidate antecedents. Each training instance corresponds to the NP to be resolved, NPk, as well as two candidate antecedents, NPi and NPj, one of which is an antecedent of NPk and the other is not. Its class value indicates which of the two candidates is better. This model is referred to as the tournament model by Iida et al. (2003) and the twin-candidate model by Yang et al. (2003; 2008b). To resolve an NP during testing, one way is to apply the model to </context>
<context position="28363" citStr="(1998)" startWordPosition="4439" endWordPosition="4439">xact string match, substring match, and head noun match for different kinds of NPs (see Daume III and Marcu (2005)), slightly more sophisticated stringmatching facilities have been attempted, including minimum edit distance (Strube et al., 2002) and longest common subsequence (Castano et al., 2002). Yang et al. (2004a) treat the two NPs involved as two bags of words, and compute their similarity using metrics commonly-used in information retrieval, such as the dot product, with each word weighted by their TF-IDF value. Syntactic features are computed based on a syntactic parse tree. Ge et al. (1998) implement 1401 \x0ca Hobbs distance feature, which encodes the rank assigned to a candidate antecedent for a pronoun by Hobbss (1978) seminal syntax-based pronoun resolution algorithm. Luo and Zitouni (2005) extract features from a parse tree for implementing Binding Constraints (Chomsky, 1988). Given an automatically parsed corpus, Bergsma and Lin (2006) extract from each parse tree a dependency path, which is represented as a sequence of nodes and dependency labels connecting a pronoun and a candidate antecedent, and collect statistical information from these paths to determine the likeliho</context>
</contexts>
<marker>1998</marker>
<rawString>Marilyn Walker, Aravind Joshi, and Ellen Prince, editors. 1998. Centering Theory in Discourse. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Holger Wunsch</author>
</authors>
<title>Rule-based and Memory-based Pronoun Resolution for German: A Comparison and Assessment of Data Sources.</title>
<date>2010</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Tubingen,</institution>
<contexts>
<context position="39699" citStr="Wunsch (2010)" startWordPosition="6264" endWordPosition="6266">07; 2010), Poon and Domingos (2008)) rival their supervised counterparts, casting doubts on whether supervised resolvers are making effective use of the available labeled data. Another issue that we have not focused on but which is becoming increasingly important is multilinguality. While many of the techniques discussed in this paper were originally developed for English, they have been applied to learn coreference models for other languages, such as Chinese (e.g., Converse (2006)), Japanese (e.g., Iida (2007)), Arabic (e.g., Luo and Zitouni (2005)), Dutch (e.g., Hoste (2005)), German (e.g., Wunsch (2010)), Swedish (e.g., Nilsson (2010)), and Czech (e.g., Ngu .y et al. (2009)). In addition, researchers have developed approaches that are targeted at handling certain kinds of anaphora present in non-English languages, such as zero anaphora (e.g., Iida et al. (2007a), Zhao and Ng (2007)). As Mitkov (2001) puts it, coreference resolution is a difficult, but not intractable problem, and we have been making slow, but steady progress on improving machine learning approaches to the problem in the past fifteen years. To ensure further progress, researchers should compare their results against a baselin</context>
</contexts>
<marker>Wunsch, 2010</marker>
<rawString>Holger Wunsch. 2010. Rule-based and Memory-based Pronoun Resolution for German: A Comparison and Assessment of Data Sources. Ph.D. thesis, University of Tubingen, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaofeng Yang</author>
<author>Jian Su</author>
</authors>
<title>Coreference resolution using semantic relatedness information from automatically discovered patterns.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>528535</pages>
<contexts>
<context position="32826" citStr="Yang and Su, 2007" startWordPosition="5164" endWordPosition="5167">re coreferent), we can instantiate it with a pair of NPs and search for the instantiated pattern in a large corpus or the Web (Daume III and Marcu, 2005; Haghighi and Klein, 2009). The more frequently the pattern occurs, the more likely they are coreferent. This technique has been applied to resolve different kinds of anaphoric references, including other-anaphora (Modjeska et al., 2003; Markert and Nissim, 2005) and bridging references (Poesio et al., 2004a). While these patterns are typically hand-crafted (e.g., Garera and Yarowsky (2006)), they can also be learned from an annotated corpus (Yang and Su, 2007) or bootstrapped from an unannotated corpus (Bean and Riloff, 2004). Despite the large amount of work on discoursebased anaphora resolution in the 1970s and 1980s (see Hirst (1981)), learning-based resolvers have only exploited shallow discourse-based features, which primarily involve characterizing the salience of a candidate antecedent by measuring its distance from the anaphoric NP to be resolved or determining whether it is in a prominent grammatical role (e.g., subject). A notable exception 1402 \x0cis Iida et al. (2009), who train a ranker to rank the candidate antecedents for an anaphor</context>
</contexts>
<marker>Yang, Su, 2007</marker>
<rawString>Xiaofeng Yang and Jian Su. 2007. Coreference resolution using semantic relatedness information from automatically discovered patterns. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics, pages 528535.</rawString>
</citation>
<citation valid="true">
<authors>
<author>\x0cXiaofeng Yang</author>
<author>Guodong Zhou</author>
<author>Jian Su</author>
<author>Chew Lim Tan</author>
</authors>
<title>Coreference resolution using competitive learning approach.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>176183</pages>
<contexts>
<context position="9925" citStr="Yang et al. (2003)" startWordPosition="1524" endWordPosition="1527">ld be formed between NPk and its closest preceding nonpronominal antecedent instead. This modification is motivated by the observation that it is not easy for a human, let alone a machine learner, to learn from a positive instance where the antecedent of a non-pronominal NP is a pronoun. To further reduce class skewness, some researchers employ a filtering mechanism on top of an instance creation method, thereby disallowing the creation of training instances from NP pairs that are unlikely to be coreferent, such as NP pairs that violate gender and number agreement (e.g., Strube et al. (2002), Yang et al. (2003)). While many instance creation methods are heuristic in nature (see Uryupina (2004) and Hoste and Daelemans (2005)), some are learning-based. For example, motivated by the fact that some coreference relations are harder to identify than the others (see Harabagiu et al. (2001)), Ng and Cardie (2002a) present a method for mining easy positive instances, in an attempt to avoid the inclusion of hard training instances that may complicate the acquisition of an accurate coreference model. 3.1.2 Training a Coreference Classifier Once a training set is created, we can train a coreference model using </context>
<context position="25769" citStr="Yang et al. (2003" startWordPosition="4030" endWordPosition="4033"> many of which use grammatical roles to rank forwardlooking centers (see Walker et al. (1998)). Ranking is first applied to learning-based coreference resolution by Connolly et al. (1994; 1997), where a model is trained to rank two candidate antecedents. Each training instance corresponds to the NP to be resolved, NPk, as well as two candidate antecedents, NPi and NPj, one of which is an antecedent of NPk and the other is not. Its class value indicates which of the two candidates is better. This model is referred to as the tournament model by Iida et al. (2003) and the twin-candidate model by Yang et al. (2003; 2008b). To resolve an NP during testing, one way is to apply the model to each pair of its candidate antecedents, and the candidate that is classified as better the largest number of times is selected as its antecedent. Advances in machine learning have made it possible to train a mention ranker that ranks all of the candidate antecedents simultaneously. While mention rankers have consistently outperformed the mention-pair model (Versley, 2006; Denis and Baldridge, 2007b), they are not more expressive than the mention-pair model, as they are unable to exploit cluster-level features, unlike t</context>
<context position="41734" citStr="Yang et al. (2003)" startWordPosition="6580" endWordPosition="6583">of the art? This is not an easy question, as researchers have been evaluating their resolvers on different corpora using different evaluation metrics and preprocessing tools. In particular, preprocessing tools can have a large impact on the performance of a resolver (Barbu and Mitkov, 2001). Worse still, assumptions about whether gold or automatically extracted NPs are used are sometimes not explicitly stated, potentially causing results to be interpreted incorrectly. To our knowledge, however, the best results on the MUC-6 and MUC-7 data sets using automatically extracted NPs are reported by Yang et al. (2003) (71.3 MUC F-score) and Ng and Cardie (2002c) (63.4 MUC F-score), respectively;8 and the best results on the ACE data sets using gold NPs can be found in Luo (2007) (88.4 ACE-value). Second, what lessons can we learn from fifteen years of learning-based coreference research? The mention-pair model is weak because it makes coreference decisions based on local information (i.e., information extracted from two NPs). Expressive models (e.g., those that can exploit cluster-level features) generally offer better performance, and so are models that are global in nature. Global coreference models may </context>
</contexts>
<marker>Yang, Zhou, Su, Tan, 2003</marker>
<rawString>\x0cXiaofeng Yang, Guodong Zhou, Jian Su, and Chew Lim Tan. 2003. Coreference resolution using competitive learning approach. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics, pages 176183.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaofeng Yang</author>
<author>Jian Su</author>
<author>Chew Lim Tan</author>
</authors>
<date>2004</date>
<contexts>
<context position="23171" citStr="Yang et al. (2004" startWordPosition="3618" endWordPosition="3621">uch as MOST, which is true if NPk agrees in number with more than half of the NPs in Cj, and ANY, which is true as long as NPk agrees in number with just one of the NPs in Cj. The ability of the entity-mention model to employ cluster-level features makes it more expressive than its mention-pair counterpart. Despite its improved expressiveness, the entitymention model has not yielded particularly encouraging results. For example, Luo et al. (2004) apply the ANY predicate to generate cluster-level features for their entity-mention model, which does not perform as well as the mention-pair model. Yang et al. (2004b; 2008a) also investigate the entity-mention model, which produces results that are only marginally better than those of the mention-pair model. However, it appears that they are not fully exploiting the expressiveness of the entity-mention model, as cluster-level features only comprise a small fraction of their features. Variants of the entity-mention model have been investigated. For example, Culotta et al. (2007) present a first-order logic model that determines 1400 \x0cthe probability that an arbitrary set of NPs are all co-referring. Their model resembles the entitymention model in that</context>
<context position="28075" citStr="Yang et al. (2004" startWordPosition="4387" endWordPosition="4390">ervised coreference research concerns the development of linguistic features. Below we give an overview of these features. String-matching features can be computed robustly and typically contribute a lot to the performance of a coreference system. Besides simple string-matching operations such as exact string match, substring match, and head noun match for different kinds of NPs (see Daume III and Marcu (2005)), slightly more sophisticated stringmatching facilities have been attempted, including minimum edit distance (Strube et al., 2002) and longest common subsequence (Castano et al., 2002). Yang et al. (2004a) treat the two NPs involved as two bags of words, and compute their similarity using metrics commonly-used in information retrieval, such as the dot product, with each word weighted by their TF-IDF value. Syntactic features are computed based on a syntactic parse tree. Ge et al. (1998) implement 1401 \x0ca Hobbs distance feature, which encodes the rank assigned to a candidate antecedent for a pronoun by Hobbss (1978) seminal syntax-based pronoun resolution algorithm. Luo and Zitouni (2005) extract features from a parse tree for implementing Binding Constraints (Chomsky, 1988). Given an autom</context>
</contexts>
<marker>Yang, Su, Tan, 2004</marker>
<rawString>Xiaofeng Yang, Jian Su, and Chew Lim Tan. 2004a.</rawString>
</citation>
<citation valid="false">
<title>Improving noun phrase coreference resolution by matching strings.</title>
<booktitle>In Proceedings of the First International Joint Conference on Natural Language Processing,</booktitle>
<pages>2231</pages>
<marker></marker>
<rawString>Improving noun phrase coreference resolution by matching strings. In Proceedings of the First International Joint Conference on Natural Language Processing, pages 2231.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaofeng Yang</author>
<author>Jian Su</author>
<author>GuoDong Zhou</author>
<author>Chew Lim Tan</author>
</authors>
<title>An NP-cluster based approach to coreference resolution.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th International Conference on Computational Linguistics,</booktitle>
<pages>226232</pages>
<contexts>
<context position="23171" citStr="Yang et al. (2004" startWordPosition="3618" endWordPosition="3621">uch as MOST, which is true if NPk agrees in number with more than half of the NPs in Cj, and ANY, which is true as long as NPk agrees in number with just one of the NPs in Cj. The ability of the entity-mention model to employ cluster-level features makes it more expressive than its mention-pair counterpart. Despite its improved expressiveness, the entitymention model has not yielded particularly encouraging results. For example, Luo et al. (2004) apply the ANY predicate to generate cluster-level features for their entity-mention model, which does not perform as well as the mention-pair model. Yang et al. (2004b; 2008a) also investigate the entity-mention model, which produces results that are only marginally better than those of the mention-pair model. However, it appears that they are not fully exploiting the expressiveness of the entity-mention model, as cluster-level features only comprise a small fraction of their features. Variants of the entity-mention model have been investigated. For example, Culotta et al. (2007) present a first-order logic model that determines 1400 \x0cthe probability that an arbitrary set of NPs are all co-referring. Their model resembles the entitymention model in that</context>
<context position="28075" citStr="Yang et al. (2004" startWordPosition="4387" endWordPosition="4390">ervised coreference research concerns the development of linguistic features. Below we give an overview of these features. String-matching features can be computed robustly and typically contribute a lot to the performance of a coreference system. Besides simple string-matching operations such as exact string match, substring match, and head noun match for different kinds of NPs (see Daume III and Marcu (2005)), slightly more sophisticated stringmatching facilities have been attempted, including minimum edit distance (Strube et al., 2002) and longest common subsequence (Castano et al., 2002). Yang et al. (2004a) treat the two NPs involved as two bags of words, and compute their similarity using metrics commonly-used in information retrieval, such as the dot product, with each word weighted by their TF-IDF value. Syntactic features are computed based on a syntactic parse tree. Ge et al. (1998) implement 1401 \x0ca Hobbs distance feature, which encodes the rank assigned to a candidate antecedent for a pronoun by Hobbss (1978) seminal syntax-based pronoun resolution algorithm. Luo and Zitouni (2005) extract features from a parse tree for implementing Binding Constraints (Chomsky, 1988). Given an autom</context>
</contexts>
<marker>Yang, Su, Zhou, Tan, 2004</marker>
<rawString>Xiaofeng Yang, Jian Su, GuoDong Zhou, and Chew Lim Tan. 2004b. An NP-cluster based approach to coreference resolution. In Proceedings of the 20th International Conference on Computational Linguistics, pages 226232.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaofeng Yang</author>
<author>Jian Su</author>
<author>Chew Lim Tan</author>
</authors>
<title>Improving pronoun resolution using statistics-based semantic compatibility information.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>165172</pages>
<contexts>
<context position="30455" citStr="Yang et al., 2005" startWordPosition="4771" endWordPosition="4774">ree in number and gender and cannot span one another (e.g., Google and Google employees). There are also features that encode general linguistic preferences either for or against coreference. For example, an indefinite NP (that is not in apposition to an anaphoric NP) is not likely to be coreferent with any NP that precedes it. There has been an increasing amount of work on investigating semantic features for coreference resolution. One of the earliest kinds of semantic knowledge employed for coreference resolution is perhaps selectional preference (Dagan and Itai, 1990; Kehler et al., 2004b; Yang et al., 2005; Haghighi and Klein, 2009): given a pronoun to be resolved, its governing verb, and its grammatical role, we prefer a candidate antecedent that can be governed by the same verb and be in the same role. Semantic knowledge has also been extracted from WordNet and unannotated corpora for computing the semantic compatibility/similarity between two common nouns (Harabagiu et al., 2001; Versley, 2007) as well as the semantic class of a noun (Ng, 2007a; Huang et al., 2009). One difficulty with deriving knowledge from WordNet is that one has to determine which sense of a given word to use. Some resea</context>
</contexts>
<marker>Yang, Su, Tan, 2005</marker>
<rawString>Xiaofeng Yang, Jian Su, and Chew Lim Tan. 2005. Improving pronoun resolution using statistics-based semantic compatibility information. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics, pages 165172.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaofeng Yang</author>
<author>Jian Su</author>
<author>Chew Lim Tan</author>
</authors>
<title>Kernel based pronoun resolution with structured syntactic knowledge.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>4148</pages>
<contexts>
<context position="29139" citStr="Yang et al. (2006)" startWordPosition="4558" endWordPosition="4561">onoun resolution algorithm. Luo and Zitouni (2005) extract features from a parse tree for implementing Binding Constraints (Chomsky, 1988). Given an automatically parsed corpus, Bergsma and Lin (2006) extract from each parse tree a dependency path, which is represented as a sequence of nodes and dependency labels connecting a pronoun and a candidate antecedent, and collect statistical information from these paths to determine the likelihood that a pronoun and a candidate antecedent connected by a given path are coreferent. Rather than deriving features from parse trees, Iida et al. (2006) and Yang et al. (2006) employ these trees directly as structured features for pronoun resolution. Specifically, Yang et al. define tree kernels for efficiently computing the similarity between two parse trees, and Iida et al. use a boosting-based algorithm to compute the usefulness of a subtree. Grammatical features encode the grammatical properties of one or both NPs involved in an instance. For example, Ng and Cardies (2002c) resolver employs 34 grammatical features. Some features determine NP type (e.g., are both NPs definite or pronouns?). Some determine the grammatical role of one or both of the NPs. Some enco</context>
</contexts>
<marker>Yang, Su, Tan, 2006</marker>
<rawString>Xiaofeng Yang, Jian Su, and Chew Lim Tan. 2006. Kernel based pronoun resolution with structured syntactic knowledge. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics, pages 4148.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaofeng Yang</author>
<author>Jian Su</author>
<author>Jun Lang</author>
<author>Chew Lim Tan</author>
<author>Sheng Li</author>
</authors>
<title>An entity-mention model for coreference resolution with inductive logic programming.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<pages>843851</pages>
<marker>Yang, Su, Lang, Tan, Li, 2008</marker>
<rawString>Xiaofeng Yang, Jian Su, Jun Lang, Chew Lim Tan, and Sheng Li. 2008a. An entity-mention model for coreference resolution with inductive logic programming. In Proceedings of ACL-08: HLT, pages 843851.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaofeng Yang</author>
<author>Jian Su</author>
<author>Chew Lim Tan</author>
</authors>
<title>A twin-candidate model for learning-based anaphora resolution.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>3</issue>
<pages>356</pages>
<marker>Yang, Su, Tan, 2008</marker>
<rawString>Xiaofeng Yang, Jian Su, and Chew Lim Tan. 2008b. A twin-candidate model for learning-based anaphora resolution. Computational Linguistics, 34(3):327 356.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dmitry Zelenko</author>
<author>Chinatsu Aone</author>
<author>Jason Tibbetts</author>
</authors>
<title>Coreference resolution for information extraction.</title>
<date>2004</date>
<booktitle>In Proceedings of the ACL Workshop on Reference Resolution and its Applications,</booktitle>
<pages>9--16</pages>
<contexts>
<context position="13433" citStr="Zelenko et al. (2004)" startWordPosition="2076" endWordPosition="2079">positive pairwise decisions are unjustifiably favored over their negative counterparts. For example, three NPs are likely to end up in the same cluster in the resulting partition even if there is strong evidence that A and C are not coreferent, as long as the other two pairs (i.e., (A,B) and (B,C)) are classified as positive. Several algorithms that address one or both of these problems have been used for coreference clustering. Correlation clustering (Bansal et al., 2002), which produces a partition that respects as many pairwise decisions as possible, is used by McCallum and Wellner (2004), Zelenko et al. (2004), and Finley and Joachims (2005). Graph partitioning algorithms are applied on a weighted, undirected graph where a vertex corresponds to an NP and an edge is weighted by the pairwise coreference scores between two NPs (e.g., McCallum and Wellner (2004), Nicolae and Nico4 If a probabilistic model is used, we can define a threshold above which a pair of NPs is considered coreferent. 1398 \x0clae (2006)). The Dempster-Shafer rule (Dempster, 1968), which combines the positive and negative pairwise decisions to score a partition, is used by Kehler (1997) and Bean and Riloff (2004) to identify the </context>
</contexts>
<marker>Zelenko, Aone, Tibbetts, 2004</marker>
<rawString>Dmitry Zelenko, Chinatsu Aone, and Jason Tibbetts. 2004. Coreference resolution for information extraction. In Proceedings of the ACL Workshop on Reference Resolution and its Applications, pages 9 16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shanheng Zhao</author>
<author>Hwee Tou Ng</author>
</authors>
<title>Identification and resolution of Chinese zero pronouns: A machine learning approach.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods on Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>541550</pages>
<contexts>
<context position="39983" citStr="Zhao and Ng (2007)" startWordPosition="6309" endWordPosition="6312">ity. While many of the techniques discussed in this paper were originally developed for English, they have been applied to learn coreference models for other languages, such as Chinese (e.g., Converse (2006)), Japanese (e.g., Iida (2007)), Arabic (e.g., Luo and Zitouni (2005)), Dutch (e.g., Hoste (2005)), German (e.g., Wunsch (2010)), Swedish (e.g., Nilsson (2010)), and Czech (e.g., Ngu .y et al. (2009)). In addition, researchers have developed approaches that are targeted at handling certain kinds of anaphora present in non-English languages, such as zero anaphora (e.g., Iida et al. (2007a), Zhao and Ng (2007)). As Mitkov (2001) puts it, coreference resolution is a difficult, but not intractable problem, and we have been making slow, but steady progress on improving machine learning approaches to the problem in the past fifteen years. To ensure further progress, researchers should compare their results against a baseline that is stronger than the commonly-used Soon et al. (2001) system, which relies on a weak model (i.e., the mention-pair model) and a small set of linguistic features. As recent systems are becoming more sophisticated, we suggest that researchers make their systems publicly availabl</context>
</contexts>
<marker>Zhao, Ng, 2007</marker>
<rawString>Shanheng Zhao and Hwee Tou Ng. 2007. Identification and resolution of Chinese zero pronouns: A machine learning approach. In Proceedings of the 2007 Joint Conference on Empirical Methods on Natural Language Processing and Computational Natural Language Learning, pages 541550.</rawString>
</citation>
<citation valid="true">
<authors>
<author>GuoDong Zhou</author>
<author>Fang Kong</author>
</authors>
<title>Global learning of noun phrase anaphoricity in coreference resolution via label propagation.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>978986--0</pages>
<contexts>
<context position="18187" citStr="Zhou and Kong, 2009" startWordPosition="2825" endWordPosition="2828"> showing that training an anaphoricity classifier to identify and filter non-anaphoric NPs prior to coreference resolution can improve a learning-based resolver (e.g., Ng and Cardie (2002b), Uryupina (2003), Poesio et al. (2004b)). Compared to earlier work on anaphoricity determination, recently proposed approaches are more global in nature, taking into account the pairwise decisions made by the mention-pair model when making anaphoricity decisions. Examples of such approaches have exploited techniques including integer linear programming (ILP) (Denis and Baldridge, 2007a), label propagation (Zhou and Kong, 2009), and minimum cuts (Ng, 2009). 3.1.5 Combining Classification &amp; Clustering From a learning perspective, a two-step approach to coreference classification and clustering is undesirable. Since the classification model is trained independently of the clustering algorithm, improvements in classification accuracy do not guarantee corresponding improvements in clustering-level accuracy. That is, overall performance on the coreference task might not improve. To address this problem, McCallum and Wellner (2004) and Finley and Joachims (2005) eliminate the classification step entirely, treating coref13</context>
</contexts>
<marker>Zhou, Kong, 2009</marker>
<rawString>GuoDong Zhou and Fang Kong. 2009. Global learning of noun phrase anaphoricity in coreference resolution via label propagation. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 978986. \x0c&apos;</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>