ments 4.1 Settings We conducted experiments using the following \x0cve statistical parsers: Table 1: The total / 11-point accuracy achieved by each individual model total 11-point A 0.8974 0.9607 B 0.8551 0.9281 C 0.8586 0.9291 D 0.8470 0.9266 E 0.7885 0.8567 \x0f KANA CITATION: a bottom-up model based on maximum entropy estimation,,
\x0f Shirai\&apos;s parser CITATION: a topdown model incorporating lexical collocation statistics,,
\x0f CHAGAKE (Fujio et al., 1998): an extension of the bottom-up model proposed by Collins CITATION,,
2.2 Estimation of DPs Some of the state-of-the-art probabilistic language models such as the bottomup models P(Rjs) proposed by CITATION and Fujio et al,,
\x0f Kanayama\&apos;s parser CITATION: a bottom-up model coupled with an HPSG,,
\x0f Peach Pie Parser CITATION: a bottom-up model based on maximum entropy estimation,,
Note that, while we restrict our discussion to analysis of Japanese sentences in this paper, what we present below should also be straightforwardly applicable to more wideranged tasks such as English dependency analysis just like the problem setting considered by CITATION,,
CITATION directly estimate DPs for a given input, whereas othe,,
