<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.2466765">
b&apos;Proceedings of the IJCNLP-08 Workshop on NER for South and South East Asian Languages, pages 97104,
Hyderabad, India, January 2008. c
</note>
<title confidence="0.6442515">
2008 Asian Federation of Natural Language Processing
Named Entity Recognition for Indian Languages
</title>
<author confidence="0.508463">
Animesh Nayan, B. Ravi Kiran Rao, Pawandeep Singh,
</author>
<figure confidence="0.23153675">
Sudip Sanyal and Ratna Sanyal
Indian Institute of Information Technology
Allahabad, India
e-mail@domain
</figure>
<sectionHeader confidence="0.917747" genericHeader="abstract">
Abstract
Abstract Stub This paper talks about a new
</sectionHeader>
<bodyText confidence="0.998636777777778">
approach to recognize named entities for
Indian languages. Phonetic matching tech-
nique is used to match the strings of differ-
ent languages on the basis of their similar
sounding property. We have tested our sys-
tem with a comparable corpus of English
and Hindi language data. This approach is
language independent and requires only a
set of rules appropriate for a language.
</bodyText>
<sectionHeader confidence="0.996918" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997522929824561">
Named Entity Recognition (NER) is a subtask of
machine translation and information retrieval.
Named entities are words which belong to certain
categories like persons, places, organizations, nu-
merical quantities, expressions of times etc. A
large number of techniques have been developed to
recognize named entities for different languages.
Some of them are Rule based and others are Statis-
tical techniques. The rule based approach uses the
morphological and contextual evidence (Kim and
Woodland, 2000) of a natural language and conse-
quently determines the named entities. This even-
tually leads to formation of some language specific
rules for identifying named entities. The statistical
techniques use large annotated data to train a
model (Malouf, 2002) (like Hidden Markov
Model) and subsequently examine it with the test
data. Both the methods mentioned above require
the efforts of a language expert. An appropriately
large set of annotated data is yet to be made avail-
able for the Indian Languages. Consequently, the
application of the statistical technique for Indian
Languages is not very feasible.
This paper deals with a new technique to recog-
nize named entities of different languages. Our
approach does not use the previously mentioned
techniques. Instead, we use an approach that not
only reduces the burden of collecting and annotat-
ing data, but is language independent as well. We
use this method to build a multilingual named en-
tity list that can be used by the named entity recog-
nizer. Our method recognizes and finds the actual
representation of the named entities in the target
language from an untagged corpus. Our idea was
to match the two representations of the same
named entity in two different languages using a
phonetic matching algorithm. This comes from the
property of named entities that they sound similar
when written in native script or any other script.
However this cross-lingual matching is not a trivial
task. First of all, the two strings to be matched
have to be represented in a common script. So we
face two choices here. Either we should convert
the two strings into some common intermediate
representation (ex. Phonemic representation) or
transliterate the name written in Indian language to
English and then look for phonetic equivalence.
Our engine has been tested for Hindi. After making
transliteration rules for Hindi, we used a variation
of the Editex algorithm to match the transliterated
string with entries in English named entity data-
base to find a match. Here it is worthwhile to men-
tion that certain class of name entities which are
not similar sounding (mostly phrases) cannot be
extracted through this cross-lingual matching. E.g.
United Nations, Government of India etc. Ab-
breviations which are spelled character by charac-
</bodyText>
<page confidence="0.995472">
97
</page>
<bodyText confidence="0.995129285714286">
\x0cter in both the languages can however be extracted.
E.g. BBC ( ), LTTE ( ) etc.
In the next section we have given the system ar-
chitecture. The logical flow and overall description
of the system are discussed here. Our own set of
transliteration rules in Hindi are given in the third
section. In the fourth section we define our base-
line task. Our system has been tested with a paral-
lel corpus which consisted of both English and
Hindi language data. The results obtained using
our system is described in the fifth section together
with an analysis. Conclusions are presented in the
last section together with directions for future im-
provements.
</bodyText>
<sectionHeader confidence="0.843772" genericHeader="method">
2 System Architecture: Logical Flow and
</sectionHeader>
<bodyText confidence="0.984977333333333">
overall description of the System
The system architecture is shown in Figure 1. It
consists of the following modules:
</bodyText>
<figureCaption confidence="0.992999">
Figure 1: System Architecture
</figureCaption>
<subsectionHeader confidence="0.950974">
2.1 Crawler
</subsectionHeader>
<bodyText confidence="0.998425411764706">
The crawler is a web-bot or spider which browses
the web in an automated manner. It starts with a
list of Uniform Resource Locators (URL) that it is
to visit, called the seeds. As the crawler visits these
URLs it collects all the hyperlinks and adds them
to a queue. URLs from the queue are crawled fur-
ther. Since the crawler collects the data from web,
the data collection is fully automated. The crawler
gathers data for both English and other Indian lan-
guages. The data collected for English is used to
populate the English named entity database which
is significantly accurate. We have used the freely
available Stanford Named Entity Recognizer
(Finkel, Grenager, and Manning, 2005) in our en-
gine. The data collected for Indian languages will
be used to build a database of named entities for
the given language.
</bodyText>
<subsectionHeader confidence="0.997799">
2.2 Parser
</subsectionHeader>
<bodyText confidence="0.998786">
The crawler saves the content in an html form
onto the system. The parser parses these html files.
Additionally the parser can also parse the PDF as
well as RTF files. The output of the parser is
passed to the corresponding modules for the two
different languages.
</bodyText>
<subsectionHeader confidence="0.999176">
2.3 Phonetic Matcher
</subsectionHeader>
<bodyText confidence="0.998018571428571">
Phonetic matching is the task of matching two rep-
resentations of the same name. A name may have
more than one representation in its native script
itself. If the name is represented in a script other
than its native script, there may be large number of
potential variants for its representation. Phonetic
matching is a fuzzy string matching technique in
which we match strings on the basis of their simi-
lar sounding property and not identity. Most com-
mon phonetic matching techniques are Soundex
and Editex. These techniques are used to match
two representations of the same name in English.
We survey the techniques in the following subsec-
tions.
</bodyText>
<subsubsectionHeader confidence="0.896339">
2.3.1 Soundex
</subsubsectionHeader>
<bodyText confidence="0.939635857142857">
Soundex algorithm was designed by Odell and
Russell in 1918 to find spelling variation of names.
It represents classes of sounds which can be
lumped together. The classes for the algorithm are
shown in Appendix A. These classes are placed for
phonetic matching according to the following algo-
rithm:
</bodyText>
<listItem confidence="0.985962">
1. Replace all but the first letter of the string
by its phonetic code.
2. Eliminate any adjacent representation of
codes.
3. Eliminate all occurrences of code 0 i.e.
eliminate all vowels.
4. Return the first four characters of the re-
sulting string.
5. Examples: Dickson = d25, Dikson = d25.
Two names match if they have the same soun-
dex representation. This method does not account
</listItem>
<page confidence="0.992056">
98
</page>
<bodyText confidence="0.654352">
\x0cfor vowels and hence is not accurate for cross-
lingual matching.
</bodyText>
<subsubsectionHeader confidence="0.79701">
2.3.2 Editex
</subsubsectionHeader>
<bodyText confidence="0.986212731707317">
The Editex algorithm was designed by Zobel and
Dart (Zobel and Dart,1996). It is an enhancement
of the Levenshtein (Levenshtein, 1966) edit dis-
tance algorithm. The Levenshtein algorithm meas-
ures the edit distance between two strings where
edit distance is defined as the minimum number of
basic operations required to match one string to the
other where the basic operations are insertion, de-
letion and substitution. Insertion and deletion costs
are 1 and substitution cost is given by a function
subst_cost (Xi, Yj) which returns 0 if the two char-
acters Xi and Yj are same and 1, if they are differ-
ent. The score dist [m, n] is returned as the edit
distance between two strings. A score of zero im-
plies a perfect match.
The algorithm has O (mn) time and space com-
plexity where m and n are the lengths of the two
strings respectively. The pseudo code for the
Levenshtein edit distance algorithm is described in
Appendix B. Editex groups similar sounding pho-
nemes into equivalence classes. The substitution
cost is determined by a function S (Xi, Yj) that
returns 0 if the two characters Xi and Yj are same,
1 if they lie in the same equivalence class and 2
otherwise. The insertion and substitution costs are
determined by a function D (Xi-1, Xi) which is
almost same as S (Xi, Yj) except for the difference
that it compares letters of the same string and it
returns 1 if Xi-1 is h or w and Xi-1 is not equal
to Xi. The editex equivalence classes and the ed-
itex pseudo-code are given in Appendix C.
Editex performs fairly better than Soundex and
Leveinshtein edit distance algorithms. However
further enhancements in Editex are also possible.
Tapering is one enhancement in which we weigh
mismatches at the beginning of the string with
higher score than mismatches towards the end
(Zobel and Dart, 1996). Other enhancements are
those in which input strings are mapped to their
phonemic representation, called phonometric
methods (Zobel and Dart, 1996).
</bodyText>
<sectionHeader confidence="0.966316" genericHeader="method">
3 Transliteration rules
</sectionHeader>
<bodyText confidence="0.997822714285714">
To perform phonetic matching of two different
representations of a named entity, we need both of
them in a common script. We choose to transliter-
ate the named entity in Indian language to English.
The transliteration rules for a language must be
written for the same. We have written our own set
of transliteration rules for Hindi. These can be de-
scribed briefly as under
The entity to be transliterated is scanned character by
character from left to right. Each character of Hindi is
mapped to an equivalent character/set of character in
English according to a mapping function. The charac-
ter set generated by the function is appended into a
string as per the rules. E.g. = + is a single
</bodyText>
<listItem confidence="0.846650857142857">
character representation in Unicode () and maps to
Ka.
1. Start with an empty string. When a conso-
nant or singleton vowel (not as matra) is
encountered append the set of characters
returned by mapping function.
2. When a consonant is followed by a vowel
</listItem>
<bodyText confidence="0.888934625">
the preceding a should be removed and
the character set for the vowel should be
appended. E.g.
consists of two charac-
ters + . Once we encounter we
append ka and when is encountered
next we remove the a and append the
mapping for i.e. e. This rule applies in
</bodyText>
<listItem confidence="0.681399666666667">
general to all the vowels.
3. If the transliterated string has a as its last
character while it doesnt have the vowel
</listItem>
<bodyText confidence="0.966642941176471">
as last character of Hindi string, re-
move this occurrence of a. The last
vowel in Hindi is very important as two al-
together different words may have the only
difference in the last vowel. E.g.
and are proper nouns having dif-
ferent genders. Their English representa-
tions are Kamal and Kamla respec-
tively.
The transliteration always performs a one to one
mapping of a character in Hindi to a set of charac-
ters in English. However the English representa-
tion may have different character sets for the same
Hindi character in different names. E.g. is
Kamal while
is Cricket. is often
represented by K for Hindi names, by C for
</bodyText>
<page confidence="0.991133">
99
</page>
<bodyText confidence="0.983636333333333">
\x0cEnglish names and by Q for Urdu names. The
Editex algorithm groups these letters in the same
equivalence class.
</bodyText>
<sectionHeader confidence="0.994724" genericHeader="method">
4 Baseline Task
</sectionHeader>
<bodyText confidence="0.999294333333333">
At the core of our method lies the phonetic match-
ing algorithm. We have modified the Editex algo-
rithm as mentioned in Appendix C. Editex can be
modified to take into account that there can be
more than three (0, 1, 2) levels of acceptability for
substitutions due to the inherent properties of par-
ticular languages. For example, say ckq is one
equivalence class in Editex. c and k have a sub-
stitution cost of 1. We may reduce this substitution
cost to 0.5 for a language in which it is highly
probable that the same character maps to c and
k in the English representation of its names.
Thus the equivalence classes and the substitution
costs in Editex can be modified for cross-lingual
phonetic matching. There can also be further lan-
guage specific enhancements. The following algo-
rithm along with some language specific enhance-
ments was implemented for Hindi.
</bodyText>
<subsectionHeader confidence="0.999603">
4.1 Abbreviation Check
</subsectionHeader>
<bodyText confidence="0.999181166666667">
Abbreviations form an important class of named
entities. So, we first check whether the Hindi string
is an abbreviation in which the English characters
are spelled individually. For each English alphabet
we have some unique Hindi representation. The
function performs accurately most of the time and
extracts such named entities. If we are able to find
out that the string is an abbreviation, the corre-
sponding English representation can be returned by
the function itself, hence there is no need of further
matching. If the string is not an abbreviation, we
proceed to the actual matching algorithm.
</bodyText>
<subsectionHeader confidence="0.665687">
4.2 4.2. First letter matching
</subsectionHeader>
<bodyText confidence="0.998731">
The first letters of the two strings must either be
the same or should belong to the same equivalence
class. The equivalence classes for first character
matching are:
&quot;ckq&quot;, &quot;wbv&quot;, &quot;iy,&quot;jz&quot;, &quot;aeiou&quot;
The English named entity database must be in-
dexed according to the first letter of the named en-
tity so that we only search for matches in those
indexes which fall into the same equivalence class.
This is very important for the computational effi-
ciency of the engine as it reduces the search space.
</bodyText>
<subsectionHeader confidence="0.999549">
4.3 Preprocessing
</subsectionHeader>
<bodyText confidence="0.965051470588235">
Often the phonetic inconsistencies in English lead
to low matching score for two representation of the
same name. To take this into account, before
matching the two strings the named entity retrieved
from English Named entity database is preproc-
essed to form a new string. We have used the fa-
mous Mark Twains plan for the improvement of
English spelling (http://grammar.ccc.commnet.edu/
grammar/twain.htm) added with some more rules.
This way we tackle the problem of more than one
possible character sets for some vowels since only
one of them can be chosen during transliteration.
We also tackle some other problems like silent-
alphabets and repeated alphabets so that the prob-
ability of generating high matching score in-
creases. The following set of rules for preprocess-
ing was used.
</bodyText>
<listItem confidence="0.998909230769231">
1. Change all occurrences of oo to u.
(both character sets are for the vowel )
2. Change all occurrences of ee to i
(both character sets are for the vowel )
3. Change all occurrences of f to ph
4. Change all occurrences of au to o
5. If a word starts with &quot;x&quot;, replace the &quot;x&quot;
with a &quot;z&quot;. Change all the remaining &quot;x&quot;s
to &quot;ks&quot;s.
6. If a &quot;c&quot; is directly followed by an &quot;e&quot; or
&quot;i&quot;, change the &quot;c&quot; to an &quot;s&quot;
7. If a &quot;c&quot; is directly followed by a &quot;k&quot;, re-
move the &quot;c&quot;. Keep applying this rule as
necessary (Example: &quot;cck&quot; becomes
&quot;k&quot;.)
8. If a word starts with &quot;sch&quot;, change the
&quot;sch&quot; to a &quot;sk&quot;.
9. If a &quot;ch&quot; is directly followed by an &quot;r&quot;,
change the &quot;ch&quot; to a &quot;k&quot;.
10. After applying the above rules, change all
&quot;c&quot;s that are not directly followed by an
&quot;h&quot;, to a &quot;k&quot;. (This includes all &quot;c&quot;s that
are last letter of a word)
11. If a word starts with &quot;kn&quot; change &quot;kn&quot;
ton
12. Change all double consonants of the same
</listItem>
<bodyText confidence="0.714482666666667">
letter to a single consonant. A consonant is
any letter that is not one of &quot;a, e, i, o, u.&quot;
(Example: &quot;apple&quot; becomes &quot;aple&quot;). Keep
</bodyText>
<page confidence="0.958648">
100
</page>
<bodyText confidence="0.9307455">
\x0capplying this rule as necessary (Example:
&quot;zzz&quot; becomes &quot;z&quot;.)
</bodyText>
<subsectionHeader confidence="0.99812">
4.4 Editex Score
</subsectionHeader>
<bodyText confidence="0.998282">
Now the transliterated string and the preprocessed
string are compared to generate an editex score.
The equivalence classes we used were similar to as
proposed in the original editex algorithm except
for some language specific changes for Hindi.
Length of the two strings has to be considered
while deciding the threshold score for a match oth-
erwise there can be greater number of mismatches
for small strings. So we normalize editex score as
d = [1- {editex(X, Y) / (length(X) + length(Y)}]
The decided threshold for match was 0.86. A
score above threshold guarantees equivalence of
the two representations. The results are shown in
</bodyText>
<figure confidence="0.926598">
Table-1.
Hindi
NE
English
NE
Transliteration
Output
Editex
Score
</figure>
<table confidence="0.9234699375">
Hindi Hindi 1.0
Philistini Phalastini 0.9
Bangladesh Bangladesh 1.0
Jharkhand Jharakhand 0.894
Pashchim Pashchim 1.0
Bengal Bangal 0.916
Bharat Bharat 1.0
Cricket Kriket 0.923
Greg Greg 1.0
Chappel Chaipal 0.857
Mahendra Mahendr 0.933
Rahul Rahul 1.0
Dravid Dravid 1.0
Chattisgarh Chattisagadh 0.866
Table-1: Hindi named entities with transliteration
output and normalized Editex scores
</table>
<sectionHeader confidence="0.996269" genericHeader="evaluation">
5 Results and Analysis
</sectionHeader>
<bodyText confidence="0.997179607142857">
We have tested our system with a parallel corpus
which consisted of both English and Hindi lan-
guage data. Further we used the web crawler to
populate our NE list of both the languages thus
embedding the concept of comparable corpus. The
results for English obtained using parallel corpus
are:
Precision: 81.40% and Recall: 81.39%
This corpus carried named entities from the do-
main of travel, tourism and culture. Further for
classifying the results for Hindi we used the defini-
tion of named entities as given by Chinchor (Chin-
chor, 1997) as for entity names organizations (OE),
person names (PE) and location names (LE). The
results for numeric expressions (monetary values
and percentages) and temporal expressions (dates
and times) were not considered for results because
it is a trivial task to build grammar rules for such
entities which appear quite regularly.
We have focused on OE, PE and LE named enti-
ties for Hindi so that we can analyze the perform-
ance on new and hitherto undiscovered entities
which come into existence with the passage of
time. This premise provides the real basis for chal-
lenging the performance of any NER technique for
Indian Languages.
The testing on the corpus of around 1000 sen-
tences revealed the following results for Hindi:
</bodyText>
<figure confidence="0.852319857142857">
Precision for all named entities
(PE+OE+LE): 80.2%
Recall for PE (person entity names):
47.4%
Recall for OE (organization entity names):
42.9%
Recall for LE (location entity names):
</figure>
<page confidence="0.485556">
74.6%
</page>
<bodyText confidence="0.9989396">
It is important to observe here that the engine
shows good recall for location entity names (LE)
which were more abundant in the corpus. Besides
this, the corpus had a heterogeneous mix of named
entities with tourism-related information not only
from India but also from the continents of South
America and Antarctica. A good recall percentage
for Hindi location entity names is encouraging as
the named entities related to South America and
Antarctica did not have phonetic similarity with
</bodyText>
<page confidence="0.992482">
101
</page>
<bodyText confidence="0.999513166666667">
\x0cthe native entities available from tourism informa-
tion from India. This gives good credence to the
phonetic matching approach used above. Causes
for the comparatively lower recall percentage
among person entity names and organization entity
names are under further investigation.
</bodyText>
<sectionHeader confidence="0.998839" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999532055555556">
We have used the phonetic matching technique to
match the strings of different languages on the ba-
sis of their similar sounding property. As the Pho-
netic Matcher module is tested for more data, more
generic rules can be made to improve its accuracy.
The Engine should be improved so that it may rec-
ognize phrasal named entities and abbreviations.
The engine will work for any language if the pho-
netic matching rules are written for that language.
We can also develop a crawler which will be fo-
cused upon a certain domain of interest. Focused
crawlers are very important for generating re-
sources for natural language processing. A focused
crawler application is an intelligent agent that
crawls the web for content related to a specific
domain. This kind of crawler could be used in the
future for purposes of data collection for a particu-
lar domain.
</bodyText>
<sectionHeader confidence="0.998265" genericHeader="acknowledgments">
7 Acknowledgements
</sectionHeader>
<bodyText confidence="0.9975965">
The authors gratefully acknowledge financial assis-
tance from TDIL, MCIT (Govt. of India).
</bodyText>
<sectionHeader confidence="0.98497" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.982327629629629">
Chinchor, N. 1997. MUC-7 Named entity task defini-
tion. In Proceedings of the 7th Message Understand-
ing Conference (MUC-7)
Finkel, Jenny Rose, Grenager, Trond and Manning,
Christopher. 2005. Incorporating Non-local Informa-
tion into Information Extraction Systems by Gibbs
Sampling. Proceedings of the 43rd Annual Meeting
of the Association for Computational Linguistics
(ACL 2005), pp. 363-370.
Kim, J. and Woodland, P.C. 2000a. Rule Based Named
Entity Recognition. Technical Report CUED/ FIN-
FENG/TR.385, Cambridge University Engineering
Department, 2000.
Malouf, Robert. 2002 Markov models for language-
independent named entity recognition. In Proceed-
ings of CoNLL-2002 Taipei, Taiwan, pages 591-599.
Levenshtein, V.I. 1966. Binary codes capable of cor-
recting deletions, insertions, and reversals. Soviet
Physics Doklady 10: 707710.
Zobel, Justin and Dart, Philip. 1996. Phonetic string
matching: Lessons from information retrieval. In
Proceedings of the Eighteenth ACM SIGIR Interna-
tional Conference on Research and Development in
Information Retrieval, Zurich, Switzerland, August
1996, pp. 166-173.
Appendix A: Soundex classes
Code Letters Code Letters
</reference>
<figure confidence="0.815193333333333">
0 aeiouyhw 4 l
1 bpfv 5 mn
2 cgjkqsxz 6 R
3 dt
Appendix B: Pseudo code for Leveinshtein edit dis-
tance:
</figure>
<bodyText confidence="0.929767">
Input: Two strings, X and Y
Output: The minimum edit dis-
tance between X and Y
m length(X)
n length(Y)
for i =0 to m do
dist[i, 0] i
for j = 0 to n do
dist[0, j] j
for i = 1 to m do
for j = 1 to n do
</bodyText>
<figure confidence="0.663717181818182">
dist[i, j] =
min{
dist[i-1, j]+inser_cost,
dist[i-1, j-1]
+ subst_cost[Xi, Yj],
dist[i, j-1] + delet_cost
}
end
Appendix C: Editex Equivalence Classes:
aeiouy bp ckq dt lr mn
gj fpy sxz csz
</figure>
<page confidence="0.984309">
102
</page>
<reference confidence="0.4792885">
\x0cPseudo code for Editex Algorithm
Input: Two strings, X and Y
Output: The editex distance
between X and Y
</reference>
<equation confidence="0.896314818181818">
m = length(X)
n = length(Y)
editex_dist[0, 0] = 0
for i = 1 to m do
editex_dist[i, 0]
= editex_dist[i-1, 0]
+ D(Xi-1, Xi)
for j = 0 to n do
editex_dist[0, j]
= editex_dist[0, j-1]
+ D(Yj-1, Yj)
</equation>
<bodyText confidence="0.837071">
for i = 1 to m do
for j = 1 to n do
editex_dist[i, j] =
</bodyText>
<equation confidence="0.507067714285714">
min { editex_dist[i-1, j]
+ D(Xi-1, Xi),
editex_dist[i-1, j-1]
+ S(X, Yj),
editex_dist[i, j-1]
+ D(Yj-1, Yj)
end
</equation>
<page confidence="0.870921">
103
</page>
<figure confidence="0.8881215">
\x0c104
\x0c&apos;
</figure>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.199189">
<note confidence="0.589308">b&apos;Proceedings of the IJCNLP-08 Workshop on NER for South and South East Asian Languages, pages 97104, Hyderabad, India, January 2008. c</note>
<title confidence="0.787296">2008 Asian Federation of Natural Language Processing Named Entity Recognition for Indian Languages</title>
<author confidence="0.912662">Animesh Nayan</author>
<author confidence="0.912662">B Ravi Kiran Rao</author>
<author confidence="0.912662">Pawandeep Singh</author>
<affiliation confidence="0.7941185">Sudip Sanyal and Ratna Sanyal Indian Institute of Information Technology</affiliation>
<address confidence="0.9861">Allahabad, India</address>
<email confidence="0.994718">e-mail@domain</email>
<abstract confidence="0.999390818181818">Abstract Stub This paper talks about a new approach to recognize named entities for Indian languages. Phonetic matching technique is used to match the strings of different languages on the basis of their similar sounding property. We have tested our system with a comparable corpus of English and Hindi language data. This approach is language independent and requires only a set of rules appropriate for a language.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>N Chinchor</author>
</authors>
<title>MUC-7 Named entity task definition.</title>
<date>1997</date>
<booktitle>In Proceedings of the 7th Message Understanding Conference (MUC-7) Finkel, Jenny Rose, Grenager, Trond</booktitle>
<pages>363--370</pages>
<contexts>
<context position="16653" citStr="Chinchor, 1997" startWordPosition="2817" endWordPosition="2819">th transliteration output and normalized Editex scores 5 Results and Analysis We have tested our system with a parallel corpus which consisted of both English and Hindi language data. Further we used the web crawler to populate our NE list of both the languages thus embedding the concept of comparable corpus. The results for English obtained using parallel corpus are: Precision: 81.40% and Recall: 81.39% This corpus carried named entities from the domain of travel, tourism and culture. Further for classifying the results for Hindi we used the definition of named entities as given by Chinchor (Chinchor, 1997) as for entity names organizations (OE), person names (PE) and location names (LE). The results for numeric expressions (monetary values and percentages) and temporal expressions (dates and times) were not considered for results because it is a trivial task to build grammar rules for such entities which appear quite regularly. We have focused on OE, PE and LE named entities for Hindi so that we can analyze the performance on new and hitherto undiscovered entities which come into existence with the passage of time. This premise provides the real basis for challenging the performance of any NER </context>
</contexts>
<marker>Chinchor, 1997</marker>
<rawString>Chinchor, N. 1997. MUC-7 Named entity task definition. In Proceedings of the 7th Message Understanding Conference (MUC-7) Finkel, Jenny Rose, Grenager, Trond and Manning, Christopher. 2005. Incorporating Non-local Information into Information Extraction Systems by Gibbs Sampling. Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL 2005), pp. 363-370.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Kim</author>
<author>P C Woodland</author>
</authors>
<title>Rule Based Named Entity Recognition.</title>
<date>2000</date>
<tech>Technical Report CUED/ FINFENG/TR.385,</tech>
<institution>Cambridge University Engineering Department,</institution>
<contexts>
<context position="1334" citStr="Kim and Woodland, 2000" startWordPosition="198" endWordPosition="201">data. This approach is language independent and requires only a set of rules appropriate for a language. 1 Introduction Named Entity Recognition (NER) is a subtask of machine translation and information retrieval. Named entities are words which belong to certain categories like persons, places, organizations, numerical quantities, expressions of times etc. A large number of techniques have been developed to recognize named entities for different languages. Some of them are Rule based and others are Statistical techniques. The rule based approach uses the morphological and contextual evidence (Kim and Woodland, 2000) of a natural language and consequently determines the named entities. This eventually leads to formation of some language specific rules for identifying named entities. The statistical techniques use large annotated data to train a model (Malouf, 2002) (like Hidden Markov Model) and subsequently examine it with the test data. Both the methods mentioned above require the efforts of a language expert. An appropriately large set of annotated data is yet to be made available for the Indian Languages. Consequently, the application of the statistical technique for Indian Languages is not very feasi</context>
</contexts>
<marker>Kim, Woodland, 2000</marker>
<rawString>Kim, J. and Woodland, P.C. 2000a. Rule Based Named Entity Recognition. Technical Report CUED/ FINFENG/TR.385, Cambridge University Engineering Department, 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Malouf</author>
</authors>
<title>Markov models for languageindependent named entity recognition.</title>
<date>2002</date>
<booktitle>In Proceedings of CoNLL-2002</booktitle>
<pages>591--599</pages>
<location>Taipei, Taiwan,</location>
<contexts>
<context position="1587" citStr="Malouf, 2002" startWordPosition="239" endWordPosition="240">categories like persons, places, organizations, numerical quantities, expressions of times etc. A large number of techniques have been developed to recognize named entities for different languages. Some of them are Rule based and others are Statistical techniques. The rule based approach uses the morphological and contextual evidence (Kim and Woodland, 2000) of a natural language and consequently determines the named entities. This eventually leads to formation of some language specific rules for identifying named entities. The statistical techniques use large annotated data to train a model (Malouf, 2002) (like Hidden Markov Model) and subsequently examine it with the test data. Both the methods mentioned above require the efforts of a language expert. An appropriately large set of annotated data is yet to be made available for the Indian Languages. Consequently, the application of the statistical technique for Indian Languages is not very feasible. This paper deals with a new technique to recognize named entities of different languages. Our approach does not use the previously mentioned techniques. Instead, we use an approach that not only reduces the burden of collecting and annotating data,</context>
</contexts>
<marker>Malouf, 2002</marker>
<rawString>Malouf, Robert. 2002 Markov models for languageindependent named entity recognition. In Proceedings of CoNLL-2002 Taipei, Taiwan, pages 591-599.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V I Levenshtein</author>
</authors>
<title>Binary codes capable of correcting deletions, insertions, and reversals.</title>
<date>1966</date>
<journal>Soviet Physics Doklady</journal>
<volume>10</volume>
<pages>707710</pages>
<contexts>
<context position="7138" citStr="Levenshtein, 1966" startWordPosition="1170" endWordPosition="1171">owing algorithm: 1. Replace all but the first letter of the string by its phonetic code. 2. Eliminate any adjacent representation of codes. 3. Eliminate all occurrences of code 0 i.e. eliminate all vowels. 4. Return the first four characters of the resulting string. 5. Examples: Dickson = d25, Dikson = d25. Two names match if they have the same soundex representation. This method does not account 98 \x0cfor vowels and hence is not accurate for crosslingual matching. 2.3.2 Editex The Editex algorithm was designed by Zobel and Dart (Zobel and Dart,1996). It is an enhancement of the Levenshtein (Levenshtein, 1966) edit distance algorithm. The Levenshtein algorithm measures the edit distance between two strings where edit distance is defined as the minimum number of basic operations required to match one string to the other where the basic operations are insertion, deletion and substitution. Insertion and deletion costs are 1 and substitution cost is given by a function subst_cost (Xi, Yj) which returns 0 if the two characters Xi and Yj are same and 1, if they are different. The score dist [m, n] is returned as the edit distance between two strings. A score of zero implies a perfect match. The algorithm</context>
</contexts>
<marker>Levenshtein, 1966</marker>
<rawString>Levenshtein, V.I. 1966. Binary codes capable of correcting deletions, insertions, and reversals. Soviet Physics Doklady 10: 707710.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Justin Zobel</author>
<author>Philip Dart</author>
</authors>
<title>Phonetic string matching: Lessons from information retrieval.</title>
<date>1996</date>
<booktitle>In Proceedings of the Eighteenth ACM SIGIR International Conference on Research and Development in Information Retrieval,</booktitle>
<pages>166--173</pages>
<location>Zurich, Switzerland,</location>
<contexts>
<context position="8807" citStr="Zobel and Dart, 1996" startWordPosition="1463" endWordPosition="1466">and substitution costs are determined by a function D (Xi-1, Xi) which is almost same as S (Xi, Yj) except for the difference that it compares letters of the same string and it returns 1 if Xi-1 is h or w and Xi-1 is not equal to Xi. The editex equivalence classes and the editex pseudo-code are given in Appendix C. Editex performs fairly better than Soundex and Leveinshtein edit distance algorithms. However further enhancements in Editex are also possible. Tapering is one enhancement in which we weigh mismatches at the beginning of the string with higher score than mismatches towards the end (Zobel and Dart, 1996). Other enhancements are those in which input strings are mapped to their phonemic representation, called phonometric methods (Zobel and Dart, 1996). 3 Transliteration rules To perform phonetic matching of two different representations of a named entity, we need both of them in a common script. We choose to transliterate the named entity in Indian language to English. The transliteration rules for a language must be written for the same. We have written our own set of transliteration rules for Hindi. These can be described briefly as under The entity to be transliterated is scanned character b</context>
</contexts>
<marker>Zobel, Dart, 1996</marker>
<rawString>Zobel, Justin and Dart, Philip. 1996. Phonetic string matching: Lessons from information retrieval. In Proceedings of the Eighteenth ACM SIGIR International Conference on Research and Development in Information Retrieval, Zurich, Switzerland, August 1996, pp. 166-173. Appendix A: Soundex classes Code Letters Code Letters \x0cPseudo code for Editex Algorithm Input: Two strings, X and Y Output: The editex distance between X and Y</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>