<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<bodyText confidence="0.3937395">
b&amp;quot;Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 592599,
Prague, Czech Republic, June 2007. c
</bodyText>
<sectionHeader confidence="0.29776" genericHeader="abstract">
2007 Association for Computational Linguistics
</sectionHeader>
<title confidence="0.985624">
A Multi-resolution Framework for Information Extraction from Free Text
</title>
<author confidence="0.842164">
Mstislav Maslennikov and Tat-Seng Chua
</author>
<affiliation confidence="0.997225">
Department of Computer Science
National University of Singapore
</affiliation>
<email confidence="0.995249">
{maslenni,chuats}@comp.nus.edu.sg
</email>
<sectionHeader confidence="0.99014" genericHeader="keywords">
Abstract
</sectionHeader>
<bodyText confidence="0.981265764705882">
Extraction of relations between entities is
an important part of Information Extraction
on free text. Previous methods are mostly
based on statistical correlation and depend-
ency relations between entities. This paper
re-examines the problem at the multi-
resolution layers of phrase, clause and sen-
tence using dependency and discourse rela-
tions. Our multi-resolution framework
ARE (Anchor and Relation) uses clausal
relations in 2 ways: 1) to filter noisy de-
pendency paths; and 2) to increase reliabil-
ity of dependency path extraction. The re-
sulting system outperforms the previous
approaches by 3%, 7%, 4% on MUC4,
MUC6 and ACE RDC domains respec-
tively.
</bodyText>
<sectionHeader confidence="0.9977" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998553375">
Information Extraction (IE) is the task of identify-
ing information in texts and converting it into a
predefined format. The possible types of informa-
tion include entities, relations or events. In this
paper, we follow the IE tasks as defined by the
conferences MUC4, MUC6 and ACE RDC: slot-
based extraction, template filling and relation ex-
traction, respectively.
Previous approaches to IE relied on co-
occurrence (Xiao et al., 2004) and dependency
(Zhang et al., 2006) relations between entities.
These relations enable us to make reliable extrac-
tion of correct entities/relations at the level of a
single clause. However, Maslennikov et al. (2006)
reported that the increase of relation path length
will lead to considerable decrease in performance.
In most cases, this decrease in performance occurs
because entities may belong to different clauses.
Since clauses in a sentence are connected by
clausal relations (Halliday and Hasan, 1976), it is
thus important to perform discourse analysis of a
sentence.
Discourse analysis may contribute to IE in sev-
eral ways. First, Taboada and Mann (2005) re-
ported that discourse analysis helps to decompose
long sentences into clauses. Therefore, it helps to
distinguish relevant clauses from non-relevant
ones. Second, Miltsakaki (2003) stated that entities
in subordinate clauses are less salient. Third, the
knowledge of textual structure helps to interpret
the meaning of entities in a text (Grosz and Sidner
1986). As an example, consider the sentences
ABC Co. appointed a new chairman. Addition-
ally, the current CEO was retired. The word ad-
ditionally connects the event in the second sen-
tence to the entity ABC Co. in the first sentence.
Fourth, Moens and De Busser (2002) reported that
discourse segments tend to be in a fixed order for
structured texts such as court decisions or news.
Hence, analysis of discourse order may reduce the
variability of possible relations between entities.
To model these factors, we propose a multi-
resolution framework ARE that integrates both
discourse and dependency relations at 2 levels.
ARE aims to filter noisy dependency relations
from training and support their evaluation with
discourse relations between entities. Additionally,
we encode semantic roles of entities in order to
utilize semantic relations. Evaluations on MUC4,
MUC6 and ACE RDC 2003 corpora demonstrates
that our approach outperforms the state-of-art sys-
tems mainly due to modeling of discourse rela-
tions.
The contribution of this paper is in applying dis-
course relations to supplement dependency rela-
tions in a multi-resolution framework for IE. The
</bodyText>
<page confidence="0.992722">
592
</page>
<bodyText confidence="0.9978419">
\x0cframework enables us to connect entities in differ-
ent clauses and thus improve the performance on
long-distance dependency paths.
Section 2 describes related work, while Section
3 presents our proposed framework, including the
extraction of anchor cues and various types of rela-
tions, integration of extracted relations, and com-
plexity classification. Section 4 describes our ex-
perimental results, with the analysis of results in
Section 5. Section 6 concludes the paper.
</bodyText>
<sectionHeader confidence="0.999268" genericHeader="method">
2 Related work
</sectionHeader>
<bodyText confidence="0.998844382978723">
Recent work in IE focuses on relation-based, se-
mantic parsing-based and discourse-based ap-
proaches. Several recent research efforts were
based on modeling relations between entities. Cu-
lotta and Sorensen (2004) extracted relationships
using dependency-based kernel trees in Support
Vector Machines (SVM). They achieved an F1-
measure of 63% in relation detection. The authors
reported that the primary source of mistakes comes
from the heterogeneous nature of non-relation in-
stances. One possible direction to tackle this prob-
lem is to carry out further relationship classifica-
tion. Maslennikov et al. (2006) classified relation
path between candidate entities into simple, aver-
age and hard cases. This classification is based on
the length of connecting path in dependency parse
tree. They reported that dependency relations are
not reliable for the hard cases, which, in our opin-
ion, need the extraction of discourse relations to
supplement dependency relation paths.
Surdeanu et al. (2003) applied semantic parsing
to capture the predicate-argument sentence struc-
ture. They suggested that semantic parsing is use-
ful to capture verb arguments, which may be con-
nected by long-distance dependency paths. How-
ever, current semantic parsers such as the ASSERT
are not able to recognize support verb construc-
tions such as X conducted an attack on Y under
the verb frame attack (Pradhan et al. 2004).
Hence, many useful predicate-argument structures
will be missed. Moreover, semantic parsing be-
longs to the intra-clausal level of sentence analysis,
which, as in the dependency case, will need the
support of discourse analysis to bridge inter-clausal
relations.
Webber et al. (2002) reported that discourse
structure helps to extract anaphoric relations. How-
ever, their set of grammatical rules is heuristic. Our
task needs construction of an automated approach
to be portable across several domains. Cimiano et
al. (2005) employed a discourse-based analysis for
IE. However, their approach requires a predefined
domain-dependent ontology in the format of ex-
tended logical description grammar as described by
Cimiano and Reely (2003). Moreover, they used
discourse relations between events, whereas in our
approach, discourse relations connect entities.
</bodyText>
<sectionHeader confidence="0.915047" genericHeader="method">
3 Motivation for using discourse relations
</sectionHeader>
<bodyText confidence="0.996067">
Our method is based on Rhetorical Structure The-
ory (RST) by Taboada and Mann (2005). RST
splits the texts into 2 parts: a) nuclei, the most im-
portant parts of texts; and b) satellites, the secon-
dary parts. We can often remove satellites without
losing the meaning of text. Both nuclei and satel-
lites are connected with discourse relations in a
hierarchical structure. In our work, we use 16
classes of discourse relations between clauses: At-
</bodyText>
<reference confidence="0.6157175">
tribution, Background, Cause, Comparison, Condi-
tion, Contrast, Elaboration, Enablement, Evalua-
tion, Explanation, Joint, Manner-Means, Topic-
Comment, Summary, Temporal, Topic-Change.
</reference>
<bodyText confidence="0.986006538461538">
The additional 3 relations impose a tree structure:
textual-organization, span and same-unit. All the
discourse relation classes are potentially useful,
since they encode some knowledge about textual
structure. Therefore, we decide to include all of
them in the learning process to learn patterns with
best possible performance.
We consider two main rationales for utilizing
discourse relations to IE. First, discourse relations
help to narrow down the search space to the level
of a single clause. For example, the sentence
[&amp;lt;Soc-A1&amp;gt;Trudeau&amp;lt;/&amp;gt;&amp;apos;s &amp;lt;Soc-A2&amp;gt;son&amp;lt;/&amp;gt; told
everyone], [their prime minister was his father],
[who took him to a secret base in the arctic] [and
let him peek through a window]. contains 4
clauses and 7 anchor cues (key phrases) for the
type Social, which leads to 21 possible variants.
Splitting this sentence into clauses reduces the
combinations to 4 possible variants. Additionally,
this reduction eliminates the long and noisy de-
pendency paths.
Second, discourse analysis enables us to connect
entities in different clauses with clausal relations.
As an example, we consider a sentence Its a dark
comedy about a boy named &amp;lt;AT-A1&amp;gt;Marshal&amp;lt;/&amp;gt;
played by Amourie Kats who discovers all kinds of
</bodyText>
<page confidence="0.996827">
593
</page>
<bodyText confidence="0.9756356">
\x0con and scary things going on in &amp;lt;AT-A2&amp;gt;a seem-
ingly quiet little town&amp;lt;/&amp;gt;. In this example, we
need to extract the relation At between the enti-
ties Marshal and a seemingly quiet little town.
The discourse structure of this sentence is given in
</bodyText>
<equation confidence="0.334584">
.
</equation>
<figureCaption confidence="0.9945395">
Figure 1
Figure 1. Example of discourse parsing
</figureCaption>
<bodyText confidence="0.944968666666667">
The discourse path Marshal &amp;lt;-elaboration- _
&amp;lt;-span- _ -elaboration-&amp;gt; _ -elaboration-&amp;gt; town
is relatively short and captures the necessary rela-
tions. At the same time, prediction based on de-
pendency path Marshal &amp;lt;obj- _ &amp;lt;-i- _ &amp;lt;-fc- _
&amp;lt;-pnmod- _ &amp;lt;-pred- _ &amp;lt;-i- _ &amp;lt;-null- _ -null-&amp;gt; _ -
rel-&amp;gt; _ -i-&amp;gt; _ -mod-&amp;gt; _ -pcomp-n-&amp;gt; town is un-
reliable, since the relation path is long. Thus, it is
important to rely on discourse analysis in this ex-
ample. In addition, we need to evaluate both the
score and reliability of prediction by relation path
of each type.
</bodyText>
<sectionHeader confidence="0.970585" genericHeader="method">
4 Anchors and Relations
</sectionHeader>
<bodyText confidence="0.9987144">
In this section, we define the key components that
we use in ARE: anchors, relation types and general
architecture of our system. Some of these compo-
nents are also presented in detail in our previous
work (Maslennikov et al., 2006).
</bodyText>
<subsectionHeader confidence="0.997907">
4.1 Anchors
</subsectionHeader>
<bodyText confidence="0.999706857142857">
The first task in IE is to identify candidate phrases
(which we call anchor or anchor cue) of a pre-
defined type (anchor type) to fill a desired slot in
an IE template. The example anchor for the phrase
Marshal is shown in Figure 2.
Given a training set of sentences,
we extract the anchor cues ACj =
[A1, ..., ANanch] of type Cj using
the procedures described in
Maslennikov et al. (2006). The
linguistic features of these an-
chors for the anchor types of Per-
petrator, Action, Victim and Target for the MUC4
domain are given in Table 1.
</bodyText>
<figure confidence="0.995890140350877">
Anchor
types
Feature
Perpetrator_Cue
(A)
Action_Cue
(D)
Victim_Cue
(A)
Target_Cue
(A)
Lexical
(Head noun)
terrorists,
individuals,
Soldiers
attacked,
murder,
Massacre
Mayor,
general,
priests
bridge,
house,
Ministry
Part-of-Speech Noun Verb Noun Noun
Named Enti-
ties
Soldiers
(PERSON)
- Jesuit priests
(PERSON)
WTC
(OBJECT)
Synonyms Synset 130, 166 Synset 22 Synset 68 Synset 71
Concept Class ID 2, 3 ID 9 ID 22, 43 ID 61, 48
Co-referenced
entity
He -&amp;gt; terrorist,
soldier
- They -&amp;gt;
peasants
-
Clausal type Nucleus
Satellite
Nucleus,
Satellite
Nucleus,
Satellite
Nucleus,
Satellite
Argument type Arg0 , Arg1
Root
Target, -,
ArgM-MNR
Arg0 , Arg1 Arg1 , ArgM-
MNR
</figure>
<tableCaption confidence="0.958064">
Table 1. Linguistic features for anchor extraction
</tableCaption>
<bodyText confidence="0.778609666666667">
Given an input phrase P from a test sentence, we
need to classify if the phrase belongs to anchor cue
type Cj. We calculate the entity score as:
</bodyText>
<equation confidence="0.997022">
Entity_Score(P) = i * Feature_Scorei(P,Cj) (1)
</equation>
<bodyText confidence="0.995731444444445">
where Feature_Score(P,Cj) is a score function for
a particular linguistic feature representation of type
Cj, and i is the corresponding weight for that rep-
resentation in the overall entity score. The weights
are learned automatically using Expectation Maxi-
mization (Dempster et al., 1977). The Fea-
ture_Scorei(P,Cj) is estimated from the training set
as the number of slots containing the correct fea-
ture representation type versus all the slots:
</bodyText>
<equation confidence="0.723256">
Feature_Scorei(P,Cj) = #(positive slots) / #(all slots) (2)
</equation>
<bodyText confidence="0.998371">
We classify the phrase P as belonging to an anchor
type Cj when its Entity_score(P) is above an em-
pirically determined threshold . We refer to this
anchor as Aj. We allow a phrase to belong to mul-
tiple anchor types and hence the anchors alone are
not enough for filling templates.
</bodyText>
<subsectionHeader confidence="0.943856">
4.2 Relations
</subsectionHeader>
<bodyText confidence="0.967037368421053">
To resolve the correct filling of phrase P of type Ci
in a desired slot in the template, we need to con-
sider the relations between multiple candidate
phrases of related slots. To do so, we consider sev-
eral types of relations between anchors: discourse,
dependency and semantic relations. These relations
capture the interactions between anchors and are
therefore useful for tackling the paraphrasing and
alignment problems (Maslennikov et al., 2006).
Given 2 anchors Ai and Aj of anchor types Ci and
Cj, we consider a relation Pathl = [Ai, Rel1,...,
Reln, Aj] between them, such that there are no an-
chors between Ai and Aj. Additionally, we assume
that the relations between anchors are represented
in the form of a tree Tl, where l = {s, c, d} refers to
Satellite
who discovers all kinds of on and
scary things going on in a seem-
ingly quiet little town.
</bodyText>
<figure confidence="0.945916">
Nucleus
It&amp;apos;s a dark
comedy
about a boy
Satellite
named Mar-
shal
Nucleus
played by
Amourie Kats
Nucleus Satellite
span elaboration
span elaboration elaboration
span
</figure>
<figureCaption confidence="0.7008345">
Figure 2. Exam-
ple of anchor
</figureCaption>
<figure confidence="0.9987865">
Anchor Ai
Marshal
pos_NNP
list_personWord
Cand_AtArg1
Minipar_obj
Arg2
Spade_Satellite
</figure>
<page confidence="0.999641">
594
</page>
<bodyText confidence="0.9971265">
\x0cdiscourse, dependency and semantic relation types
respectively. We describe the nodes and edges of
Tl separately for each type, because their represen-
tations are different:
</bodyText>
<listItem confidence="0.732927888888889">
1) The nodes of discourse tree Tc consist of clauses
[Clause1, ..., ClauseNcl]; and their relation edges
are obtained from the Spade system described in
Soricut and Marcu (2003). This system performs
RST-based parsing at the sentence level. The re-
ported accuracy of Spade is 49% on the RST-DT
corpus. To obtain a clausal path, we map each
anchor Ai to its clause in Spade. If anchors Ai
and Aj belong to the same clause, we assign
them the relation same-clause.
es.
2) The nodes of dependency tree Td consist of
words in sentences; and their relation edges are
obtained from Minipar by Lin (1997). Lin
(1997) reported a parsing performance of Preci-
sion = 88.5% and Recall = 78.6% on the SU-
SANNE corpus.
3) The nodes of semantic tree Ts consist of argu-
</listItem>
<bodyText confidence="0.785029666666667">
ments [Arg0, ..., ArgNarg] and targets [Target1,
..., TargetNtarg]. Both arguments and targets are
obtained from the ASSERT parser developed by
Pradhan (2004). The reported performance of
ASSERT is F1=83.8% on the identification and
classification task for all arguments, evaluated
using PropBank and AQUAINT as the training
and testing corpora, respectively. Since the rela-
tion edges have a form Targetk -&amp;gt; Argl, the rela-
tion path in semantic frame contains only a sin-
gle relation. Therefore, we encode semantic rela-
tions as part of the anchor features.
In later parts of this paper, we consider only dis-
course and dependency relation paths Pathl, where
l={c, d}.
</bodyText>
<figureCaption confidence="0.950951">
Figure 3. Architecture of the system
</figureCaption>
<subsectionHeader confidence="0.9973">
4.3 Architecture of ARE system
</subsectionHeader>
<bodyText confidence="0.9990661">
In order to perform IE, it is important to extract
candidate entities (anchors) of appropriate anchor
types, evaluate the relationships between them,
further evaluate all possible candidate templates,
and output the final template. For the case of rela-
tion extraction task, the final templates are the
same as an extracted binary relation. The overall
architecture of ARE is given in Figure 3.
The focus of this paper is in applying discourse
relations for binary relationship evaluation.
</bodyText>
<sectionHeader confidence="0.844401" genericHeader="method">
5 Overall approach
</sectionHeader>
<bodyText confidence="0.999738333333333">
In this section, we describe our relation-based ap-
proach to IE. We start with the evaluation of rela-
tion paths (single relation ranking, relation path
ranking) to assess the suitability of their anchors as
entities to template slots. Here we want to evaluate
given a single relation or relation path, whether the
two anchors are correct in filling the appropriate
slots in a template. This is followed by the integra-
tion of relation paths and evaluation of templates.
</bodyText>
<subsectionHeader confidence="0.99566">
5.1 Evaluation of relation path
</subsectionHeader>
<bodyText confidence="0.990253352941177">
In the first stage, we evaluate from training data
the relevance of relation path Pathl = [Ai, Rel1,...,
Reln, Aj] between candidate anchors Ai and Aj of
types Ci and Cj. We divide this task into 2 steps.
The first step ranks each single relation Relk
Pathl; while the second step combines the evalua-
tions of Relk to rank the whole relation path Pathl.
Single relation ranking
Let Seti and Setj be the set of linguistic features of
anchors Ai and Aj respectively. To evaluate Relk,
we consider 2 characteristics: (1) the direction of
relation Relk as encoded in the tree structure; and
(2) the linguistic features, Seti and Setj, of anchors
Ai and Aj. We need to construct multiple single
relation classifiers, one for each anchor pair of
types Ci and Cj, to evaluate the relevance of Relk
with respect to these 2 anchor typ
</bodyText>
<figure confidence="0.410218666666667">
Preprocessing
Corpus
(a) Construction of classifiers. The training data
</figure>
<bodyText confidence="0.9824078">
to each classifier consists of anchor pairs of types
Ci and Cj extracted from the training corpus. We
use these anchor pairs to construct each classifier
in four stages. First, we compose the set of possi-
ble patterns in the form P+
</bodyText>
<equation confidence="0.873424">
= { Pm = &amp;lt;Si Rel-&amp;gt;
Sj&amp;gt;  |Si Seti , Sj Setj }. The construction of Pm
</equation>
<figure confidence="0.986402454545455">
Anchor
evaluation
Templates
Anchor NEs
Template
evaluation
Sentences
Binary relationship
evaluation
Candidate
templates
</figure>
<page confidence="0.719862">
595
</page>
<figureCaption confidence="0.921449333333333">
\x0cconforms to the 2 characteristics given above.
Figure 4 illustrates several discourse and depend-
ency patterns of P+
constructed from a sample sen-
tence.
Figure 4. Examples of discourse and dependency patterns
</figureCaption>
<bodyText confidence="0.823258230769231">
Second, we identify the candidate anchor A,
whose type matches slot C in a template. Third, we
find the correct patterns for the following 2 cases:
1) Ai, Aj are of correct anchor types; and 2) Ai is an
action anchor, while Aj is a correct anchor. Any
other patterns are considered as incorrect. We note
that the discourse and dependency paths between
anchors Ai and Aj are either correct or wrong si-
multaneously.
Fourth, we evaluate the relevance of each pat-
tern Pm P+
. Given the training set, let PairSetm
be the set of anchor pairs extracted by Pm; and
</bodyText>
<equation confidence="0.959218919354839">
PairSet+
(Ci, Cj) be the set of correct anchor pairs
of types Ci, Cj. We evaluate both precision and
recall of Pm as
||
||
|
)
,
(
||
)
(
m
j
i
m
m
PairSet
C
C
PairsSet
PairSet
P
recision
P
|
=
+
(3)
||
)
,
(
||
|
)
,
(
||
)
(
j
i
j
i
m
m
C
C
PairsSet
C
C
PairsSet
PairSet
P
ecall
R +
+
|
=
(4)
</equation>
<bodyText confidence="0.948145">
These values are stored and used in the training
model for use during testing.
(b) Evaluation of relation. Here we want to
evaluate whether relation InputRel belongs to a
path between anchors InputAi and InputAj. We
employ the constructed classifier for the anchor
types InputCi and InputCj in 2 stages. First, we
</bodyText>
<equation confidence="0.97127625">
find a subset P(0)
= { Pm = &amp;lt;Si InputRel-&amp;gt; Sj&amp;gt;
P+
 |Si InputSeti, Sj InputSetj } of applicable
</equation>
<bodyText confidence="0.9019975">
patterns. Second, we utilize P(0)
to find the pattern
</bodyText>
<equation confidence="0.806388833333333">
Pm
(0)
with maximal precision:
Precision(Pm
(0)
) = argmaxPmP(0) Precision (Pm) (5)
</equation>
<bodyText confidence="0.862638777777778">
A problem arises if Pm
(0)
is evaluated only on a
small amount of training instances. For example,
we noticed that patterns that cover 1 or 2 instances
may lead to Precision=1, whereas on the testing
corpus their accuracy becomes less than 50%.
Therefore, it is important to additionally consider
the recall parameter of Pm
</bodyText>
<equation confidence="0.630490333333333">
(0)
.
Relation path ranking
</equation>
<bodyText confidence="0.9738945">
In this section, we want to evaluate relation path
connecting template slots Ci and Cj. We do this
independently for each relation of type discourse
and dependency. Let Recallk and Precisionk be the
recall and precision values of Relk in Path = [Ai,
Rel1,..., Reln, Aj], both obtained from the previous
step. First, we calculate the average recall of the
involved relations:
</bodyText>
<equation confidence="0.999451">
W = (1/LengthPath) * RelkPath Recallk (6)
</equation>
<bodyText confidence="0.9841125">
W gives the average recall of the involved rela-
tions and can be used as a measure of reliability of
the relation Path. Next, we compute a combined
score of average Precisionk weighted by Recallk:
</bodyText>
<equation confidence="0.884804">
Score = 1/(W*LengthPath)*RelkPath Recallk*Precisionk (7)
</equation>
<bodyText confidence="0.994566428571429">
We use all Precisionk values in the path here, be-
cause omitting a single relation may turn a correct
path into the wrong one, or vice versa. The com-
bined score value is used as a ranking of the rela-
tion path. Experiments show that we need to give
priority to scores with higher reliability W. Hence
we use (W, Score) to evaluate each Path.
</bodyText>
<subsectionHeader confidence="0.880568">
5.2 Integration of different relation path
types
</subsectionHeader>
<bodyText confidence="0.980114181818182">
The purpose of this stage is to integrate the evalua-
tions for different types of relation paths. The input
to this stage consists of evaluated relation paths
PathC and PathD for discourse and dependency
relations respectively. Let (Wl, Scorel) be an
evaluation for Pathl, l [c, d]. We first define an
integral path PathI between Ai and Aj as: 1) PathI
is enabled if at least one of Pathl, l [c, d], is en-
abled; and 2) PathI is correct if at least one of
Pathl is correct. To evaluate PathI, we consider the
average recall Wl of each Pathl, because Wl esti-
</bodyText>
<figure confidence="0.9969499375">
elaboration
obj
Anchor Aj
town
pos_NN
Cand_AtArg2
Minipar_pcompn
ArgM-Loc
Spade_Satellite
Anchor Ai
Marshal
pos_NNP
list_personWord
Cand_AtArg1
Minipar_obj
Arg2
Spade Satellite
pcomp-n
fc
span
Discourse path
Dependency path
i
elaboration
Input sentence
Marshal
... named &amp;lt;At-A1&amp;gt; &amp;lt;/&amp;gt; played by Amourie Kats who discovers all kinds
of on and scary things going on in &amp;lt;At-A2&amp;gt;
Dependency patterns
Minipar_obj &amp;lt;i- ArgM-Loc
Minipar_obj &amp;lt;obj- ArgM-Loc
Minipar_obj pcompn-&amp;gt; Minipar_pcompn
Minipar_obj mod-&amp;gt; Minipar_pcompn
...
a seemingly quiet little town&amp;lt;/&amp;gt; ...
elaboration
pnmod
pred i
null
null
rel
i mod
Discourse patterns
list_personWord &amp;lt;elaboration- pos_NN
list_personWord elaboration-&amp;gt; town
list_personWord &amp;lt;span- town
list_personWord &amp;lt;elaboration- town
...
</figure>
<page confidence="0.98855">
596
</page>
<bodyText confidence="0.5824285">
\x0cmates the reliability of Scorel. We define a
weighted average for Pathl as:
</bodyText>
<equation confidence="0.999988">
WI = WC + WD (8)
ScoreI = 1/WI * l Wl*Scorel (9)
</equation>
<bodyText confidence="0.967379">
Next, we want to determine the threshold score
</bodyText>
<equation confidence="0.867555">
ScoreI
O
</equation>
<bodyText confidence="0.958008888888889">
above which ScoreI is acceptable. This
score may be found by analyzing the integral paths
on the training corpus. Let SI = { PathI } be the set
of integral paths between anchors Ai and Aj on the
training set. Among the paths in SI, we need to de-
fine a set function SI(X) = { PathI  |ScoreI(PathI)
X } and find the optimal threshold for X. We find
the optimal threshold based on F1-measure, be-
cause precision and recall are equally important in
</bodyText>
<listItem confidence="0.5294196">
IE. Let SI(X)+
SI(X) and S(X)+
S(X) be sets of
correct path extractions. Let FI(X) be F1-measure
of SI(X):
</listItem>
<equation confidence="0.689295657142857">
||
)
(
||
||
)
(
||
)
(
X
S
X
S
X
P
I
I
I
+
= (10)
||
)
(
||
||
)
(
||
)
( +
+
=
X
S
X
S
X
R I
I (11)
)
(
)
(
)
(
*
)
(
*
2
)
(
X
R
X
P
X
R
X
P
X
F
I
I
I
I
I
+
= (12)
</equation>
<bodyText confidence="0.988195333333333">
Based on the computed values FI(X) for each X on
the training data, we determine the optimal thresh-
old as Score = argmax F (X)
</bodyText>
<equation confidence="0.936180666666667">
I
O
X I , which corre-
</equation>
<bodyText confidence="0.98903">
sponds to the maximal expected F1-measure of
anchor pair Ai and Aj.
</bodyText>
<subsectionHeader confidence="0.998617">
5.3 Evaluation of templates
</subsectionHeader>
<bodyText confidence="0.935067272727273">
At this stage, we have a set of accepted integral
relation paths between any anchor pair Ai and Aj.
The next task is to merge appropriate set of an-
chors into candidate templates. Here we follow the
methodology of Maslennikov et al. (2006). For
each sentence, we compose a set of candidate tem-
plates T using the extracted relation paths between
each Ai and Aj. To evaluate each template TiT,
we combine the integral scores from relation paths
between its anchors Ai and Aj into the overall Rela-
tion_ScoreT:
</bodyText>
<figure confidence="0.894755555555556">
M
A
A
Score
T
Score
elation
R K
j
</figure>
<equation confidence="0.962548769230769">
i j
i
I
i
T
= ,
1
)
,
(
)
(
_ (13)
</equation>
<bodyText confidence="0.998297333333333">
where K is the number of extracted slots, M is the
number of extracted relation paths between an-
chors Ai and Aj, and ScoreI(Ai, Aj) is obtained
from Equation (9).
Next, we calculate the extracted entity score
based on the scores of all the anchors in Ti:
</bodyText>
<figure confidence="0.7035665">
= K
k k
i
T K
A
Score
Entity
T
Score
Entity 1
/
)
(
_
)
(
</figure>
<equation confidence="0.966999">
_ (14)
</equation>
<bodyText confidence="0.943330666666667">
where Entity_Score(Ai) is taken from Equation (1).
Finally, we obtain the combined evaluation for a
template:
</bodyText>
<equation confidence="0.926849666666667">
ScoreT(Ti) = (1- )* Entity_ScoreT (Ti) +
* Relation_ScoreT (Ti)
(15)
</equation>
<bodyText confidence="0.964444523809524">
where is a predefined constant.
In order to decide whether the template Ti
should be accepted or rejected, we need to deter-
mine a threshold ScoreT
O
from the training data. If
anchors of a candidate template match slots in a
correct template, we consider the candidate tem-
plate as correct. Let TrainT = { Ti } be the set of
candidate templates extracted from the training
data, TrainT+
TrainT be the subset of correct
candidate templates, and TotalT+
be the total set of
correct templates in the training data. Also, let
TrainT(X) = { Ti  |ScoreT(Ti) X, Ti TrainT } be
the set of candidate templates with score above X
and TrainT+
(X) TrainT(X) be the subset of cor-
rect candidate templates. We define the measures
of precision, recall and F1 as follows:
</bodyText>
<figure confidence="0.950714183333333">
||
)
(
||
||
)
(
||
)
(
X
TrainT
X
TrainT
X
PT
+
= (16) ||
||
||
)
(
||
)
( +
+
=
TotalT
X
TrainT
X
RT (17)
)
(
)
(
)
(
)
(
*
2
)
(
X
R
X
P
X
R
X
P
X
F
T
T
T
T
T
+
</figure>
<equation confidence="0.908484">
= (18)
</equation>
<bodyText confidence="0.999229666666667">
Since the performance in IE is measured in F1-
measure, an appropriate threshold to be used for
the most prominent candidate templates is:
</bodyText>
<equation confidence="0.9547078">
ScoreT
O
= argmaxX FT (X) (19)
The value ScoreT
O
</equation>
<bodyText confidence="0.8178035">
is used as a training model.
During testing, we accept a candidate template In-
</bodyText>
<equation confidence="0.988874333333333">
putTi if ScoreT(InputTi) &amp;gt; Sco O
re .
T
</equation>
<bodyText confidence="0.998887428571429">
As an additional remark, we note that domains
MUC4, MUC6 and ACE RDC 2003 are signifi-
cantly different in the evaluation methodology for
the candidate templates. While the performance of
the MUC4 domain is measured for each slot indi-
vidually; the MUC6 task measures the perform-
ance on the extracted templates; and the ACE RDC
2003 task evaluates performance on the matching
relations. To overcome these differences, we con-
struct candidate templates for all the domains and
measure the required type of performance for each
domain. Our candidate templates for the ACE
RDC 2003 task consist of only 2 slots, which cor-
respond to entities of the correct relations.
</bodyText>
<page confidence="0.983384">
597
</page>
<sectionHeader confidence="0.750196" genericHeader="evaluation">
\x0c6 Experimental results
</sectionHeader>
<bodyText confidence="0.955328333333333">
We carry out our experiments on 3 domains:
MUC4 (Terrorism), MUC6 (Management Succes-
sion), and ACE-Relation Detection and Characteri-
zation (2003). The MUC4 corpus contains 1,300
documents as training set and 200 documents
(TST3 and TST4) as official testing set. We used a
modified version of the MUC6 corpus described
by Soderland (1999). This version includes 599
documents as training set and 100 documents as
testing set. Following the methodology of Zhang et
al. (2006), we use only the English portion of ACE
RDC 2003 training data. We used 97 documents
for testing and the remaining 155 documents for
training. Our task is to extract 5 major relation
types and 24 subtypes.
</bodyText>
<table confidence="0.9966196">
Case (%) P R F1
GRID 52% 62% 57%
Riloff05 46% 51% 48%
ARE (2006) 58% 61% 60%
ARE 65% 61% 63%
</table>
<tableCaption confidence="0.998684">
Table 2. Results on MUC4
</tableCaption>
<bodyText confidence="0.951182045454545">
To compare the results on the terrorism domain
in MUC4, we choose the recent state-of-art sys-
tems GRID by Xiao et al. (2004), Riloff et al.
(2005) and ARE (2006) by Maslennikov et al.
(2006) which does not utilize discourse and seman-
tic relations. The comparative results are given in
Table 2. It shows that our enhanced ARE results in
3% improvement in F1 measure over ARE (2006)
that does not use clausal relations. The improve-
ment was due to the use of discourse relations on
long paths, such as X distributed leaflets claiming
responsibility for murder of Y. At the same time,
for many instances, it would be useful to store the
extracted anchors for another round of learning.
For example, the extracted features of discourse
pattern murder same_clause-&amp;gt; HUM_PERSON
may boost the score for patterns that correspond to
relation path X &amp;lt;-span- _ -Elaboration-&amp;gt; mur-
der. In this way, high-precision patterns will sup-
port the refinement of patterns with average recall
and low precision. This observation is similar to
that described in Ciravegnas work on (LP)2
</bodyText>
<table confidence="0.9266908">
(Ciravegna 2001).
Case (%) P R F1
Chieu et al.02 75% 49% 59%
ARE (2006) 73% 58% 65%
ARE 73% 70% 72%
</table>
<tableCaption confidence="0.998733">
Table 3. Results on MUC6
</tableCaption>
<bodyText confidence="0.998502783783784">
Next, we present the performance of our system
on MUC6 corpus (Management Succession) as
shown in Table 3. The improvement of 7% in F1 is
mainly due to the filtering of irrelevant depend-
ency relations. Additionally, we noticed that 22%
of testing sentences contain 2 answer templates,
and entities in many of such templates are inter-
twined. One example is the sentence Mr. Bronc-
zek who is 39 years old succeeds Kenneth Newell
55 who was named to the new post of senior vice
president, which refers to 2 positions. We there-
fore we need to extract 2 templates PersonIn:
Bronczek, PersonOut: Newell and PersonIn:
Newell, Post: senior vice president. The discourse
analysis is useful to extract the second template,
while rejecting another long-distance template
PersonIn: Bronczek, PersonOut: Newell, Post:
seniour vice president. Another remark is that it
is important to assign 2 anchors of
Cand_PersonIn and Cand_PersonOut for the
phrase Kenneth Newell.
The characteristic of the ACE corpus is that it
contains a large amount of variations, while only
2% of possible dependency paths are correct. Since
many of the relations occur only at the level of sin-
gle clause (for example, most instances of relation
At), the discourse analysis is used to eliminate
long-distance dependency paths. It allows us to
significantly decrease the dimensionality of the
problem. We noticed that 38% of relation paths in
ACE contain a single relation, 28% contain 2 rela-
tions and 34% contain 3 relations. For the case
of 3 relations, the analysis of dependency paths
alone is not sufficient to eliminate the unreliable
paths. Our results for general types and specific
subtypes are presented in Tables 6 and 7, respec-
tively.
</bodyText>
<table confidence="0.985649666666667">
Case (%) P R F1
Zhang et al.06 77% 65% 70%
ARE 79% 66% 73%
</table>
<tableCaption confidence="0.995829">
Table 4. Results on ACE RDC03, general types
</tableCaption>
<bodyText confidence="0.998088666666667">
Based on our results in Table 4, discourse and
dependency relations support each other in differ-
ent situations. We also notice that multiple in-
stances require modeling of entities in the path.
Thus, in our future work we need to enrich the
search space for relation patterns. This observation
corresponds to that reported in Zhang et al. (2006).
Discourse parsing is very important to reduce
the amount of variations for specific types on ACE
</bodyText>
<page confidence="0.97461">
598
</page>
<bodyText confidence="0.867611">
\x0cRDC03, as there are 48 possible anchor types.
</bodyText>
<table confidence="0.979796333333333">
Case (%) P R F1
Zhang et al.06 64% 51% 57%
ARE 67% 54% 61%
</table>
<tableCaption confidence="0.982401">
Table 5. Results on ACE RDC03, specific types
</tableCaption>
<bodyText confidence="0.9995649">
The relatively small improvement of results in
Table 5 may be attributed to the following reasons:
1) it is important to model the commonality rela-
tions, as was done by Zhou et al. (2006); and 2)
our relation paths do not encode entities. This is
different from Zhang et al. (2006), who were using
entities in their subtrees.
Overall, the results indicate that the use of dis-
course relations leads to improvement over the
state-of-art systems.
</bodyText>
<sectionHeader confidence="0.998165" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.9991935">
We presented a framework that permits the inte-
gration of discourse relations with dependency re-
lations. Different from previous works, we tried to
use the information about sentence structure based
on discourse analysis. Consequently, our system
improves the performance in comparison with the
state-of-art IE systems. Another advantage of our
approach is in using domain-independent parsers
and features. Therefore, ARE may be easily port-
able into new domains.
Currently, we explored only 2 types of relation
paths: dependency and discourse. For future re-
search, we plan to integrate more relations in our
multi-resolution framework.
</bodyText>
<sectionHeader confidence="0.991519" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999668515625">
P. Cimiano and U. Reyle. 2003. Ontology-based semantic
construction, underspecification and disambiguation. In
Proc of the Prospects and Advances in the Syntax-
Semantic Interface Workshop.
P. Cimiano, U. Reyle and J. Saric. 2005. Ontology-driven
discourse analysis for information extraction. Data &amp;
Knowledge Engineering, 55(1):59-83.
H.L. Chieu and H.T. Ng. 2002. A Maximum Entropy Ap-
proach to Information Extraction from Semi-Structured
and Free Text. In Proc of AAAI-2002.
F. Ciravegna. 2001. Adaptive Information Extraction from
Text by Rule Induction and Generalization. In Proc of
IJCAI-2001.
A. Culotta and J. Sorensen J. 2004. Dependency tree ker-
nels for relation extraction. In Proc of ACL-2004.
A. Dempster, N. Laird, and D. Rubin. 1977. Maximum
likelihood from incomplete data via the EM algorithm.
Journal of the Royal Statistical Society B, 39(1):138.
B. Grosz and C. Sidner. 1986. Attention, Intentions and
the Structure of Discourse. Computational Linguistics,
12(3):175-204.
M. Halliday and R. Hasan. 1976. Cohesion in English.
Longman, London.
D. Lin. 1997. Dependency-based Evaluation of Minipar. In
Workshop on the Evaluation of Parsing systems.
M. Maslennikov, H.K. Goh and T.S. Chua. 2006. ARE:
Instance Splitting Strategies for Dependency Relation-
based Information Extraction. In Proc of ACL-2006.
E. Miltsakaki. 2003. The Syntax-Discourse Interface: Ef-
fects of the Main-Subordinate Distinction on Attention
Structure. PhD thesis.
M.F. Moens and R. De Busser. 2002. First steps in building
a model for the retrieval of court decisions. International
Journal of Human-Computer Studies, 57(5):429-446.
S. Pradhan, W. Ward, K. Hacioglu, J. Martin and D. Juraf-
sky. 2004. Shallow Semantic Parsing using Support
Vector Machines. In Proc of HLT/NAACL-2004.
E. Riloff, J. Wiebe, and W. Phillips. 2005. Exploiting Sub-
jectivity Classification to Improve Information Extrac-
tion. In Proc of AAAI-2005.
S. Soderland. 1999. Learning Information Extraction Rules
for Semi-Structured and Free Text. Machine Learning,
34:233-272.
R. Soricut and D. Marcu. 2003. Sentence Level Discourse
Parsing using Syntactic and Lexical Information. In
Proc of HLT/NAACL.
M. Surdeanu, S. Harabagiu, J. Williams, P. Aarseth. 2003.
Using Predicate Arguments Structures for Information
Extraction. In Proc of ACL-2003.
M. Taboada and W. Mann. 2005. Applications of Rhetori-
cal Structure Theory. Discourse studies, 8(4).
B. Webber, M. Stone, A. Joshi and A. Knott. 2002.
Anaphora and Discourse Structure. Computational Lin-
guistics, 29(4).
J. Xiao, T.S. Chua and H. Cui. 2004. Cascading Use of
Soft and Hard Matching Pattern Rules for Weakly Su-
pervised Information Extraction. In Proc of COLING-
2004.
M. Zhang, J. Zhang, J. Su and G. Zhou. 2006. A Compos-
ite Kernel to Extract Relations between Entities with
both Flat and Structured Features. In Proc of ACL-2006.
G. Zhou, J. Su and M. Zhang. 2006. Modeling Commonal-
ity among Related Classes in Relation Extraction. In
Proc of ACL-2006.
</reference>
<page confidence="0.97173">
599
</page>
<figure confidence="0.255408">
\x0c&amp;quot;
</figure>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.439091">
<note confidence="0.913412333333333">b&amp;quot;Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 592599, Prague, Czech Republic, June 2007. c 2007 Association for Computational Linguistics</note>
<title confidence="0.725733">A Multi-resolution Framework for Information Extraction from Free Text</title>
<author confidence="0.930295">Mstislav Maslennikov</author>
<author confidence="0.930295">Tat-Seng Chua</author>
<affiliation confidence="0.999732">Department of Computer Science National University of Singapore</affiliation>
<email confidence="0.990305">maslenni@comp.nus.edu.sg</email>
<email confidence="0.990305">chuats@comp.nus.edu.sg</email>
<abstract confidence="0.990156833333333">Extraction of relations between entities is an important part of Information Extraction on free text. Previous methods are mostly based on statistical correlation and dependency relations between entities. This paper re-examines the problem at the multiresolution layers of phrase, clause and sentence using dependency and discourse relations. Our multi-resolution framework ARE (Anchor and Relation) uses clausal relations in 2 ways: 1) to filter noisy dependency paths; and 2) to increase reliability of dependency path extraction. The resulting system outperforms the previous approaches by 3%, 7%, 4% on MUC4, MUC6 and ACE RDC domains respectively.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>P Cimiano</author>
<author>U Reyle</author>
</authors>
<title>Ontology-based semantic construction, underspecification and disambiguation.</title>
<date>2003</date>
<booktitle>In Proc of the Prospects and Advances in the SyntaxSemantic Interface Workshop.</booktitle>
<marker>Cimiano, Reyle, 2003</marker>
<rawString>P. Cimiano and U. Reyle. 2003. Ontology-based semantic construction, underspecification and disambiguation. In Proc of the Prospects and Advances in the SyntaxSemantic Interface Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Cimiano</author>
<author>U Reyle</author>
<author>J Saric</author>
</authors>
<title>Ontology-driven discourse analysis for information extraction.</title>
<date>2005</date>
<journal>Data &amp; Knowledge Engineering,</journal>
<pages>55--1</pages>
<contexts>
<context position="6093" citStr="Cimiano et al. (2005)" startWordPosition="923" endWordPosition="926">onstructions such as X conducted an attack on Y under the verb frame attack (Pradhan et al. 2004). Hence, many useful predicate-argument structures will be missed. Moreover, semantic parsing belongs to the intra-clausal level of sentence analysis, which, as in the dependency case, will need the support of discourse analysis to bridge inter-clausal relations. Webber et al. (2002) reported that discourse structure helps to extract anaphoric relations. However, their set of grammatical rules is heuristic. Our task needs construction of an automated approach to be portable across several domains. Cimiano et al. (2005) employed a discourse-based analysis for IE. However, their approach requires a predefined domain-dependent ontology in the format of extended logical description grammar as described by Cimiano and Reely (2003). Moreover, they used discourse relations between events, whereas in our approach, discourse relations connect entities. 3 Motivation for using discourse relations Our method is based on Rhetorical Structure Theory (RST) by Taboada and Mann (2005). RST splits the texts into 2 parts: a) nuclei, the most important parts of texts; and b) satellites, the secondary parts. We can often remove</context>
</contexts>
<marker>Cimiano, Reyle, Saric, 2005</marker>
<rawString>P. Cimiano, U. Reyle and J. Saric. 2005. Ontology-driven discourse analysis for information extraction. Data &amp; Knowledge Engineering, 55(1):59-83.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H L Chieu</author>
<author>H T Ng</author>
</authors>
<title>A Maximum Entropy Approach to Information Extraction from Semi-Structured and Free Text.</title>
<date>2002</date>
<booktitle>In Proc of AAAI-2002.</booktitle>
<marker>Chieu, Ng, 2002</marker>
<rawString>H.L. Chieu and H.T. Ng. 2002. A Maximum Entropy Approach to Information Extraction from Semi-Structured and Free Text. In Proc of AAAI-2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Ciravegna</author>
</authors>
<title>Adaptive Information Extraction from Text by Rule Induction and Generalization.</title>
<date>2001</date>
<booktitle>In Proc of IJCAI-2001.</booktitle>
<marker>Ciravegna, 2001</marker>
<rawString>F. Ciravegna. 2001. Adaptive Information Extraction from Text by Rule Induction and Generalization. In Proc of IJCAI-2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Culotta</author>
<author>J Sorensen J</author>
</authors>
<title>Dependency tree kernels for relation extraction.</title>
<date>2004</date>
<booktitle>In Proc of ACL-2004.</booktitle>
<marker>Culotta, J, 2004</marker>
<rawString>A. Culotta and J. Sorensen J. 2004. Dependency tree kernels for relation extraction. In Proc of ACL-2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Dempster</author>
<author>N Laird</author>
<author>D Rubin</author>
</authors>
<title>Maximum likelihood from incomplete data via the EM algorithm.</title>
<date>1977</date>
<journal>Journal of the Royal Statistical Society B,</journal>
<volume>39</volume>
<issue>1</issue>
<marker>Dempster, Laird, Rubin, 1977</marker>
<rawString>A. Dempster, N. Laird, and D. Rubin. 1977. Maximum likelihood from incomplete data via the EM algorithm. Journal of the Royal Statistical Society B, 39(1):138.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Grosz</author>
<author>C Sidner</author>
</authors>
<date>1986</date>
<booktitle>Attention, Intentions and the Structure of Discourse. Computational Linguistics,</booktitle>
<pages>12--3</pages>
<contexts>
<context position="2532" citStr="Grosz and Sidner 1986" startWordPosition="376" endWordPosition="379">rent clauses. Since clauses in a sentence are connected by clausal relations (Halliday and Hasan, 1976), it is thus important to perform discourse analysis of a sentence. Discourse analysis may contribute to IE in several ways. First, Taboada and Mann (2005) reported that discourse analysis helps to decompose long sentences into clauses. Therefore, it helps to distinguish relevant clauses from non-relevant ones. Second, Miltsakaki (2003) stated that entities in subordinate clauses are less salient. Third, the knowledge of textual structure helps to interpret the meaning of entities in a text (Grosz and Sidner 1986). As an example, consider the sentences ABC Co. appointed a new chairman. Additionally, the current CEO was retired. The word additionally connects the event in the second sentence to the entity ABC Co. in the first sentence. Fourth, Moens and De Busser (2002) reported that discourse segments tend to be in a fixed order for structured texts such as court decisions or news. Hence, analysis of discourse order may reduce the variability of possible relations between entities. To model these factors, we propose a multiresolution framework ARE that integrates both discourse and dependency relations</context>
</contexts>
<marker>Grosz, Sidner, 1986</marker>
<rawString>B. Grosz and C. Sidner. 1986. Attention, Intentions and the Structure of Discourse. Computational Linguistics, 12(3):175-204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Halliday</author>
<author>R Hasan</author>
</authors>
<title>Cohesion in English.</title>
<date>1976</date>
<publisher>Longman,</publisher>
<location>London.</location>
<contexts>
<context position="2013" citStr="Halliday and Hasan, 1976" startWordPosition="296" endWordPosition="299"> filling and relation extraction, respectively. Previous approaches to IE relied on cooccurrence (Xiao et al., 2004) and dependency (Zhang et al., 2006) relations between entities. These relations enable us to make reliable extraction of correct entities/relations at the level of a single clause. However, Maslennikov et al. (2006) reported that the increase of relation path length will lead to considerable decrease in performance. In most cases, this decrease in performance occurs because entities may belong to different clauses. Since clauses in a sentence are connected by clausal relations (Halliday and Hasan, 1976), it is thus important to perform discourse analysis of a sentence. Discourse analysis may contribute to IE in several ways. First, Taboada and Mann (2005) reported that discourse analysis helps to decompose long sentences into clauses. Therefore, it helps to distinguish relevant clauses from non-relevant ones. Second, Miltsakaki (2003) stated that entities in subordinate clauses are less salient. Third, the knowledge of textual structure helps to interpret the meaning of entities in a text (Grosz and Sidner 1986). As an example, consider the sentences ABC Co. appointed a new chairman. Additio</context>
</contexts>
<marker>Halliday, Hasan, 1976</marker>
<rawString>M. Halliday and R. Hasan. 1976. Cohesion in English. Longman, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
</authors>
<title>Dependency-based Evaluation of Minipar.</title>
<date>1997</date>
<booktitle>In Workshop on the Evaluation of Parsing systems.</booktitle>
<marker>Lin, 1997</marker>
<rawString>D. Lin. 1997. Dependency-based Evaluation of Minipar. In Workshop on the Evaluation of Parsing systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Maslennikov</author>
<author>H K Goh</author>
<author>T S Chua</author>
</authors>
<title>ARE: Instance Splitting Strategies for Dependency Relationbased Information Extraction.</title>
<date>2006</date>
<booktitle>In Proc of ACL-2006.</booktitle>
<contexts>
<context position="1720" citStr="Maslennikov et al. (2006)" startWordPosition="252" endWordPosition="255"> (IE) is the task of identifying information in texts and converting it into a predefined format. The possible types of information include entities, relations or events. In this paper, we follow the IE tasks as defined by the conferences MUC4, MUC6 and ACE RDC: slotbased extraction, template filling and relation extraction, respectively. Previous approaches to IE relied on cooccurrence (Xiao et al., 2004) and dependency (Zhang et al., 2006) relations between entities. These relations enable us to make reliable extraction of correct entities/relations at the level of a single clause. However, Maslennikov et al. (2006) reported that the increase of relation path length will lead to considerable decrease in performance. In most cases, this decrease in performance occurs because entities may belong to different clauses. Since clauses in a sentence are connected by clausal relations (Halliday and Hasan, 1976), it is thus important to perform discourse analysis of a sentence. Discourse analysis may contribute to IE in several ways. First, Taboada and Mann (2005) reported that discourse analysis helps to decompose long sentences into clauses. Therefore, it helps to distinguish relevant clauses from non-relevant </context>
<context position="4783" citStr="Maslennikov et al. (2006)" startWordPosition="721" endWordPosition="724">. 2 Related work Recent work in IE focuses on relation-based, semantic parsing-based and discourse-based approaches. Several recent research efforts were based on modeling relations between entities. Culotta and Sorensen (2004) extracted relationships using dependency-based kernel trees in Support Vector Machines (SVM). They achieved an F1- measure of 63% in relation detection. The authors reported that the primary source of mistakes comes from the heterogeneous nature of non-relation instances. One possible direction to tackle this problem is to carry out further relationship classification. Maslennikov et al. (2006) classified relation path between candidate entities into simple, average and hard cases. This classification is based on the length of connecting path in dependency parse tree. They reported that dependency relations are not reliable for the hard cases, which, in our opinion, need the extraction of discourse relations to supplement dependency relation paths. Surdeanu et al. (2003) applied semantic parsing to capture the predicate-argument sentence structure. They suggested that semantic parsing is useful to capture verb arguments, which may be connected by long-distance dependency paths. Howe</context>
</contexts>
<marker>Maslennikov, Goh, Chua, 2006</marker>
<rawString>M. Maslennikov, H.K. Goh and T.S. Chua. 2006. ARE: Instance Splitting Strategies for Dependency Relationbased Information Extraction. In Proc of ACL-2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Miltsakaki</author>
</authors>
<title>The Syntax-Discourse Interface: Effects of the Main-Subordinate Distinction on Attention Structure.</title>
<date>2003</date>
<tech>PhD thesis.</tech>
<contexts>
<context position="2351" citStr="Miltsakaki (2003)" startWordPosition="349" endWordPosition="350"> the increase of relation path length will lead to considerable decrease in performance. In most cases, this decrease in performance occurs because entities may belong to different clauses. Since clauses in a sentence are connected by clausal relations (Halliday and Hasan, 1976), it is thus important to perform discourse analysis of a sentence. Discourse analysis may contribute to IE in several ways. First, Taboada and Mann (2005) reported that discourse analysis helps to decompose long sentences into clauses. Therefore, it helps to distinguish relevant clauses from non-relevant ones. Second, Miltsakaki (2003) stated that entities in subordinate clauses are less salient. Third, the knowledge of textual structure helps to interpret the meaning of entities in a text (Grosz and Sidner 1986). As an example, consider the sentences ABC Co. appointed a new chairman. Additionally, the current CEO was retired. The word additionally connects the event in the second sentence to the entity ABC Co. in the first sentence. Fourth, Moens and De Busser (2002) reported that discourse segments tend to be in a fixed order for structured texts such as court decisions or news. Hence, analysis of discourse order may redu</context>
</contexts>
<marker>Miltsakaki, 2003</marker>
<rawString>E. Miltsakaki. 2003. The Syntax-Discourse Interface: Effects of the Main-Subordinate Distinction on Attention Structure. PhD thesis.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M F Moens</author>
<author>R De Busser</author>
</authors>
<title>First steps in building a model for the retrieval of court decisions.</title>
<date>2002</date>
<journal>International Journal of Human-Computer Studies,</journal>
<pages>57--5</pages>
<marker>Moens, De Busser, 2002</marker>
<rawString>M.F. Moens and R. De Busser. 2002. First steps in building a model for the retrieval of court decisions. International Journal of Human-Computer Studies, 57(5):429-446.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pradhan</author>
<author>W Ward</author>
<author>K Hacioglu</author>
<author>J Martin</author>
<author>D Jurafsky</author>
</authors>
<title>Shallow Semantic Parsing using Support Vector Machines.</title>
<date>2004</date>
<booktitle>In Proc of HLT/NAACL-2004.</booktitle>
<contexts>
<context position="5569" citStr="Pradhan et al. 2004" startWordPosition="846" endWordPosition="849">parse tree. They reported that dependency relations are not reliable for the hard cases, which, in our opinion, need the extraction of discourse relations to supplement dependency relation paths. Surdeanu et al. (2003) applied semantic parsing to capture the predicate-argument sentence structure. They suggested that semantic parsing is useful to capture verb arguments, which may be connected by long-distance dependency paths. However, current semantic parsers such as the ASSERT are not able to recognize support verb constructions such as X conducted an attack on Y under the verb frame attack (Pradhan et al. 2004). Hence, many useful predicate-argument structures will be missed. Moreover, semantic parsing belongs to the intra-clausal level of sentence analysis, which, as in the dependency case, will need the support of discourse analysis to bridge inter-clausal relations. Webber et al. (2002) reported that discourse structure helps to extract anaphoric relations. However, their set of grammatical rules is heuristic. Our task needs construction of an automated approach to be portable across several domains. Cimiano et al. (2005) employed a discourse-based analysis for IE. However, their approach require</context>
</contexts>
<marker>Pradhan, Ward, Hacioglu, Martin, Jurafsky, 2004</marker>
<rawString>S. Pradhan, W. Ward, K. Hacioglu, J. Martin and D. Jurafsky. 2004. Shallow Semantic Parsing using Support Vector Machines. In Proc of HLT/NAACL-2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Riloff</author>
<author>J Wiebe</author>
<author>W Phillips</author>
</authors>
<title>Exploiting Subjectivity Classification to Improve Information Extraction.</title>
<date>2005</date>
<booktitle>In Proc of AAAI-2005.</booktitle>
<marker>Riloff, Wiebe, Phillips, 2005</marker>
<rawString>E. Riloff, J. Wiebe, and W. Phillips. 2005. Exploiting Subjectivity Classification to Improve Information Extraction. In Proc of AAAI-2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Soderland</author>
</authors>
<title>Learning Information Extraction Rules for Semi-Structured and Free Text.</title>
<date>1999</date>
<booktitle>Machine Learning,</booktitle>
<pages>34--233</pages>
<marker>Soderland, 1999</marker>
<rawString>S. Soderland. 1999. Learning Information Extraction Rules for Semi-Structured and Free Text. Machine Learning, 34:233-272.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Soricut</author>
<author>D Marcu</author>
</authors>
<title>Sentence Level Discourse Parsing using Syntactic and Lexical Information.</title>
<date>2003</date>
<booktitle>In Proc of HLT/NAACL.</booktitle>
<marker>Soricut, Marcu, 2003</marker>
<rawString>R. Soricut and D. Marcu. 2003. Sentence Level Discourse Parsing using Syntactic and Lexical Information. In Proc of HLT/NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Surdeanu</author>
<author>S Harabagiu</author>
<author>J Williams</author>
<author>P Aarseth</author>
</authors>
<date>2003</date>
<contexts>
<context position="5167" citStr="Surdeanu et al. (2003)" startWordPosition="780" endWordPosition="783">thors reported that the primary source of mistakes comes from the heterogeneous nature of non-relation instances. One possible direction to tackle this problem is to carry out further relationship classification. Maslennikov et al. (2006) classified relation path between candidate entities into simple, average and hard cases. This classification is based on the length of connecting path in dependency parse tree. They reported that dependency relations are not reliable for the hard cases, which, in our opinion, need the extraction of discourse relations to supplement dependency relation paths. Surdeanu et al. (2003) applied semantic parsing to capture the predicate-argument sentence structure. They suggested that semantic parsing is useful to capture verb arguments, which may be connected by long-distance dependency paths. However, current semantic parsers such as the ASSERT are not able to recognize support verb constructions such as X conducted an attack on Y under the verb frame attack (Pradhan et al. 2004). Hence, many useful predicate-argument structures will be missed. Moreover, semantic parsing belongs to the intra-clausal level of sentence analysis, which, as in the dependency case, will need the</context>
</contexts>
<marker>Surdeanu, Harabagiu, Williams, Aarseth, 2003</marker>
<rawString>M. Surdeanu, S. Harabagiu, J. Williams, P. Aarseth. 2003.</rawString>
</citation>
<citation valid="false">
<title>Using Predicate Argument Structures for Information Extraction.</title>
<booktitle>In Proc of ACL-2003.</booktitle>
<marker></marker>
<rawString>Using Predicate Arguments Structures for Information Extraction. In Proc of ACL-2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Taboada</author>
<author>W Mann</author>
</authors>
<date>2005</date>
<booktitle>Applications of Rhetorical Structure Theory. Discourse studies,</booktitle>
<pages>8--4</pages>
<contexts>
<context position="2168" citStr="Taboada and Mann (2005)" startWordPosition="322" endWordPosition="325">tions between entities. These relations enable us to make reliable extraction of correct entities/relations at the level of a single clause. However, Maslennikov et al. (2006) reported that the increase of relation path length will lead to considerable decrease in performance. In most cases, this decrease in performance occurs because entities may belong to different clauses. Since clauses in a sentence are connected by clausal relations (Halliday and Hasan, 1976), it is thus important to perform discourse analysis of a sentence. Discourse analysis may contribute to IE in several ways. First, Taboada and Mann (2005) reported that discourse analysis helps to decompose long sentences into clauses. Therefore, it helps to distinguish relevant clauses from non-relevant ones. Second, Miltsakaki (2003) stated that entities in subordinate clauses are less salient. Third, the knowledge of textual structure helps to interpret the meaning of entities in a text (Grosz and Sidner 1986). As an example, consider the sentences ABC Co. appointed a new chairman. Additionally, the current CEO was retired. The word additionally connects the event in the second sentence to the entity ABC Co. in the first sentence. Fourth, Mo</context>
</contexts>
<marker>Taboada, Mann, 2005</marker>
<rawString>M. Taboada and W. Mann. 2005. Applications of Rhetorical Structure Theory. Discourse studies, 8(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Webber</author>
<author>M Stone</author>
<author>A Joshi</author>
<author>A Knott</author>
</authors>
<date>2002</date>
<booktitle>Anaphora and Discourse Structure. Computational Linguistics,</booktitle>
<volume>29</volume>
<issue>4</issue>
<contexts>
<context position="5853" citStr="Webber et al. (2002)" startWordPosition="887" endWordPosition="890">ce structure. They suggested that semantic parsing is useful to capture verb arguments, which may be connected by long-distance dependency paths. However, current semantic parsers such as the ASSERT are not able to recognize support verb constructions such as X conducted an attack on Y under the verb frame attack (Pradhan et al. 2004). Hence, many useful predicate-argument structures will be missed. Moreover, semantic parsing belongs to the intra-clausal level of sentence analysis, which, as in the dependency case, will need the support of discourse analysis to bridge inter-clausal relations. Webber et al. (2002) reported that discourse structure helps to extract anaphoric relations. However, their set of grammatical rules is heuristic. Our task needs construction of an automated approach to be portable across several domains. Cimiano et al. (2005) employed a discourse-based analysis for IE. However, their approach requires a predefined domain-dependent ontology in the format of extended logical description grammar as described by Cimiano and Reely (2003). Moreover, they used discourse relations between events, whereas in our approach, discourse relations connect entities. 3 Motivation for using disco</context>
</contexts>
<marker>Webber, Stone, Joshi, Knott, 2002</marker>
<rawString>B. Webber, M. Stone, A. Joshi and A. Knott. 2002. Anaphora and Discourse Structure. Computational Linguistics, 29(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Xiao</author>
<author>T S Chua</author>
<author>H Cui</author>
</authors>
<title>Cascading Use of Soft and Hard Matching Pattern Rules for Weakly Supervised Information Extraction.</title>
<date>2004</date>
<booktitle>In Proc of COLING2004.</booktitle>
<contexts>
<context position="1504" citStr="Xiao et al., 2004" startWordPosition="219" endWordPosition="222"> increase reliability of dependency path extraction. The resulting system outperforms the previous approaches by 3%, 7%, 4% on MUC4, MUC6 and ACE RDC domains respectively. 1 Introduction Information Extraction (IE) is the task of identifying information in texts and converting it into a predefined format. The possible types of information include entities, relations or events. In this paper, we follow the IE tasks as defined by the conferences MUC4, MUC6 and ACE RDC: slotbased extraction, template filling and relation extraction, respectively. Previous approaches to IE relied on cooccurrence (Xiao et al., 2004) and dependency (Zhang et al., 2006) relations between entities. These relations enable us to make reliable extraction of correct entities/relations at the level of a single clause. However, Maslennikov et al. (2006) reported that the increase of relation path length will lead to considerable decrease in performance. In most cases, this decrease in performance occurs because entities may belong to different clauses. Since clauses in a sentence are connected by clausal relations (Halliday and Hasan, 1976), it is thus important to perform discourse analysis of a sentence. Discourse analysis may </context>
</contexts>
<marker>Xiao, Chua, Cui, 2004</marker>
<rawString>J. Xiao, T.S. Chua and H. Cui. 2004. Cascading Use of Soft and Hard Matching Pattern Rules for Weakly Supervised Information Extraction. In Proc of COLING2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Zhang</author>
<author>J Zhang</author>
<author>J Su</author>
<author>G Zhou</author>
</authors>
<title>A Composite Kernel to Extract Relations between Entities with both Flat and Structured Features.</title>
<date>2006</date>
<booktitle>In Proc of ACL-2006.</booktitle>
<contexts>
<context position="1540" citStr="Zhang et al., 2006" startWordPosition="225" endWordPosition="228"> path extraction. The resulting system outperforms the previous approaches by 3%, 7%, 4% on MUC4, MUC6 and ACE RDC domains respectively. 1 Introduction Information Extraction (IE) is the task of identifying information in texts and converting it into a predefined format. The possible types of information include entities, relations or events. In this paper, we follow the IE tasks as defined by the conferences MUC4, MUC6 and ACE RDC: slotbased extraction, template filling and relation extraction, respectively. Previous approaches to IE relied on cooccurrence (Xiao et al., 2004) and dependency (Zhang et al., 2006) relations between entities. These relations enable us to make reliable extraction of correct entities/relations at the level of a single clause. However, Maslennikov et al. (2006) reported that the increase of relation path length will lead to considerable decrease in performance. In most cases, this decrease in performance occurs because entities may belong to different clauses. Since clauses in a sentence are connected by clausal relations (Halliday and Hasan, 1976), it is thus important to perform discourse analysis of a sentence. Discourse analysis may contribute to IE in several ways. Fi</context>
</contexts>
<marker>Zhang, Zhang, Su, Zhou, 2006</marker>
<rawString>M. Zhang, J. Zhang, J. Su and G. Zhou. 2006. A Composite Kernel to Extract Relations between Entities with both Flat and Structured Features. In Proc of ACL-2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Zhou</author>
<author>J Su</author>
<author>M Zhang</author>
</authors>
<title>Modeling Commonality among Related Classes in Relation Extraction.</title>
<date>2006</date>
<booktitle>In Proc of ACL-2006.</booktitle>
<marker>Zhou, Su, Zhang, 2006</marker>
<rawString>G. Zhou, J. Su and M. Zhang. 2006. Modeling Commonality among Related Classes in Relation Extraction. In Proc of ACL-2006.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>