As the source of Neg, we used 600 million Japanese Web pages CITATION and the ClueWeb09 corpus for English (about 504 million pages) and Chinese (about 177 million pages).4 From each Web corpus, we collected the sentences satisfying following conditions: 1) they contain 5 to 50 words and at least one verb, 2) less than half of their words are numbers, and 3) they end with a period,,
1 Introduction Automatic paraphrasing has been recognized as an important component for NLP systems, and many methods have been proposed to acquire paraphrase knowledge (CITATION; CITATION; CITATION; CITATION; CITATION; Callison-Burch, 2008; Hashimoto et al., 2011; CITATION),,
se extraction method is mostly language-independent and, through experiments for the three languages, we show that it outperforms unsupervised methods (CITATION; CITATION) and is comparable to Hashimoto et al.s supervised method for Japanese,,
Previous methods for paraphrase (and entailment) extraction can be classified into a distributional similarity based approach (CITATION; CITATION; Bhagat et al., 2007; CITATION; Hashimoto et al., 2009) and a parallel corpus based approach (CITATION; CITATION; CITATION; CITATION; Callison-Burch, 2008),,
The former can exploit large scale monolingual corpora, but is known to be unable to distinguish paraphrase pairs from antonymous pairs CITATION,,
1 Introduction Automatic paraphrasing has been recognized as an important component for NLP systems, and many methods have been proposed to acquire paraphrase knowledge (CITATION; CITATION; CITATION; CITATION; CITATION; Callison-Burch, 2008; Hashimoto et al., 2011; CITATION),,
Our paraphrase extraction method is mostly language-independent and, through experiments for the three languages, we show that it outperforms unsupervised methods (CITATION; CITATION) and is comparable to Hashimoto et al.s supervised method for Japanese,,
Previous methods for paraphrase (and entailment) extraction can be classified into a distributional similarity based approach (CITATION; CITATION; Bhagat et al., 2007; CITATION; Hashimoto et al., 2009) and a parallel corpus based approach (CITATION; CITATION; CITATION; CITATION; Callison-Burch, 2008),,
The former can exploit large scale monolingual corpora, but is known to be unable to distinguish paraphrase pairs from antonymous pairs CITATION,,
Cohens kappa CITATION was 0.55 for English (moderate agreement CITATION), 0.73 for Japanese (substantial agreement), and 0.69 for Chinese (substantial agreement),,
Cohens kappa CITATION was 0.83 for English, 0.88 for Japanese, 5 We filtered out phrase pairs in which one phrase contained a named entity but the other did not contain the named entity from the output of ProposedScore, Proposedlocal, SMT, and P&D, since most of them were not paraphrases,,
We used Stanford NER CITATION for English named entity recognition (NER), KNP for Japanese NER, and BaseNER CITATION for Chinese NER,,
1 Introduction Automatic paraphrasing has been recognized as an important component for NLP systems, and many methods have been proposed to acquire paraphrase knowledge (CITATION; CITATION; CITATION; CITATION; CITATION; Callison-Burch, 2008; Hashimoto et al., 2011; CITATION),,
mostly language-independent and, through experiments for the three languages, we show that it outperforms unsupervised methods (CITATION; CITATION) and is comparable to Hashimoto et al.s supervised method for Japanese,,
Previous methods for paraphrase (and entailment) extraction can be classified into a distributional similarity based approach (CITATION; CITATION; Bhagat et al., 2007; CITATION; Hashimoto et al., 2009) and a parallel corpus based approach (CITATION; CITATION; CITATION; CITATION; Callison-Burch, 2008),,
The former can exploit large scale monolingual corpora, but is known to be unable to distinguish paraphrase pairs from antonymous pairs CITATION,,
The probability rate is based on the growth rate CITATION,,
Cohens kappa CITATION was 0.83 for English, 0.88 for Japanese, 5 We filtered out phrase pairs in which one phrase contained a named entity but the other did not contain the named entity from the output of ProposedScore, Proposedlocal, SMT, and P&D, since most of them were not paraphrases,,
We used Stanford NER CITATION for English named entity recognition (NER), KNP for Japanese NER, and BaseNER CITATION for Chinese NER,,
and 0.85 for Chinese, all of which indicated reasonably good CITATION,,
SMT: The phrase table construction method of Moses CITATION,,
P&D: The distributional similarity based method by Pasca and Dienes CITATION (their N-gram-Only method),,
Following Pasca and Dienes CITATION, we used the parameters LC = 3 and MaxP = 4, while MinP, which was 1 in Pasca and Dienes CITATION, was set to 2 since our target was phrasal paraphrases,,
1 Introduction Automatic paraphrasing has been recognized as an important component for NLP systems, and many methods have been proposed to acquire paraphrase knowledge (CITATION; CITATION; CITATION; CITATION; CITATION; Callison-Burch, 2008; Hashimoto et al., 2011; CITATION),,
Our paraphrase extraction method is mostly language-independent and, through experiments for the three languages, we show that it outperforms unsupervised methods (CITATION; CITATION) and is comparable to Hashimoto et al.s supervised method for Japanese,,
Previous methods for paraphrase (and entailment) extraction can be classified into a distributional similarity based approach (CITATION; CITATION; Bhagat et al., 2007; CITATION; Hashimoto et al., 2009) and a parallel corpus based approach (CITATION; CITATION; CITATION; CITATION; Callison-Burch, 2008),,
The former can exploit large scale monolingual corpora, but is known to be unable to distinguish paraphrase pairs from antonymous pairs CITATION,,
Wikipedia articles, which can be regarded as the definition of the title of Wikipedia article CITATION and hence can be used as positive examples,,
Our paraphrase extraction method is mostly language-independent and, through experiments for the three languages, we show that it outperforms unsupervised methods (CITATION; CITATION) and is comparable to Hashimoto et al.s supervised method for Japanese,,
Previous methods for paraphrase (and entailment) extraction can be classified into a distributional similarity based approach (CITATION; CITATION; Bhagat et al., 2007; CITATION; Hashimoto et al., 2009) and a parallel corpus based approach (CITATION; CITATION; CITATION; CITATION; Callison-Burch, 2008),,
SMT: The phrase table construction method of Moses CITATION,,
P&D: The distributional similarity based method by Pasca and Dienes CITATION (their N-gram-Only method),,
Following Pasca and Dienes CITATION, we used the parameters LC = 3 and MaxP = 4, while MinP, which was 1 in Pasca and Dienes,,
We used TreeTagger and MSTParser CITATION for English, JUMAN (CITATIONa) and KNP (CITATIONb) for Japanese, MMA CITATION and CNP (Chen et al., 2009) for Chinese,,
3.1.2 Comparison with Previous Methods We compared our method with the state-of-theart supervised methods proposed by CITATION, using their WCL datasets v1.0 (http: //lcl.uniroma1.it/wcl/), definition and nondefinition datasets for English CITATION,,
We used TreeTagger and MSTParser CITATION for English, JUMAN (CITATIONa) and KNP (CITATIONb) for Japanese, MMA CITATION and CNP (Chen et al., 2009) for Chinese,,
3.1.2 Comparison with Previous Methods We compared our method with the state-of-theart supervised methods proposed by CITATION, using their WCL datasets v1.0 (http: //lcl.uniroma1.it/wcl/), definition and nondefinition datasets for English CITATION,,
We used TreeTagger and MSTParser CITATION for English, JUMAN (CITATIONa) and KNP (CITATIONb) for Japanese, MMA CITATION and CNP (Chen et al., 2009) for Chinese,,
3.1.2 Comparison with Previous Methods We compared our method with the state-of-theart supervised methods proposed by CITATION, using their WCL datasets v1.0 (http: //lcl.uniroma1.it/wcl/), definition and nondefinition datasets for English CITATION,,
Cohens kappa CITATION was 0.55 for English (moderate agreement CITATION), 0.73 for Japanese (substantial agreement), and 0.69 for Chinese (substantial agreement),,
We used Stanford NER CITATION for English named entity recognition (NER), KNP for Japanese NER, and BaseNER CITATION for Chinese NER,,
and 0.85 for Chinese, all of which indicated reasonably good CITATION,,
1 Introduction Automatic paraphrasing has been recognized as an important component for NLP systems, and many methods have been proposed to acquire paraphrase knowledge (CITATION; CITATION; CITATION; CITATION; CITATION; Callison-Burch, 2008; Hashimoto et al., 2011; CITATION),,
Our paraphrase extraction method is mostly language-independent and, through experiments for the three languages, we show that it outperforms unsupervised methods (CITATION; CITATION) and is comparable to Hashimoto et al.s supervised method for Japanese,,
Previous methods for paraphrase (and entailment) extraction can be classified into a distributional similarity based approach (CITATION; CITATION; Bhagat et al., 2007; CITATION; Hashimoto et al., 2009) and a parallel corpus based approach (CITATION; CITATION; CITATION; CITATION; Callison-Burch, 2008),,
The former can exploit large scale monolingual corpora, but is known to be unable to distinguish paraphrase pairs from antonymous pairs CITATION,,
Previous methods for paraphrase (and entailment) extraction can be classified into a distributional similarity based approach (CITATION; CITATION; Bhagat et al., 2007; CITATION; Hashimoto et al., 2009) and a parallel corpus based approach (CITATION; CITATION; CITATION; CITATION; Callison-Burch, 2008),,
The former can exploit large scale monolingual corpora, but is known to be unable to distinguish paraphrase pairs from antonymous pairs CITATION,,
We used TreeTagger and MSTParser CITATION for English, JUMAN (CITATIONa) and KNP (CITATIONb) for Japanese, MMA CITATION and CNP (Chen et al., 2009) for Chinese,,
3.1.2 Comparison with Previous Methods We compared our method with the state-of-theart supervised methods proposed by CITATION, using their WCL datasets v1.0 (http: //lcl.uniroma1.it/wcl/), definition and nondefinition datasets for English CITATION,,
We show that our method is applicable to English, Japanese, and Chinese, and that its performance is comparable to state-of-the-art supervised methods CITATION,,
3 Experiments 3.1 Experiments of Definition Extraction We show that our unsupervised definition extraction method is competitive with state-of-the-art supervised methods for English CITATION, and that it extracts a large number of definitions reasonably accurately for English (3,216,121 definitions with 70% precision), Japanese (651,293 definitions with 62.5% precision), and Chinese (682,661 definitions with 67% precision),,
We used TreeTagger and MSTParser CITATION for English, JUMAN (CITATIONa) and KNP (CITATIONb) for Japanese, MMA CITATION and CNP (Chen et al., 2009) for Chinese,,
3.1.2 Comparison with Previous Methods We compared our method with the state-of-theart supervised methods proposed by CITATION, using their WCL datasets v1.0 (http: //lcl.uniroma1.it/wcl/), definition and nondefinition datasets for English CITATION,,
We used TreeTagger and MSTParser CITATION for English, JUMAN (CITATIONa) and KNP (CITATIONb) for Japanese, MMA CITATION and CNP (Chen et al., 2009) for Chinese,,
3.1.2 Comparison with Previous Methods We compared our method with the state-of-theart supervised methods proposed by CITATION, using their WCL datasets v1.0 (http: //lcl.uniroma1.it/wcl/), definition and nondefinition datasets for English CITATION,,
WCL-1 and WCL-3 are methods proposed by CITATION,,
Our paraphrase extraction method is mostly language-independent and, through experiments for the three languages, we show that it outperforms unsupervised methods (CITATION; CITATION) and is comparable to Hashimoto et al.s supervised method for Japanese,,
Previous methods for paraphrase (and entailment) extraction can be classified into a distributional similarity based approach (CITATION; CITATION; Bhagat et al., 2007; CITATION; Hashimoto et al., 2009) and a parallel corpus based approach (CITATION; CITATION; CITATION; CITATION; Callison-Burch, 2008),,
SMT: The phrase table construction method of Moses CITATION,,
P&D: The distributional similarity based method by Pasca and Dienes CITATION (their N-gram-Only method),,
Following Pasca and Dienes CITATION, we used the parameters LC = 3 and MaxP = 4, while MinP, which was 1 in Pasca and Dienes CITATION, was set to 2 since our target was phrasal paraphrases,,
For English, NPs are identified using TreeTagger CITATION and two NPs are merged into one when they are connected by for or of,,
1 Introduction Automatic paraphrasing has been recognized as an important component for NLP systems, and many methods have been proposed to acquire paraphrase knowledge (CITATION; CITATION; CITATION; CITATION; CITATION; Callison-Burch, 2008; Hashimoto et al., 2011; CITATION),,
Our paraphrase extraction method is mostly language-independent and, through experiments for the three languages, we show that it outperforms unsupervised methods (CITATION; CITATION) and is comparable to Hashimoto et al.s supervised method for Japanese,,
Previous methods for paraphrase (and entailment) extraction can be classified into a distributional similarity based approach (CITATION; CITATION; Bhagat et al., 2007; CITATION; Hashimoto et al., 2009) and a parallel corpus based approach (CITATION; CITATION; CITATION; CITATION; Callison-Burch, 2008),,
The former can exploit large scale monolingual corpora, but is known to be unable to distinguish paraphrase pairs from antonymous pairs CITATION,,
Our paraphrase extraction method is mostly language-independent and, through experiments for the three languages, we show that it outperforms unsupervised methods (CITATION; CITATION) and is comparable to Hashimoto et al.s supervised method for Japanese,,
Previous methods for paraphrase (and entailment) extraction can be classified into a distributional similarity based approach (CITATION; CITATION; Bhagat et al., 2007; CITATION; Hashimoto et al., 2009) and a parallel corpus based approach (CITATION; CITATION; CITATION; CITATION; Callison-Burch, 2008),,
The former can exploit large scale monolingual corpora, but is known to be unable to distinguish paraphrase pairs from antonymous pairs CITATION,,
Cohens kappa CITATION was 0.83 for English, 0.88 for Japanese, 5 We filtered out phrase pairs in which one phrase contained a named entity but the other did not contain the named entity from the output of ProposedScore, Proposedlocal, SMT, and P&D, since most of them were not paraphrases,,
We used Stanford NER CITATION for English named entity recognition (NER), KNP for Japanese NER, and BaseNER CITATION for Chinese NER,,
and 0.85 for Chinese, all of which indicated reasonably good CITATION,,
