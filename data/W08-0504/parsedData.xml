<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<keyword confidence="0.5969305">
b&amp;quot;Software Engineering, Testing, and Quality Assurance for Natural Language Processing, pages 1420,
Columbus, Ohio, USA, June 2008. c
</keyword>
<sectionHeader confidence="0.465745" genericHeader="abstract">
2008 Association for Computational Linguistics
</sectionHeader>
<title confidence="0.480994">
Evaluating the Effects of Treebank Size in a Practical Application for
</title>
<table confidence="0.5488792">
Parsing
Kenji Sagae1
, Yusuke Miyao1
, Rune Stre1
and Jun&apos;ichi Tsujii1,2,3
</table>
<page confidence="0.585053">
1
</page>
<affiliation confidence="0.761741">
Department of Computer Science, Univerisity of Tokyo, Japan
</affiliation>
<page confidence="0.817182">
2
</page>
<affiliation confidence="0.768312">
School of Computer Science, University of Manchester
</affiliation>
<page confidence="0.936489">
3
</page>
<affiliation confidence="0.754476">
National Center for Text Mining, Manchester, UK
</affiliation>
<email confidence="0.974424">
{sagae,yusuke,rune.saetre,tsujii@is.s.u-tokyo.ac.jp}
</email>
<sectionHeader confidence="0.989159" genericHeader="keywords">
Abstract
</sectionHeader>
<bodyText confidence="0.999179583333333">
Natural language processing modules such as
part-of-speech taggers, named-entity recog-
nizers and syntactic parsers are commonly
evaluated in isolation, under the assumption
that artificial evaluation metrics for individual
parts are predictive of practical performance
of more complex language technology sys-
tems that perform practical tasks. Although
this is an important issue in the design and en-
gineering of systems that use natural language
input, it is often unclear how the accuracy of
an end-user application is affected by parame-
ters that affect individual NLP modules. We
explore this issue in the context of a specific
task by examining the relationship between
the accuracy of a syntactic parser and the
overall performance of an information extrac-
tion system for biomedical text that includes
the parser as one of its components. We
present an empirical investigation of the rela-
tionship between factors that affect the accu-
racy of syntactic analysis, and how the
difference in parse accuracy affects the overall
system.
</bodyText>
<sectionHeader confidence="0.99828" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998874">
Software systems that perform practical tasks with
natural language input often include, in addition to
task-specific components, a pipeline of basic natu-
ral language processing modules, such as part-of-
speech taggers, named-entity recognizers, syntactic
parsers and semantic-role labelers. Although such
building blocks of larger language technology so-
lutions are usually carefully evaluated in isolation
using standard test sets, the impact of improve-
ments in each individual module on the overall
performance of end-to-end systems is less well
understood. While the effects of the amount of
training data, search beam widths and various ma-
chine learning frameworks have been explored in
detail with respect to speed and accuracy in basic
natural language processing tasks, how these trade-
offs in individual modules affect the performance
of the larger systems they compose is an issue that
has received relatively little attention. This issue,
however, is of great practical importance in the
effective design and engineering of complex soft-
ware systems that deal with natural language.
In this paper we explore some of these issues
empirically in an information extraction task in the
biomedical domain, the identification of protein-
protein interactions (PPI) mentioned in papers ab-
stracts from MEDLINE, a large database of bio-
medical papers. Due in large part to the creation of
biomedical treebanks (Kulick et al., 2004; Tateisi
et al., 2005) and rapid progress of data-driven
parsers (Lease and Charniak, 2005; Nivre et al.,
2007), there are now fast, robust and accurate syn-
tactic parsers for text in the biomedical domain.
Recent research shows that parsing accuracy of
biomedical corpora is now between 80% and 90%
(Clegg and Shepherd, 2007; Pyysalo et al., 2007;
Sagae et al., 2008). Intuitively, syntactic relation-
ships between words should be valuable in deter-
mining possible interactions between entities
present in text. Recent PPI extraction systems
have confirmed this intuition (Erkan et al., 2007;
Stre et al., 2007; Katrenko and Adriaans, 2006).
While it is now relatively clear that syntactic
parsing is useful in practical tasks that use natural
language corpora in bioinformatics, several ques-
</bodyText>
<page confidence="0.99907">
14
</page>
<bodyText confidence="0.999677">
\x0ctions remain as to research issues that affect the
design and testing of end-user applications, includ-
ing how syntactic analyses should be used in a
practical setting, whether further improvements in
parsing technologies will result in further im-
provements in practical systems, whether it is im-
portant to continue the development of treebanks
and parser adaptation techniques for the biomedi-
cal domain, and how much effort should be spent
on comparing and benchmarking parsers for bio-
medical data. We attempt to shed some light on
these matters by presenting experiments that show
the relationship of the accuracy of a dependency
parser and the accuracy of the larger PPI system
that includes the parser. We investigate the effects
of domain-specific treebank size (the amount of
available manually annotated training data for syn-
tactic parsers) and final system performance, and
obtain results that should be informative to re-
searchers in bioinformatics who rely on existing
NLP resources to design information extraction
systems, as well as to members of the parsing
community who are interested in the practical im-
pact of parsing research.
In section 2 we discuss our motivation and re-
lated efforts. Section 3 describes the system for
identification of protein-protein interactions used
in our experiments, and in section 4 describes the
syntactic parser that provides the analyses for the
PPI system, and the data used to train the parser.
We describe our experiments, results and analysis
in section 5, and conclude in section 6.
</bodyText>
<sectionHeader confidence="0.738376" genericHeader="method">
2 Motivation and related work
</sectionHeader>
<bodyText confidence="0.998795036363636">
While recent work has addressed questions relating
to the use of different parsers or different types of
syntactic representations in the PPI extraction task
(Stre et al., 2007, Miyao et al., 2008), little con-
crete evidence has been provided for potential ben-
efits of improved parsers or additional resources
for training syntactic parsers. In fact, although
there is increasing interest in parser evaluation in
the biomedical domain in terms of precision/recall
of brackets and dependency accuracy (Clegg and
Shepherd, 2007; Pyysalo et al., 2007; Sagae et al.,
2008), the relationship between these evaluation
metrics and the performance of practical informa-
tion extraction systems remains unclear. In the
parsing community, relatively small accuracy gains
are often reported as success stories, but again, the
precise impact of such improvements on practical
tasks in bioinformatics has not been established.
One aspect of this issue is the question of do-
main portability and domain adaptation for parsers
and other NLP modules. Clegg and Shepherd
(2007) mention that available statistical parsers
appear to overfit to the newswire domain, because
of their extensive use of the Wall Street Journal
portion of the Penn Treebank (Marcus et al., 1994)
during development and training. While this claim
is supported by convincing evaluations that show
that parsers trained on the WSJ Penn Treebank
alone perform poorly on biomedical text in terms
of accuracy of dependencies or bracketing of
phrase structure, the benefits of using domain-
specific data in terms of practical system perfor-
mance have not been quantified. These expected
benefits drive the development of domain-specific
resources, such as the GENIA treebank (Tateisi et
al., 2005), and parser domain adaption (Hara et al.,
2007), which are of clear importance in parsing
research, but of largely unconfirmed impact on
practical systems.
Quirk and Corston-Oliver (2006) examine a
similar issue, the relationship between parser accu-
racy and overall system accuracy in syntax-
informed machine translation. Their research is
similar to the work presented here, but they fo-
cused on the use of varying amounts of out-of-
domain training data for the parser, measuring how
a translation system for technical text performed
when its syntactic parser was trained with varying
amounts of Wall Street Journal text. Our work, in
contrast, investigates the use of domain-specific
training material in parsers for biomedical text, a
domain where significant amounts of effort are
allocated for development of domain-specific NLP
resources in hope that such resources will result in
better overall performance in practical systems.
</bodyText>
<sectionHeader confidence="0.963045" genericHeader="method">
3 A PPI extraction system based on syn-
</sectionHeader>
<bodyText confidence="0.992647875">
tactic parsing
PPI extraction is an NLP task to identify protein
pairs that are mentioned as interacting in biomedi-
cal papers. Figure 2 shows two sentences that in-
clude protein names: the former sentence mentions
a protein interaction, while the latter does not.
Given a protein pair, PPI extraction is a task of
binary classification; for example, &lt;IL-8, CXCR1&gt;
</bodyText>
<page confidence="0.986941">
15
</page>
<bodyText confidence="0.997356184210526">
\x0cis a positive example, and &lt;RBP, TTR&gt; is a ne-
gative example.
Following recent work on using dependency
parsing in systems that identify protein interactions
in biomedical text (Erkan et al., 2007; Stre et al.,
2007; Katrenko and Adriaans, 2006), we have built
a system for PPI extraction that uses dependency
relations as features. As exemplified, for the pro-
tein pair IL-8 and CXCR1 in the first sentence of
Figure 2, a dependency parser outputs a dependen-
cy tree shown in Figure 1. From this dependency
tree, we can extract a dependency path between
IL-8 and CXCR1 (Figure 3), which appears to be
a strong clue in knowing that these proteins are
mentioned as interacting.
The system we use in this paper is similar to the
one described in Stre et al. (2007), except that it
uses syntactic dependency paths obtained with a
dependency parser, but not predicate-argument
paths based on deep-parsing. This method is based
on SVM with SubSet Tree Kernels (Collins, 2002;
Moschitti, 2006). A dependency path is encoded
as a flat tree as depicted in Figure 4. Because a tree
kernel measures the similarity of trees by counting
common subtrees, it is expected that the system
finds effective subsequences of dependency paths.
In addition to syntactic dependency features, we
incorporate bag-of-words features, which are re-
garded as a strong baseline for IE systems. We use
lemmas of words before, between and after the pair
of target proteins.
In this paper, we use Aimed (Bunescu and
Mooney, 2004), which is a popular benchmark for
the evaluation of PPI extraction systems. The
Aimed corpus consists of 225 biomedical paper
abstracts (1970 sentences), which are sentence-
split, tokenized, and annotated with proteins and
PPIs.
</bodyText>
<sectionHeader confidence="0.784983" genericHeader="method">
4 A data-driven dependency parser for
</sectionHeader>
<bodyText confidence="0.97866096875">
biomedical text
The parser we used as component of our PPI ex-
traction system was a shift-reduce dependency
parser that uses maximum entropy models to de-
termine the parsers actions. Our overall parsing
approach uses a best-first probabilistic shift-reduce
algorithm, working left-to right to find labeled de-
pendencies one at a time. The algorithm is essen-
tially a dependency version of the constituent
parsing algorithm for probabilistic parsing with
LR-like data-driven models described by Sagae
and Lavie (2006). This dependency parser has
been shown to have state-of-the-art accuracy in the
CoNLL shared tasks on dependency parsing
(Buchholz and Marsi, 2006; Nivre, 2007). Sagae
and Tsujii (2007) present a detailed description of
the parsing approach used in our work, including
the parsing algorithm and the features used to clas-
sify parser actions. In summary, the parser uses an
algorithm similar to the LR parsing algorithm
(Knuth, 1965), keeping a stack of partially built
syntactic structures, and a queue of remaining in-
put tokens. At each step in the parsing process, the
parser can apply a shift action (remove a token
from the front of the queue and place it on top of
the stack), or a reduce action (pop the two topmost
This study demonstrates that IL-8 recognizes
and activates CXCR1, CXCR2, and the Duf-
fy antigen by distinct mechanisms.
The molar ratio of serum retinol-binding pro-
tein (RBP) to transthyretin (TTR) is not
useful to assess vitamin A status during infec-
</bodyText>
<figureCaption confidence="0.926315666666667">
tion in hospitalized children.
Figure 2: Example sentences with protein names
Figure 1: A dependency tree
</figureCaption>
<figure confidence="0.940233285714286">
ROOT IL-8 recognizes and activates CXCR1
ROOT
SBJ
OBJ
COORD
CC
ENTITY1(IL-8) recognizes ENTITY2(CXCR1)
</figure>
<figureCaption confidence="0.989192">
Figure 3: A dependency path between protein names
</figureCaption>
<sectionHeader confidence="0.461589" genericHeader="method">
SBJ OBJ
</sectionHeader>
<page confidence="0.975579">
16
</page>
<bodyText confidence="0.99724585106383">
\x0cstack items, and push a new item composed of the
two popped items combined in a single structure).
This parsing approach is very similar to the one
used successfully by Nivre et al. (2006), but we
use a maximum entropy classifier (Berger et al.,
1996) to determine parser actions, which makes
parsing considerably faster. In addition, our pars-
ing approach performs a search over the space of
possible parser actions, while Nivre et al.s ap-
proach is deterministic.
The parser was trained using 8,000 sentences
from the GENIA Treebank (Tateisi et al., 2005),
which contains abstracts of papers taken from
MEDLINE, annotated with syntactic structures.
To determine the effects of training set size on the
parser, and consequently on the PPI extraction sys-
tem, we trained several parsing models with differ-
ent amounts of GENIA Treebank data. We started
with 100 sentences, and increased the training set
by 100 sentence increments, up to 1,000 sentences.
From that point, we increased the training set by
1,000 sentence increments. Figure 5 shows the
labeled dependency accuracy for the varying sizes
of training sets. The accuracy was measured on a
portion of the GENIA Treebank reserved as devel-
opment data. The result clearly demonstrates that
the increase in the size of the training set contri-
butes to increasing parse accuracy. Training the
parser with only 100 sentences results in parse ac-
curacy of about 72.5%. Accuracy rises sharply
with additional training data until the size of the
training set reaches about 1,000 sentences (about
82.5% accuracy). From there, accuracy climbs
consistently, but slowly, until 85.6% accuracy is
reached with 8,000 sentences of training data.
It should be noted that parser accuracy on the
Aimed data used in our PPI extraction experiments
may be slightly lower, since the domain of the
GENIA Treebank is not exactly the same as the
Aimed corpus. Both of them were extracted from
MEDLINE, but the criteria for data selection were
not the same in the two corpora, creating possible
differences in sub-domains. We also note that the
accuracy of a parser trained with more than 40,000
sentences from the Wall Street Journal portion of
the Penn Treebank is under 79%, a level equivalent
to that obtained by training the parser with only
</bodyText>
<figure confidence="0.652561">
500 sentences of GENIA data.
</figure>
<figureCaption confidence="0.995859">
Figure 5: Data size vs. parse accuracy
</figureCaption>
<sectionHeader confidence="0.983474" genericHeader="evaluation">
5 Experiments and Results
</sectionHeader>
<bodyText confidence="0.997802346153846">
In this section we present our PPI extraction expe-
riments applying the dependency parsers trained
with the different amounts of the GENIA Treebank
in our PPI system. As we mentioned, the GENIA
Treebank is used for training the parser, while the
Aimed is used for training and evaluation of PPI
extraction. A part-of-speech tagger trained with
GENIA and PennBioIE was used. We do not ap-
ply automatic protein name detection, and instead
use the gold-standard protein annotations in the
Aimed corpus. Before running a parser, multiword
protein names are concatenated and treated as sin-
gle words. As described in Section 3, bag-of-words
and syntactic dependency paths are fed as features
to the PPI classifier. The accuracy of PPI extrac-
tion is measured by the abstract-wise 10-fold cross
validation (Stre et al, 2007).
When we use the part-of-speech tagger and the
dependency parser trained with WSJ, the accuracy
(F-score) of PPI extraction on this data set is 55.2.
The accuracy increases to 56.9 when we train the
part-of-speech tagger with GENIA and Penn BioIE,
while using the WSJ-trained parser. This confirms
the claims by Lease and Charniak (2005) that sub-
sentential lexical analysis alone is helpful in adapt-
ing WSJ parsers to the biomedical domain. While
</bodyText>
<figure confidence="0.879619285714286">
Lease and Charniak looked only at parse accuracy,
70
75
80
85
90
0 2000 4000 6000 8000
</figure>
<figureCaption confidence="0.996792">
Figure 4: A tree kernel representation of the dependency
</figureCaption>
<figure confidence="0.308213">
path
(dep_path (SBJ (ENTITY1 ecognizes))
(rOBJ (recognizes ENTITY2)))
</figure>
<page confidence="0.990579">
17
</page>
<bodyText confidence="0.995145275862069">
\x0cour result shows that the increase in parse accuracy
is, as expected, beneficial in practice.
Figure 6 shows the relationship between the
amount of parser training data and the F-score for
the PPI extraction. The result shows that the accu-
racy of PPI extraction increases with the use of
more sentences to train the parser. The best accu-
racy was obtained when using 4,000 sentences,
where parsing accuracy is around 84.3. Although
it may appear that further increasing the training
data for the parser may not improve the PPI extrac-
tion accuracy (since only small and inconsistent
variations in F-score are observed in Figure 6),
when we plot the curves shown in Figures 5 and 6
in a single graph (Figure 7), we see that the two
curves match each other to a large extent. This is
supported by the strong correlation between parse
accuracy and PPI accuracy observed in Figure 8.
While this suggests that training the parser with a
larger treebank may result in improved accuracy in
PPI extraction, we observe that a 1% absolute im-
provement in parser accuracy corresponds roughly
to a 0.25 improvement in PPI extraction F-score.
Figure 5 indicates that to obtain even a 1% im-
provement in parser accuracy by using more train-
ing data, the size of the treebank would have to
increase significantly.
Although the results presented so far seem to
suggest the need for a large data annotation effort
to achieve a meaningful improvement in PPI ex-
traction accuracy, there are other ways to improve
the overall accuracy of the system without an im-
provement in parser accuracy. One obvious alter-
native is to increase the size of the PPI-annotated
corpus (which is distinct from the treebank used to
train the parser). As mentioned in section 3, our
system is trained using the Aimed corpus, which
contains 225 abstracts from biomedical papers with
manual annotations indicating interactions between
proteins. Pairs of proteins with no interaction de-
scribed in the text are used as negative examples,
and pairs of proteins described as interacting are
used as positive examples. The corpus contains a
total of roughly 9,000 examples. Figure 9 shows
how the overall system accuracy varies when dif-
ferent amounts of training data (varying amounts
of training examples) are used to train the PPI sys-
tem (keeping the parse accuracy constant, using all
of the available training data in the GENIA tree-
bank to train the parser). While Figure 5 indicates
that a significant improvement in parse accuracy
requires a large increase in the treebank used to
train the parser, and Figure 7 shows that improve-
ments in PPI extraction accuracy may require a
sizable improvement in parse accuracy, Figure 9
suggests that even a relatively small increase in the
PPI corpus may lead to a significant improvement
in PPI extraction accuracy.
</bodyText>
<figureCaption confidence="0.999315">
Figure 6: Parser training data size vs. PPI extraction
accuracy
Figure 7: Parser training data size vs. parser accuracy
and PPI extraction accuracy
Figure 8: Parse accuracy vs. PPI extraction accuracy
</figureCaption>
<page confidence="0.901337">
53
</page>
<figure confidence="0.919890821428571">
54
55
56
57
58
0 2000 4000 6000 8000
53
54
55
56
57
58
68
72
76
80
84
88
0 5000 10000
Parser
PPI F-score
53
54
55
56
57
58
70 75 80 85 90
</figure>
<page confidence="0.809565">
18
</page>
<figureCaption confidence="0.694227">
\x0cFigure 9: Number of PPI training examples vs. PPI ex-
traction accuracy
</figureCaption>
<bodyText confidence="0.998359272727272">
While some of the conclusions that can be
drawn from these results may be somewhat sur-
prising, most are entirely expected. However, even
in these straightforward cases, our experiments
provide some empirical evidence and concrete
quantitative analysis to complement intuition. We
see that using domain-specific training data for the
parsing component for the PPI extraction system
produces superior results, compared to using train-
ing data from the WSJ Penn Treebank. When the
parser trained on WSJ sentences is used, PPI ex-
traction accuracy is about 55, compared to over 57
when sentences from biomedical papers are used.
This corresponds fairly closely to the differences in
parser accuracy: the accuracy of the parser trained
on 500 sentences from GENIA is about the same
as the accuracy of the parser trained on the entire
WSJ Penn Treebank, and when these parsers are
used in the PPI extraction system, they result in
similar overall task accuracy. However, the results
obtained when a domain-specific POS tagger is
combined with a parser trained with out-of-domain
data, overall PPI results are nearly at the same lev-
el as those obtained with domain-specific training
data (just below 57 with a domain-specific POS
tagger and out-of-domain parser, and just above 57
for domain-specific POS tagger and parser). At
the same time, the argument against annotating
domain-specific data for parsers in new domains is
not a strong one, since higher accuracy levels (for
both the parser and the overall system) can be ob-
tained with a relatively small amount of domain-
specific data.
Figures 5, 6 and 7 also suggest that additional
efforts in improving parser accuracy (through the
use of feature engineering, other machine learning
techniques, or an increase in the size of its training
set) could improve PPI extraction accuracy, but a
large improvement in parser accuracy may be re-
quired. When we combine these results with the
findings obtained by Miyao et al. (2008), they sug-
gest that a better way to improve the overall sys-
tem is to spend more effort in designing a specific
syntactic representation that addresses the needs of
the system, instead of using a generic representa-
tion designed for measuring parser accuracy.
Another potentially fruitful course of action is to
design more sophisticated and effective ways for
information extraction systems to use NLP tools,
rather than simply extracting features that corres-
pond to small fragments of syntactic trees. Of
course, making proper use of natural language
analysis is a considerable challenge, but one that
should be kept in mind through the design of prac-
tical systems that use NLP components.
</bodyText>
<sectionHeader confidence="0.997872" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999174769230769">
This paper presented empirical results on the rela-
tionship between the amount of training data used
to create a dependency parser, and the accuracy of
a system that performs identification of protein-
protein interactions using the dependency parser.
We trained a dependency parser with different
amounts of data from the GENIA Treebank to es-
tablish how the improvement in parse accuracy
corresponds to improvement in practical task per-
formance in this information extraction task.
While parsing accuracy clearly increased with
larger amounts of data, and is likely to continue
increasing with additional annotation of data for
the GENIA Treebank, the trend in the accuracy of
PPI extraction indicates that a sizable improvement
in parse accuracy may be necessary for improved
detection of protein interactions.
When combined with recent findings by Miyao
et al. (2008), our results indicate that further work
in designing PPI extraction systems that use syn-
tactic dependency features would benefit from
more adequate syntactic representations or more
sophisticated use of NLP than simple extraction of
syntactic subtrees. Furthermore, to improve accu-
racy in this task, efforts on data annotation should
focus on task-specific data (manual annotation of
</bodyText>
<figure confidence="0.940127714285714">
40
45
50
55
60
65
0 5000 10000 15000
</figure>
<page confidence="0.914862">
19
</page>
<tableCaption confidence="0.5497195">
\x0cprotein interactions in biomedical papers), rather
than on additional training data for syntactic pars-
</tableCaption>
<bodyText confidence="0.985119857142857">
ers. While annotation of parser training data might
seems like a cost-effective choice, since improved
parser results might be beneficial in a number of
systems where the parser can be used, our results
show that, in this particular task, efforts should be
focused elsewhere, such as the annotation of addi-
tion PPI data.
</bodyText>
<sectionHeader confidence="0.945272" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.984658">
We thank the anonymous reviewers for their in-
sightful comments. This work was partially sup-
ported by Grant-in-Aid for Specially Promoted
</bodyText>
<table confidence="0.304137">
Research (MEXT, Japan), Genome Network
Project (MEXT, Japan), and Grant-in-Aid for
Young Scientists (MEXT, Japan).
</table>
<sectionHeader confidence="0.7563" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99921217721519">
Berger, A., S. A. Della Pietra, and V. J. Della Pietra.
1996. A maximum entropy approach to natural lan-
guage processing. Computational Linguistics,
22(1):3971.
Clegg, A. and Shepherd, A. 2007. Benchmarking natu-
ral-language parsers for biological applications using
dependency graphs. BMC Bioinformatics, 8:24.
Erkan, G., A. Ozgur, and D. R. Radev. 2007. Semisu-
pervised classification for extracting protein interac-
tion sentences using dependency parsing. In
Proceedings of CoNLL-EMNLP 2007.
Hara, T., Miyao, Y and Tsujii, J. 2007. Evaluating Im-
pact of Re-training a Lexical Disambiguation Model
on Domain Adaptation of an HPSG Parser. In Pro-
ceedings of the International Conference on Parsing
Technologies (IWPT).
Katrenko, S. and P. W. Adriaans. 2006. Learning rela-
tions from biomedical corpora using dependency
trees. In Proceedings of the first workshop on Know-
ledge Discovery and Emergent Complexity in BioIn-
formatics (KDECB), pages 6180.
Kulick, S., A. Bies, M. Liberman, M. Mandel, R.
McDonald, M. Palmer, A. Schein and L. Ungar. 2004.
Integrated Annotation for Biomedical Information
Extraction. In Proceedings of Biolink 2004: Linking
Biological Literature, Ontologies and Databases
(HLT-NAACL workshop).
Lease, M. and Charniak, E. 2005. Parsing Biomedical
Literature. In R. Dale, K.-F. Wong, J. Su, and O.
Kwong, editors, Proceedings of the 2nd International
Joint Conference on Natural Language Processing
(IJCNLP&apos;05), volume 3651 of Lecture Notes in
Computer Science, pages 58 69.
Miyao, Y., Stre, R., Sagae, K., Matsuzaki, T. and Tsu-
jii, J. 2008. Task-Oriented Evaluation of Syntactic
Parsers and Their Representations. In Proceedings of
the 46th Annual Meeting of the Association for Com-
putational Linguistics.
Nivre, J., Hall, J., Kubler, S., McDonald, R., Nilsson, J.,
Riedel, S. and Yuret, D. 2007. The CoNLL 2007
Shared Task on Dependency Parsing. In Proceedings
the CoNLL 2007 Shared Task in EMNLP-CoNLL.
Nivre, Joakim, Johan Hall, Jens Nilsson, Gulsen Eryi-
git,and Svetoslav Marinov. 2006. Labeled pseudo-
projective dependency parsing with support vector
machines. In Proceedings of the Tenth Conference on
Computational Natural Language Learning, shared
task session.
Pyysalo S., Ginter F., Haverinen K., Heimonen J., Sala-
koski T. and Laippala V. 2007. On the unification of
syntactic annotations under the Stanford dependency
scheme: A case study on BioInfer and GENIA. In
Proceedings of BioNLP 2007: Biological, Transla-
tional and Clinical Language Processing.
Quirk, C. and Corston-Oliver S. 2006. The impact of
parse quality on syntactically-informed statistical
machine translation. In Proceedings of EMNLP 2007.
Stre, R., Sagae, K., and Tsujii, J. 2007. Syntactic fea-
tures for protein-protein interaction extraction. In
Proceedings of the International Symposium on Lan-
guages in Biology and Medicine (LBM short oral
presentations).
Sagae, K. and Lavie, A. 2006. A best-first probabilistic
shift-reduce parser. In Proceedings of the
COLING/ACL 2006 Main Conference Poster Ses-
sions, pages 691698, Sydney, Australia, July. Asso-
ciation for Computational Linguistics.
Sagae, K., Miyao, Y. and Tsujii, J. 2008. Challenges in
Mapping of Syntactic Representations for Frame-
work-Independent Parser Evaluation. In Proceedings
of the Workshop on Automated Syntatic Annotations
for Interoperable Language Resources at the First
International Conference on Global Interoperability
for Language Resources (ICGL&apos;08).
Tateisi, Y., Yakushiji, A., Ohta, T., and Tsujii, J. 2005.
Syntax annotation for the GENIA corpus. In Pro-
ceedings Second International Joint Conference on
Natural Language Processing: Companion Volume
including Posters/Demos and tutorial abstracts.
</reference>
<figure confidence="0.393985">
20
\x0c&amp;quot;
</figure>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.028342">
<note confidence="0.915224">b&amp;quot;Software Engineering, Testing, and Quality Assurance for Natural Language Processing, pages 1420, Columbus, Ohio, USA, June 2008. c 2008 Association for Computational Linguistics</note>
<title confidence="0.5700744">Evaluating the Effects of Treebank Size in a Practical Application for Parsing Kenji Sagae1 , Yusuke Miyao1 , Rune Stre1</title>
<author confidence="0.669558">Jun&apos;ichi Tsujii</author>
<email confidence="0.630716">1</email>
<affiliation confidence="0.815901333333333">Department of Computer Science, Univerisity of Tokyo, Japan 2 School of Computer Science, University of Manchester</affiliation>
<address confidence="0.696411">3 National Center for Text Mining, Manchester, UK</address>
<email confidence="0.945208">{sagae,yusuke,rune.saetre,tsujii@is.s.u-tokyo.ac.jp}</email>
<abstract confidence="0.99892544">Natural language processing modules such as part-of-speech taggers, named-entity recognizers and syntactic parsers are commonly evaluated in isolation, under the assumption that artificial evaluation metrics for individual parts are predictive of practical performance of more complex language technology systems that perform practical tasks. Although this is an important issue in the design and engineering of systems that use natural language input, it is often unclear how the accuracy of an end-user application is affected by parameters that affect individual NLP modules. We explore this issue in the context of a specific task by examining the relationship between the accuracy of a syntactic parser and the overall performance of an information extraction system for biomedical text that includes the parser as one of its components. We present an empirical investigation of the relationship between factors that affect the accuracy of syntactic analysis, and how the difference in parse accuracy affects the overall system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Berger</author>
<author>S A Della Pietra</author>
<author>V J Della Pietra</author>
</authors>
<title>A maximum entropy approach to natural language processing.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<issue>1</issue>
<contexts>
<context position="12245" citStr="Berger et al., 1996" startWordPosition="1913" endWordPosition="1916">ding protein (RBP) to transthyretin (TTR) is not useful to assess vitamin A status during infection in hospitalized children. Figure 2: Example sentences with protein names Figure 1: A dependency tree ROOT IL-8 recognizes and activates CXCR1 ROOT SBJ OBJ COORD CC ENTITY1(IL-8) recognizes ENTITY2(CXCR1) Figure 3: A dependency path between protein names SBJ OBJ 16 \x0cstack items, and push a new item composed of the two popped items combined in a single structure). This parsing approach is very similar to the one used successfully by Nivre et al. (2006), but we use a maximum entropy classifier (Berger et al., 1996) to determine parser actions, which makes parsing considerably faster. In addition, our parsing approach performs a search over the space of possible parser actions, while Nivre et al.s approach is deterministic. The parser was trained using 8,000 sentences from the GENIA Treebank (Tateisi et al., 2005), which contains abstracts of papers taken from MEDLINE, annotated with syntactic structures. To determine the effects of training set size on the parser, and consequently on the PPI extraction system, we trained several parsing models with different amounts of GENIA Treebank data. We started wi</context>
</contexts>
<marker>Berger, Pietra, Pietra, 1996</marker>
<rawString>Berger, A., S. A. Della Pietra, and V. J. Della Pietra. 1996. A maximum entropy approach to natural language processing. Computational Linguistics, 22(1):3971.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Clegg</author>
<author>A Shepherd</author>
</authors>
<title>Benchmarking natural-language parsers for biological applications using dependency graphs.</title>
<date>2007</date>
<journal>BMC Bioinformatics,</journal>
<volume>8</volume>
<contexts>
<context position="3354" citStr="Clegg and Shepherd, 2007" startWordPosition="499" endWordPosition="502">se issues empirically in an information extraction task in the biomedical domain, the identification of proteinprotein interactions (PPI) mentioned in papers abstracts from MEDLINE, a large database of biomedical papers. Due in large part to the creation of biomedical treebanks (Kulick et al., 2004; Tateisi et al., 2005) and rapid progress of data-driven parsers (Lease and Charniak, 2005; Nivre et al., 2007), there are now fast, robust and accurate syntactic parsers for text in the biomedical domain. Recent research shows that parsing accuracy of biomedical corpora is now between 80% and 90% (Clegg and Shepherd, 2007; Pyysalo et al., 2007; Sagae et al., 2008). Intuitively, syntactic relationships between words should be valuable in determining possible interactions between entities present in text. Recent PPI extraction systems have confirmed this intuition (Erkan et al., 2007; Stre et al., 2007; Katrenko and Adriaans, 2006). While it is now relatively clear that syntactic parsing is useful in practical tasks that use natural language corpora in bioinformatics, several ques14 \x0ctions remain as to research issues that affect the design and testing of end-user applications, including how syntactic analyse</context>
<context position="5917" citStr="Clegg and Shepherd, 2007" startWordPosition="899" endWordPosition="902">iments, results and analysis in section 5, and conclude in section 6. 2 Motivation and related work While recent work has addressed questions relating to the use of different parsers or different types of syntactic representations in the PPI extraction task (Stre et al., 2007, Miyao et al., 2008), little concrete evidence has been provided for potential benefits of improved parsers or additional resources for training syntactic parsers. In fact, although there is increasing interest in parser evaluation in the biomedical domain in terms of precision/recall of brackets and dependency accuracy (Clegg and Shepherd, 2007; Pyysalo et al., 2007; Sagae et al., 2008), the relationship between these evaluation metrics and the performance of practical information extraction systems remains unclear. In the parsing community, relatively small accuracy gains are often reported as success stories, but again, the precise impact of such improvements on practical tasks in bioinformatics has not been established. One aspect of this issue is the question of domain portability and domain adaptation for parsers and other NLP modules. Clegg and Shepherd (2007) mention that available statistical parsers appear to overfit to the</context>
</contexts>
<marker>Clegg, Shepherd, 2007</marker>
<rawString>Clegg, A. and Shepherd, A. 2007. Benchmarking natural-language parsers for biological applications using dependency graphs. BMC Bioinformatics, 8:24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Erkan</author>
<author>A Ozgur</author>
<author>D R Radev</author>
</authors>
<title>Semisupervised classification for extracting protein interaction sentences using dependency parsing.</title>
<date>2007</date>
<booktitle>In Proceedings of CoNLL-EMNLP</booktitle>
<contexts>
<context position="3619" citStr="Erkan et al., 2007" startWordPosition="538" endWordPosition="541">eebanks (Kulick et al., 2004; Tateisi et al., 2005) and rapid progress of data-driven parsers (Lease and Charniak, 2005; Nivre et al., 2007), there are now fast, robust and accurate syntactic parsers for text in the biomedical domain. Recent research shows that parsing accuracy of biomedical corpora is now between 80% and 90% (Clegg and Shepherd, 2007; Pyysalo et al., 2007; Sagae et al., 2008). Intuitively, syntactic relationships between words should be valuable in determining possible interactions between entities present in text. Recent PPI extraction systems have confirmed this intuition (Erkan et al., 2007; Stre et al., 2007; Katrenko and Adriaans, 2006). While it is now relatively clear that syntactic parsing is useful in practical tasks that use natural language corpora in bioinformatics, several ques14 \x0ctions remain as to research issues that affect the design and testing of end-user applications, including how syntactic analyses should be used in a practical setting, whether further improvements in parsing technologies will result in further improvements in practical systems, whether it is important to continue the development of treebanks and parser adaptation techniques for the biomedi</context>
<context position="8672" citStr="Erkan et al., 2007" startWordPosition="1328" endWordPosition="1331">tical systems. 3 A PPI extraction system based on syntactic parsing PPI extraction is an NLP task to identify protein pairs that are mentioned as interacting in biomedical papers. Figure 2 shows two sentences that include protein names: the former sentence mentions a protein interaction, while the latter does not. Given a protein pair, PPI extraction is a task of binary classification; for example, &lt;IL-8, CXCR1&gt; 15 \x0cis a positive example, and &lt;RBP, TTR&gt; is a negative example. Following recent work on using dependency parsing in systems that identify protein interactions in biomedical text (Erkan et al., 2007; Stre et al., 2007; Katrenko and Adriaans, 2006), we have built a system for PPI extraction that uses dependency relations as features. As exemplified, for the protein pair IL-8 and CXCR1 in the first sentence of Figure 2, a dependency parser outputs a dependency tree shown in Figure 1. From this dependency tree, we can extract a dependency path between IL-8 and CXCR1 (Figure 3), which appears to be a strong clue in knowing that these proteins are mentioned as interacting. The system we use in this paper is similar to the one described in Stre et al. (2007), except that it uses syntactic depe</context>
</contexts>
<marker>Erkan, Ozgur, Radev, 2007</marker>
<rawString>Erkan, G., A. Ozgur, and D. R. Radev. 2007. Semisupervised classification for extracting protein interaction sentences using dependency parsing. In Proceedings of CoNLL-EMNLP 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Hara</author>
<author>Y Miyao</author>
<author>J Tsujii</author>
</authors>
<title>Evaluating Impact of Re-training a Lexical Disambiguation Model on Domain Adaptation of an HPSG Parser.</title>
<date>2007</date>
<booktitle>In Proceedings of the International Conference on Parsing Technologies (IWPT).</booktitle>
<contexts>
<context position="7183" citStr="Hara et al., 2007" startWordPosition="1094" endWordPosition="1097"> of the Wall Street Journal portion of the Penn Treebank (Marcus et al., 1994) during development and training. While this claim is supported by convincing evaluations that show that parsers trained on the WSJ Penn Treebank alone perform poorly on biomedical text in terms of accuracy of dependencies or bracketing of phrase structure, the benefits of using domainspecific data in terms of practical system performance have not been quantified. These expected benefits drive the development of domain-specific resources, such as the GENIA treebank (Tateisi et al., 2005), and parser domain adaption (Hara et al., 2007), which are of clear importance in parsing research, but of largely unconfirmed impact on practical systems. Quirk and Corston-Oliver (2006) examine a similar issue, the relationship between parser accuracy and overall system accuracy in syntaxinformed machine translation. Their research is similar to the work presented here, but they focused on the use of varying amounts of out-ofdomain training data for the parser, measuring how a translation system for technical text performed when its syntactic parser was trained with varying amounts of Wall Street Journal text. Our work, in contrast, inve</context>
</contexts>
<marker>Hara, Miyao, Tsujii, 2007</marker>
<rawString>Hara, T., Miyao, Y and Tsujii, J. 2007. Evaluating Impact of Re-training a Lexical Disambiguation Model on Domain Adaptation of an HPSG Parser. In Proceedings of the International Conference on Parsing Technologies (IWPT).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Katrenko</author>
<author>P W Adriaans</author>
</authors>
<title>Learning relations from biomedical corpora using dependency trees.</title>
<date>2006</date>
<booktitle>In Proceedings of the first workshop on Knowledge Discovery and Emergent Complexity in BioInformatics (KDECB),</booktitle>
<pages>6180</pages>
<contexts>
<context position="3668" citStr="Katrenko and Adriaans, 2006" startWordPosition="546" endWordPosition="549">t al., 2005) and rapid progress of data-driven parsers (Lease and Charniak, 2005; Nivre et al., 2007), there are now fast, robust and accurate syntactic parsers for text in the biomedical domain. Recent research shows that parsing accuracy of biomedical corpora is now between 80% and 90% (Clegg and Shepherd, 2007; Pyysalo et al., 2007; Sagae et al., 2008). Intuitively, syntactic relationships between words should be valuable in determining possible interactions between entities present in text. Recent PPI extraction systems have confirmed this intuition (Erkan et al., 2007; Stre et al., 2007; Katrenko and Adriaans, 2006). While it is now relatively clear that syntactic parsing is useful in practical tasks that use natural language corpora in bioinformatics, several ques14 \x0ctions remain as to research issues that affect the design and testing of end-user applications, including how syntactic analyses should be used in a practical setting, whether further improvements in parsing technologies will result in further improvements in practical systems, whether it is important to continue the development of treebanks and parser adaptation techniques for the biomedical domain, and how much effort should be spent o</context>
<context position="8721" citStr="Katrenko and Adriaans, 2006" startWordPosition="1336" endWordPosition="1339">m based on syntactic parsing PPI extraction is an NLP task to identify protein pairs that are mentioned as interacting in biomedical papers. Figure 2 shows two sentences that include protein names: the former sentence mentions a protein interaction, while the latter does not. Given a protein pair, PPI extraction is a task of binary classification; for example, &lt;IL-8, CXCR1&gt; 15 \x0cis a positive example, and &lt;RBP, TTR&gt; is a negative example. Following recent work on using dependency parsing in systems that identify protein interactions in biomedical text (Erkan et al., 2007; Stre et al., 2007; Katrenko and Adriaans, 2006), we have built a system for PPI extraction that uses dependency relations as features. As exemplified, for the protein pair IL-8 and CXCR1 in the first sentence of Figure 2, a dependency parser outputs a dependency tree shown in Figure 1. From this dependency tree, we can extract a dependency path between IL-8 and CXCR1 (Figure 3), which appears to be a strong clue in knowing that these proteins are mentioned as interacting. The system we use in this paper is similar to the one described in Stre et al. (2007), except that it uses syntactic dependency paths obtained with a dependency parser, b</context>
</contexts>
<marker>Katrenko, Adriaans, 2006</marker>
<rawString>Katrenko, S. and P. W. Adriaans. 2006. Learning relations from biomedical corpora using dependency trees. In Proceedings of the first workshop on Knowledge Discovery and Emergent Complexity in BioInformatics (KDECB), pages 6180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kulick</author>
<author>A Bies</author>
<author>M Liberman</author>
<author>M Mandel</author>
<author>R McDonald</author>
<author>M Palmer</author>
<author>A Schein</author>
<author>L Ungar</author>
</authors>
<date>2004</date>
<contexts>
<context position="3029" citStr="Kulick et al., 2004" startWordPosition="446" endWordPosition="449">ual modules affect the performance of the larger systems they compose is an issue that has received relatively little attention. This issue, however, is of great practical importance in the effective design and engineering of complex software systems that deal with natural language. In this paper we explore some of these issues empirically in an information extraction task in the biomedical domain, the identification of proteinprotein interactions (PPI) mentioned in papers abstracts from MEDLINE, a large database of biomedical papers. Due in large part to the creation of biomedical treebanks (Kulick et al., 2004; Tateisi et al., 2005) and rapid progress of data-driven parsers (Lease and Charniak, 2005; Nivre et al., 2007), there are now fast, robust and accurate syntactic parsers for text in the biomedical domain. Recent research shows that parsing accuracy of biomedical corpora is now between 80% and 90% (Clegg and Shepherd, 2007; Pyysalo et al., 2007; Sagae et al., 2008). Intuitively, syntactic relationships between words should be valuable in determining possible interactions between entities present in text. Recent PPI extraction systems have confirmed this intuition (Erkan et al., 2007; Stre et </context>
</contexts>
<marker>Kulick, Bies, Liberman, Mandel, McDonald, Palmer, Schein, Ungar, 2004</marker>
<rawString>Kulick, S., A. Bies, M. Liberman, M. Mandel, R. McDonald, M. Palmer, A. Schein and L. Ungar. 2004.</rawString>
</citation>
<citation valid="false">
<title>Integrated Annotation for Biomedical Information Extraction.</title>
<booktitle>In Proceedings of Biolink 2004: Linking Biological Literature, Ontologies and Databases (HLT-NAACL workshop).</booktitle>
<marker></marker>
<rawString>Integrated Annotation for Biomedical Information Extraction. In Proceedings of Biolink 2004: Linking Biological Literature, Ontologies and Databases (HLT-NAACL workshop).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Lease</author>
<author>E Charniak</author>
</authors>
<title>Parsing Biomedical Literature. In</title>
<date>2005</date>
<booktitle>Proceedings of the 2nd International Joint Conference on Natural Language Processing (IJCNLP&apos;05),</booktitle>
<volume>3651</volume>
<pages>58--69</pages>
<editor>R. Dale, K.-F. Wong, J. Su, and O. Kwong, editors,</editor>
<contexts>
<context position="3120" citStr="Lease and Charniak, 2005" startWordPosition="460" endWordPosition="463"> has received relatively little attention. This issue, however, is of great practical importance in the effective design and engineering of complex software systems that deal with natural language. In this paper we explore some of these issues empirically in an information extraction task in the biomedical domain, the identification of proteinprotein interactions (PPI) mentioned in papers abstracts from MEDLINE, a large database of biomedical papers. Due in large part to the creation of biomedical treebanks (Kulick et al., 2004; Tateisi et al., 2005) and rapid progress of data-driven parsers (Lease and Charniak, 2005; Nivre et al., 2007), there are now fast, robust and accurate syntactic parsers for text in the biomedical domain. Recent research shows that parsing accuracy of biomedical corpora is now between 80% and 90% (Clegg and Shepherd, 2007; Pyysalo et al., 2007; Sagae et al., 2008). Intuitively, syntactic relationships between words should be valuable in determining possible interactions between entities present in text. Recent PPI extraction systems have confirmed this intuition (Erkan et al., 2007; Stre et al., 2007; Katrenko and Adriaans, 2006). While it is now relatively clear that syntactic pa</context>
<context position="15513" citStr="Lease and Charniak (2005)" startWordPosition="2445" endWordPosition="2448">iword protein names are concatenated and treated as single words. As described in Section 3, bag-of-words and syntactic dependency paths are fed as features to the PPI classifier. The accuracy of PPI extraction is measured by the abstract-wise 10-fold cross validation (Stre et al, 2007). When we use the part-of-speech tagger and the dependency parser trained with WSJ, the accuracy (F-score) of PPI extraction on this data set is 55.2. The accuracy increases to 56.9 when we train the part-of-speech tagger with GENIA and Penn BioIE, while using the WSJ-trained parser. This confirms the claims by Lease and Charniak (2005) that subsentential lexical analysis alone is helpful in adapting WSJ parsers to the biomedical domain. While Lease and Charniak looked only at parse accuracy, 70 75 80 85 90 0 2000 4000 6000 8000 Figure 4: A tree kernel representation of the dependency path (dep_path (SBJ (ENTITY1 ecognizes)) (rOBJ (recognizes ENTITY2))) 17 \x0cour result shows that the increase in parse accuracy is, as expected, beneficial in practice. Figure 6 shows the relationship between the amount of parser training data and the F-score for the PPI extraction. The result shows that the accuracy of PPI extraction increas</context>
</contexts>
<marker>Lease, Charniak, 2005</marker>
<rawString>Lease, M. and Charniak, E. 2005. Parsing Biomedical Literature. In R. Dale, K.-F. Wong, J. Su, and O. Kwong, editors, Proceedings of the 2nd International Joint Conference on Natural Language Processing (IJCNLP&apos;05), volume 3651 of Lecture Notes in Computer Science, pages 58 69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Miyao</author>
<author>R Stre</author>
<author>K Sagae</author>
<author>T Matsuzaki</author>
<author>J Tsujii</author>
</authors>
<title>Task-Oriented Evaluation of Syntactic Parsers and Their Representations.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="5590" citStr="Miyao et al., 2008" startWordPosition="851" endWordPosition="854">In section 2 we discuss our motivation and related efforts. Section 3 describes the system for identification of protein-protein interactions used in our experiments, and in section 4 describes the syntactic parser that provides the analyses for the PPI system, and the data used to train the parser. We describe our experiments, results and analysis in section 5, and conclude in section 6. 2 Motivation and related work While recent work has addressed questions relating to the use of different parsers or different types of syntactic representations in the PPI extraction task (Stre et al., 2007, Miyao et al., 2008), little concrete evidence has been provided for potential benefits of improved parsers or additional resources for training syntactic parsers. In fact, although there is increasing interest in parser evaluation in the biomedical domain in terms of precision/recall of brackets and dependency accuracy (Clegg and Shepherd, 2007; Pyysalo et al., 2007; Sagae et al., 2008), the relationship between these evaluation metrics and the performance of practical information extraction systems remains unclear. In the parsing community, relatively small accuracy gains are often reported as success stories, </context>
<context position="21039" citStr="Miyao et al. (2008)" startWordPosition="3372" endWordPosition="3375">gainst annotating domain-specific data for parsers in new domains is not a strong one, since higher accuracy levels (for both the parser and the overall system) can be obtained with a relatively small amount of domainspecific data. Figures 5, 6 and 7 also suggest that additional efforts in improving parser accuracy (through the use of feature engineering, other machine learning techniques, or an increase in the size of its training set) could improve PPI extraction accuracy, but a large improvement in parser accuracy may be required. When we combine these results with the findings obtained by Miyao et al. (2008), they suggest that a better way to improve the overall system is to spend more effort in designing a specific syntactic representation that addresses the needs of the system, instead of using a generic representation designed for measuring parser accuracy. Another potentially fruitful course of action is to design more sophisticated and effective ways for information extraction systems to use NLP tools, rather than simply extracting features that correspond to small fragments of syntactic trees. Of course, making proper use of natural language analysis is a considerable challenge, but one tha</context>
<context position="22609" citStr="Miyao et al. (2008)" startWordPosition="3619" endWordPosition="3622"> We trained a dependency parser with different amounts of data from the GENIA Treebank to establish how the improvement in parse accuracy corresponds to improvement in practical task performance in this information extraction task. While parsing accuracy clearly increased with larger amounts of data, and is likely to continue increasing with additional annotation of data for the GENIA Treebank, the trend in the accuracy of PPI extraction indicates that a sizable improvement in parse accuracy may be necessary for improved detection of protein interactions. When combined with recent findings by Miyao et al. (2008), our results indicate that further work in designing PPI extraction systems that use syntactic dependency features would benefit from more adequate syntactic representations or more sophisticated use of NLP than simple extraction of syntactic subtrees. Furthermore, to improve accuracy in this task, efforts on data annotation should focus on task-specific data (manual annotation of 40 45 50 55 60 65 0 5000 10000 15000 19 \x0cprotein interactions in biomedical papers), rather than on additional training data for syntactic parsers. While annotation of parser training data might seems like a cost</context>
</contexts>
<marker>Miyao, Stre, Sagae, Matsuzaki, Tsujii, 2008</marker>
<rawString>Miyao, Y., Stre, R., Sagae, K., Matsuzaki, T. and Tsujii, J. 2008. Task-Oriented Evaluation of Syntactic Parsers and Their Representations. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
<author>J Hall</author>
<author>S Kubler</author>
<author>R McDonald</author>
<author>J Nilsson</author>
<author>S Riedel</author>
<author>D Yuret</author>
</authors>
<date>2007</date>
<booktitle>The CoNLL 2007 Shared Task on Dependency Parsing. In Proceedings the CoNLL</booktitle>
<note>Shared Task in EMNLP-CoNLL.</note>
<contexts>
<context position="3141" citStr="Nivre et al., 2007" startWordPosition="464" endWordPosition="467">ittle attention. This issue, however, is of great practical importance in the effective design and engineering of complex software systems that deal with natural language. In this paper we explore some of these issues empirically in an information extraction task in the biomedical domain, the identification of proteinprotein interactions (PPI) mentioned in papers abstracts from MEDLINE, a large database of biomedical papers. Due in large part to the creation of biomedical treebanks (Kulick et al., 2004; Tateisi et al., 2005) and rapid progress of data-driven parsers (Lease and Charniak, 2005; Nivre et al., 2007), there are now fast, robust and accurate syntactic parsers for text in the biomedical domain. Recent research shows that parsing accuracy of biomedical corpora is now between 80% and 90% (Clegg and Shepherd, 2007; Pyysalo et al., 2007; Sagae et al., 2008). Intuitively, syntactic relationships between words should be valuable in determining possible interactions between entities present in text. Recent PPI extraction systems have confirmed this intuition (Erkan et al., 2007; Stre et al., 2007; Katrenko and Adriaans, 2006). While it is now relatively clear that syntactic parsing is useful in pr</context>
</contexts>
<marker>Nivre, Hall, Kubler, McDonald, Nilsson, Riedel, Yuret, 2007</marker>
<rawString>Nivre, J., Hall, J., Kubler, S., McDonald, R., Nilsson, J., Riedel, S. and Yuret, D. 2007. The CoNLL 2007 Shared Task on Dependency Parsing. In Proceedings the CoNLL 2007 Shared Task in EMNLP-CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Jens Nilsson</author>
</authors>
<title>Gulsen Eryigit,and Svetoslav Marinov.</title>
<date>2006</date>
<booktitle>In Proceedings of the Tenth Conference on Computational Natural Language Learning, shared task session.</booktitle>
<contexts>
<context position="12182" citStr="Nivre et al. (2006)" startWordPosition="1902" endWordPosition="1905">n by distinct mechanisms. The molar ratio of serum retinol-binding protein (RBP) to transthyretin (TTR) is not useful to assess vitamin A status during infection in hospitalized children. Figure 2: Example sentences with protein names Figure 1: A dependency tree ROOT IL-8 recognizes and activates CXCR1 ROOT SBJ OBJ COORD CC ENTITY1(IL-8) recognizes ENTITY2(CXCR1) Figure 3: A dependency path between protein names SBJ OBJ 16 \x0cstack items, and push a new item composed of the two popped items combined in a single structure). This parsing approach is very similar to the one used successfully by Nivre et al. (2006), but we use a maximum entropy classifier (Berger et al., 1996) to determine parser actions, which makes parsing considerably faster. In addition, our parsing approach performs a search over the space of possible parser actions, while Nivre et al.s approach is deterministic. The parser was trained using 8,000 sentences from the GENIA Treebank (Tateisi et al., 2005), which contains abstracts of papers taken from MEDLINE, annotated with syntactic structures. To determine the effects of training set size on the parser, and consequently on the PPI extraction system, we trained several parsing mode</context>
</contexts>
<marker>Nivre, Hall, Nilsson, 2006</marker>
<rawString>Nivre, Joakim, Johan Hall, Jens Nilsson, Gulsen Eryigit,and Svetoslav Marinov. 2006. Labeled pseudoprojective dependency parsing with support vector machines. In Proceedings of the Tenth Conference on Computational Natural Language Learning, shared task session.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pyysalo</author>
<author>F Ginter</author>
<author>K Haverinen</author>
<author>J Heimonen</author>
<author>T Salakoski</author>
<author>V Laippala</author>
</authors>
<title>On the unification of syntactic annotations under the Stanford dependency scheme: A case study on BioInfer and GENIA.</title>
<date>2007</date>
<booktitle>In Proceedings of BioNLP 2007: Biological, Translational and Clinical Language Processing.</booktitle>
<contexts>
<context position="3376" citStr="Pyysalo et al., 2007" startWordPosition="503" endWordPosition="506">n information extraction task in the biomedical domain, the identification of proteinprotein interactions (PPI) mentioned in papers abstracts from MEDLINE, a large database of biomedical papers. Due in large part to the creation of biomedical treebanks (Kulick et al., 2004; Tateisi et al., 2005) and rapid progress of data-driven parsers (Lease and Charniak, 2005; Nivre et al., 2007), there are now fast, robust and accurate syntactic parsers for text in the biomedical domain. Recent research shows that parsing accuracy of biomedical corpora is now between 80% and 90% (Clegg and Shepherd, 2007; Pyysalo et al., 2007; Sagae et al., 2008). Intuitively, syntactic relationships between words should be valuable in determining possible interactions between entities present in text. Recent PPI extraction systems have confirmed this intuition (Erkan et al., 2007; Stre et al., 2007; Katrenko and Adriaans, 2006). While it is now relatively clear that syntactic parsing is useful in practical tasks that use natural language corpora in bioinformatics, several ques14 \x0ctions remain as to research issues that affect the design and testing of end-user applications, including how syntactic analyses should be used in a </context>
<context position="5939" citStr="Pyysalo et al., 2007" startWordPosition="903" endWordPosition="906">is in section 5, and conclude in section 6. 2 Motivation and related work While recent work has addressed questions relating to the use of different parsers or different types of syntactic representations in the PPI extraction task (Stre et al., 2007, Miyao et al., 2008), little concrete evidence has been provided for potential benefits of improved parsers or additional resources for training syntactic parsers. In fact, although there is increasing interest in parser evaluation in the biomedical domain in terms of precision/recall of brackets and dependency accuracy (Clegg and Shepherd, 2007; Pyysalo et al., 2007; Sagae et al., 2008), the relationship between these evaluation metrics and the performance of practical information extraction systems remains unclear. In the parsing community, relatively small accuracy gains are often reported as success stories, but again, the precise impact of such improvements on practical tasks in bioinformatics has not been established. One aspect of this issue is the question of domain portability and domain adaptation for parsers and other NLP modules. Clegg and Shepherd (2007) mention that available statistical parsers appear to overfit to the newswire domain, beca</context>
</contexts>
<marker>Pyysalo, Ginter, Haverinen, Heimonen, Salakoski, Laippala, 2007</marker>
<rawString>Pyysalo S., Ginter F., Haverinen K., Heimonen J., Salakoski T. and Laippala V. 2007. On the unification of syntactic annotations under the Stanford dependency scheme: A case study on BioInfer and GENIA. In Proceedings of BioNLP 2007: Biological, Translational and Clinical Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Quirk</author>
<author>S Corston-Oliver</author>
</authors>
<title>The impact of parse quality on syntactically-informed statistical machine translation.</title>
<date>2006</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<contexts>
<context position="7323" citStr="Quirk and Corston-Oliver (2006)" startWordPosition="1114" endWordPosition="1117">m is supported by convincing evaluations that show that parsers trained on the WSJ Penn Treebank alone perform poorly on biomedical text in terms of accuracy of dependencies or bracketing of phrase structure, the benefits of using domainspecific data in terms of practical system performance have not been quantified. These expected benefits drive the development of domain-specific resources, such as the GENIA treebank (Tateisi et al., 2005), and parser domain adaption (Hara et al., 2007), which are of clear importance in parsing research, but of largely unconfirmed impact on practical systems. Quirk and Corston-Oliver (2006) examine a similar issue, the relationship between parser accuracy and overall system accuracy in syntaxinformed machine translation. Their research is similar to the work presented here, but they focused on the use of varying amounts of out-ofdomain training data for the parser, measuring how a translation system for technical text performed when its syntactic parser was trained with varying amounts of Wall Street Journal text. Our work, in contrast, investigates the use of domain-specific training material in parsers for biomedical text, a domain where significant amounts of effort are alloc</context>
</contexts>
<marker>Quirk, Corston-Oliver, 2006</marker>
<rawString>Quirk, C. and Corston-Oliver S. 2006. The impact of parse quality on syntactically-informed statistical machine translation. In Proceedings of EMNLP 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Stre</author>
<author>K Sagae</author>
<author>J Tsujii</author>
</authors>
<title>Syntactic features for protein-protein interaction extraction.</title>
<date>2007</date>
<booktitle>In Proceedings of the International Symposium on Languages in Biology and Medicine (LBM</booktitle>
<contexts>
<context position="3638" citStr="Stre et al., 2007" startWordPosition="542" endWordPosition="545">l., 2004; Tateisi et al., 2005) and rapid progress of data-driven parsers (Lease and Charniak, 2005; Nivre et al., 2007), there are now fast, robust and accurate syntactic parsers for text in the biomedical domain. Recent research shows that parsing accuracy of biomedical corpora is now between 80% and 90% (Clegg and Shepherd, 2007; Pyysalo et al., 2007; Sagae et al., 2008). Intuitively, syntactic relationships between words should be valuable in determining possible interactions between entities present in text. Recent PPI extraction systems have confirmed this intuition (Erkan et al., 2007; Stre et al., 2007; Katrenko and Adriaans, 2006). While it is now relatively clear that syntactic parsing is useful in practical tasks that use natural language corpora in bioinformatics, several ques14 \x0ctions remain as to research issues that affect the design and testing of end-user applications, including how syntactic analyses should be used in a practical setting, whether further improvements in parsing technologies will result in further improvements in practical systems, whether it is important to continue the development of treebanks and parser adaptation techniques for the biomedical domain, and how</context>
<context position="5569" citStr="Stre et al., 2007" startWordPosition="847" endWordPosition="850"> parsing research. In section 2 we discuss our motivation and related efforts. Section 3 describes the system for identification of protein-protein interactions used in our experiments, and in section 4 describes the syntactic parser that provides the analyses for the PPI system, and the data used to train the parser. We describe our experiments, results and analysis in section 5, and conclude in section 6. 2 Motivation and related work While recent work has addressed questions relating to the use of different parsers or different types of syntactic representations in the PPI extraction task (Stre et al., 2007, Miyao et al., 2008), little concrete evidence has been provided for potential benefits of improved parsers or additional resources for training syntactic parsers. In fact, although there is increasing interest in parser evaluation in the biomedical domain in terms of precision/recall of brackets and dependency accuracy (Clegg and Shepherd, 2007; Pyysalo et al., 2007; Sagae et al., 2008), the relationship between these evaluation metrics and the performance of practical information extraction systems remains unclear. In the parsing community, relatively small accuracy gains are often reported</context>
<context position="8691" citStr="Stre et al., 2007" startWordPosition="1332" endWordPosition="1335">PI extraction system based on syntactic parsing PPI extraction is an NLP task to identify protein pairs that are mentioned as interacting in biomedical papers. Figure 2 shows two sentences that include protein names: the former sentence mentions a protein interaction, while the latter does not. Given a protein pair, PPI extraction is a task of binary classification; for example, &lt;IL-8, CXCR1&gt; 15 \x0cis a positive example, and &lt;RBP, TTR&gt; is a negative example. Following recent work on using dependency parsing in systems that identify protein interactions in biomedical text (Erkan et al., 2007; Stre et al., 2007; Katrenko and Adriaans, 2006), we have built a system for PPI extraction that uses dependency relations as features. As exemplified, for the protein pair IL-8 and CXCR1 in the first sentence of Figure 2, a dependency parser outputs a dependency tree shown in Figure 1. From this dependency tree, we can extract a dependency path between IL-8 and CXCR1 (Figure 3), which appears to be a strong clue in knowing that these proteins are mentioned as interacting. The system we use in this paper is similar to the one described in Stre et al. (2007), except that it uses syntactic dependency paths obtain</context>
<context position="15175" citStr="Stre et al, 2007" startWordPosition="2390" endWordPosition="2393">bank is used for training the parser, while the Aimed is used for training and evaluation of PPI extraction. A part-of-speech tagger trained with GENIA and PennBioIE was used. We do not apply automatic protein name detection, and instead use the gold-standard protein annotations in the Aimed corpus. Before running a parser, multiword protein names are concatenated and treated as single words. As described in Section 3, bag-of-words and syntactic dependency paths are fed as features to the PPI classifier. The accuracy of PPI extraction is measured by the abstract-wise 10-fold cross validation (Stre et al, 2007). When we use the part-of-speech tagger and the dependency parser trained with WSJ, the accuracy (F-score) of PPI extraction on this data set is 55.2. The accuracy increases to 56.9 when we train the part-of-speech tagger with GENIA and Penn BioIE, while using the WSJ-trained parser. This confirms the claims by Lease and Charniak (2005) that subsentential lexical analysis alone is helpful in adapting WSJ parsers to the biomedical domain. While Lease and Charniak looked only at parse accuracy, 70 75 80 85 90 0 2000 4000 6000 8000 Figure 4: A tree kernel representation of the dependency path (de</context>
</contexts>
<marker>Stre, Sagae, Tsujii, 2007</marker>
<rawString>Stre, R., Sagae, K., and Tsujii, J. 2007. Syntactic features for protein-protein interaction extraction. In Proceedings of the International Symposium on Languages in Biology and Medicine (LBM short oral presentations).</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Sagae</author>
<author>A Lavie</author>
</authors>
<title>A best-first probabilistic shift-reduce parser.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions,</booktitle>
<pages>691698</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sydney, Australia,</location>
<contexts>
<context position="10748" citStr="Sagae and Lavie (2006)" startWordPosition="1664" endWordPosition="1667">ich are sentencesplit, tokenized, and annotated with proteins and PPIs. 4 A data-driven dependency parser for biomedical text The parser we used as component of our PPI extraction system was a shift-reduce dependency parser that uses maximum entropy models to determine the parsers actions. Our overall parsing approach uses a best-first probabilistic shift-reduce algorithm, working left-to right to find labeled dependencies one at a time. The algorithm is essentially a dependency version of the constituent parsing algorithm for probabilistic parsing with LR-like data-driven models described by Sagae and Lavie (2006). This dependency parser has been shown to have state-of-the-art accuracy in the CoNLL shared tasks on dependency parsing (Buchholz and Marsi, 2006; Nivre, 2007). Sagae and Tsujii (2007) present a detailed description of the parsing approach used in our work, including the parsing algorithm and the features used to classify parser actions. In summary, the parser uses an algorithm similar to the LR parsing algorithm (Knuth, 1965), keeping a stack of partially built syntactic structures, and a queue of remaining input tokens. At each step in the parsing process, the parser can apply a shift acti</context>
</contexts>
<marker>Sagae, Lavie, 2006</marker>
<rawString>Sagae, K. and Lavie, A. 2006. A best-first probabilistic shift-reduce parser. In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 691698, Sydney, Australia, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Sagae</author>
<author>Y Miyao</author>
<author>J Tsujii</author>
</authors>
<title>Challenges in Mapping of Syntactic Representations for Framework-Independent Parser Evaluation.</title>
<date>2008</date>
<booktitle>In Proceedings of the Workshop on Automated Syntatic Annotations for Interoperable Language Resources at the First International Conference on Global Interoperability for Language Resources (ICGL&apos;08).</booktitle>
<contexts>
<context position="3397" citStr="Sagae et al., 2008" startWordPosition="507" endWordPosition="510">on task in the biomedical domain, the identification of proteinprotein interactions (PPI) mentioned in papers abstracts from MEDLINE, a large database of biomedical papers. Due in large part to the creation of biomedical treebanks (Kulick et al., 2004; Tateisi et al., 2005) and rapid progress of data-driven parsers (Lease and Charniak, 2005; Nivre et al., 2007), there are now fast, robust and accurate syntactic parsers for text in the biomedical domain. Recent research shows that parsing accuracy of biomedical corpora is now between 80% and 90% (Clegg and Shepherd, 2007; Pyysalo et al., 2007; Sagae et al., 2008). Intuitively, syntactic relationships between words should be valuable in determining possible interactions between entities present in text. Recent PPI extraction systems have confirmed this intuition (Erkan et al., 2007; Stre et al., 2007; Katrenko and Adriaans, 2006). While it is now relatively clear that syntactic parsing is useful in practical tasks that use natural language corpora in bioinformatics, several ques14 \x0ctions remain as to research issues that affect the design and testing of end-user applications, including how syntactic analyses should be used in a practical setting, wh</context>
<context position="5960" citStr="Sagae et al., 2008" startWordPosition="907" endWordPosition="910">onclude in section 6. 2 Motivation and related work While recent work has addressed questions relating to the use of different parsers or different types of syntactic representations in the PPI extraction task (Stre et al., 2007, Miyao et al., 2008), little concrete evidence has been provided for potential benefits of improved parsers or additional resources for training syntactic parsers. In fact, although there is increasing interest in parser evaluation in the biomedical domain in terms of precision/recall of brackets and dependency accuracy (Clegg and Shepherd, 2007; Pyysalo et al., 2007; Sagae et al., 2008), the relationship between these evaluation metrics and the performance of practical information extraction systems remains unclear. In the parsing community, relatively small accuracy gains are often reported as success stories, but again, the precise impact of such improvements on practical tasks in bioinformatics has not been established. One aspect of this issue is the question of domain portability and domain adaptation for parsers and other NLP modules. Clegg and Shepherd (2007) mention that available statistical parsers appear to overfit to the newswire domain, because of their extensiv</context>
</contexts>
<marker>Sagae, Miyao, Tsujii, 2008</marker>
<rawString>Sagae, K., Miyao, Y. and Tsujii, J. 2008. Challenges in Mapping of Syntactic Representations for Framework-Independent Parser Evaluation. In Proceedings of the Workshop on Automated Syntatic Annotations for Interoperable Language Resources at the First International Conference on Global Interoperability for Language Resources (ICGL&apos;08).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Tateisi</author>
<author>A Yakushiji</author>
<author>T Ohta</author>
<author>J Tsujii</author>
</authors>
<title>Syntax annotation for the GENIA corpus.</title>
<date>2005</date>
<booktitle>In Proceedings Second International Joint Conference on Natural Language Processing: Companion Volume including Posters/Demos and tutorial abstracts.</booktitle>
<contexts>
<context position="3052" citStr="Tateisi et al., 2005" startWordPosition="450" endWordPosition="453">e performance of the larger systems they compose is an issue that has received relatively little attention. This issue, however, is of great practical importance in the effective design and engineering of complex software systems that deal with natural language. In this paper we explore some of these issues empirically in an information extraction task in the biomedical domain, the identification of proteinprotein interactions (PPI) mentioned in papers abstracts from MEDLINE, a large database of biomedical papers. Due in large part to the creation of biomedical treebanks (Kulick et al., 2004; Tateisi et al., 2005) and rapid progress of data-driven parsers (Lease and Charniak, 2005; Nivre et al., 2007), there are now fast, robust and accurate syntactic parsers for text in the biomedical domain. Recent research shows that parsing accuracy of biomedical corpora is now between 80% and 90% (Clegg and Shepherd, 2007; Pyysalo et al., 2007; Sagae et al., 2008). Intuitively, syntactic relationships between words should be valuable in determining possible interactions between entities present in text. Recent PPI extraction systems have confirmed this intuition (Erkan et al., 2007; Stre et al., 2007; Katrenko and</context>
<context position="7135" citStr="Tateisi et al., 2005" startWordPosition="1086" endWordPosition="1089">the newswire domain, because of their extensive use of the Wall Street Journal portion of the Penn Treebank (Marcus et al., 1994) during development and training. While this claim is supported by convincing evaluations that show that parsers trained on the WSJ Penn Treebank alone perform poorly on biomedical text in terms of accuracy of dependencies or bracketing of phrase structure, the benefits of using domainspecific data in terms of practical system performance have not been quantified. These expected benefits drive the development of domain-specific resources, such as the GENIA treebank (Tateisi et al., 2005), and parser domain adaption (Hara et al., 2007), which are of clear importance in parsing research, but of largely unconfirmed impact on practical systems. Quirk and Corston-Oliver (2006) examine a similar issue, the relationship between parser accuracy and overall system accuracy in syntaxinformed machine translation. Their research is similar to the work presented here, but they focused on the use of varying amounts of out-ofdomain training data for the parser, measuring how a translation system for technical text performed when its syntactic parser was trained with varying amounts of Wall </context>
<context position="12549" citStr="Tateisi et al., 2005" startWordPosition="1961" endWordPosition="1964"> Figure 3: A dependency path between protein names SBJ OBJ 16 \x0cstack items, and push a new item composed of the two popped items combined in a single structure). This parsing approach is very similar to the one used successfully by Nivre et al. (2006), but we use a maximum entropy classifier (Berger et al., 1996) to determine parser actions, which makes parsing considerably faster. In addition, our parsing approach performs a search over the space of possible parser actions, while Nivre et al.s approach is deterministic. The parser was trained using 8,000 sentences from the GENIA Treebank (Tateisi et al., 2005), which contains abstracts of papers taken from MEDLINE, annotated with syntactic structures. To determine the effects of training set size on the parser, and consequently on the PPI extraction system, we trained several parsing models with different amounts of GENIA Treebank data. We started with 100 sentences, and increased the training set by 100 sentence increments, up to 1,000 sentences. From that point, we increased the training set by 1,000 sentence increments. Figure 5 shows the labeled dependency accuracy for the varying sizes of training sets. The accuracy was measured on a portion o</context>
</contexts>
<marker>Tateisi, Yakushiji, Ohta, Tsujii, 2005</marker>
<rawString>Tateisi, Y., Yakushiji, A., Ohta, T., and Tsujii, J. 2005. Syntax annotation for the GENIA corpus. In Proceedings Second International Joint Conference on Natural Language Processing: Companion Volume including Posters/Demos and tutorial abstracts.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>