 A different approach is proposed by CITATION, who develops log-linear models for attribute-value grammars, such as Head-driven Phrase Structure Grammar (HPSG),,
 A recent development in the theory of CCG is the multi-modal treatment given by CITATION and CITATION, following the type-logical approaches to Categorial Grammar CITATION,,
 A recent development in the theory of CCG is the multi-modal treatment given by CITATION and CITATION, following the type-logical approaches to Categorial Grammar CITATION,,
 A key component of the parsing system is a Maximum Entropy CCG supertagger (CITATION; CITATION) which assigns lexical categories to words in a sentence,,
 Second, it greatly increases the efficiency of the parser, which was the original motivation for supertagging CITATION,,
 TAG grammars have been automatically extracted from the Penn Treebank, using techniques similar to those used by Hockenmaier (CITATION; Xia, Palmer, and Joshi 2000),,
 Also, the supertagging idea which is central to the efficiency of the CCG parser originated with TAG CITATION,,
 CITATION describe the results of reranking the output of an HMM supertagger using an automatically extracted LTAG,,
 CITATION investigate the potential impact of LTAG supertagging on parsing speed and accuracy by performing a number of oracle experiments,,
 CITATION show how this can be done for the grammar and parser described in this article,,
 Later we show that use of a supertagger CITATION prior to parsing can produce an extremely efficient parser,,
 The first step can be performed by simply assigning to each word all lexical categories the word is seen with in the training data, together with some strategy for dealing with rare and unknown words (such as assigning the complete lexical category set; CITATIONa),,
 In this article we take a different approach, by using a supertagger CITATION to perform step one,,
 CITATIONa) describe the supertagger, which uses log-linear models to define a distribution over the lexical category set for each local five-word context containing the target word CITATION,,
 In the original Categorial Grammar CITATION, which is context-free, there are two rules of functional application: X/Y Y X (>) (3) Y X\\Y X (<) (4) where X and Y denote categories (either basic or complex),,
 Introduction Log-linear models have been applied to a number of problems in NLP, for example, POS tagging (CITATION; Lafferty, McCallum, and Pereira 2001), named entity recognition CITATION, chunking CITATION, and parsing CITATION,,
 Log-linear models have previously been applied to statistical parsing (CITATION; CITATION; CITATION; Malouf and van Noord 2004), but typically under the assumption that all possible parses for a sentence can be en,,
 Combinatory Categorial Grammar Combinatory Categorial Grammar (CCG) (CITATION, 2000) is a type-driven lexicalized theory of grammar based on Categorial Grammar CITATION,,
 In this article we are concerned with the syntactic component; see CITATION for how a semantic interpretation can be composed during a syntactic derivation, and also CITATION for how semantic interpretations can be built for newspaper text using the wide-coverage parser described in this article,,
 parsing process in a straightforward manner, rather than be relegated to such a post-processing phase (Clark, Hockenmaier, and Steedman 2002; CITATIONa; Clark, Steedman, and Curran 2004),,
 CITATION show how this can be done for the grammar and parser described in this article,,
 Later we show that use of a supertagger CITATION prior to parsi,,
 The GRs are described in CITATION, CITATION, and Briscoe, Carroll, and Watson (2006),,
 The ta relation, which identifies text adjuncts delimited by punctuation CITATION, is difficult to assign correctly to the parser output,,
 CITATION evaluate their HPSG parser against PropBank (Palmer, Gildea, and Kingsbury 2005),,
 CITATION compare the Collins parser with the Parc LFG parser by mapping Penn Treebank parses into the dependencies of DepBank, claiming that the LFG parser is more accurate with only a slight reduction in speed,,
 CITATION compares the parsers of Collins and Charniak, the grammatical relations finder of Buchholz, Veenstra, and Daelemans (1999), and the CITATION parser, using the gold-standard grammatical relations (GRs) from Carroll, Briscoe, and Sanfilippo (1998),,
 CITATION evaluate the RASP parser on the Parc Dependency Bank (DepBank; King et al,,
 CITATION evaluate their HPSG parser against PropBank (Palmer, Gildea, and Kingsbury 2005),,
 CITATION compare the Collins parser with the Parc LFG parser by mapping Penn Treebank parses into the dependencies of DepBank, claiming that the LFG parser is more accurate with only a slight reduction in speed,,
 CITATION compares the parsers of Collins and Charniak, the grammatical re,,
 The second difficulty is that some constructions may be analyzed differently across formalisms, and even apparently trivial differences such as tokenization can complicate the comparison CITATION,,
 For the gold standard we chose the version of DepBank reannotated by CITATION (hereafter B&C), consisting of 700 sentences from Section 23 of the Penn Treebank,,
 CITATION describe the differences between the two schemes,,
76 The CCG parser results are based on automatically assigned POS tags, using the CITATION tagger,,
 The coverage of the RASP parser is also 100%: 84% of the analyses are complete parses rooted in S and the rest are obtained using a robustness technique based on fragmentary analyses CITATION,,
 CITATION give a rough comparison of RASP with the Parc LFG parser CITATION on DepBank, obtaining similar results overall, but acknowledging that the results are not strictly comparable because of the different annotation schemes used,,
 CITATIONa) and CITATIONb) present a generative model of normal-form derivations, based on various techniques from the statistical parsing literature (CITATION; CITATION; CITATION),,
 Long-range dependencies are relatively common in text such as newspaper text, but are typically not recovered by treebank parsers such as CITATION and CITATION,,
 This has led to a number of proposals for post-processing the output of the Collins and Charniak parsers, in which trace sites are located and the antecedent of the trace determined (CITATION; CITATION; CITATION),,
 An advantage of using CCG is that 501 \x0cComputational Linguistics Volume 33, Number 4 the recovery of long-range dependencies can be integrated into the parsing process in a straightforward manner, rather than be relegated to such a post-processing phase (Clark, Hockenmaier, and Steedman 2002; CITATIONa; Clark, Steedman, and Curran 2004),,
 TAG grammars have been automatically extracted from the Penn Treebank, using techniques similar to those used by Hockenmaier (CITATION; Xia, Palmer, and Joshi 2000),,
 Also, the supertagging idea which is central to the efficiency of the CCG parser originated with TAG CITATION,,
 CITATION describe the results of reranking the output of an HMM supertagger using an automatically extracted LTAG,,
 CITATION investigate the potential impact of LTAG supertagging on parsing speed and accuracy by performing a number of oracle experiments,,
 2002; CITATION; Cahill et al,,
 2004), and HPSG (CITATION; Toutanova, Markova, and Manning 2004; CITATION; Malouf and van Noord 2004), among others,,
 TAG grammars have been automatically extracted from the Penn Treebank, using techniques similar to those used by Hockenmaier (CITATION; Xia, Palmer, and Joshi 2000),,
 Also, the supertagging idea which is central to the efficiency of the CCG parser originated with TAG CITATION,,
 CITATION describe the results of reranking the output of an HMM supertagger using an automatically extracted LTAG,,
 CITATION investigate the potential impact of LTAG supertagging on parsing speed and accura,,
 The treebank is CCGbank (CITATIONa; CITATIONa), a CCG version of the Penn Treebank (Marcus, Santorini, and Marcinkiewicz 1993),,
 Penn Treebank conversions have also been carried out for other linguistic formalisms, including TAG (CITATION; Xia, Palmer, and Joshi 2000), LFG (Burke et al,,
 CITATIONa) gives a detailed description of the procedure used to create CCGbank,,
 The conditional-likelihood estimator is also consistent for the conditional distributions CITATION,,
 This smoothing method for log-linear models is also proposed by CITATION,,
 This is not a problem for CITATION because their grammars are hand-written and constraining enough to allow the analyses for each sentence to be enumerated,,
 CITATION investigates training on a sample of the analyses for each sentence, for example the top-n most probable according to some other probab,,
 We follow CITATION in using a discriminative estimation method by maximizing the conditional log-likelihood of the model given the data, minus a Gaussian prior 2 We could model predicateargument dependencies together with the derivation, but we wanted to use features from the derivation only, following CITATIONb),,
 508 \x0cClark and Curran Wide-Coverage Efficient Statistical Parsing term to prevent overfitting (CITATION; CITATION),,
 Statistical parsers have been developed for TAG (CITATION; CITATION), LFG (CITATION; CITATION; Cahill et al,,
 2004), and HPSG (CITATION; Toutanova, Markova, and Manning 2004; CITATION; Malouf and van Noord 2004), among others,,
 And finally, packed charts are an instance of a feature forest, which CITATION show can be used to efficiently estimate expected values of features, even though the expectation may involve a sum over an exponential number of trees in the forest,,
 As CITATION points out, Miyao and Tsujii do not provide a way of constructing a feature forest given a sentence, but provide the mathematical tools for estimation once the feature forest has been constructed,,
 The probability of the category sequence is estimated using a maximum entropy model, following the supertagger described in CITATION,,
 The probabilities of the dependencies are estimated using relative frequencies, following CITATION,,
 With automatically assigned POS tags, using the POS tagger of CITATION, the accuracies drop to 91,,
 CITATION reports that a significant loss in coverage results if the supertagger is used as a front-end to the parser of CITATIONb),,
 CITATION outline an algorithm for finding the most probable dependency structure, which keeps track of the highest scoring set of dependencies for each node in the chart,,
1 Combining the Supertagger and the Parser The philosophy in earlier work which combined the supertagger and parser (Clark, Hockenmaier, and Steedman 2002; CITATION) was to use an unrestrictive setting of the supertagger, but still allow a reasonable compromise between speed and accuracy,,
 The use of conditional log-linear models in this article is designed to overcome some of the weaknesses identified in the approach of Clark, Hockenmaier, and Steedman 503 \x0cComputational Linguistics Volume 33, Number 4 (2002), and to offer a more flexible framework for including features than the generative models of CITATIONa),,
 We also showed in CITATIONb) that, in contrast with CITATIONa), adding distance to the dependency features in the log-linear model does improve parsing accuracy,,
e first step can be performed by simply assigning to each word all lexical categories the word is seen with in the training data, together with some strategy for dealing with rare and unknown words (such as assigning the complete lexical category set; CITATIONa),,
 In this article we take a different approach, by using a supertagger CITATION to perform step one,,
 CITATIONa) describe the supertagger, which uses log-linear models to define a distribution over the lexical category set for each local five-word context containing the target word CITATION,,
 The lexical category set used by the supertagger is described in CITATIONa) and Curran, Clark, and Vadas (2006),,
sing POS tags automatically assigned by the POS tagger described in CITATION,,
 In our earlier work (CITATIONa) the forwardbackward algorithm was not used to estimate the probability in Equation (32),,
 This set has excellent coverage on unseen data (CITATIONa) and is a manageable size for adding the head and dependency information, and also mapping to grammatical relations for evaluation purposes (Section 11),,
 This is a larger grammar than we have used in previous articles (CITATIONb, 2004a, 2006), mainly because the improvement in the supertagger since the earlier work means that we can now use a larger grammar but still maintain highly efficient parsing,,
 The use of conditional log-linear models in this article is designed to overcome some of the weaknesses identified in the approach of Clark, Hockenmaier, and Steedman 503 \x0cComputational Linguistics Volume 33, Number 4 (2002), and to offer a more flexible framework for including features than the generative models of CITATIONa),,
 We also showed in CITATIONb) that, in contrast with CITATIONa), adding distance to the dependency features in the log-linear model does improve parsing accuracy,,
e first step can be performed by simply assigning to each word all lexical categories the word is seen with in the training data, together with some strategy for dealing with rare and unknown words (such as assigning the complete lexical category set; CITATIONa),,
 In this article we take a different approach, by using a supertagger CITATION to perform step one,,
 CITATIONa) describe the supertagger, which uses log-linear models to define a distribution over the lexical category set for each local five-word context containing the target word CITATION,,
 The lexical category set used by the supertagger is described in CITATIONa) and Curran, Clark, and Vadas (2006),,
sing POS tags automatically assigned by the POS tagger described in CITATION,,
 In our earlier work (CITATIONa) the forwardbackward algorithm was not used to estimate the probability in Equation (32),,
 This set has excellent coverage on unseen data (CITATIONa) and is a manageable size for adding the head and dependency information, and also mapping to grammatical relations for evaluation purposes (Section 11),,
 This is a larger grammar than we have used in previous articles (CITATIONb, 2004a, 2006), mainly because the improvement in the supertagger since the earlier work means that we can now use a larger grammar but still maintain highly efficient parsing,,
 For example, we have developed a method for training the dependency model which requires lexical category data only CITATION,,
) 11 The results reported in CITATION differ from those here because Clark and Curran used the normal-form model and Viterbi decoder,,
 There has been some other work on defining stochastic categorial grammars, but mainly in the context of grammar learning (CITATION; CITATION; CITATION),,
 In order to deal with the problem of the additional, nonstandard CCG derivations, a conditional model of dependency structures is presented, based on CITATION, in which the dependencies are modeled directly and derivations are not modeled at all,,
 Long-range dependencies are relatively common in text such as newspaper text, but are typically not recovered by treebank parsers such as CITATION and CITATION,,
 This has led to a number of proposals for post-processing the output of the Collins and Charniak parsers, in which trace sites are located and the antecedent of the trace determined (CITATION; CITATION; CITATION),,
 An advantage of using CCG is that 501 \x0cComputational Linguistics Volume 33, Number 4 the recovery of long-range dependencies can be integrated into the parsing process in a straightforward manner, rather than be relegated to such a post-processing phase (Clark, Hockenmaier, and Steedman 2002; CITATIONa; Clark, Steedman, a,,
 CITATIONa) and CITATIONb) present a generative model of normal-form derivations, based on various techniques from the statistical parsing literature (CITATION; CITATION; CITATION),,
 A possible response to our policy of adaptive supertagging is that any statistical parser can be made to run faster, for example by changing the beam parameter in the CITATION parser, but that any increase in speed is typically associated with a reduction in accuracy,,
 CITATION is a classifier-based linear time p,,
 Two possible extensions, which we have not investigated, include defining dependency features which account for all three elements of the triple in a PP-attachment CITATION, and defining a rule feature which includes the grandparent node CITATION,,
 Another alternative for future work is to compare the dynamic programming approach taken here with the beam-search approach of CITATION, which allows more global features,,
 These scores could be incorporated as real-valued features, or as auxiliary functions, as in CITATION,,
 We would also like to investigate using the generative model of CITATIONb) in a similar way,,
 Using a generative models score as a feature in a discriminative framework has been beneficial for reranking approaches CITATION,,
 If enough unlabeled data is parsed, then the large volume can overcome the noise in the data (CITATION; Prins and van Noord 2003),,
 Two possible extensions, which we have not investigated, include defining dependency features which account for all three elements of the triple in a PP-attachment CITATION, and defining a rule feature which includes the grandparent node CITATION,,
 Another alternative for future work is to compare the dynamic programming approach taken here with the beam-search approach of CITATION, which allows more global features,,
 The second difficulty is that some constructions may be analyzed differently across formalisms, and even apparently trivial differences such as tokenization can complicate the comparison CITATION,,
 For the gold standard we chose the version of DepBank reannotated by CITATION (hereafter B&C), consisting of 700 sentences from Section 23 of the Penn Treebank,,
 CITATION describe the differences between the two schemes,,
 To solve this problem, we have adapted the dynamic programming method of CITATION to packed CCG charts,,
 The dynamic programming method uses inside and outside scores to calculate expectations, similar to the insideoutside algorithm for estimating the parameters of a PCFG from unlabeled data CITATION,,
 Generalized Iterative Scaling CITATION is a common choice in the NLP literature for estimating a log-linear model (e,,
, CITATION; CITATION),,
 Initially we used generalized iterative scaling (GIS) for the parsing models described here, but found that convergence was extremely slow; CITATION present a similar finding for globally optimized log-linear models for sequences,,
 As an alternative to GIS, we use the limited-memory BFGS algorithm CITATION,,
 As CITATION demonstrates, general purpose numerical optimization algorithms such as BFGS can converge much faster than iterative scaling algorithms (including Improved Iterative Scaling; Della Pietra, Della Pietra, and Lafferty 1997),,
ficient parsing algorithm for such a model, based on CITATION, which maximizes the expected recall of dependencies,,
 A key component of the parsing system is a Maximum Entropy CCG supertagger (CITATION; CITATION) which assigns lexical categories to words in a sentence,,
 Second, it greatly increases the efficiency of the parser, which was the original motivation for supertagging CITATION,,
 CITATION gives a more thorough description of numerical optimization methods applied to log-linear models,,
3 Malouf uses standard numerical computation libraries 3 One NLP task for which we have found GIS to be especially suitable is sequence tagging, and we still use GIS to estimate tagging models CITATION,,
 One of our aims was to provide a self contained estimation code base, and so we implemented our own version of the L-BFGS algorithm as described in CITATION,,
 With automatically assigned POS tags, using the POS tagger of CITATION, the accuracies drop to 91,,
 CITATION reports that a significant loss in coverage results if the supertagger is used as a front-end to the parser of CITATIONb),,
 The table gives results when using gold standard POS tags and, in the final two columns, when using POS tags automatically assigned by the POS tagger described in CITATION,,
 In our earlier work (CITATIONa) the forwardbackward algorithm was not used to estimate the probabil,,
76 The CCG parser results are based on automatically assigned POS tags, using the CITATION tagger,,
 The coverage of the RASP parser is also 100%: 84% of the analyses are complete parses rooted in S and the rest are obtained using a robustness technique based on fragmentary analyses CITATION,,
 by > B (because B is the symbol used by Curry to denote function composition in combinatory logic; CITATION): X/Y Y/Z B X/Z (> B) (5) Forward composition is often used in conjunction with type-raising (T), as in Figure 2,,
 To solve this problem, we have adapted the dynamic programming method of CITATION to packed CCG charts,,
 The dynamic programming method uses inside and outside scores to calculate expectations, similar to the insideoutside algorithm for estimating the parameters of a PCFG from unlabeled data CITATION,,
 Generalized Iterative Scaling CITATION is a common choice in the NLP literature for estimating a log-linear model (e,,
, CITATION; CITATION),,
 Initially we used generalized iterative scaling (GIS) for the parsing models described here, but found that convergence was extremely slow; CITATION present a similar finding for globally optimized log-linear models for sequences,,
 As an alternative to GIS, we use the limited-memory BFGS algorithm CITATION,,
 As CITATION demonstrates, general purpose numerical optimization algorithms such as BFGS can converge much faster than iterative sc,,
 Long-range dependencies are relatively common in text such as newspaper text, but are typically not recovered by treebank parsers such as CITATION and CITATION,,
 This has led to a number of proposals for post-processing the output of the Collins and Charniak parsers, in which trace sites are located and the antecedent of the trace determined (CITATION; CITATION; CITATION),,
 An advantage of using CCG is that 501 \x0cComputational Linguistics Volume 33, Number 4 the recovery of long-range dependencies can be integrated into the parsing process in a straightforward manner, rather than be relegated to such a post-processing phase (Clark, Hockenmaier, and Steedman 2002; CITATIONa; Clark, Steedman, and Curran 2004),,
 The first, following CITATIONa), is to define a model in terms of normal-form derivations CITATION,,
 We also define a new efficient parsing algorithm for such a model, based on CITATION, which maximizes the expected recall of dependencies,,
 CITATION describes a technique for eliminating spurious ambiguity entirely, by defining exactly one normal-form derivation for each semantic equivalence class of derivations,,
 CITATION investigates training on a sample of the analyses for each sentence, for example the top-n most probable according to some other probability model, or simply a random sample,,
 We adapt the feature-forest method of CITATION, which involves using dynamic programming to efficiently calculate the feature expectations,,
 CITATION propose a similar method in the context of LFG parsing; an implementation is described in CITATION,,
 In CITATIONb, 2003a) log-linear models are developed for automatically extracted grammars for Lexicalized Tree Adjoining Grammar (LTAG) and Head Driven Phrase Structure Grammar (HPSG),,
 There is some experimental evidence showing that, perhaps not surprisingly, the performance of parsers trained on the WSJ Penn Treebank drops significantly when the parser is applied to domains outside of newspaper text (CITATION; CITATION),,
 The first, following CITATIONa), is to define a model in terms of normal-form derivations CITATION,,
 We also define a new efficient parsing algorithm for such a model, based on CITATION, which maximizes the expected recall of dependencies,,
 A key component of the parsing system is a Maximum Entropy CCG supertagger (CITATION; CITATION) which assigns lexical categories to words in,,
 CITATIONa) and CITATIONb) present a generative model of normal-form derivations, based on various techniques from the statistical parsing literature (CITATION; CITATION; CITATION),,
 We use the the Message Passing Interface (MPI) standard for the implementation CITATION,,
 The lexicalized grammar formalism we use is Combinatory Categorial Grammar (CCG; CITATION),,
 A number of statistical parsing models have recently been developed for CCG and used in parsers applied to newspaper text (Clark, Hockenmaier, and Steedman 2002; CITATIONb; CITATIONb),,
 The first, following CITATIONa), is to define a model in terms of normal-form derivations CITATION,,
 We also define a new efficient parsing algorithm for such a model, based on CITATION, which maximizes the expected recall of dependencies,,
eebank parsers such as CITATION and CITATION,,
 This has led to a number of proposals for post-processing the output of the Collins and Charniak parsers, in which trace sites are located and the antecedent of the trace determined (CITATION; CITATION; CITATION),,
 An advantage of using CCG is that 501 \x0cComputational Linguistics Volume 33, Number 4 the recovery of long-range dependencies can be integrated into the parsing process in a straightforward manner, rather than be relegated to such a post-processing phase (Clark, Hockenmaier, and Steedman 2002; CITATIONa; Clark, Steedman, and Curran 2004),,
 CITATION show how this can be done for the grammar and parser described in this article,,
 CITATIONa) and CITATIONb) present a generative model of normal-form derivations, based on various techniques from the statistical parsing literature (CITATION; CITATION; CITATION),,
 Various extensions to the baseline are considered: increasing the amount of lexicalization; generating a lexical category at its maximal projection; conditioning the probability of a rule instantiation on the grandparent node CITATION; adding features designed to deal with coordination; and adding distance to the dependency features,,
 CITATIONa) conjectures that the reduced performance is due to the problem of data sparseness, which becomes particularly severe for the generative model when the number of features is increased,,
 CITATIONb) presents another generative model of normal-form derivations, which is based on the dependencies in the predicateargument structure, including long-range dependencies, rather than the dependenci,,
 The use of conditional log-linear models in this article is designed to overcome some of the weaknesses identified in the approach of Clark, Hockenmaier, and Steedman 503 \x0cComputational Linguistics Volume 33, Number 4 (2002), and to offer a more flexible framework for including features than the generative models of CITATIONa),,
 We also showed in CITATIONb) that, in contrast with CITATIONa), adding distance to the dependency features in the log-linear model does improve parsing accuracy,,
; CITATIONa), a CCG version of the Penn Treebank (Marcus, Santorini, and Marcinkiewicz 1993),,
 Penn Treebank conversions have also been carried out for other linguistic formalisms, including TAG (CITATION; Xia, Palmer, and Joshi 2000), LFG (Burke et al,,
 CITATIONa) gives a detailed description of the procedure used to create CCGbank,,
 Sentence categories (S) in CCGbank carry features, such as [dcl] for declarative, [wq] for wh-questions, and [for] for small clauses headed by for; see CITATIONa) for the complete list,,
 The following examples, taken from CITATIONa), demonstrate the most common rules,,
 One of the advantages of log-linear models is that it is easy to include such features; CITATIONb) describes the difficulties in including such 512 \x0cClark and Curran Wide-Coverage Efficient Statistical Parsing features in a generative model,,
 The first step can be performed by simply assigning to each word all lexical categories the word is seen with in the training data, together with some strategy for dealing with rare and unknown words (such as assigning the complete lexical category set; CITATIONa),,
 In this article we take a different approach, by using a supertagger CITATION to perform step one,,
 CITATIONa) describe the supertagger, which uses log-linear models to define a distribution over the lexical category set for each local five-word context containing the target word CITATION,,
 With automatically assigned POS tags, using the POS tagger of CITATION, the accuracies drop to 91,,
 CITATION reports that a significant loss in coverage results if the supertagger is used as a front-end to the parser of CITATIONb),,
 These scores could be incorporated as real-valued features, or as auxiliary functions, as in CITATION,,
 We would also like to investigate using the generative model of CITATIONb) in a similar way,,
 Using a generative models score as a feature in a discriminative framework has been beneficial for reranking approaches CITATION,,
dynamic programming method of CITATION to a packed chart; however, because the grammar is automatically extracted, the packed charts require a considerable amount of memory: up to 25 GB,,
 The lexicalized grammar formalism we use is Combinatory Categorial Grammar (CCG; CITATION),,
 A number of statistical parsing models have recently been developed for CCG and used in parsers applied to newspaper text (Clark, Hockenmaier, and Steedman 2002; CITATIONb; CITATIONb),,
 CITATIONa) and CITATIONb) present a generative model of normal-form derivations, based on various techniques from the statistical parsing literature (CITATION; CITATION; CITATION),,
 CITATIONb) presents another generative model of normal-form derivations, which is based on the dependencies in the predicateargument structure, including long-range dependencies, rather than the dependencies defined by the local trees in the derivation,,
 Hockenmaier also argues that, compared to CITATIONb), the predicateargument model is better suited to languages with freer word order than English,,
 In fact, the results given in CITATIONb) are lower than previous results,,
 However, CITATIONb) reports that the increased complexity of the model reduces the effectiveness of the dynamic programming used in the parser, and hence a more aggressive beam search is required to produce reasonable parse times,,
 The treebank is CCGbank (CITATIONa; CITATIONa), a CCG version of the Penn Treebank (Marcus, Santorini, and Marcinkiewicz 1993),,
 Penn Treebank conversions have also been carried out for other linguistic formalisms, including TAG (CITATION; Xia, Palmer, and Joshi 2000), LFG (Burke et al,,
 We follow CITATION in using a discriminative estimation method by maximizing the conditional log-likelihood of the model given the data, minus a Gaussian prior 2 We could model predicateargument dependencies together with the derivation, but we wanted to use features from the derivation only, following CITATIONb),,
 508 \x0cClark and Curran Wide-Coverage Efficient Statistical Parsing term to prevent overfitting (CITATION; CITATION),,
rdWord \x05company, S[dcl]NP S[dcl]\\NP, bought\x06 WordPOS \x05company, S[dcl]NP S[dcl]\\NP, VBD\x06 POSWord \x05NN, S[dcl]NP S[dcl]\\NP, bought\x06 POSPOS \x05NN, S[dcl]NP S[dcl]\\NP, VBD\x06 Word + Distance(words) \x05bought, S[dcl]NP S[dcl]\\NP\x06 + > 2 Word + Distance(punct) \x05bought, S[dcl]NP S[dcl]\\NP\x06 + 2 Word + Distance(verbs) \x05bought, S[dcl]NP S[dcl]\\NP\x06 + 0 POS + Distance(words) \x05VBD, S[dcl]NP S[dcl]\\NP\x06 + > 2 POS + Distance(punct) \x05VBD, S[dcl]NP S[dcl]\\NP\x06 + 2 POS + Distance(verbs) \x05VBD, S[dcl]NP S[dcl]\\NP\x06 + 0 For the normal-form model we follow CITATIONb) by defining dependency features in terms of the local rule instantiations, by adding the heads of the combining categories to the rule instantiation features,,
 With automatically assigned POS tags, using the POS tagger of CITATION, the accuracies drop to 91,,
 CITATION reports that a significant loss in coverage results if the supertagger is used as a front-end to the parser of CITATIONb),,
 These scores could be incorporated as real-valued features, or as auxiliary functions, as in CITATION,,
 We would also like to investigate using the generative model of CITATIONb) in a similar way,,
 Using a generative models score as a feature in a discriminative framework has been beneficial for reranking approaches CITATION,,
 CITATIONa) compares a number of generative models, starting with a baseline model based on a PCFG,,
 Various extensions to the baseline are considered: increasing the amount of lexicalization; generating a lexical category at its maximal projection; conditioning the probability of a rule instantiation on the grandparent node CITATION; adding features designed to deal with coordination; and adding distance to the dependency features,,
 CITATIONa) conjectures that the reduced performance is due to the problem of data sparseness, which becomes particularly severe for the generative model when the number of features is increased,,
 Two possible extensions, which we have not investigated, include defining dependency features which account for all three elements of the triple in a PP-attachment CITATION, and defining a rule feature which includes the grandparent node CITATION,,
 Another alternative for future work is to compare the dynamic programming approach taken here with the beam-search approach of CITATION, which allows more global features,,
 CITATION investigates training on a sample of the analyses for each sentence, for example the top-n most probable according to some other probability model, or simply a random sample,,
 We adapt the feature-forest method of CITATION, which involves using dynamic programming to efficiently calculate the feature expectations,,
 CITATION propose a similar method in the context of LFG parsing; an implementation is described in CITATION,,
 In CITATIONb, 2003a) log-linear models are developed for automatically extracted grammars for Lexicalized Tree Adjoining Grammar (LTAG) and Head Driven Phrase Structure Grammar (HPSG),,
 Long-range dependencies are relatively common in text such as newspaper text, but are typically not recovered by treebank parsers such as CITATION and CITATION,,
 This has led to a number of proposals for post-processing the output of the Collins and Charniak parsers, in which trace sites are located and the antecedent of the trace determined (CITATION; CITATION; CITATION),,
 An advantage of using CCG is that 501 \x0cComputational Linguistics Volume 33, Number 4 the recovery of long-range dependencies can be integrated into the parsing process in a straightforward manner, rather than be relegated to such a post-processing phase (Clark, Hockenmaier, and Steedman 2002; CITATIONa; Clark, Steedman, and Curran 2004),,
 Introduction Log-linear models have been applied to a number of problems in NLP, for example, POS tagging (CITATION; Lafferty, McCallum, and Pereira 2001), named entity recognition CITATION, chunking CITATION, and parsing CITATION,,
 Log-linear models have previously been applied to statistical parsing (CITATION; CITATION; CITATION; Malouf and van Noord 2004), but typically under the assumption that all possible parses for a sentence can be enumerated,,
 CITATION propose an alternative solution, which is to maximize the conditional likelihood function,,
 This smoothing method for log-linear models is also proposed by CITATION,,
 This is not a problem for CITATION because their grammars are hand-written and constraining enough to allow the analyses for each sentence to be enumerated,,
 CITATION investigates training on a sample of the analyses for each sentence, for example the top-n most probable according to some other probability model, or simply a random sample,,
 We follow CITATION in using a discriminative estimation method by maximizing the conditional log-likelihood of the model given the data, minus a Gaussian prior 2 We could model predicateargument dependencies together with the derivation, but we wanted to use features from the derivation only, following CITATIONb),,
 508 \x0cClark and Curran Wide-Coverage Efficient Statistical Parsing term to prevent overfitting (CITATION; CITATION),,
 These scores could be incorporated as real-valued features, or as auxiliary functions, as in CITATION,,
 We would also like to investigate using the generative model of CITATIONb) in a similar way,,
 Using a generative models score as a feature in a discriminative framework has been beneficial for reranking approaches CITATION,,
 We adapt the feature-forest method of CITATION, which involves using dynamic programming to efficiently calculate the feature expectations,,
 CITATION propose a similar method in the context of LFG parsing; an implementation is described in CITATION,,
 In CITATIONb, 2003a) log-linear models are developed for automatically extracted grammars for Lexicalized Tree Adjoining Grammar (LTAG) and Head Driven Phrase Structure Grammar (HPSG),,
 CITATIONa) present another log-linear model for an automatically extracted LTAG which u,,
 Another difference is that Malouf and van Noord use the random sampling method of CITATION to allow practical estimation, whereas we construct the complete parse forest but use the supertagger to limit the size of the charts,,
 CITATION present similar work to ours in the context of an LFG grammar for English,,
 CITATION evaluate the RASP parser on the Parc Dependency Bank (DepBank; King et al,,
 CITATION evaluate their HPSG parser against PropBank (Palmer, Gildea, and Kingsbury 2005),,
 CITATION compare the Collins parser with the Parc LFG parser by mapping Penn Treebank parses into the dependencies of DepBank, claiming that the LFG parser is more accurate with only a slight reduction in speed,,
 CITATION compares the parsers of Collins and Charniak, the grammatical relations finder of Buchholz, Veenstra, and Daelemans (1999), and the CITATION parser, using the gold-standard grammatical relations (GRs) from Carroll, Briscoe, and Sanfilippo (1998),,
 This method would be useful when converting the output of the Collins parser into an alternative representation CITATION: Applying the transformation to the gold-standard Penn Treebank trees and comparing with DepBank would provide an upper bound on the performance of the Collins parser and give some indication of the effectiveness of the transformation,,
 CITATION give a rough comparison of RASP with the Parc LFG parser CITATION on DepBank, obtaining similar results overall, but acknowledging that the results are not strictly comparable because of the different annotation schemes used,,
2 Chart Parsing Algorithm The algorithm used to build the packed charts is the CKY chart parsing algorithm (CITATION; CITATION) described in CITATION,,
 Introduction Log-linear models have been applied to a number of problems in NLP, for example, POS tagging (CITATION; Lafferty, McCallum, and Pereira 2001), named entity recognition CITATION, chunking CITATION, and parsing CITATION,,
 Log-linear models have previously been applied to statistical parsing (CITATION; CITATION; CITATION; Malouf and van Noord 2004), but typically under the assumption that all possible parses for a sentence can be enumerated,,
 To solve this problem, we have adapted the dynamic programming method of CITATION to packed CCG charts,,
 The dynamic programming method uses inside and outside scores to calculate expectations, similar to the insideoutside algorithm for estimating the parameters of a PCFG from unlabeled data CITATION,,
 Generalized Iterative Scaling CITATION is a common choice in the NLP literature for estimating a log-linear model (e,,
, CITATION; CITATION),,
 Initially we used generalized iterative scaling (GIS) for the parsing models described here, but found that convergence was extremely slow; CITATION present a similar finding for globally optimized log-linear models for sequences,,
 As an alternative to GIS, we use the limited-memory BFGS algorithm CITATION,,
 As CITATION demonstrates, general purpose numerical optimization algorit,,
 There is some experimental evidence showing that, perhaps not surprisingly, the performance of parsers trained on the WSJ Penn Treebank drops significantly when the parser is applied to domains outside of newspaper text (CITATION; CITATION),,
 Long-range dependencies are relatively common in text such as newspaper text, but are typically not recovered by treebank parsers such as CITATION and CITATION,,
 This has led to a number of proposals for post-processing the output of the Collins and Charniak parsers, in which trace sites are located and the antecedent of the trace determined (CITATION; CITATION; CITATION),,
 An advantage of using CCG is that 501 \x0cComputational Linguistics Volume 33, Number 4 the recovery of long-range dependencies can be integrated into the parsing process in a straightforward manner, rather than be relegated to such a post-processing phase (Clark, Hockenmaier, and Steedman 2002; CITATIONa; Clark, Steedman, and Curran 2004),,
imating the parameters of a PCFG from unlabeled data CITATION,,
 Generalized Iterative Scaling CITATION is a common choice in the NLP literature for estimating a log-linear model (e,,
, CITATION; CITATION),,
 Initially we used generalized iterative scaling (GIS) for the parsing models described here, but found that convergence was extremely slow; CITATION present a similar finding for globally optimized log-linear models for sequences,,
 As an alternative to GIS, we use the limited-memory BFGS algorithm CITATION,,
 As CITATION demonstrates, general purpose numerical optimization algorithms such as BFGS can converge much faster than iterative scaling algorithms (including Improved Iterative Scaling; Della Pietra, Della Pietra, and Lafferty 1997),,
 CITATION gives a more thorough description of numerical optimization methods applied to log-linear models,,
3 Malouf uses standard numerical computation libraries 3 One NLP task for which we have found GIS to be especially suitable is sequence tagging, and we still use GIS to estimate tagging models CITATION,,
 Log-linear models have previously been applied to statistical parsing (CITATION; CITATION; CITATION; Malouf and van Noord 2004), but typically under the assumption that all possible parses for a sentence can be enumerated,,
 In this article we apply the dynamic programming method of CITATION to a packed chart; however, because the grammar is automatically extracted, the packed charts require a considerable amount of memory: up to 25 GB,,
 The lexicalized grammar formalism we use is Combinatory Categorial Grammar (CCG; CITATION),,
 A number of statistical parsing models have recently been developed for CCG and used in parsers applied to newspaper text (Clark, Hockenmaier, and Steedman 2002; CITATIONb; CITATIONb),,
 To solve this problem, we have adapted the dynamic programming method of CITATION to packed CCG charts,,
 The dynamic programming method uses inside and outside scores to calculate expectations, similar to the insideoutside algorithm for estimating the parameters of a PCFG from unlabeled data CITATION,,
 Generalized Iterative Scaling CITATION is a common choice in the NLP literature for estimating a log-linear model (e,,
, CITATION; CITATION),,
 CITATION investigates training on a sample of the analyses for each sentence, for example the top-n most probable according to some other probability model, or simply a random sample,,
 We adapt the feature-forest method of CITATION, which involves using dynamic programming to efficiently calculate the feature expectations,,
 CITATION propose a similar method in the context of LFG parsing; an implementation is described in CITATION,,
 In CITATIONb, 2003a) log-linear models are developed for automatically extracted grammars for Lexicalized Tree Adjoining Grammar (LTAG) and Head Driven Phrase Structure Grammar (HPSG),,
 And finally, packed charts are an instance of a feature forest, which CITATION show can be used to efficiently estimate expected values of features, even though the expectation may involve a sum over an exponential number of trees in the forest,,
 As CITATION points out, Miyao and Tsujii do not provide a way of constructing a feature forest given a sentence, but provide the mathematical tools for estimation once the feature forest has been constructed,,
 We adapt the feature-forest method of CITATION, which involves using dynamic programming to efficiently calculate the feature expectations,,
 CITATION propose a similar method in the context of LFG parsing; an implementation is described in CITATION,,
 In CITATIONb, 2003a) log-linear models are developed for automatically extracted grammars for Lexicalized Tree Adjoining Grammar (LTAG) and Head Driven Phrase Structure Grammar (HPSG),,
 CITATIONa) present another log-linear model for an automatically extracted LTAG which uses a simple unigram model of the elementary trees together with a loglinear model of the attachments,,
 We adapt the feature-forest method of CITATION, which involves using dynamic programming to efficiently calculate the feature expectations,,
 CITATION propose a similar method in the context of LFG parsing; an implementation is described in CITATION,,
 In CITATIONb, 2003a) log-linear models are developed for automatically extracted grammars for Lexicalized Tree Adjoining Grammar (LTAG) and Head Driven Phrase Structure Grammar (HPSG),,
 CITATIONa) present another log-linear model for an automatically extracted LTAG which uses a simple unigram model of the elementary trees together with a loglinear model of the attachments,,
 Statistical parsers have been developed for TAG (CITATION; CITATION), LFG (CITATION; CITATION; Cahill et al,,
 2004), and HPSG (CITATION; Toutanova, Markova, and Manning 2004; CITATION; Malouf and van Noord 2004), among others,,
 TAG grammars have been automatically extracted from the Penn Treebank, using techniques similar to those used by Hockenmaier (CITATION; Xia, Palmer, and Joshi 2000),,
 CITATION evaluate the RASP parser on the Parc Dependency Bank (DepBank; King et al,,
 CITATION evaluate their HPSG parser against PropBank (Palmer, Gildea, and Kingsbury 2005),,
 CITATION compare the Collins parser with the Parc LFG parser by mapping Penn Treebank parses into the dependencies of DepBank, claiming that the LFG parser is more accurate with only a slight reduction in speed,,
 CITATION compares the parsers of Collins and Charniak, the grammatical relations finder of Buchholz, Veenstra, and Daelemans (1999), and the CITATION parser, using the gold-standard grammatical relations (GRs) from Carroll, Briscoe, and Sanfilippo (1998),,
CITATIONb, 2003a) log-linear models are developed for automatically extracted grammars for Lexicalized Tree Adjoining Grammar (LTAG) and Head Driven Phrase Structure Grammar (HPSG),,
 CITATIONa) present another log-linear model for an automatically extracted LTAG which uses a simple unigram model of the elementary trees together with a loglinear model of the attachments,,
 CITATION address the issue of practical estimation using an automatically extracted HPSG grammar,,
 A recent development in the theory of CCG is the multi-modal treatment given by CITATION and CITATION, following the type-logical approaches to Categorial Grammar CITATION,,
om the Penn Treebank, using techniques similar to those used by Hockenmaier (CITATION; Xia, Palmer, and Joshi 2000),,
 Also, the supertagging idea which is central to the efficiency of the CCG parser originated with TAG CITATION,,
 CITATION describe the results of reranking the output of an HMM supertagger using an automatically extracted LTAG,,
 CITATION investigate the potential impact of LTAG supertagging on parsing speed and accuracy by performing a number of oracle experiments,,
sideoutside algorithm for estimating the parameters of a PCFG from unlabeled data CITATION,,
 Generalized Iterative Scaling CITATION is a common choice in the NLP literature for estimating a log-linear model (e,,
, CITATION; CITATION),,
 Initially we used generalized iterative scaling (GIS) for the parsing models described here, but found that convergence was extremely slow; CITATION present a similar finding for globally optimized log-linear models for sequences,,
 As an alternative to GIS, we use the limited-memory BFGS algorithm CITATION,,
 As CITATION demonstrates, general purpose numerical optimization algorithms such as BFGS can converge much faster than iterative scaling algorithms (including Improved Iterative Scaling; Della Pietra, Della Pietra, and Lafferty 1997),,
3 The Limited-Memory BFGS Algorithm The limited memory BFGS (L-BFGS) algorithm is a general purpose numerical optimization algorithm CITATION,,
3 Malouf uses standard numerical computation libraries 3 One NLP task for which we have found GIS to be especially suitable is sequence tagging, and we still use GIS to estimate tagging models CITATION,,
 One of our aims was to provide a self contained estimation code base, and so we implemented our own version of the L-BFGS algorithm as described in CITATION,,
 This smoothing method for log-linear models is also proposed by CITATION,,
 This is not a problem for CITATION because their grammars are hand-written and constraining enough to allow the analyses for each sentence to be enumerated,,
 CITATION investigates training on a sample of the analyses for each sentence, for example the top-n most probable according to some other probability model, or simply a random sample,,
 We adapt the feature-forest method of CITATION, which involves using dynamic programming to efficiently calculate the feature expectations,,
 CITATION propose a similar method in the context of LFG parsing; ,,
 Another difference is that Malouf and van Noord use the random sampling method of CITATION to allow practical estimation, whereas we construct the complete parse forest but use the supertagger to limit the size of the charts,,
 CITATION present similar work to ours in the context of an LFG grammar for English,,
 There has been some other work on defining stochastic categorial grammars, but mainly in the context of grammar learning (CITATION; CITATION; CITATION),,
 In order to deal with the problem of the additional, nonstandard CCG derivations, a conditional model of dependency structures is presented, based on CITATION, in which the dependencies are modeled directly and derivations are not modeled at all,,
 CITATION evaluate the RASP parser on the Parc Dependency Bank (DepBank; King et al,,
 CITATION evaluate their HPSG parser against PropBank (Palmer, Gildea, and Kingsbury 2005),,
 CITATION compare the Collins parser with the Parc LFG parser by mapping Penn Treebank parses into the dependencies of DepBank, claiming that the LFG parser is more accurate with only a slight reduction in speed,,
 CITATION compares the parsers of Collins and Charniak, the grammatical relations finder of Buchholz, Veenstra, and Daelemans (1999), and the CITATION parser, using the gold-standard grammatical relations (GRs) from Carroll, Briscoe, and Sanfilippo (1998),,
 Introduction Log-linear models have been applied to a number of problems in NLP, for example, POS tagging (CITATION; Lafferty, McCallum, and Pereira 2001), named entity recognition CITATION, chunking CITATION, and parsing CITATION,,
 Log-linear models have previously been applied to statistical parsing (CITATION; CITATION; CITATION; Malouf and van Noord 2004), bu,,
so define a new efficient parsing algorithm for such a model, based on CITATION, which maximizes the expected recall of dependencies,,
 A key component of the parsing system is a Maximum Entropy CCG supertagger (CITATION; CITATION) which assigns lexical categories to words in a sentence,,
 Second, it greatly increases the efficiency of the parser, which was the original motivation for supertagging CITATION,,
 Related Work The first application of log-linear models to parsing is the work of Ratnaparkhi and colleagues (Ratnaparkhi, Roukos, and Ward 1994; CITATION, 1999),,
s (such as assigning the complete lexical category set; CITATIONa),,
 In this article we take a different approach, by using a supertagger CITATION to perform step one,,
 CITATIONa) describe the supertagger, which uses log-linear models to define a distribution over the lexical category set for each local five-word context containing the target word CITATION,,
 To solve this problem, we have adapted the dynamic programming method of CITATION to packed CCG charts,,
 The dynamic programming method uses inside and outside scores to calculate expectations, similar to the insideoutside algorithm for estimating the parameters of a PCFG from unlabeled data CITATION,,
 Generalized Iterative Scaling CITATION is a common choice in the NLP literature for estimating a log-linear model (e,,
, CITATION; CITATION),,
 Initially we used generalized iterative scaling (GIS) for the parsing models described here, but found that convergence was extremely slow; CITATION present a similar finding for globally optimized log-linear models for sequences,,
 As an alternative to GIS, we use the limited-memory BFGS algorithm CITATION,,
 As CITATION demonstrates, general purpose numerical optimization algorithms such as BFGS can converge much faster than iterative scaling algorithms (including Improved Iterative Scaling; Della Pietra, Della Pietra, and Lafferty 19,,
 in NLP, for example, POS tagging (CITATION; Lafferty, McCallum, and Pereira 2001), named entity recognition CITATION, chunking CITATION, and parsing CITATION,,
 Log-linear models have previously been applied to statistical parsing (CITATION; CITATION; CITATION; Malouf and van Noord 2004), but typically under the assumption that all possible parses for a sentence can be enumerated,,
 In this article we apply the dynamic programming method of CITATION to a packed chart; however, because the grammar is automatically extracted, the packed charts require a considerable amount of memory: up to 25 GB,,
 Statistical parsers have been developed for TAG (CITATION; CITATION), LFG (CITATION; CITATION; Cahill et al,,
 2004), and HPSG (CITATION; Toutanova, Markova, and Manning 2004; CITATION; Malouf and van Noord 2004), among others,,
 We follow CITATION in using a discriminative estimation method by maximizing the conditional log-likelihood of the model given the data, minus a Gaussian prior 2 We could model predicateargument dependencies together with the derivation, but we wanted to use features from the derivation only, following CITATIONb),,
 508 \x0cClark and Curran Wide-Coverage Efficient Statistical Parsing term to prevent overfitting (CITATION; CITATION),,
 Another way to think of the estimation process is that it attempts to put as much mass as possible on the derivations leading to the goldstandard structures CITATION,,
ample by changing the beam parameter in the CITATION parser, but that any increase in speed is typically associated with a reduction in accuracy,,
 CITATION is a classifier-based linear time parser,,
 Statistical parsers have been developed for TAG (CITATION; CITATION), LFG (CITATION; CITATION; Cahill et al,,
 2004), and HPSG (CITATION; Toutanova, Markova, and Manning 2004; CITATION; Malouf and van Noord 2004), among others,,
 The dynamic programming method uses inside and outside scores to calculate expectations, similar to the insideoutside algorithm for estimating the parameters of a PCFG from unlabeled data CITATION,,
 Generalized Iterative Scaling CITATION is a common choice in the NLP literature for estimating a log-linear model (e,,
, CITATION; CITATION),,
 Initially we used generalized iterative scaling (GIS) for the parsing models described here, but found that convergence was extremely slow; CITATION present a similar finding for globally optimized log-linear models for sequences,,
 As an alternative to GIS, we use the limited-memory BFGS algorithm CITATION,,
 As CITATION demonstrates, general purpose numerical optimization algorithms such as BFGS can converge much faster than iterative scaling algorithms (including Improved Iterative Scaling; Della Pietra, Della Pietra, and Lafferty 1997),,
 Combinatory Categorial Grammar Combinatory Categorial Grammar (CCG) (CITATION, 2000) is a type-driven lexicalized theory of grammar based on Categorial Grammar CITATION,,
 In this article we are concerned with the syntactic component; see CITATION for how a semantic interpretation can be composed during a syntactic derivation, and also CITATION for how semantic interpretations can be built for newspaper text using the wide-coverage parser described in this arti,,
 In this article we apply the dynamic programming method of CITATION to a packed chart; however, because the grammar is automatically extracted, the packed charts require a considerable amount of memory: up to 25 GB,,
 The lexicalized grammar formalism we use is Combinatory Categorial Grammar (CCG; CITATION),,
 A number of statistical parsing models have recently been developed for CCG and used in parsers applied to newspaper text (Clark, Hockenmaier, and Steedman 2002; CITATIONb; CITATIONb),,
 Combinatory Categorial Grammar Combinatory Categorial Grammar (CCG) (CITATION, 2000) is a type-driven lexicalized theory of grammar based on Categorial Grammar CITATION,,
 In this article we are concerned with the syntactic component; see CITATION for how a semantic interpretation can be composed during a syntactic derivation, and also CITATION for how semantic interpretations can be built for newspaper text using the wide-coverage parser described in this article,,
 For example, the following combination allows analysis of sentences such as I offered, and may give, a flower to a policeman CITATION: may give (S\\NP)/(S\\NP) ((S\\NP)/PP)/NP >B ((S\\NP)/PP)/NP This example shows how the categories for may and give combine, resulting in a category of the same type as offered, which can then be coordinated,,
 CITATION gives a more precise definition of generalized forward composition,,
2 Chart Parsing Algorithm The algorithm used to build the packed charts is the CKY chart parsing algorithm (CITATION; CITATION) described in CITATION,,
 Neither of these constraints guarantee a normal-form derivation, but they are both effective at reducing the size of the charts, which can greatly increase parser speed (CITATIONa),,
 Following CITATION, we place the following constraint on backward crossed composition (for all models): The Y category in (7) cannot be an N or NP category,,
re in a discriminative framework has been beneficial for reranking approaches CITATION,,
 If enough unlabeled data is parsed, then the large volume can overcome the noise in the data (CITATION; Prins and van Noord 2003),,
 It may also not be possible to train or run the system on anything other than short sentences CITATION,,
to a number of problems in NLP, for example, POS tagging (CITATION; Lafferty, McCallum, and Pereira 2001), named entity recognition CITATION, chunking CITATION, and parsing CITATION,,
 Log-linear models have previously been applied to statistical parsing (CITATION; CITATION; CITATION; Malouf and van Noord 2004), but typically under the assumption that all possible parses for a sentence can be enumerated,,
 In this article we apply the dynamic programming method of CITATION to a packed chart; however, because the grammar is automatically extracted, the packed charts require a considerable amount of memory: up to 25 GB,,
 Statistical parsers have been developed for TAG (CITATION; CITATION), LFG (CITATION; CITATION; Cahill et al,,
 2004), and HPSG (CITATION; Toutanova, Markova, and Manning 2004; CITATION; Malouf and van Noord 2004), among others,,
 TAG grammars have been automatically extracted from the Penn Treebank, using techniques similar to those used by Hockenmaier (CITATION; Xia, Palmer, and Joshi 2000),,
 There has been some other work on defining stochastic categorial grammars, but mainly in the context of grammar learning (CITATION; CITATION; CITATION),,
 In order to deal with the problem of the additional, nonstandard CCG derivations, a conditional model of dependency structures is presented, based on CITATION, in which the dependencies are modeled directly and derivations are not modeled at all,,
 Combinatory Categorial Grammar Combinatory Categorial Grammar (CCG) (CITATION, 2000) is a type-driven lexicalized theory of grammar based on Categorial Grammar CITATION,,
 In this article we are concerned with the syntactic component; see CITATION for how a semantic interpretation can be composed during a syntactic derivation, and also CITATION for how semantic interpretations can be built for newspaper text using the wide-coverage parser described in this article,,
2 Chart Parsing Algorithm The algorithm used to build the packed charts is the CKY chart parsing algorithm (CITATION; CITATION) described in CITATION,,
 There has been some other work on defining stochastic categorial grammars, but mainly in the context of grammar learning (CITATION; CITATION; CITATION),,
 In order to deal with the problem of the additional, nonstandard CCG derivations, a conditional model of dependency structures is presented, based on CITATION, in which the dependencies are modeled directly and derivations are not modeled at all,,
