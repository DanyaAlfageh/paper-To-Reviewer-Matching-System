 As reported in CITATION, B-cubed metrics are more suitable than traditional metrics, such as NMI and purity,,
 Traditionally, we can utilize topic models CITATION or social tagging to structuralize UGC,,
 However, for topic models, it is not easy to control the granularity of topics, and it is hard for users to interpret a topic only based on the multinomial distribution CITATION,,
 For social tagging, it is not applicable in many sites and has sparsity problem CITATION,,
 These categories give shallow semantics of UGC, and boosts the performance of information retrieval (CITATION; CITATION; CITATION) and recommendation (CITATION; CITATION),,
 With new content kept adding into a hierarchy, we need to maintain category hierarchy CITATION to make content within the same category more topically cohesive,,
 Topic models, such as latent Dirichlet allocation (LDA) CITATION, are widely applied in document clustering and classification, However, it is not trivial to control the granularity of topics CITATION,,
 Whats more, it is generally difficult to understand a topic only from the multinomial distribution CITATION,,
 Social tagging provides an alternative approach in document organization CITATION,,
 However, tags are not widely applicable and tags are usually sparse CITATION,,
 These categories give shallow semantics of UGC, and boosts the performance of information retrieval (CITATION; CITATION; CITATION) and recommendation (CITATION; CITATION),,
 With new content kept adding into a hierarchy, we need to maintain category hierarchy CITATION to make content within the same category more topically cohesive,,
 Topic models, such as latent Dirichlet allocation (LDA) CITATION, are widely applied in document clustering and classification, However, it is not trivial to control the granularity of topics CITATION,,
 However, traditional question retrieval models CITATION such as QLLM and VSM do not capture key semantics and give more weights for entity terms,,
 These categories give shallow semantics of UGC, and boosts the performance of information retrieval (CITATION; CITATION; CITATION) and recommendation (CITATION; CITATION),,
 With new content kept adding into a hierarchy, we need to maintain category hierarchy CITATION to make content within the same category more topically cohesive,,
 Topic models, such as latent Dirichlet allocation (LDA) CITATION, are widely applied in document clustering and classification, However, it is not trivial to control the granularity of topics CITATION,,
nce of information retrieval (CITATION; CITATION; CITATION) and recommendation (CITATION; CITATION),,
 With new content kept adding into a hierarchy, we need to maintain category hierarchy CITATION to make content within the same category more topically cohesive,,
 Topic models, such as latent Dirichlet allocation (LDA) CITATION, are widely applied in document clustering and classification, However, it is not trivial to control the granularity of topics CITATION,,
 Whats more, it is generally difficult to understand a topic only from the multinomial distribution CITATION,,
 Social tagging provides an alternative approach in document organization CITATION,,
 However, tags are not widely applicable and tags are usually sparse CITATION,,
 These categories give shallow semantics of UGC, and boosts the performance of information retrieval (CITATION; CITATION; CITATION) and recommendation (CITATION; CITATION),,
 With new content kept adding into a hierarchy, we need to maintain category hierarchy CITATION to make content within the same category more topically cohesive,,
 Topic models, such as latent Dirichlet allocation (LDA) CITATION, are widely applied in document clustering and classification, However, it is not trivial to control the granularity of topics CITATION,,
 The metro maps proposed in CITATION are also related to our work,,
 Different from CITATION, we employ a large-scale entity repository to extract more meaningful and interpretable key terms (entities), which make each subtopic much easier to understand,,
 A common approach is to utilize a Named Entity Recognition (NER) system like Stanford NER CITATION, which recognizes the names of things (e,,
 For cross-domain NER, CITATION employed search engines,,
 For short-text NER, CITATION proposed a graphical model,,
 To address the problem, CITATION defined a fine-grained set of 112 tags based on Freebase for entity extraction,,
 In addition, we compare our approach with Stanford NER CITATION and fine-grained entity recognition (FIGER) CITATION,,
 These categories give shallow semantics of UGC, and boosts the performance of information retrieval (CITATION; CITATION; CITATION) and recommendation (CITATION; CITATION),,
 With new content kept adding into a hierarchy, we need to maintain category hierarchy CITATION to make content within the same category more topically cohesive,,
 Topic models, such as latent Dirichlet allocation (LDA) CITATION, are widely applied in document clustering and classification, However, it is not trivial to control the granularity of topics CITATION,,
ory hierarchy CITATION to make content within the same category more topically cohesive,,
 Topic models, such as latent Dirichlet allocation (LDA) CITATION, are widely applied in document clustering and classification, However, it is not trivial to control the granularity of topics CITATION,,
 Whats more, it is generally difficult to understand a topic only from the multinomial distribution CITATION,,
 Social tagging provides an alternative approach in document organization CITATION,,
 However, tags are not widely applicable and tags are usually sparse CITATION,,
 The work in CITATION, which automatically generates and updates topic terms to organize UGC, i,,
 In this paper, we follow the work in CITATION and employ an agglomerative clustering algorithm for two reasons: 1) it is easy to implement and its time complexity is O(N2); 2) there is no need to set the number of clusters,,
 Any other advanced algorithms like spectral clustering CITATION can also be applied, but that is not the emphasis of this paper,,
 Following the work in CITATION, we collect information from 5 aspects: familiarity, easiness, satisfaction, adequate time, and helpfulness,,
 These categories give shallow semantics of UGC, and boosts the performance of information retrieval (CITATION; CITATION; CITATION) and recommendation (CITATION; CITATION),,
 With new content kept adding into a hierarchy, we need to maintain category hierarchy CITATION to make content within the same category more topically cohesive,,
 Topic models, such as latent Dirichlet allocation (LDA) CITATION, are widely applied in document clustering and classification, However, it is not trivial to control the granularity of topics CITATION,,
 Whats more, it is generally difficult to understand a topic only from the multinomial distribution CITATION,,
 A common approach is to utilize a Named Entity Recognition (NER) system like Stanford NER CITATION, which recognizes the names of things (e,,
 For cross-domain NER, CITATION employed search engines,,
 For short-text NER, CITATION proposed a graphical model,,
 To address the problem, CITATION defined a fine-grained set of 112 tags based on Freebase for entity extraction,,
 CITATION utilized Wikipedia to classify documents,,
 (CITATIONa) proposed an entity-based classification for tweets,,
 In addition, we compare our approach with Stanford NER CITATION and fine-grained entity recognition (FIGER) CITATION,,
 Different from CITATION, we employ a large-scale entity repository to extract more meaningful and interpretable key terms (entities), which make each subtopic much easier to understand,,
 A common approach is to utilize a Named Entity Recognition (NER) system like Stanford NER CITATION, which recognizes the names of things (e,,
 For cross-domain NER, CITATION employed search engines,,
 For short-text NER, CITATION proposed a graphical model,,
 To address the problem, CITATION defined a fine-grained set of 112 tags based on Freebase for entity extraction,,
 Traditionally, we can utilize topic models CITATION or social tagging to structuralize UGC,,
 However, for topic models, it is not easy to control the granularity of topics, and it is hard for users to interpret a topic only based on the multinomial distribution CITATION,,
 For social tagging, it is not applicable in many sites and has sparsity problem CITATION,,
8; CITATION),,
 With new content kept adding into a hierarchy, we need to maintain category hierarchy CITATION to make content within the same category more topically cohesive,,
 Topic models, such as latent Dirichlet allocation (LDA) CITATION, are widely applied in document clustering and classification, However, it is not trivial to control the granularity of topics CITATION,,
 Whats more, it is generally difficult to understand a topic only from the multinomial distribution CITATION,,
 Social tagging provides an alternative approach in document organization CITATION,,
 However, tags are not widely applicable and tags are usually sparse CITATION,,
 In this paper, we follow the work in CITATION and employ an agglomerative clustering algorithm for two reasons: 1) it is easy to implement and its time complexity is O(N2); 2) there is no need to set the number of clusters,,
 Any other advanced algorithms like spectral clustering CITATION can also be applied, but that is not the emphasis of this paper,,
 In our entity repository, the similarity between two entities is computed using the approach in CITATION, which estimates the similarity of two terms according to their firstorder and second-order co-occurrences,,
 To construct similarity functions, pattern-based approaches (CITATION; CITATION) utilize first-order co-occurrences while distributional similarity approaches (CITATION; CITATION) employ second-order co-occurrences,,
 In the following, we briefly introduce the patternbased approach (PB) and the distributional similarity approach (DS) in CITATION,,
ties is computed using the approach in CITATION, which estimates the similarity of two terms according to their firstorder and second-order co-occurrences,,
 To construct similarity functions, pattern-based approaches (CITATION; CITATION) utilize first-order co-occurrences while distributional similarity approaches (CITATION; CITATION) employ second-order co-occurrences,,
 In the following, we briefly introduce the patternbased approach (PB) and the distributional similarity approach (DS) in CITATION,,
 Given two entities ta and tb, PB calculates their similarity based on the number of RASCs containing both of them CITATION: Sim(ta, tb) = log(1 + rab X i=1 Pabi )) p idf(,,
ng the approach in CITATION, which estimates the similarity of two terms according to their firstorder and second-order co-occurrences,,
 To construct similarity functions, pattern-based approaches (CITATION; CITATION) utilize first-order co-occurrences while distributional similarity approaches (CITATION; CITATION) employ second-order co-occurrences,,
 In the following, we briefly introduce the patternbased approach (PB) and the distributional similarity approach (DS) in CITATION,,
 Given two entities ta and tb, PB calculates their similarity based on the number of RASCs containing both of them CITATION: Sim(ta, tb) = log(1 + rab X i=1 Pabi )) p idf(ta) idf(tb), (2) where idf(ta) = ,,
e metro maps proposed in CITATION are also related to our work,,
 Different from CITATION, we employ a large-scale entity repository to extract more meaningful and interpretable key terms (entities), which make each subtopic much easier to understand,,
 A common approach is to utilize a Named Entity Recognition (NER) system like Stanford NER CITATION, which recognizes the names of things (e,,
 For cross-domain NER, CITATION employed search engines,,
 For short-text NER, CITATION proposed a graphical model,,
 To address the problem, CITATION defined a fine-grained set of 112 tags based on Freebase for entity extraction,,
 To address the problem, CITATION defined a fine-grained set of 112 tags based on Freebase for entity extraction,,
 CITATION utilized Wikipedia to classify documents,,
 (CITATIONa) proposed an entity-based classification for tweets,,
 In addition, entity-based retrieval models were proposed and applied in both QA archives (CITATIONa) and tweets (CITATIONb),,
 Besides, (CITATIONb) proposed an entitybased translation language model and demonstrated that it outperformed classical translation language model in question retrieval,,
 The work in CITATION, which automatically generates and updates topic terms to organize UGC, is mostly related to our work,,
 However, in CITATION more external sources are utilized to identify subtopics,,
 The metro maps proposed in CITATION are also related to our work,,
 Different from CITATION, we employ a large-scale entity repository to extract more meaningful and interpretable key terms (entities), which make each subtopic much easier to understand,,
 A common approach is to utilize a Named Entity Recognition (NER) system like Stanford NER CITATION, which recognizes the names of things (e,,
 For cross-domain NER, CITATION employed search engines,,
 Traditionally, we can utilize topic models CITATION or social tagging to structuralize UGC,,
 However, for topic models, it is not easy to control the granularity of topics, and it is hard for users to interpret a topic only based on the multinomial distribution CITATION,,
 For social tagging, it is not applicable in many sites and has sparsity problem CITATION,,
Topic models, such as latent Dirichlet allocation (LDA) CITATION, are widely applied in document clustering and classification, However, it is not trivial to control the granularity of topics CITATION,,
 Whats more, it is generally difficult to understand a topic only from the multinomial distribution CITATION,,
 Social tagging provides an alternative approach in document organization CITATION,,
 However, tags are not widely applicable and tags are usually sparse CITATION,,
 The work in CITATION, which automatically generates and updates topic terms to organize UGC, is mostly related to our work,,
 In our entity repository, the similarity between two entities is computed using the approach in CITATION, which estimates the similarity of two terms according to their firstorder and second-order co-occurrences,,
 To construct similarity functions, pattern-based approaches (CITATION; CITATION) utilize first-order co-occurrences while distributional similarity approaches (CITATION; CITATION) emplo,,
 CITATION found that PB performed better when dealing with proper nouns; while DS was relatively good at estimating similarity of other types of entities,,
 The similarity function in our ER follows the suggestion of CITATION: if at least one entity is proper noun, PB is employed; otherwise DS is used,,
 CITATION utilized Wikipedia to classify documents,,
 (CITATIONa) proposed an entity-based classification for tweets,,
 In addition, entity-based retrieval models were proposed and applied in both QA archives (CITATIONa) and tweets (CITATIONb),,
 Besides, (CITATIONb) proposed an entitybased translation language model and demonstrated that it outperformed classical translation language model in question retrieval,,
 CITATION utilized Wikipedia to classify documents,,
 (CITATIONa) proposed an entity-based classification for tweets,,
 In addition, entity-based retrieval models were proposed and applied in both QA archives (CITATIONa) and tweets (CITATIONb),,
 Besides, (CITATIONb) proposed an entitybased translation language model and demonstrated that it outperformed classical translation language model in question retrieval,,
 To address the problem, CITATION defined a fine-grained set of 112 tags based on Freebase for entity extraction,,
 CITATION utilized Wikipedia to classify documents,,
 (CITATIONa) proposed an entity-based classification for tweets,,
 In addition, entity-based retrieval models were proposed and applied in both QA archives (CITATIONa) and tweets (CITATIONb),,
 Besides, (CITATIONb) proposed an entitybased translation language model and demonstrated that it outperformed classical translation language model in question retrieval,,
 These categories give shallow semantics of UGC, and boosts the performance of information retrieval (CITATION; CITATION; CITATION) and recommendation (CITATION; CITATION),,
 With new content kept adding into a hierarchy, we need to maintain category hierarchy CITATION to make content within the same category more topically cohesive,,
 Topic models, such as latent Dirichlet allocation (LDA) CITATION, are widely applied in document clustering and classification, However, it is not trivial to control the granularity of topics CITATION,,
 Whats more, it is generally difficult to understand a topic only from the multinomial distribution CITATION,,
 Social tagging provides an alternative approach in document organization CITATION,,
 10 Following CITATION, we set to 0,,
 In our entity repository, the similarity between two entities is computed using the approach in CITATION, which estimates the similarity of two terms according to their firstorder and second-order co-occurrences,,
 To construct similarity functions, pattern-based approaches (CITATION; CITATION) utilize first-order co-occurrences while distributional similarity approaches (CITATION; CITATION) employ second-order co-occurrences,,
 In the following, we briefly introduce the patternbased approach (PB) and the distributional similarity approach (DS) in CITATION,,
cial tagging provides an alternative approach in document organization CITATION,,
 However, tags are not widely applicable and tags are usually sparse CITATION,,
 The work in CITATION, which automatically generates and updates topic terms to organize UGC, is mostly related to our work,,
 However, in CITATION more external sources are utilized to identify subtopics,,
 The metro maps proposed in CITATION are also related to our work,,
 Different from CITATION, we employ a large-scale entity reposit,,
