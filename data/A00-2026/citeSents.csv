The form of the maximum entropy probability model is identical to the one used in (CITATION; CITATION): k f$(wi ,wi-1 ,wi-2,at~ri) YIj=I Otj p(wilwi-l, wi-2,attri) = Z(Wi-l, wi-2, attri) k tot j=l where wi ranges over V t3 .stop,,0
CITATION maps from semantics to words with a concept ontology, grammar, and lexicon, and ranks the resulting word lattice with corpus-based statistics, whereas NLG2 and NLG3 automatically learn the mapping from semantics to words from a corpus,,0
Our approach differs from the corpus-based surface generation approaches of CITATION and CITATION,,1
The only trainable approaches (known to the author) to surface generation are the purely statistical machine translation (MT) systems such as CITATION and the corpus-based generation system described in,,0
surface generation packages, such as FUF/SURGE CITATION, KPML CITATION, MUMBLE CITATION, and RealPro CITATION, which produce natural language text from an abstract semantic representation,,0
There are more sophisticated surface generation packages, such as FUF/SURGE CITATION, KPML CITATION, MUMBLE CITATION, and RealPro CITATION, which produce natural language text from an abstract semantic representation,,0
In contrast, CITATION uses corpus-derived statistical knowledge to rank plausible hypotheses from a grammarbased surface generation component,,0
NLG2 and NLG3 solve the lexical choice problem by learning the words (via features in the maximum entropy probability model) that correlate with a given attribute and local context, whereas CITATION uses a rule-based approach to decide the word choice,,0
The approach of writing individualtemplates isconvenient, but may not scale to complex domains in which hundreds or thousands of templates would be necessary, and may have shortcomings in maintainability and text quality (e.g., see CITATION for a discussion),,0
The MT systems of CITATION learn to generate te,,0
The MT systems of CITATION learn to generate text in the target language straight from the source language, without the aid of an explicit semantic representation,,0
KPML CITATION, MUMBLE CITATION, and RealPro CITATION, which produce natural language text from an abstract semantic representation,,0
The only trainable approaches (known to the author) to surface generation are the purely statistical machine translation (MT) systems such as CITATION and the corpus-based generation system described in (Langkilde and Knight,,0
The only trainable approaches (known to the author) to surface generation are the purely statistical machine translation (MT) systems such as CITATION and the corpus-based generation system described in CITATION,,0
