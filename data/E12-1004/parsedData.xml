<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<bodyText confidence="0.704329">
b&apos;Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 2332,
Avignon, France, April 23 - 27 2012. c
</bodyText>
<sectionHeader confidence="0.63262" genericHeader="abstract">
2012 Association for Computational Linguistics
</sectionHeader>
<bodyText confidence="0.462456">
Entailment above the word level in distributional semantics
</bodyText>
<author confidence="0.617604">
Marco Baroni
Raffaella Bernardi
</author>
<affiliation confidence="0.991475">
University of Trento
</affiliation>
<email confidence="0.98154">
name.surname@unitn.it
</email>
<author confidence="0.963581">
Ngoc-Quynh Do
</author>
<affiliation confidence="0.995152">
Free University of Bozen-Bolzano
</affiliation>
<email confidence="0.986906">
quynhdtn.hut@gmail.com
</email>
<author confidence="0.854101">
Chung-chieh Shan
</author>
<affiliation confidence="0.9779295">
Cornell University
University of Tsukuba
</affiliation>
<email confidence="0.996605">
ccshan@post.harvard.edu
</email>
<sectionHeader confidence="0.990799" genericHeader="keywords">
Abstract
</sectionHeader>
<bodyText confidence="0.999455277777778">
We introduce two ways to detect entail-
ment using distributional semantic repre-
sentations of phrases. Our first experiment
shows that the entailment relation between
adjective-noun constructions and their head
nouns (big cat |= cat), once represented as
semantic vector pairs, generalizes to lexical
entailment among nouns (dog |= animal).
Our second experiment shows that a classi-
fier fed semantic vector pairs can similarly
generalize the entailment relation among
quantifier phrases (many dogs|=some dogs)
to entailment involving unseen quantifiers
(all cats|=several cats). Moreover, nominal
and quantifier phrase entailment appears to
be cued by different distributional corre-
lates, as predicted by the type-based view
of entailment in formal semantics.
</bodyText>
<sectionHeader confidence="0.998259" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998497210526316">
Distributional semantics (DS) approximates lin-
guistic meaning with vectors summarizing the
contexts where expressions occur. The success
of DS in lexical semantics has validated the hy-
pothesis that semantically similar expressions oc-
cur in similar contexts (Landauer and Dumais,
1997; Lund and Burgess, 1996; Sahlgren, 2006;
Schutze, 1997; Turney and Pantel, 2010). For-
mal semantics (FS) represents linguistic mean-
ings as symbolic formulas and assemble them via
composition rules. FS has successfully modeled
quantification and captured inferential relations
between phrases and between sentences (Mon-
tague, 1970; Thomason, 1974; Heim and Kratzer,
1998). The strengths of DS and FS have been
complementary to date: On one hand, DS has in-
duced large-scale semantic representations from
corpora, but it has been largely limited to the
lexical domain. On the other hand, FS has pro-
vided sophisticated models of sentence meaning,
but it has been largely limited to hand-coded mod-
els that do not scale up to real-life challenges by
learning from data.
Given these complementary strengths, we nat-
urally ask if DS and FS can address each others
limitations. Two recent strands of research are
bringing DS closer to meeting core FS chal-
lenges. One strand attempts to model compo-
sitionality with DS methods, representing both
primitive and composed linguistic expressions
as distributional vectors (Baroni and Zamparelli,
2010; Grefenstette and Sadrzadeh, 2011; Gue-
vara, 2010; Mitchell and Lapata, 2010). The
other strand attempts to reformulate FSs notion
of logical inference in terms that DS can cap-
ture (Erk, 2009; Geffet and Dagan, 2005; Kotler-
man et al., 2010; Zhitomirsky-Geffet and Dagan,
2010). In keeping with the lexical emphasis of
DS, this strand has focused on inference at the
word level, or lexical entailment, that is, discover-
ing from distributional vectors of hyponyms (dog)
that they entail their hypernyms (animal).
This paper brings these two strands of research
together by demonstrating two ways in which the
distributional vectors of composite expressions
bear on inference. Here we focus on phrasal vec-
tors harvested directly from the corpus rather than
obtained compositionally. In a first experiment,
we exploit the entailment properties of a class
of composite expressions, namely adjective-noun
constructions (ANs), to harvest training data for
an entailment recognizer. The recognizer is then
successfully applied to detect lexical entailment.
In short, since almost all ANs entail the noun they
contain (red car entails car), the distributional
vectors of AN-N pairs can train a classifier to de-
tect noun pairs that stand in the same relation (dog
</bodyText>
<page confidence="0.997855">
23
</page>
<bodyText confidence="0.998508978260869">
\x0centails animal). With almost no manual effort,
we achieve performance nearly identical with the
state-of-the-art balAPinc measure that Kotlerman
et al. (2010) crafted, which detects feature inclu-
sion between the two nouns occurrence contexts.
Our second experiment goes beyond lexical in-
ference. We look at phrases built from a quanti-
fying determiner1 and a noun (QNs) and use their
distributional vectors to recognize entailment re-
lations of the form many dogs |= some dogs, be-
tween two QNs sharing the same noun. It turns
out that a classifier trained on a set of Q1N|=Q2N
pairs can recognize entailment in pairs with a new
quantifier configuration. For example, we can
train on many dogs |= some dogs then correctly
predict all cats|=several cats. Interestingly, on the
QN entailment task, neither our classifier trained
on AN-N pairs nor the balAPinc method beat
baseline methods. This suggests that our success-
ful QN classifiers tap into vector properties be-
yond such relations as feature inclusion that those
methods for nominal entailment rely upon.
Together, our experiments show that corpus-
harvested DS representations of composite ex-
pressions such as ANs and QNs contain suffi-
cient information to capture and generalize their
inference patterns. This result brings DS closer
to the central concerns of FS. In particular, the
QN study is the first to our knowledge to show
that DS vectors capture semantic properties not
only of content words, but of an important class of
function words (quantifying determiners) deeply
studied in FS but of little interest until now in DS.
Besides these theoretical implications, our re-
sults are of practical import. First, our AN study
presents a novel, practical method for detect-
ing lexical entailment that reaches state-of-the-
art performance with little or no manual interven-
tion. Lexical entailment is in turn fundamental
for constructing ontologies and other lexical re-
sources (Buitelaar and Cimiano, 2008). Second,
our QN study demonstrates that phrasal entail-
ment can be automatically detected and thus paves
the way to apply DS to advanced NLP tasks such
as recognizing textual entailment (Dagan et al.,
2009).
</bodyText>
<page confidence="0.930069">
1
</page>
<bodyText confidence="0.9933875">
In the sequel we will simply refer to a quantifying de-
terminer as a quantifier.
</bodyText>
<sectionHeader confidence="0.979955" genericHeader="method">
2 Background
</sectionHeader>
<subsectionHeader confidence="0.790484">
2.1 Distributional semantics above the word
</subsectionHeader>
<bodyText confidence="0.997300487179487">
level
DS models such as LSA (Landauer and Dumais,
1997) and HAL (Lund and Burgess, 1996) ap-
proximate the meaning of a word by a vector that
summarizes its distribution in a corpus, for exam-
ple by counting co-occurrences of the word with
other words. Since semantically similar words
tend to share similar contexts, DS has been very
successful in tasks that require quantifying se-
mantic similarity among words, such as synonym
detection and concept clustering (Turney and Pan-
tel, 2010).
Recently, there has been a flurry of interest
in DS to model meaning composition: How can
we derive the DS representation of a composite
phrase from that of its constituents? Although the
general focus in the area is to perform algebraic
operations on word semantic vectors (Mitchell
and Lapata, 2010), some researchers have also di-
rectly examined the corpus contexts of phrases.
For example, Baldwin et al. (2003) studied vec-
tor extraction for phrases because they were inter-
ested in the decomposability of multiword expres-
sions. Baroni and Zamparelli (2010) and Gue-
vara (2010) look at corpus-harvested phrase vec-
tors to learn composition functions that should de-
rive such composite vectors automatically. Ba-
roni and Zamparelli, in particular, showed qual-
itatively that directly corpus-harvested vectors for
AN constructions are meaningful; for example,
the vector of young husband has nearest neigh-
bors small son, small daughter and mistress. Fol-
lowing up on this approach, we show here quanti-
tatively that corpus-harvested AN vectors are also
useful for detecting entailment. We find moreover
distributional vectors informative and useful not
only for phrases made of content words (such as
ANs) but also for phrases containing functional
elements, namely quantifying determiners.
</bodyText>
<subsectionHeader confidence="0.863074">
2.2 Entailment from formal to distributional
</subsectionHeader>
<bodyText confidence="0.940309142857143">
semantics
Entailment in FS To characterize the condi-
tions under which a sentence is true, FS begins
with the lexical meanings of the words in the sen-
tence and builds up the meanings of larger and
larger phrases until it arrives at the meaning of the
whole sentence. The meanings throughout this
</bodyText>
<page confidence="0.996563">
24
</page>
<bodyText confidence="0.98461072">
\x0ccompositional process inhabit a variety of seman-
tic domains, depending on the syntactic category
of the expressions: typically, a sentence denotes a
truth value (true or false) or truth conditions,
a noun such as cat denotes a set of entities, and a
quantifier phrase (QP) such as all cats denotes a
set of sets of entities.
The entailment relation (|=) is a core notion of
logic: it holds between one or more sentences and
a sentence such that it cannot be that the former
(antecedent) are true and the latter (consequent)
is false. FS extends this notion from formal-logic
sentences to natural-language expressions. By as-
signing meanings to parts of a sentence, FS allows
defining entailment not only among sentences but
also among words and phrases. Each semantic
domain A has its own entailment relation |=A.
The entailment relation |=S among sentences is
the logical notion just described, whereas the en-
tailment relations |=N and |=QP among nouns
and quantifier phrases are the inclusion relations
among sets of entities and sets of sets of entities
respectively. Our results in Section 5 show that
DS needs to treat |=N and |=QP differently as well.
Empirical, corpus-based perspectives on en-
tailment Until recently, the corpus-based re-
search tradition has studied entailment mostly at
the word level, with applied goals such as clas-
sifying lexical relations and building taxonomic
WordNet-like resources automatically. The most
popular approach, first adopted by Hearst (1992),
extracts lexical relations from patterns in large
corpora. For instance, from the pattern N1 such
as N2 one learns that N2 |= N1 (from insects such
as beetles, derive beetles|=insects). Several stud-
ies have refined and extended this approach (Pan-
tel and Ravichandran, 2004; Snow et al., 2005;
Snow et al., 2006; Turney, 2008).
While empirically very successful, the pattern-
based method is mostly limited to single content
words (or frequent content-word phrases). We are
interested in entailment between phrases, where it
is not obvious how to use lexico-syntactic patterns
and cope with data sparsity. For instance, it seems
hard to find a pattern that frequently connects one
QP to another it entails, as in all beetles PATTERN
many beetles. Hence, we aim to find a more gen-
eral method and investigate whether DS vectors
(whether corpus-harvested or compositionally de-
rived) encode the information needed to account
for phrasal entailment in a way that can be cap-
tured and generalized to unseen phrase pairs.
Rather recently, the study of sentential entail-
ment has taken an empirical turn, thanks to the de-
velopment of benchmarks for entailment systems.
The FS definition of entailment has been modified
by taking common sense into account. Instead of
a relation from the truth of the consequent to the
truth of the antecedent in any circumstance, the
applied view looks at entailment in terms of plau-
sibility: |= if a human who reads (and trusts)
would most likely infer that is also true. En-
tailment systems have been compared under this
new perspective in various evaluation campaigns,
the best known being the Recognizing Textual En-
tailment (RTE) initiative (Dagan et al., 2009).
Most RTE systems are based on advanced NLP
components, machine learning techniques, and/or
syntactic transformations (Zanzotto et al., 2007;
Kouleykov and Magnini, 2005). A few systems
exploit deep FS analysis (Bos and Markert, 2006;
Chambers et al., 2007). In particular, the FS re-
sults about QP properties that affect entailment
have been exploited by Chambers et al, who com-
plement a core broad-coverage system with a Nat-
ural Logic module to trade lower recall for higher
precision. For instance, they exploit the mono-
tonicity properties of no that cause the follow-
ing reversal in entailment direction: some bee-
tles |= some insects but no insects |= no beetles.
To investigate entailment step by step, we ad-
dress here a much simpler and clearer type of
entailment than the more complex notion taken
up by the RTE community. While RTE is out-
side our present scope, we do focus on QP entail-
ment as Natural Logic does. However, our eval-
uation differs from Chambers et al.s, since we
rely on general-purpose DS vectors as our only
resource, and we look at phrase pairs with differ-
ent quantifiers but the same noun. For instance,
we aim to predict that all beetles |= many beetles
but few beetles6|=all beetles. QPs, of course, have
many well-known semantic properties besides en-
tailment; we leave their analysis to future study.
Entailment in DS Erk (2009) suggests that it
may not be possible to induce lexical entailment
directly from a vector space representation, but it
is possible to encode the relation in this space af-
ter it has been derived through other means. On
the other hand, recent studies (Geffet and Dagan,
</bodyText>
<page confidence="0.992921">
25
</page>
<bodyText confidence="0.998258347826087">
\x0c2005; Kotlerman et al., 2010; Weeds et al., 2004)
have pursued the intuition that entailment is the
asymmetric ability of one term to substitute for
another. For example, baseball contexts are also
sport contexts but not vice versa, hence baseball
is narrower than sport and baseball|=sport. On
this view, entailment between vectors corresponds
to inclusion of contexts or features, and can be
captured by asymmetric measures of distribution
similarity. In particular, Kotlerman et al. (2010)
carefully crafted the balAPinc measure (see Sec-
tion 3.5 below). We adopt this measure because
it has been shown to outperform others in several
tasks that require lexical entailment information.
Like Kotlerman et al., we want to capture the
entailment relation between vectors of features.
However, we are interested in entailment not only
between words but also between phrases, and we
ask whether the DS view of entailment as fea-
ture inclusion, which captures entailment between
nouns, also captures entailment between QPs. To
this end, we complement balAPinc with a more
flexible supervised classifier.
</bodyText>
<sectionHeader confidence="0.882154" genericHeader="method">
3 Data and methods
</sectionHeader>
<subsectionHeader confidence="0.997776">
3.1 Semantic space
</subsectionHeader>
<bodyText confidence="0.987425965517241">
We construct distributional semantic vectors from
the 2.83-billion-token concatenation of the British
National Corpus (http://www.natcorp.
ox.ac.uk/), WackyPedia and ukWaC (http:
//wacky.sslmit.unibo.it/). We tok-
enize and POS-tag this corpus, then lemmatize
it with TreeTagger (Schmid, 1995) to merge sin-
gular and plural instances of words and phrases
(some dogs is mapped to some dog).
We process the corpus in two steps to compute
semantic vectors representing our phrases of in-
terest. We use phrases of interest as a general
term to refer to both multiword phrases and sin-
gle words, and more precisely to: those AN and
QN sequences that are in the data sets (see next
subsections), the adjectives, quantifiers and nouns
contained in those sequences, and the most fre-
quent (9.8K) nouns and (8.1K) adjectives in the
corpus. The first step is to count the content
words (more precisely, the most frequent 9.8K
nouns, 8.1K adjectives, and 9.6K verbs in the cor-
pus) that occur in the same sentence as phrases
of interest. In the second step, following standard
practice, the co-occurrence counts are converted
into pointwise mutual information (PMI) scores
(Church and Hanks, 1990). The result of this step
is a sparse matrix (with both positive and negative
entries) with 48K rows (one per phrase of interest)
and 27K columns (one per content word).
</bodyText>
<subsectionHeader confidence="0.921461">
3.2 The AN |= N data set
</subsectionHeader>
<bodyText confidence="0.999455340909091">
To characterize entailment between nouns using
their semantic vectors, we need data exemplifying
which noun entails which. This section introduces
one cheap way to collect such a training data set
exploiting semantic vectors for composed expres-
sions, namely AN sequences. We rely on the lin-
guistic fact that ANs share a syntactic category
and semantic type with plain common nouns (big
cat shares syntactic category and semantic type
with cat). Furthermore, most adjectives are re-
strictive in the sense that, for every noun N, the
AN sequence entails the N alone (every big cat
is a cat). From a distributional point of view, the
vector for an N should by construction include the
information in the vector for an AN, given that the
contexts where the AN occurs are a subset of the
contexts where the N occurs (cat occurs in all the
contexts where big cat occurs). This ideal inclu-
sion suggests that the DS notion of lexical entail-
ment as feature inclusion (see Section 2.2 above)
should be reflected in the AN |= N pattern.
Because most ANs entail their head Ns, we can
create positive examples of AN |= N without any
manual inspection of the corpus: simply pair up
the semantic vectors of ANs and Ns. Furthermore,
because an AN usually does not entail another N,
we can create negative examples (AN1 6|= N2) just
by randomly permuting the Ns. Of course, such
unsupervised data would be slightly noisy, espe-
cially because some of the most frequent adjec-
tives are not restrictive.
To collect cleaner data and to be sure that we
are really examining the phenomenon of entail-
ment, we took a mere few moments of man-
ual effort to select the 256 restrictive adjectives
from the most frequent 300 adjectives in the cor-
pus. We then took the Cartesian product of these
256 adjectives with the 200 concrete nouns in the
BLESS data set (Baroni and Lenci, 2011). Those
nouns were chosen to avoid highly polysemous
words. From the Cartesian product, we obtain a
total of 1246 AN sequences, such as big cat, that
occur more than 100 times in the corpus. These
AN sequences encompass 190 of the 256 adjec-
</bodyText>
<page confidence="0.967619">
26
</page>
<bodyText confidence="0.9828116">
\x0ctives and 128 of the 200 nouns.
The process results in 1246 positive instances
of AN |= N entailment, which we use as training
data. To create a comparable amount of negative
data, we randomly permuted the nouns in the pos-
itive instances to obtain pairs of AN1 6|= N2 (e.g.,
big cat6|=dog). We manually double-checked that
all positive and negative examples are correctly
classified (2 of 1246 negative instances were re-
moved, leaving 1244 negative training examples).
</bodyText>
<subsectionHeader confidence="0.818636">
3.3 The lexical entailment N1 |= N2 data set
</subsectionHeader>
<bodyText confidence="0.997244789473684">
For testing data, we first listed all WordNet nouns
in our corpus, then extracted hyponym-hypernym
chains linking the first synsets of these nouns. For
example, pope is found to entail leader because
WordNet contains the chain pope spiritual
leader leader. Eliminating the 20 hypernyms
with more than 180 hyponyms (mostly very ab-
stract nouns such as entity, object, and quality)
yields 9734 hyponym-hypernym pairs, encom-
passing 6402 nouns. Manually double-checking
these pairs leaves us with 1385 positive instances
of N1 |= N2 entailment.
We created the negative instances of again 1385
pairs by inverting 33% of the positive instances
(from pope|=leader to leader6|=pope), and by ran-
domly shuffling the words across the positive in-
stances. We also manually double-checked these
pairs to make sure that they are not hyponym-
hypernym pairs.
</bodyText>
<subsectionHeader confidence="0.909272">
3.4 The Q1N |= Q2N data set
</subsectionHeader>
<bodyText confidence="0.9054808125">
We study 12 quantifiers: all, both, each, either,
every, few, many, most, much, no, several, some.
We took the Cartesian product of these quantifiers
with the 6402 WordNet nouns described in Sec-
tion 3.3. From this Cartesian product, we obtain
a total of 28926 QN sequences, such as every cat,
that occur at least 100 times in the corpus. These
are our QN phrases of interest to which the proce-
dure in Section 3.1 assigns a semantic vector.
Also, from the set of quantifier pairs (Q1, Q2)
where Q1 6= Q2, we identified 13 clear cases
where Q1 |=Q2 and 17 clear cases where Q1 6|=Q2.
These 30 cases are listed in the first column of
Table 1. For each of these 30 quantifier pairs
(Q1, Q2), we enumerate those WordNet nouns N
such that semantic vectors are available for both
</bodyText>
<table confidence="0.856885916666666">
Q1N and Q2N (that is, both sequences occur in
at least 100 times). Each such noun then gives
Quantifier pair Instances Correct
all |= some 1054 1044 (99%)
all |= several 557 550 (99%)
each |= some 656 647 (99%)
all |= many 873 772 (88%)
much |= some 248 217 (88%)
every |= many 460 400 (87%)
many |= some 951 822 (86%)
all |= most 465 393 (85%)
several |= some 580 439 (76%)
both |= some 573 322 (56%)
many |= several 594 113 (19%)
most |= many 463 84 (18%)
both |= either 63 1 (2%)
Subtotal 7537 5804 (77%)
some 6|= every 484 481 (99%)
several 6|= all 557 553 (99%)
several 6|= every 378 375 (99%)
some 6|= all 1054 1043 (99%)
many 6|= every 460 452 (98%)
some 6|= each 656 640 (98%)
few 6|= all 157 153 (97%)
many 6|= all 873 843 (97%)
both 6|= most 369 347 (94%)
several 6|= few 143 134 (94%)
both 6|= many 541 397 (73%)
many 6|= most 463 300 (65%)
either 6|= both 63 39 (62%)
many 6|= no 714 369 (52%)
some 6|= many 951 468 (49%)
few 6|= many 161 33 (20%)
both 6|= several 431 63 (15%)
Subtotal 8455 6690 (79%)
Total 15992 12494 (78%)
</table>
<tableCaption confidence="0.998021">
Table 1: Entailing and non-entailing quantifier pairs
</tableCaption>
<bodyText confidence="0.663140666666667">
with number of instances per pair (Section 3.4) and
SVMpair-out performance breakdown (Section 5).
rise to an instance of entailment (Q1N |= Q2N if
</bodyText>
<equation confidence="0.6947925">
Q1 |= Q2; example: many dogs |= several dogs) or
non-entailment (Q1N6|=Q2N if Q16|=Q2; example:
</equation>
<bodyText confidence="0.9989514">
many dogs6|=most dogs). The number of QN pairs
that each quantifier pair gives rise to in this way is
listed in the second column of Table 1. As shown
there, we have a total of 7537 positive instances
and 8455 negative instances of QN entailment.
</bodyText>
<subsectionHeader confidence="0.774985">
3.5 Classification methods
</subsectionHeader>
<bodyText confidence="0.98774675">
We consider two methods to classify candidate
pairs as entailing or non-entailing, the balAPinc
measure of Kotlerman et al. (2010) and a standard
Support Vector Machine (SVM) classifier.
</bodyText>
<page confidence="0.987126">
27
</page>
<bodyText confidence="0.984759285714286">
\x0cbalAPinc As discussed in Section 2.2, balAP-
inc is optimized to capture a relation of feature
inclusion between the narrower (entailing) and
broader (entailed) terms, while capturing other in-
tuitions about the relative relevance of features.
balAPinc averages two terms, APinc and LIN.
APinc is given by:
</bodyText>
<equation confidence="0.994172">
APinc(u |= v) =
P|Fu|
r=1 P(r) rel0(fr)
\x01
|Fu|
</equation>
<bodyText confidence="0.979901566666667">
APinc is a version of the Average Precision
measure from Information Retrieval tailored to
lexical inclusion. Given vectors Fu and Fv rep-
resenting the dimensions with positive PMI val-
ues in the semantic vectors of the candidate pair
u |= v, the idea is that we want the features (that
is, vector dimensions) that have larger values in
Fu to also have large values in Fv (the opposite
does not matter because it is u that should be in-
cluded in v, not vice versa). The Fu features are
ranked according to their PMI value so that fr
is the feature in Fu with rank r, i.e., r-th high-
est PMI. Then the sum of the product of the two
terms P(r) and rel0(fr) across the features in Fu
is computed. The first term is the precision at r,
which is higher when highly ranked u features are
present in Fv as well. The relevance term rel0(fr)
is higher when the feature fr in Fu also appears
in Fv with a high rank. (See Kotlerman et al. for
how P(r) and rel0(fr) are computed.) The result-
ing score is normalized by dividing by the entail-
ing vector size |Fu |(in accordance with the idea
that having more v features should not hurt be-
cause the u features should be included in the v
features, not vice versa).
To balance the potentially excessive asymmetry
of APinc towards the features of the antecedent,
Kotlerman et al. average it with LIN, the widely
used symmetric measure of distributional similar-
ity proposed by Lin (1998):
</bodyText>
<equation confidence="0.9974705">
LIN(u, v) =
P
fFuFv
[wu(f) + wv(f)]
P
fFu
wu(f) +
P
fFv
wv(f)
</equation>
<bodyText confidence="0.996905142857143">
LIN essentially measures feature vector overlap.
The positive PMI values wu(f) and wv(f) of a
feature f in Fu and Fv are summed across those
features that are positive in both vectors, normal-
izing by the cumulative positive PMI mass in both
vectors. Finally, balAPinc is the geometric aver-
age of APinc and LIN:
</bodyText>
<equation confidence="0.999042">
balAPinc(u|=v) =
p
APinc(u |= v) LIN(u, v)
</equation>
<bodyText confidence="0.993373103448276">
To adapt balAPinc to recognize entailment, we
must select a threshold t above which we classify
a pair as entailing. In the experiments below, we
explore two approaches. In balAPincupper, we op-
timize the threshold directly on the test data, by
setting t to maximize the F-measure on the test
set. This gives us an upper bound on how well bal-
APinc could perform on the test set (but note that
optimizing F does not necessarily translate into a
good accuracy performance, as clearly illustrated
by Table 3 below). In balAPincAN |= N, we use the
AN |= N data set as training data and pick the t
that maximizes F on this training set.
We use the balAPinc measure as a refer-
ence point because, on the evidence provided by
Kotlerman et al., it is the state of the art in various
tasks related to lexical entailment. We recognize
however that it is somewhat complex and specifi-
cally tuned to capturing the relation of feature in-
clusion. Consequently, we also experiment with
a more flexible classifier, which can detect other
systematic properties of vectors in an entailment
relation. We present this classifier next.
SVM Support vector machines are widely used
high-performance discriminative classifiers that
find the hyperplane providing the best separation
between negative and positive instances (Cristian-
ini and Shawe-Taylor, 2000). Our SVM classifiers
are trained and tested using Weka 3 and LIBSVM
</bodyText>
<subsectionHeader confidence="0.524043">
2.8 (Chang and Lin, 2011). We use the default
</subsectionHeader>
<bodyText confidence="0.980459928571428">
polynomial kernel ((uv/600)3) with \x0f (tolerance
of termination criterion) set to 1.6. This value was
tuned on the AN|=N data set, which we never use
for testing. In the same initial tuning experiments
on the AN|=N data set, SVM outperformed deci-
sion trees, naive Bayes, and k-nearest neighbors.
We feed each potential entailment pair to SVM
by concatenating the two vectors representing the
antecedent and consequent expressions.2 How-
ever, for efficiency and to mitigate data sparse-
ness, we reduce the dimensionality of the seman-
tic vectors to 300 columns using Singular Value
Decomposition (SVD) before feeding them to the
classifier.3 Because the SVD-reduced semantic
</bodyText>
<page confidence="0.965215">
2
</page>
<bodyText confidence="0.998618333333333">
We have tried also to represent a pair by subtracting and
by dividing the two vectors. The concatenation operation
gave more successful results.
</bodyText>
<page confidence="0.987961">
3
</page>
<bodyText confidence="0.9993355">
To keep a manageable parameter space, we picked 300
columns without tuning. This is the best value reported in
many earlier studies, including classic LSA. Since SVD
sometimes improves the semantic space (Landauer and Du-
</bodyText>
<page confidence="0.991632">
28
</page>
<bodyText confidence="0.977228866666667">
\x0cvectors occupy a 300-dimensional space, the en-
tailment pairs occupy a 600-dimensional space.
An SVM with a polynomial kernel takes into
account not only individual input features but also
their interactions (Manning et al., 2008, chapter
15). Thus, our classifier can capture not just prop-
erties of individual dimensions of the antecedent
and consequent pairs, but also properties of their
combinations (e.g., the product of the first dimen-
sions of the antecedent and the consequent). We
conjecture that this property of SVMs is funda-
mental to their success at detecting entailment,
where relations between the antecedent and the
consequent should matter more than their inde-
pendent characteristics.
</bodyText>
<figure confidence="0.30504">
4 Predicting lexical entailment from
AN |= N evidence
</figure>
<bodyText confidence="0.974632916666667">
Since the contexts of AN must be a subset of the
contexts of N, semantic vectors harvested from
AN phrases and their head Ns are by construc-
tion in an inclusion relation. The first experiment
shows that these vectors constitute excellent train-
ing data to discover entailment between nouns.
This suggests that the vector pairs representing
entailment between nouns are also in an inclusion
relation, supporting the conjectures of Kotlerman
et al. (2010) and others.
Table 2 reports the results we obtained with
balAPincupper, balAPincAN |= N (Section 3.5) and
</bodyText>
<equation confidence="0.7728675">
SVMAN |= N (the SVM classifier trained on the
AN |= N data). As an upper bound for meth-
</equation>
<bodyText confidence="0.99724047368421">
ods that generalize from AN |= N, we also re-
port the performance of SVM trained with 10-fold
cross-validation on the N1 |= N2 data themselves
(SVMupper). Finally, we tried two baseline classi-
fiers. The first baseline (fq(N1) &lt; fq(N2)) guesses
entailment if the first word is less frequent than
the second. The second (cos(N1, N2)) applies a
threshold (determined on the test set) to the co-
sine similarity of the pair. The results of these
baselines shown in Table 2 use SVD; those with-
out SVD are similar. Both baselines outperformed
more trivial methods such as random guessing or
fixed response, but they performed significantly
worse than SVM and balAPinc.
Both methods that generalize entailment from
AN |= N to N1 |= N2 perform well, with 70%
mais, 1997; Rapp, 2003; Schutze, 1997), we tried balAPinc
on the SVD-reduced vectors as well, but results were consis-
tently worse than with PMI vectors.
</bodyText>
<table confidence="0.995580125">
P R F Accuracy
(95% C.I.)
SVMupper 88.6 88.6 88.5 88.6 (87.389.7)
balAPincAN |= N 65.2 87.5 74.7 70.4 (68.772.1)
balAPincupper 64.4 90.0 75.1 70.1 (68.471.8)
SVMAN |= N 69.3 69.3 69.3 69.3 (67.671.0)
cos(N1, N2) 57.7 57.6 57.5 57.6 (55.859.5)
fq(N1) &lt; fq(N2) 52.1 52.1 51.8 53.3 (51.455.2)
</table>
<tableCaption confidence="0.998843">
Table 2: Detecting lexical entailment. Results ranked
</tableCaption>
<bodyText confidence="0.9930605">
by accuracy and expressed as percentages. 95% con-
fidence intervals around accuracy calculated by bino-
mial exact tests.
accuracy on the test set, which is balanced be-
tween positive and negative instances. Interest-
ingly, the balAPinc decision thresholds tuned on
the AN |= N set and on the test data are very
close (0.26 vs. 0.24), resulting in very similar per-
formance for balAPincAN |= N and balAPincupper.
This suggests that the relation captured by bal-
APinc on the phrasal entailment training data is
indeed the same that the measure captures when
applied to lexical entailment data.
The success of this first experiment shows that
the entailment relation present in the distribu-
tional representation of AN phrases and their
head Ns transfers to lexical entailment (entailment
among Ns). Most importantly, this result demon-
strates that the semantic vectors of composite ex-
pressions (such as ANs) are useful for lexical en-
tailment. Moreover, the result is in accordance
with the view of FS, that ANs and Ns have the
same semantic type, and thus they enter entail-
ment relations of the same kind. Finally, the hy-
pothesis that entailment among nouns is reflected
by distributional inclusion among their semantic
vectors (Kotlerman et al., 2010) is supported both
by the successful generalization of the SVM clas-
sifier trained on AN |= N pairs and by the good
performance of the balAPinc measure.
</bodyText>
<sectionHeader confidence="0.927417" genericHeader="method">
5 Generalizing QN entailment
</sectionHeader>
<bodyText confidence="0.99974">
The second study is somewhat more ambitious,
as it aims to capture and generalize the entailment
relation between QPs (of shape QN) using only
the corpus-harvested semantic vectors represent-
ing these phrases as evidence. We are thus first
and foremost interested in testing whether these
vectors encode information that can help a power-
</bodyText>
<page confidence="0.997743">
29
</page>
<table confidence="0.999006769230769">
\x0cP R F Accuracy
(95% C.I.)
SVMpair-out 76.7 77.0 76.8 78.1 (77.578.8)
SVMquantifier-out 70.1 65.3 68.0 71.0 (70.371.7)
SVMQ
pair-out 67.9 69.8 68.9 70.2 (69.570.9)
SVMQ
quantifier-out 53.3 52.9 53.1 56.0 (55.256.8)
cos(QN1, QN2) 52.9 52.3 52.3 53.1 (52.353.9)
balAPincAN |= N 46.7 5.6 10.0 52.5 (51.753.3)
SVMAN |= N 2.8 42.9 5.2 52.4 (51.753.2)
fq(QN1)&lt;fq(QN2) 51.0 47.4 49.1 50.2 (49.451.0)
balAPincupper 47.1 100 64.1 47.2 (46.447.9)
</table>
<tableCaption confidence="0.999303">
Table 3: Detecting quantifier entailment. Results
</tableCaption>
<bodyText confidence="0.993130037037037">
ranked by accuracy and expressed as percentages.
95% confidence intervals around accuracy calculated
by binomial exact tests.
ful classifier, such as SVM, to detect entailment.
To abstract away from lexical or other effects
linked to a specific quantifier, we consider two
challenging training and testing regimes. In the
first (SVMpair-out), we hold out one quantifier pair
as testing data and use the other 29 pairs in Table 1
as training data. Thus, for example, the classifier
must discover all dogs |= some dogs without see-
ing any all N |= some N instance in the training
data. In the second (SVMquantifier-out), we hold out
one of the 12 quantifiers as testing data (that is,
hold out every pair involving a certain quantifier)
and use the rest as training data. For example,
the quantifier must guess all dogs |= some dogs
without ever seeing all in the training data. We
expect the second training regime to be more dif-
ficult, not just because there is less training data,
but also because the trained classifier is tested on
a quantifier that it has never encountered within
any training QN sequence.4
Table 3 reports the results for SVMpair-out and
SVMquantifier-out, as well as for the methods we
tried in the lexical entailment experiments. (As
in the first study, the frequency- and cosine-based
</bodyText>
<page confidence="0.980746">
4
</page>
<bodyText confidence="0.997695512195122">
In our initial experiments, we added negative entail-
ment instances by blindly permuting the nouns, under the
assumption that Q1N1 typically does not entail Q2N2 when
Q1 6= Q2 and N1 6= N2. These additional instances turned
out to be much easier to classify: adding an equal proportion
of them to the training data and testing data, such that the
number of instances where N1 = N2 and where N1 6= N2
is equal, reduced every error rate roughly by half. The re-
ported results do not involve these additional instances.
baselines are only slightly better overall than more
trivial baselines.) We consider moreover an alter-
native approach that ignores the noun altogether
and uses vectors for the quantifiers only (e.g., the
decision about all dogs|=some dogs considers the
corpus-derived all and some vectors only). The
models resulting from this Q-only strategy are
marked with the superscript Q in the table.
The results confirm clearly that semantic vec-
tors for QNs contain enough information to allow
a classifier to detect entailment: SVMquantifier-out
performs as well as the lexical entailment classi-
fiers of our first study, and SVMpair-out does even
better. This success is especially impressive given
our challenging training and testing regimes.
In contrast to the first study, now SVMAN |= N,
the classifier trained on the AN |= N data set,
and balAPinc perform no better than the base-
lines. (Here balAPincupper and balAPincAN |= N
pick very different thresholds: the first settling
on a very low t = 0.01, whereas for the sec-
ond t = 0.26.) As predicted by FS (see Section
2.2 above), noun-level entailment does not gen-
eralize to quantifier phrase entailment, since the
two structures have different semantic types, cor-
responding to different kinds of entailment rela-
tions. Moreover, the failure of balAPinc suggests
that, whatever evidence the SVMs rely upon, it is
not simple feature inclusion.
Interestingly, even the Q vectors alone encode
enough information to capture entailment above
chance. Still, the huge drop in performance from
</bodyText>
<sectionHeader confidence="0.634904" genericHeader="method">
SVMQ
</sectionHeader>
<bodyText confidence="0.99271805">
pair-out to SVMQ
quantifier-out suggests that the Q-
only method learned ad-hoc properties that do not
generalize (e.g., all entails every Q2).
Tables 1 and 4 break down the SVM results by
(pairs of) quantifiers. We highlight the remark-
able dichotomy in Table 4 between the good per-
formance on the universal-like quantifiers (each,
every, all, much) and the poor performance on the
existential-like ones (some, no, both, either).
In sum, the QN experiments show that seman-
tic vectors contain enough information to detect
a logical relation such as entailment not only be-
tween words, but also between phrases contain-
ing quantifiers that determine their entailment re-
lation. While a flexible classifier such as SVM
performs this task well, neither measuring fea-
ture inclusion nor generalizing nominal entail-
ment works. SVMs are evidently tapping into
other properties of the vectors.
</bodyText>
<page confidence="0.987281">
30
</page>
<table confidence="0.999013733333333">
\x0cQuantifier Instances Correct
|= 6|= |= 6|=
each 656 656 649 637 (98%)
every 460 1322 402 1293 (95%)
much 248 0 216 0 (87%)
all 2949 2641 2011 2494 (81%)
several 1731 1509 1302 1267 (79%)
many 3341 4163 2349 3443 (77%)
few 0 461 0 311 (67%)
most 928 832 549 511 (60%)
some 4062 3145 1780 2190 (55%)
no 0 714 0 380 (53%)
both 636 1404 589 303 (44%)
either 63 63 2 41 (34%)
Total 15074 16910 9849 12870 (71%)
</table>
<tableCaption confidence="0.927172">
Table 4: Breakdown of results with leaving-one-
quantifier-out (SVMquantifier-out) training regime.
</tableCaption>
<sectionHeader confidence="0.922169" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.935521634146342">
Our main results are as follows.
1. Corpus-harvested semantic vectors repre-
senting adjective-noun constructions and
their heads encode a relation of entailment
that can be exploited to train a classifier
to detect lexical entailment. In particular,
a relation of feature inclusion between the
narrower antecedent and broader consequent
terms captures both AN |= N and N1 |= N2
entailment.
2. The semantic vectors of quantifier-noun con-
structions also encode information sufficient
to learn an entailment relation that general-
izes to QNs containing quantifiers that were
not seen during training.
3. Neither the entailment information encoded
in AN |= N vectors nor the balAPinc mea-
sure generalizes well to entailment detection
in QNs. This result suggests that QN vectors
encode a different kind of entailment, as also
suggested by type distinctions in Formal Se-
mantics.
In future work, we want first of all to conduct
an analysis of the features in the Q1N|=Q2N vec-
tors that are crucially exploited by our success-
ful entailment recognizers, in order to understand
which characteristics of entailment are encoded in
these vectors.
Very importantly, instead of extracting vectors
representing phrases directly from the corpus, we
intend to derive them by compositional operations
proposed in the literature (see Section 2.1 above).
We will look for composition methods producing
vector representations of composite expressions
that are as good as (or better than) vectors directly
extracted from the corpus at encoding entailment.
Finally, we would like to evaluate our entail-
ment detection strategies for larger phrases and
sentences, possibly containing multiple quanti-
fiers, and eventually embed them as core compo-
nents of an RTE system.
</bodyText>
<sectionHeader confidence="0.966938" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9772804">
We thank the Erasmus Mundus EMLCT Program
for the student and visiting scholar grants to the
third and fourth author, respectively. The first
two authors are partially funded by the ERC 2011
Starting Independent Research Grant supporting
the COMPOSES project (nr. 283554). We are
grateful to Gemma Boleda, Louise McNally, and
the anonymous reviewers for valuable comments,
and to Ido Dagan for important insights into en-
tailment from an empirical point of view.
</bodyText>
<sectionHeader confidence="0.935667" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.7051406">
Timothy Baldwin, Colin Bannard, Takaaki Tanaka,
and Dominic Widdows. 2003. An empirical model
of multiword expression decomposability. In Pro-
ceedings of the ACL 2003 Workshop on Multiword
Expressions, pages 8996.
Marco Baroni and Alessandro Lenci. 2011. How
we BLESSed distributional semantic evaluation. In
Proceedings of the Workshop on Geometrical Mod-
els of Natural Language Semantics.
Marco Baroni and Roberto Zamparelli. 2010. Nouns
are vectors, adjectives are matrices: Representing
adjective-noun constructions in semantic space. In
Proceedings of EMNLP, pages 11831193, Boston,
MA.
Johan Bos and Katja Markert. 2006. When logical
inference helps determining textual entailment (and
when it doesnt. In Proceedings of the Second PAS-
CAL Challenges Workshop on Recognising Textual
Entailment.
Paul Buitelaar and Philipp Cimiano. 2008. Bridging
the Gap between Text and Knowledge. IOS, Ams-
terdam.
Nathanael Chambers, Daniel Cer, Trond Grenager,
David Hall, Chloe Kiddon, Bill MacCartney, Marie-
Catherine de Marneffe, Daniel Ramage, Eric Yeh,
</reference>
<page confidence="0.996273">
31
</page>
<reference confidence="0.999768321428572">
\x0cand Christopher D. Manning. 2007. Learning
alignments and leveraging natural logic. In ACL-
PASCAL Workshop on Textual Entailment and Para-
phrasing.
Chih-Chung Chang and Chih-Jen Lin. 2011. LIB-
SVM: A library for support vector machines. ACM
Transactions on Intelligent Systems and Technol-
ogy, 2(3):27:127:27.
Kenneth Church and Peter Hanks. 1990. Word associ-
ation norms, mutual information, and lexicography.
Computational Linguistics, 16(1):2229.
Nello Cristianini and John Shawe-Taylor. 2000. An
introduction to Support Vector Machines and other
kernel-based learning methods. Cambridge Univer-
sity Press, Cambridge.
Ido Dagan, Bill Dolan, Bernardo Magnini, and Dan
Roth. 2009. Recognizing textual entailment: ratio-
nal, evaluation and approaches. Natural Language
Engineering, 15:459476.
Katrin Erk. 2009. Supporting inferences in semantic
space: representing words as regions. In Proceed-
ings of IWCS, pages 104115, Tilburg, Netherlands.
Maayan Geffet and Ido Dagan. 2005. The distribu-
tional inclusion hypotheses and lexical entailment.
In Proceedings of ACL, pages 107114, Ann Arbor,
MI.
Edward Grefenstette and Mehrnoosh Sadrzadeh.
2011. Experimental support for a categorical com-
positional distributional model of meaning. In Pro-
ceedings of EMNLP, pages 13951404, Edinburgh.
Emiliano Guevara. 2010. A regression model
of adjective-noun compositionality in distributional
semantics. In Proceedings of the ACL GEMS Work-
shop, pages 3337, Uppsala, Sweden.
Marti Hearst. 1992. Automatic acquisition of hy-
ponyms from large text corpora. In Proceedings of
COLING, pages 539545, Nantes, France.
Irene Heim and Angelika Kratzer. 1998. Semantics in
Generative Grammar. Blackwell, Oxford.
Lili Kotlerman, Ido Dagan, Idan Szpektor, and
Maayan Zhitomirsky-Geffet. 2010. Directional
distributional similarity for lexical inference. Natu-
ral Language Engineering, 16(4):359389.
Milen Kouleykov and Bernardo Magnini. 2005. Tree
edit sistance for textual entailment. In Proceed-
ings of RALNP-2005, International Conference on
Recent Advances in Natural Language Processing,
pages 271278.
Thomas Landauer and Susan Dumais. 1997. A
solution to Platos problem: The latent semantic
analysis theory of acquisition, induction, and rep-
resentation of knowledge. Psychological Review,
104(2):211240.
Dekang Lin. 1998. An information-theoretic defini-
tion of similarity. In Proceedings of ICML, pages
296304, Madison, WI, USA.
Kevin Lund and Curt Burgess. 1996. Producing
high-dimensional semantic spaces from lexical co-
occurrence. Behavior Research Methods, 28:203
208.
Chris Manning, Prabhakar Raghavan, and Hinrich
Schutze. 2008. Introduction to Information Re-
trieval. Cambridge University Press, Cambridge.
Jeff Mitchell and Mirella Lapata. 2010. Composi-
tion in distributional models of semantics. Cogni-
tive Science, 34(8):13881429.
Richard Montague. 1970. Universal Grammar. Theo-
ria, 36:373398.
Patrick Pantel and Deepak Ravichandran. 2004. Au-
tomatically labeliing semantic classes. In Proceed-
ings of HLT-NAACL 2004, pages 321328.
Reinhard Rapp. 2003. Word sense discovery based on
sense descriptor dissimilarity. In Proceedings of the
9th MT Summit, pages 315322, New Orleans, LA.
Magnus Sahlgren. 2006. The Word-Space Model.
Dissertation, Stockholm University.
Helmut Schmid. 1995. Improvements in part-of-
speech tagging with an application to German.
In Proceedings of the EACL-SIGDAT Workshop,
Dublin, Ireland.
Hinrich Schutze. 1997. Ambiguity Resolution in Nat-
ural Language Learning. CSLI, Stanford, CA.
Rion Snow, Daniel Juravsky, and Andrew Y. Ng.
2005. Learning syntactic patterns for automatic hy-
pernym discovery. In Proceedings of NIPS 17.
Rion Snow, Daniel Juravsky, and Andrew Y. Ng.
2006. Semantic taxonomy induction from het-
erogenous evidence. In Proceedings of ACL 2006,
pages 801808.
Richmond H. Thomason, editor. 1974. Formal Phi-
losophy: Selected Papers of Richard Montague.
Yale University Press, New York.
Peter Turney and Patrick Pantel. 2010. From fre-
quency to meaning: Vector space models of se-
mantics. Journal of Artificial Intelligence Research,
37:141188.
Peter Turney. 2008. A uniform approach to analogies,
synonyms, antonyms and associations. In Proceed-
ings of COLING, pages 905912, Manchester, UK.
Julie Weeds, David Weir, and Diana McCarthy. 2004.
Characterising measures of lexical distributional
similarity. In Proceedings of the 20th Interna-
tional Conference of Computational Linguistics,
COLING-2004, pages 10151021.
Fabio M. Zanzotto, Marco Pennacchiotti, and Alessan-
dro Moschitti. 2007. Shallow semantics in fast tex-
tual entailment rule learners. In Proceedings of the
ACL-PASCAL Workshop on Textual Entailment and
Paraphrasing.
Maayan Zhitomirsky-Geffet and Ido Dagan. 2010.
Bootstrapping distributional feature vector quality.
Computational Linguistics, 35(3):435461.
</reference>
<page confidence="0.983286">
32
</page>
<figure confidence="0.252151">
\x0c&apos;
</figure>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.522291">
<note confidence="0.9173305">b&apos;Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 2332, Avignon, France, April 23 - 27 2012. c 2012 Association for Computational Linguistics Entailment above the word level in distributional semantics</note>
<author confidence="0.9681625">Marco Baroni Raffaella Bernardi</author>
<affiliation confidence="0.999746">University of Trento</affiliation>
<email confidence="0.982932">name.surname@unitn.it</email>
<author confidence="0.838818">Ngoc-Quynh Do</author>
<affiliation confidence="0.991271">Free University of Bozen-Bolzano</affiliation>
<email confidence="0.997612">quynhdtn.hut@gmail.com</email>
<author confidence="0.922733">Chung-chieh Shan</author>
<affiliation confidence="0.9995425">Cornell University University of Tsukuba</affiliation>
<email confidence="0.999773">ccshan@post.harvard.edu</email>
<abstract confidence="0.999569210526316">We introduce two ways to detect entailment using distributional semantic representations of phrases. Our first experiment shows that the entailment relation between adjective-noun constructions and their head nouns (big cat |= cat), once represented as semantic vector pairs, generalizes to lexical entailment among nouns (dog |= animal). Our second experiment shows that a classifier fed semantic vector pairs can similarly generalize the entailment relation among quantifier phrases (many dogs|=some dogs) to entailment involving unseen quantifiers (all cats|=several cats). Moreover, nominal and quantifier phrase entailment appears to be cued by different distributional correlates, as predicted by the type-based view of entailment in formal semantics.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
<author>Colin Bannard</author>
<author>Takaaki Tanaka</author>
<author>Dominic Widdows</author>
</authors>
<title>An empirical model of multiword expression decomposability.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL 2003 Workshop on Multiword Expressions,</booktitle>
<pages>8996</pages>
<contexts>
<context position="7159" citStr="Baldwin et al. (2003)" startWordPosition="1096" endWordPosition="1099">rds tend to share similar contexts, DS has been very successful in tasks that require quantifying semantic similarity among words, such as synonym detection and concept clustering (Turney and Pantel, 2010). Recently, there has been a flurry of interest in DS to model meaning composition: How can we derive the DS representation of a composite phrase from that of its constituents? Although the general focus in the area is to perform algebraic operations on word semantic vectors (Mitchell and Lapata, 2010), some researchers have also directly examined the corpus contexts of phrases. For example, Baldwin et al. (2003) studied vector extraction for phrases because they were interested in the decomposability of multiword expressions. Baroni and Zamparelli (2010) and Guevara (2010) look at corpus-harvested phrase vectors to learn composition functions that should derive such composite vectors automatically. Baroni and Zamparelli, in particular, showed qualitatively that directly corpus-harvested vectors for AN constructions are meaningful; for example, the vector of young husband has nearest neighbors small son, small daughter and mistress. Following up on this approach, we show here quantitatively that corpu</context>
</contexts>
<marker>Baldwin, Bannard, Tanaka, Widdows, 2003</marker>
<rawString>Timothy Baldwin, Colin Bannard, Takaaki Tanaka, and Dominic Widdows. 2003. An empirical model of multiword expression decomposability. In Proceedings of the ACL 2003 Workshop on Multiword Expressions, pages 8996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Baroni</author>
<author>Alessandro Lenci</author>
</authors>
<title>How we BLESSed distributional semantic evaluation.</title>
<date>2011</date>
<booktitle>In Proceedings of the Workshop on Geometrical Models of Natural Language Semantics.</booktitle>
<contexts>
<context position="17539" citStr="Baroni and Lenci, 2011" startWordPosition="2797" endWordPosition="2800">AN usually does not entail another N, we can create negative examples (AN1 6|= N2) just by randomly permuting the Ns. Of course, such unsupervised data would be slightly noisy, especially because some of the most frequent adjectives are not restrictive. To collect cleaner data and to be sure that we are really examining the phenomenon of entailment, we took a mere few moments of manual effort to select the 256 restrictive adjectives from the most frequent 300 adjectives in the corpus. We then took the Cartesian product of these 256 adjectives with the 200 concrete nouns in the BLESS data set (Baroni and Lenci, 2011). Those nouns were chosen to avoid highly polysemous words. From the Cartesian product, we obtain a total of 1246 AN sequences, such as big cat, that occur more than 100 times in the corpus. These AN sequences encompass 190 of the 256 adjec26 \x0ctives and 128 of the 200 nouns. The process results in 1246 positive instances of AN |= N entailment, which we use as training data. To create a comparable amount of negative data, we randomly permuted the nouns in the positive instances to obtain pairs of AN1 6|= N2 (e.g., big cat6|=dog). We manually double-checked that all positive and negative exam</context>
</contexts>
<marker>Baroni, Lenci, 2011</marker>
<rawString>Marco Baroni and Alessandro Lenci. 2011. How we BLESSed distributional semantic evaluation. In Proceedings of the Workshop on Geometrical Models of Natural Language Semantics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Baroni</author>
<author>Roberto Zamparelli</author>
</authors>
<title>Nouns are vectors, adjectives are matrices: Representing adjective-noun constructions in semantic space.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>11831193</pages>
<location>Boston, MA.</location>
<contexts>
<context position="2695" citStr="Baroni and Zamparelli, 2010" startWordPosition="383" endWordPosition="386">ra, but it has been largely limited to the lexical domain. On the other hand, FS has provided sophisticated models of sentence meaning, but it has been largely limited to hand-coded models that do not scale up to real-life challenges by learning from data. Given these complementary strengths, we naturally ask if DS and FS can address each others limitations. Two recent strands of research are bringing DS closer to meeting core FS challenges. One strand attempts to model compositionality with DS methods, representing both primitive and composed linguistic expressions as distributional vectors (Baroni and Zamparelli, 2010; Grefenstette and Sadrzadeh, 2011; Guevara, 2010; Mitchell and Lapata, 2010). The other strand attempts to reformulate FSs notion of logical inference in terms that DS can capture (Erk, 2009; Geffet and Dagan, 2005; Kotlerman et al., 2010; Zhitomirsky-Geffet and Dagan, 2010). In keeping with the lexical emphasis of DS, this strand has focused on inference at the word level, or lexical entailment, that is, discovering from distributional vectors of hyponyms (dog) that they entail their hypernyms (animal). This paper brings these two strands of research together by demonstrating two ways in whi</context>
<context position="7304" citStr="Baroni and Zamparelli (2010)" startWordPosition="1118" endWordPosition="1121"> synonym detection and concept clustering (Turney and Pantel, 2010). Recently, there has been a flurry of interest in DS to model meaning composition: How can we derive the DS representation of a composite phrase from that of its constituents? Although the general focus in the area is to perform algebraic operations on word semantic vectors (Mitchell and Lapata, 2010), some researchers have also directly examined the corpus contexts of phrases. For example, Baldwin et al. (2003) studied vector extraction for phrases because they were interested in the decomposability of multiword expressions. Baroni and Zamparelli (2010) and Guevara (2010) look at corpus-harvested phrase vectors to learn composition functions that should derive such composite vectors automatically. Baroni and Zamparelli, in particular, showed qualitatively that directly corpus-harvested vectors for AN constructions are meaningful; for example, the vector of young husband has nearest neighbors small son, small daughter and mistress. Following up on this approach, we show here quantitatively that corpus-harvested AN vectors are also useful for detecting entailment. We find moreover distributional vectors informative and useful not only for phra</context>
</contexts>
<marker>Baroni, Zamparelli, 2010</marker>
<rawString>Marco Baroni and Roberto Zamparelli. 2010. Nouns are vectors, adjectives are matrices: Representing adjective-noun constructions in semantic space. In Proceedings of EMNLP, pages 11831193, Boston, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan Bos</author>
<author>Katja Markert</author>
</authors>
<title>When logical inference helps determining textual entailment (and when it doesnt.</title>
<date>2006</date>
<booktitle>In Proceedings of the Second PASCAL Challenges Workshop on Recognising Textual Entailment.</booktitle>
<contexts>
<context position="11780" citStr="Bos and Markert, 2006" startWordPosition="1832" endWordPosition="1835"> to the truth of the antecedent in any circumstance, the applied view looks at entailment in terms of plausibility: |= if a human who reads (and trusts) would most likely infer that is also true. Entailment systems have been compared under this new perspective in various evaluation campaigns, the best known being the Recognizing Textual Entailment (RTE) initiative (Dagan et al., 2009). Most RTE systems are based on advanced NLP components, machine learning techniques, and/or syntactic transformations (Zanzotto et al., 2007; Kouleykov and Magnini, 2005). A few systems exploit deep FS analysis (Bos and Markert, 2006; Chambers et al., 2007). In particular, the FS results about QP properties that affect entailment have been exploited by Chambers et al, who complement a core broad-coverage system with a Natural Logic module to trade lower recall for higher precision. For instance, they exploit the monotonicity properties of no that cause the following reversal in entailment direction: some beetles |= some insects but no insects |= no beetles. To investigate entailment step by step, we address here a much simpler and clearer type of entailment than the more complex notion taken up by the RTE community. While</context>
</contexts>
<marker>Bos, Markert, 2006</marker>
<rawString>Johan Bos and Katja Markert. 2006. When logical inference helps determining textual entailment (and when it doesnt. In Proceedings of the Second PASCAL Challenges Workshop on Recognising Textual Entailment.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Buitelaar</author>
<author>Philipp Cimiano</author>
</authors>
<date>2008</date>
<booktitle>Bridging the Gap between Text and Knowledge. IOS,</booktitle>
<location>Amsterdam.</location>
<contexts>
<context position="5912" citStr="Buitelaar and Cimiano, 2008" startWordPosition="889" endWordPosition="892">r, the QN study is the first to our knowledge to show that DS vectors capture semantic properties not only of content words, but of an important class of function words (quantifying determiners) deeply studied in FS but of little interest until now in DS. Besides these theoretical implications, our results are of practical import. First, our AN study presents a novel, practical method for detecting lexical entailment that reaches state-of-theart performance with little or no manual intervention. Lexical entailment is in turn fundamental for constructing ontologies and other lexical resources (Buitelaar and Cimiano, 2008). Second, our QN study demonstrates that phrasal entailment can be automatically detected and thus paves the way to apply DS to advanced NLP tasks such as recognizing textual entailment (Dagan et al., 2009). 1 In the sequel we will simply refer to a quantifying determiner as a quantifier. 2 Background 2.1 Distributional semantics above the word level DS models such as LSA (Landauer and Dumais, 1997) and HAL (Lund and Burgess, 1996) approximate the meaning of a word by a vector that summarizes its distribution in a corpus, for example by counting co-occurrences of the word with other words. Sin</context>
</contexts>
<marker>Buitelaar, Cimiano, 2008</marker>
<rawString>Paul Buitelaar and Philipp Cimiano. 2008. Bridging the Gap between Text and Knowledge. IOS, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nathanael Chambers</author>
<author>Daniel Cer</author>
<author>Trond Grenager</author>
<author>David Hall</author>
<author>Chloe Kiddon</author>
<author>Bill MacCartney</author>
</authors>
<title>MarieCatherine de Marneffe, Daniel Ramage, Eric Yeh,</title>
<date>2007</date>
<booktitle>In ACLPASCAL Workshop on Textual Entailment and Paraphrasing.</booktitle>
<location>x0cand</location>
<contexts>
<context position="11804" citStr="Chambers et al., 2007" startWordPosition="1836" endWordPosition="1839">tecedent in any circumstance, the applied view looks at entailment in terms of plausibility: |= if a human who reads (and trusts) would most likely infer that is also true. Entailment systems have been compared under this new perspective in various evaluation campaigns, the best known being the Recognizing Textual Entailment (RTE) initiative (Dagan et al., 2009). Most RTE systems are based on advanced NLP components, machine learning techniques, and/or syntactic transformations (Zanzotto et al., 2007; Kouleykov and Magnini, 2005). A few systems exploit deep FS analysis (Bos and Markert, 2006; Chambers et al., 2007). In particular, the FS results about QP properties that affect entailment have been exploited by Chambers et al, who complement a core broad-coverage system with a Natural Logic module to trade lower recall for higher precision. For instance, they exploit the monotonicity properties of no that cause the following reversal in entailment direction: some beetles |= some insects but no insects |= no beetles. To investigate entailment step by step, we address here a much simpler and clearer type of entailment than the more complex notion taken up by the RTE community. While RTE is outside our pres</context>
</contexts>
<marker>Chambers, Cer, Grenager, Hall, Kiddon, MacCartney, 2007</marker>
<rawString>Nathanael Chambers, Daniel Cer, Trond Grenager, David Hall, Chloe Kiddon, Bill MacCartney, MarieCatherine de Marneffe, Daniel Ramage, Eric Yeh, \x0cand Christopher D. Manning. 2007. Learning alignments and leveraging natural logic. In ACLPASCAL Workshop on Textual Entailment and Paraphrasing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chih-Chung Chang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBSVM: A library for support vector machines.</title>
<date>2011</date>
<journal>ACM Transactions on Intelligent Systems and Technology,</journal>
<volume>2</volume>
<issue>3</issue>
<contexts>
<context position="25358" citStr="Chang and Lin, 2011" startWordPosition="4178" endWordPosition="4181">ent. We recognize however that it is somewhat complex and specifically tuned to capturing the relation of feature inclusion. Consequently, we also experiment with a more flexible classifier, which can detect other systematic properties of vectors in an entailment relation. We present this classifier next. SVM Support vector machines are widely used high-performance discriminative classifiers that find the hyperplane providing the best separation between negative and positive instances (Cristianini and Shawe-Taylor, 2000). Our SVM classifiers are trained and tested using Weka 3 and LIBSVM 2.8 (Chang and Lin, 2011). We use the default polynomial kernel ((uv/600)3) with \x0f (tolerance of termination criterion) set to 1.6. This value was tuned on the AN|=N data set, which we never use for testing. In the same initial tuning experiments on the AN|=N data set, SVM outperformed decision trees, naive Bayes, and k-nearest neighbors. We feed each potential entailment pair to SVM by concatenating the two vectors representing the antecedent and consequent expressions.2 However, for efficiency and to mitigate data sparseness, we reduce the dimensionality of the semantic vectors to 300 columns using Singular Value</context>
</contexts>
<marker>Chang, Lin, 2011</marker>
<rawString>Chih-Chung Chang and Chih-Jen Lin. 2011. LIBSVM: A library for support vector machines. ACM Transactions on Intelligent Systems and Technology, 2(3):27:127:27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Church</author>
<author>Peter Hanks</author>
</authors>
<title>Word association norms, mutual information, and lexicography.</title>
<date>1990</date>
<contexts>
<context position="15494" citStr="Church and Hanks, 1990" startWordPosition="2436" endWordPosition="2439">ord phrases and single words, and more precisely to: those AN and QN sequences that are in the data sets (see next subsections), the adjectives, quantifiers and nouns contained in those sequences, and the most frequent (9.8K) nouns and (8.1K) adjectives in the corpus. The first step is to count the content words (more precisely, the most frequent 9.8K nouns, 8.1K adjectives, and 9.6K verbs in the corpus) that occur in the same sentence as phrases of interest. In the second step, following standard practice, the co-occurrence counts are converted into pointwise mutual information (PMI) scores (Church and Hanks, 1990). The result of this step is a sparse matrix (with both positive and negative entries) with 48K rows (one per phrase of interest) and 27K columns (one per content word). 3.2 The AN |= N data set To characterize entailment between nouns using their semantic vectors, we need data exemplifying which noun entails which. This section introduces one cheap way to collect such a training data set exploiting semantic vectors for composed expressions, namely AN sequences. We rely on the linguistic fact that ANs share a syntactic category and semantic type with plain common nouns (big cat shares syntacti</context>
</contexts>
<marker>Church, Hanks, 1990</marker>
<rawString>Kenneth Church and Peter Hanks. 1990. Word association norms, mutual information, and lexicography.</rawString>
</citation>
<citation valid="false">
<journal>Computational Linguistics,</journal>
<volume>16</volume>
<issue>1</issue>
<marker></marker>
<rawString>Computational Linguistics, 16(1):2229.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nello Cristianini</author>
<author>John Shawe-Taylor</author>
</authors>
<title>An introduction to Support Vector Machines and other kernel-based learning methods.</title>
<date>2000</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge.</location>
<contexts>
<context position="25264" citStr="Cristianini and Shawe-Taylor, 2000" startWordPosition="4160" endWordPosition="4164">evidence provided by Kotlerman et al., it is the state of the art in various tasks related to lexical entailment. We recognize however that it is somewhat complex and specifically tuned to capturing the relation of feature inclusion. Consequently, we also experiment with a more flexible classifier, which can detect other systematic properties of vectors in an entailment relation. We present this classifier next. SVM Support vector machines are widely used high-performance discriminative classifiers that find the hyperplane providing the best separation between negative and positive instances (Cristianini and Shawe-Taylor, 2000). Our SVM classifiers are trained and tested using Weka 3 and LIBSVM 2.8 (Chang and Lin, 2011). We use the default polynomial kernel ((uv/600)3) with \x0f (tolerance of termination criterion) set to 1.6. This value was tuned on the AN|=N data set, which we never use for testing. In the same initial tuning experiments on the AN|=N data set, SVM outperformed decision trees, naive Bayes, and k-nearest neighbors. We feed each potential entailment pair to SVM by concatenating the two vectors representing the antecedent and consequent expressions.2 However, for efficiency and to mitigate data sparse</context>
</contexts>
<marker>Cristianini, Shawe-Taylor, 2000</marker>
<rawString>Nello Cristianini and John Shawe-Taylor. 2000. An introduction to Support Vector Machines and other kernel-based learning methods. Cambridge University Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Bill Dolan</author>
<author>Bernardo Magnini</author>
<author>Dan Roth</author>
</authors>
<title>Recognizing textual entailment: rational, evaluation and approaches.</title>
<date>2009</date>
<journal>Natural Language Engineering,</journal>
<pages>15--459476</pages>
<contexts>
<context position="6118" citStr="Dagan et al., 2009" startWordPosition="923" endWordPosition="926"> but of little interest until now in DS. Besides these theoretical implications, our results are of practical import. First, our AN study presents a novel, practical method for detecting lexical entailment that reaches state-of-theart performance with little or no manual intervention. Lexical entailment is in turn fundamental for constructing ontologies and other lexical resources (Buitelaar and Cimiano, 2008). Second, our QN study demonstrates that phrasal entailment can be automatically detected and thus paves the way to apply DS to advanced NLP tasks such as recognizing textual entailment (Dagan et al., 2009). 1 In the sequel we will simply refer to a quantifying determiner as a quantifier. 2 Background 2.1 Distributional semantics above the word level DS models such as LSA (Landauer and Dumais, 1997) and HAL (Lund and Burgess, 1996) approximate the meaning of a word by a vector that summarizes its distribution in a corpus, for example by counting co-occurrences of the word with other words. Since semantically similar words tend to share similar contexts, DS has been very successful in tasks that require quantifying semantic similarity among words, such as synonym detection and concept clustering </context>
<context position="11546" citStr="Dagan et al., 2009" startWordPosition="1798" endWordPosition="1801">s taken an empirical turn, thanks to the development of benchmarks for entailment systems. The FS definition of entailment has been modified by taking common sense into account. Instead of a relation from the truth of the consequent to the truth of the antecedent in any circumstance, the applied view looks at entailment in terms of plausibility: |= if a human who reads (and trusts) would most likely infer that is also true. Entailment systems have been compared under this new perspective in various evaluation campaigns, the best known being the Recognizing Textual Entailment (RTE) initiative (Dagan et al., 2009). Most RTE systems are based on advanced NLP components, machine learning techniques, and/or syntactic transformations (Zanzotto et al., 2007; Kouleykov and Magnini, 2005). A few systems exploit deep FS analysis (Bos and Markert, 2006; Chambers et al., 2007). In particular, the FS results about QP properties that affect entailment have been exploited by Chambers et al, who complement a core broad-coverage system with a Natural Logic module to trade lower recall for higher precision. For instance, they exploit the monotonicity properties of no that cause the following reversal in entailment dir</context>
</contexts>
<marker>Dagan, Dolan, Magnini, Roth, 2009</marker>
<rawString>Ido Dagan, Bill Dolan, Bernardo Magnini, and Dan Roth. 2009. Recognizing textual entailment: rational, evaluation and approaches. Natural Language Engineering, 15:459476.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Erk</author>
</authors>
<title>Supporting inferences in semantic space: representing words as regions.</title>
<date>2009</date>
<booktitle>In Proceedings of IWCS,</booktitle>
<pages>104115</pages>
<location>Tilburg, Netherlands.</location>
<contexts>
<context position="2886" citStr="Erk, 2009" startWordPosition="416" endWordPosition="417"> to real-life challenges by learning from data. Given these complementary strengths, we naturally ask if DS and FS can address each others limitations. Two recent strands of research are bringing DS closer to meeting core FS challenges. One strand attempts to model compositionality with DS methods, representing both primitive and composed linguistic expressions as distributional vectors (Baroni and Zamparelli, 2010; Grefenstette and Sadrzadeh, 2011; Guevara, 2010; Mitchell and Lapata, 2010). The other strand attempts to reformulate FSs notion of logical inference in terms that DS can capture (Erk, 2009; Geffet and Dagan, 2005; Kotlerman et al., 2010; Zhitomirsky-Geffet and Dagan, 2010). In keeping with the lexical emphasis of DS, this strand has focused on inference at the word level, or lexical entailment, that is, discovering from distributional vectors of hyponyms (dog) that they entail their hypernyms (animal). This paper brings these two strands of research together by demonstrating two ways in which the distributional vectors of composite expressions bear on inference. Here we focus on phrasal vectors harvested directly from the corpus rather than obtained compositionally. In a first </context>
<context position="12903" citStr="Erk (2009)" startWordPosition="2029" endWordPosition="2030">er type of entailment than the more complex notion taken up by the RTE community. While RTE is outside our present scope, we do focus on QP entailment as Natural Logic does. However, our evaluation differs from Chambers et al.s, since we rely on general-purpose DS vectors as our only resource, and we look at phrase pairs with different quantifiers but the same noun. For instance, we aim to predict that all beetles |= many beetles but few beetles6|=all beetles. QPs, of course, have many well-known semantic properties besides entailment; we leave their analysis to future study. Entailment in DS Erk (2009) suggests that it may not be possible to induce lexical entailment directly from a vector space representation, but it is possible to encode the relation in this space after it has been derived through other means. On the other hand, recent studies (Geffet and Dagan, 25 \x0c2005; Kotlerman et al., 2010; Weeds et al., 2004) have pursued the intuition that entailment is the asymmetric ability of one term to substitute for another. For example, baseball contexts are also sport contexts but not vice versa, hence baseball is narrower than sport and baseball|=sport. On this view, entailment between </context>
</contexts>
<marker>Erk, 2009</marker>
<rawString>Katrin Erk. 2009. Supporting inferences in semantic space: representing words as regions. In Proceedings of IWCS, pages 104115, Tilburg, Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maayan Geffet</author>
<author>Ido Dagan</author>
</authors>
<title>The distributional inclusion hypotheses and lexical entailment.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>107114</pages>
<location>Ann Arbor, MI.</location>
<contexts>
<context position="2910" citStr="Geffet and Dagan, 2005" startWordPosition="418" endWordPosition="421">fe challenges by learning from data. Given these complementary strengths, we naturally ask if DS and FS can address each others limitations. Two recent strands of research are bringing DS closer to meeting core FS challenges. One strand attempts to model compositionality with DS methods, representing both primitive and composed linguistic expressions as distributional vectors (Baroni and Zamparelli, 2010; Grefenstette and Sadrzadeh, 2011; Guevara, 2010; Mitchell and Lapata, 2010). The other strand attempts to reformulate FSs notion of logical inference in terms that DS can capture (Erk, 2009; Geffet and Dagan, 2005; Kotlerman et al., 2010; Zhitomirsky-Geffet and Dagan, 2010). In keeping with the lexical emphasis of DS, this strand has focused on inference at the word level, or lexical entailment, that is, discovering from distributional vectors of hyponyms (dog) that they entail their hypernyms (animal). This paper brings these two strands of research together by demonstrating two ways in which the distributional vectors of composite expressions bear on inference. Here we focus on phrasal vectors harvested directly from the corpus rather than obtained compositionally. In a first experiment, we exploit t</context>
</contexts>
<marker>Geffet, Dagan, 2005</marker>
<rawString>Maayan Geffet and Ido Dagan. 2005. The distributional inclusion hypotheses and lexical entailment. In Proceedings of ACL, pages 107114, Ann Arbor, MI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward Grefenstette</author>
<author>Mehrnoosh Sadrzadeh</author>
</authors>
<title>Experimental support for a categorical compositional distributional model of meaning.</title>
<date>2011</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>13951404</pages>
<location>Edinburgh.</location>
<contexts>
<context position="2729" citStr="Grefenstette and Sadrzadeh, 2011" startWordPosition="387" endWordPosition="390">imited to the lexical domain. On the other hand, FS has provided sophisticated models of sentence meaning, but it has been largely limited to hand-coded models that do not scale up to real-life challenges by learning from data. Given these complementary strengths, we naturally ask if DS and FS can address each others limitations. Two recent strands of research are bringing DS closer to meeting core FS challenges. One strand attempts to model compositionality with DS methods, representing both primitive and composed linguistic expressions as distributional vectors (Baroni and Zamparelli, 2010; Grefenstette and Sadrzadeh, 2011; Guevara, 2010; Mitchell and Lapata, 2010). The other strand attempts to reformulate FSs notion of logical inference in terms that DS can capture (Erk, 2009; Geffet and Dagan, 2005; Kotlerman et al., 2010; Zhitomirsky-Geffet and Dagan, 2010). In keeping with the lexical emphasis of DS, this strand has focused on inference at the word level, or lexical entailment, that is, discovering from distributional vectors of hyponyms (dog) that they entail their hypernyms (animal). This paper brings these two strands of research together by demonstrating two ways in which the distributional vectors of c</context>
</contexts>
<marker>Grefenstette, Sadrzadeh, 2011</marker>
<rawString>Edward Grefenstette and Mehrnoosh Sadrzadeh. 2011. Experimental support for a categorical compositional distributional model of meaning. In Proceedings of EMNLP, pages 13951404, Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emiliano Guevara</author>
</authors>
<title>A regression model of adjective-noun compositionality in distributional semantics.</title>
<date>2010</date>
<booktitle>In Proceedings of the ACL GEMS Workshop,</booktitle>
<pages>3337</pages>
<location>Uppsala,</location>
<contexts>
<context position="2744" citStr="Guevara, 2010" startWordPosition="391" endWordPosition="393">he other hand, FS has provided sophisticated models of sentence meaning, but it has been largely limited to hand-coded models that do not scale up to real-life challenges by learning from data. Given these complementary strengths, we naturally ask if DS and FS can address each others limitations. Two recent strands of research are bringing DS closer to meeting core FS challenges. One strand attempts to model compositionality with DS methods, representing both primitive and composed linguistic expressions as distributional vectors (Baroni and Zamparelli, 2010; Grefenstette and Sadrzadeh, 2011; Guevara, 2010; Mitchell and Lapata, 2010). The other strand attempts to reformulate FSs notion of logical inference in terms that DS can capture (Erk, 2009; Geffet and Dagan, 2005; Kotlerman et al., 2010; Zhitomirsky-Geffet and Dagan, 2010). In keeping with the lexical emphasis of DS, this strand has focused on inference at the word level, or lexical entailment, that is, discovering from distributional vectors of hyponyms (dog) that they entail their hypernyms (animal). This paper brings these two strands of research together by demonstrating two ways in which the distributional vectors of composite expres</context>
<context position="7323" citStr="Guevara (2010)" startWordPosition="1123" endWordPosition="1125">ustering (Turney and Pantel, 2010). Recently, there has been a flurry of interest in DS to model meaning composition: How can we derive the DS representation of a composite phrase from that of its constituents? Although the general focus in the area is to perform algebraic operations on word semantic vectors (Mitchell and Lapata, 2010), some researchers have also directly examined the corpus contexts of phrases. For example, Baldwin et al. (2003) studied vector extraction for phrases because they were interested in the decomposability of multiword expressions. Baroni and Zamparelli (2010) and Guevara (2010) look at corpus-harvested phrase vectors to learn composition functions that should derive such composite vectors automatically. Baroni and Zamparelli, in particular, showed qualitatively that directly corpus-harvested vectors for AN constructions are meaningful; for example, the vector of young husband has nearest neighbors small son, small daughter and mistress. Following up on this approach, we show here quantitatively that corpus-harvested AN vectors are also useful for detecting entailment. We find moreover distributional vectors informative and useful not only for phrases made of content</context>
</contexts>
<marker>Guevara, 2010</marker>
<rawString>Emiliano Guevara. 2010. A regression model of adjective-noun compositionality in distributional semantics. In Proceedings of the ACL GEMS Workshop, pages 3337, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti Hearst</author>
</authors>
<title>Automatic acquisition of hyponyms from large text corpora.</title>
<date>1992</date>
<booktitle>In Proceedings of COLING,</booktitle>
<pages>539545</pages>
<location>Nantes, France.</location>
<contexts>
<context position="9860" citStr="Hearst (1992)" startWordPosition="1524" endWordPosition="1525"> notion just described, whereas the entailment relations |=N and |=QP among nouns and quantifier phrases are the inclusion relations among sets of entities and sets of sets of entities respectively. Our results in Section 5 show that DS needs to treat |=N and |=QP differently as well. Empirical, corpus-based perspectives on entailment Until recently, the corpus-based research tradition has studied entailment mostly at the word level, with applied goals such as classifying lexical relations and building taxonomic WordNet-like resources automatically. The most popular approach, first adopted by Hearst (1992), extracts lexical relations from patterns in large corpora. For instance, from the pattern N1 such as N2 one learns that N2 |= N1 (from insects such as beetles, derive beetles|=insects). Several studies have refined and extended this approach (Pantel and Ravichandran, 2004; Snow et al., 2005; Snow et al., 2006; Turney, 2008). While empirically very successful, the patternbased method is mostly limited to single content words (or frequent content-word phrases). We are interested in entailment between phrases, where it is not obvious how to use lexico-syntactic patterns and cope with data spars</context>
</contexts>
<marker>Hearst, 1992</marker>
<rawString>Marti Hearst. 1992. Automatic acquisition of hyponyms from large text corpora. In Proceedings of COLING, pages 539545, Nantes, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Irene Heim</author>
<author>Angelika Kratzer</author>
</authors>
<title>Semantics in Generative Grammar.</title>
<date>1998</date>
<publisher>Blackwell,</publisher>
<location>Oxford.</location>
<contexts>
<context position="1931" citStr="Heim and Kratzer, 1998" startWordPosition="259" endWordPosition="262">approximates linguistic meaning with vectors summarizing the contexts where expressions occur. The success of DS in lexical semantics has validated the hypothesis that semantically similar expressions occur in similar contexts (Landauer and Dumais, 1997; Lund and Burgess, 1996; Sahlgren, 2006; Schutze, 1997; Turney and Pantel, 2010). Formal semantics (FS) represents linguistic meanings as symbolic formulas and assemble them via composition rules. FS has successfully modeled quantification and captured inferential relations between phrases and between sentences (Montague, 1970; Thomason, 1974; Heim and Kratzer, 1998). The strengths of DS and FS have been complementary to date: On one hand, DS has induced large-scale semantic representations from corpora, but it has been largely limited to the lexical domain. On the other hand, FS has provided sophisticated models of sentence meaning, but it has been largely limited to hand-coded models that do not scale up to real-life challenges by learning from data. Given these complementary strengths, we naturally ask if DS and FS can address each others limitations. Two recent strands of research are bringing DS closer to meeting core FS challenges. One strand attemp</context>
</contexts>
<marker>Heim, Kratzer, 1998</marker>
<rawString>Irene Heim and Angelika Kratzer. 1998. Semantics in Generative Grammar. Blackwell, Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lili Kotlerman</author>
<author>Ido Dagan</author>
<author>Idan Szpektor</author>
<author>Maayan Zhitomirsky-Geffet</author>
</authors>
<title>Directional distributional similarity for lexical inference.</title>
<date>2010</date>
<journal>Natural Language Engineering,</journal>
<volume>16</volume>
<issue>4</issue>
<contexts>
<context position="2934" citStr="Kotlerman et al., 2010" startWordPosition="422" endWordPosition="426">g from data. Given these complementary strengths, we naturally ask if DS and FS can address each others limitations. Two recent strands of research are bringing DS closer to meeting core FS challenges. One strand attempts to model compositionality with DS methods, representing both primitive and composed linguistic expressions as distributional vectors (Baroni and Zamparelli, 2010; Grefenstette and Sadrzadeh, 2011; Guevara, 2010; Mitchell and Lapata, 2010). The other strand attempts to reformulate FSs notion of logical inference in terms that DS can capture (Erk, 2009; Geffet and Dagan, 2005; Kotlerman et al., 2010; Zhitomirsky-Geffet and Dagan, 2010). In keeping with the lexical emphasis of DS, this strand has focused on inference at the word level, or lexical entailment, that is, discovering from distributional vectors of hyponyms (dog) that they entail their hypernyms (animal). This paper brings these two strands of research together by demonstrating two ways in which the distributional vectors of composite expressions bear on inference. Here we focus on phrasal vectors harvested directly from the corpus rather than obtained compositionally. In a first experiment, we exploit the entailment properties</context>
<context position="13206" citStr="Kotlerman et al., 2010" startWordPosition="2079" endWordPosition="2082">ce, and we look at phrase pairs with different quantifiers but the same noun. For instance, we aim to predict that all beetles |= many beetles but few beetles6|=all beetles. QPs, of course, have many well-known semantic properties besides entailment; we leave their analysis to future study. Entailment in DS Erk (2009) suggests that it may not be possible to induce lexical entailment directly from a vector space representation, but it is possible to encode the relation in this space after it has been derived through other means. On the other hand, recent studies (Geffet and Dagan, 25 \x0c2005; Kotlerman et al., 2010; Weeds et al., 2004) have pursued the intuition that entailment is the asymmetric ability of one term to substitute for another. For example, baseball contexts are also sport contexts but not vice versa, hence baseball is narrower than sport and baseball|=sport. On this view, entailment between vectors corresponds to inclusion of contexts or features, and can be captured by asymmetric measures of distribution similarity. In particular, Kotlerman et al. (2010) carefully crafted the balAPinc measure (see Section 3.5 below). We adopt this measure because it has been shown to outperform others in</context>
<context position="21682" citStr="Kotlerman et al. (2010)" startWordPosition="3535" endWordPosition="3538">per pair (Section 3.4) and SVMpair-out performance breakdown (Section 5). rise to an instance of entailment (Q1N |= Q2N if Q1 |= Q2; example: many dogs |= several dogs) or non-entailment (Q1N6|=Q2N if Q16|=Q2; example: many dogs6|=most dogs). The number of QN pairs that each quantifier pair gives rise to in this way is listed in the second column of Table 1. As shown there, we have a total of 7537 positive instances and 8455 negative instances of QN entailment. 3.5 Classification methods We consider two methods to classify candidate pairs as entailing or non-entailing, the balAPinc measure of Kotlerman et al. (2010) and a standard Support Vector Machine (SVM) classifier. 27 \x0cbalAPinc As discussed in Section 2.2, balAPinc is optimized to capture a relation of feature inclusion between the narrower (entailing) and broader (entailed) terms, while capturing other intuitions about the relative relevance of features. balAPinc averages two terms, APinc and LIN. APinc is given by: APinc(u |= v) = P|Fu| r=1 P(r) rel0(fr) \x01 |Fu| APinc is a version of the Average Precision measure from Information Retrieval tailored to lexical inclusion. Given vectors Fu and Fv representing the dimensions with positive PMI va</context>
<context position="27634" citStr="Kotlerman et al. (2010)" startWordPosition="4536" endWordPosition="4539">where relations between the antecedent and the consequent should matter more than their independent characteristics. 4 Predicting lexical entailment from AN |= N evidence Since the contexts of AN must be a subset of the contexts of N, semantic vectors harvested from AN phrases and their head Ns are by construction in an inclusion relation. The first experiment shows that these vectors constitute excellent training data to discover entailment between nouns. This suggests that the vector pairs representing entailment between nouns are also in an inclusion relation, supporting the conjectures of Kotlerman et al. (2010) and others. Table 2 reports the results we obtained with balAPincupper, balAPincAN |= N (Section 3.5) and SVMAN |= N (the SVM classifier trained on the AN |= N data). As an upper bound for methods that generalize from AN |= N, we also report the performance of SVM trained with 10-fold cross-validation on the N1 |= N2 data themselves (SVMupper). Finally, we tried two baseline classifiers. The first baseline (fq(N1) &lt; fq(N2)) guesses entailment if the first word is less frequent than the second. The second (cos(N1, N2)) applies a threshold (determined on the test set) to the cosine similarity o</context>
<context position="30315" citStr="Kotlerman et al., 2010" startWordPosition="4984" endWordPosition="4987">ent shows that the entailment relation present in the distributional representation of AN phrases and their head Ns transfers to lexical entailment (entailment among Ns). Most importantly, this result demonstrates that the semantic vectors of composite expressions (such as ANs) are useful for lexical entailment. Moreover, the result is in accordance with the view of FS, that ANs and Ns have the same semantic type, and thus they enter entailment relations of the same kind. Finally, the hypothesis that entailment among nouns is reflected by distributional inclusion among their semantic vectors (Kotlerman et al., 2010) is supported both by the successful generalization of the SVM classifier trained on AN |= N pairs and by the good performance of the balAPinc measure. 5 Generalizing QN entailment The second study is somewhat more ambitious, as it aims to capture and generalize the entailment relation between QPs (of shape QN) using only the corpus-harvested semantic vectors representing these phrases as evidence. We are thus first and foremost interested in testing whether these vectors encode information that can help a power29 \x0cP R F Accuracy (95% C.I.) SVMpair-out 76.7 77.0 76.8 78.1 (77.578.8) SVMquan</context>
</contexts>
<marker>Kotlerman, Dagan, Szpektor, Zhitomirsky-Geffet, 2010</marker>
<rawString>Lili Kotlerman, Ido Dagan, Idan Szpektor, and Maayan Zhitomirsky-Geffet. 2010. Directional distributional similarity for lexical inference. Natural Language Engineering, 16(4):359389.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Milen Kouleykov</author>
<author>Bernardo Magnini</author>
</authors>
<title>Tree edit sistance for textual entailment.</title>
<date>2005</date>
<booktitle>In Proceedings of RALNP-2005, International Conference on Recent Advances in Natural Language Processing,</booktitle>
<pages>271278</pages>
<contexts>
<context position="11717" citStr="Kouleykov and Magnini, 2005" startWordPosition="1821" endWordPosition="1824">e into account. Instead of a relation from the truth of the consequent to the truth of the antecedent in any circumstance, the applied view looks at entailment in terms of plausibility: |= if a human who reads (and trusts) would most likely infer that is also true. Entailment systems have been compared under this new perspective in various evaluation campaigns, the best known being the Recognizing Textual Entailment (RTE) initiative (Dagan et al., 2009). Most RTE systems are based on advanced NLP components, machine learning techniques, and/or syntactic transformations (Zanzotto et al., 2007; Kouleykov and Magnini, 2005). A few systems exploit deep FS analysis (Bos and Markert, 2006; Chambers et al., 2007). In particular, the FS results about QP properties that affect entailment have been exploited by Chambers et al, who complement a core broad-coverage system with a Natural Logic module to trade lower recall for higher precision. For instance, they exploit the monotonicity properties of no that cause the following reversal in entailment direction: some beetles |= some insects but no insects |= no beetles. To investigate entailment step by step, we address here a much simpler and clearer type of entailment th</context>
</contexts>
<marker>Kouleykov, Magnini, 2005</marker>
<rawString>Milen Kouleykov and Bernardo Magnini. 2005. Tree edit sistance for textual entailment. In Proceedings of RALNP-2005, International Conference on Recent Advances in Natural Language Processing, pages 271278.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Landauer</author>
<author>Susan Dumais</author>
</authors>
<title>A solution to Platos problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge.</title>
<date>1997</date>
<journal>Psychological Review,</journal>
<volume>104</volume>
<issue>2</issue>
<contexts>
<context position="1561" citStr="Landauer and Dumais, 1997" startWordPosition="207" endWordPosition="210">lize the entailment relation among quantifier phrases (many dogs|=some dogs) to entailment involving unseen quantifiers (all cats|=several cats). Moreover, nominal and quantifier phrase entailment appears to be cued by different distributional correlates, as predicted by the type-based view of entailment in formal semantics. 1 Introduction Distributional semantics (DS) approximates linguistic meaning with vectors summarizing the contexts where expressions occur. The success of DS in lexical semantics has validated the hypothesis that semantically similar expressions occur in similar contexts (Landauer and Dumais, 1997; Lund and Burgess, 1996; Sahlgren, 2006; Schutze, 1997; Turney and Pantel, 2010). Formal semantics (FS) represents linguistic meanings as symbolic formulas and assemble them via composition rules. FS has successfully modeled quantification and captured inferential relations between phrases and between sentences (Montague, 1970; Thomason, 1974; Heim and Kratzer, 1998). The strengths of DS and FS have been complementary to date: On one hand, DS has induced large-scale semantic representations from corpora, but it has been largely limited to the lexical domain. On the other hand, FS has provided</context>
<context position="6314" citStr="Landauer and Dumais, 1997" startWordPosition="957" endWordPosition="960">xical entailment that reaches state-of-theart performance with little or no manual intervention. Lexical entailment is in turn fundamental for constructing ontologies and other lexical resources (Buitelaar and Cimiano, 2008). Second, our QN study demonstrates that phrasal entailment can be automatically detected and thus paves the way to apply DS to advanced NLP tasks such as recognizing textual entailment (Dagan et al., 2009). 1 In the sequel we will simply refer to a quantifying determiner as a quantifier. 2 Background 2.1 Distributional semantics above the word level DS models such as LSA (Landauer and Dumais, 1997) and HAL (Lund and Burgess, 1996) approximate the meaning of a word by a vector that summarizes its distribution in a corpus, for example by counting co-occurrences of the word with other words. Since semantically similar words tend to share similar contexts, DS has been very successful in tasks that require quantifying semantic similarity among words, such as synonym detection and concept clustering (Turney and Pantel, 2010). Recently, there has been a flurry of interest in DS to model meaning composition: How can we derive the DS representation of a composite phrase from that of its constitu</context>
</contexts>
<marker>Landauer, Dumais, 1997</marker>
<rawString>Thomas Landauer and Susan Dumais. 1997. A solution to Platos problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge. Psychological Review, 104(2):211240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>An information-theoretic definition of similarity.</title>
<date>1998</date>
<booktitle>In Proceedings of ICML,</booktitle>
<pages>296304</pages>
<location>Madison, WI, USA.</location>
<contexts>
<context position="23515" citStr="Lin (1998)" startWordPosition="3864" endWordPosition="3865">relevance term rel0(fr) is higher when the feature fr in Fu also appears in Fv with a high rank. (See Kotlerman et al. for how P(r) and rel0(fr) are computed.) The resulting score is normalized by dividing by the entailing vector size |Fu |(in accordance with the idea that having more v features should not hurt because the u features should be included in the v features, not vice versa). To balance the potentially excessive asymmetry of APinc towards the features of the antecedent, Kotlerman et al. average it with LIN, the widely used symmetric measure of distributional similarity proposed by Lin (1998): LIN(u, v) = P fFuFv [wu(f) + wv(f)] P fFu wu(f) + P fFv wv(f) LIN essentially measures feature vector overlap. The positive PMI values wu(f) and wv(f) of a feature f in Fu and Fv are summed across those features that are positive in both vectors, normalizing by the cumulative positive PMI mass in both vectors. Finally, balAPinc is the geometric average of APinc and LIN: balAPinc(u|=v) = p APinc(u |= v) LIN(u, v) To adapt balAPinc to recognize entailment, we must select a threshold t above which we classify a pair as entailing. In the experiments below, we explore two approaches. In balAPincu</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. 1998. An information-theoretic definition of similarity. In Proceedings of ICML, pages 296304, Madison, WI, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Lund</author>
<author>Curt Burgess</author>
</authors>
<title>Producing high-dimensional semantic spaces from lexical cooccurrence. Behavior Research Methods,</title>
<date>1996</date>
<pages>28--203</pages>
<contexts>
<context position="1585" citStr="Lund and Burgess, 1996" startWordPosition="211" endWordPosition="214">n among quantifier phrases (many dogs|=some dogs) to entailment involving unseen quantifiers (all cats|=several cats). Moreover, nominal and quantifier phrase entailment appears to be cued by different distributional correlates, as predicted by the type-based view of entailment in formal semantics. 1 Introduction Distributional semantics (DS) approximates linguistic meaning with vectors summarizing the contexts where expressions occur. The success of DS in lexical semantics has validated the hypothesis that semantically similar expressions occur in similar contexts (Landauer and Dumais, 1997; Lund and Burgess, 1996; Sahlgren, 2006; Schutze, 1997; Turney and Pantel, 2010). Formal semantics (FS) represents linguistic meanings as symbolic formulas and assemble them via composition rules. FS has successfully modeled quantification and captured inferential relations between phrases and between sentences (Montague, 1970; Thomason, 1974; Heim and Kratzer, 1998). The strengths of DS and FS have been complementary to date: On one hand, DS has induced large-scale semantic representations from corpora, but it has been largely limited to the lexical domain. On the other hand, FS has provided sophisticated models of</context>
<context position="6347" citStr="Lund and Burgess, 1996" startWordPosition="963" endWordPosition="966">of-theart performance with little or no manual intervention. Lexical entailment is in turn fundamental for constructing ontologies and other lexical resources (Buitelaar and Cimiano, 2008). Second, our QN study demonstrates that phrasal entailment can be automatically detected and thus paves the way to apply DS to advanced NLP tasks such as recognizing textual entailment (Dagan et al., 2009). 1 In the sequel we will simply refer to a quantifying determiner as a quantifier. 2 Background 2.1 Distributional semantics above the word level DS models such as LSA (Landauer and Dumais, 1997) and HAL (Lund and Burgess, 1996) approximate the meaning of a word by a vector that summarizes its distribution in a corpus, for example by counting co-occurrences of the word with other words. Since semantically similar words tend to share similar contexts, DS has been very successful in tasks that require quantifying semantic similarity among words, such as synonym detection and concept clustering (Turney and Pantel, 2010). Recently, there has been a flurry of interest in DS to model meaning composition: How can we derive the DS representation of a composite phrase from that of its constituents? Although the general focus </context>
</contexts>
<marker>Lund, Burgess, 1996</marker>
<rawString>Kevin Lund and Curt Burgess. 1996. Producing high-dimensional semantic spaces from lexical cooccurrence. Behavior Research Methods, 28:203 208.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Manning</author>
<author>Prabhakar Raghavan</author>
<author>Hinrich Schutze</author>
</authors>
<title>Introduction to Information Retrieval.</title>
<date>2008</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge.</location>
<contexts>
<context position="26656" citStr="Manning et al., 2008" startWordPosition="4382" endWordPosition="4385">educed semantic 2 We have tried also to represent a pair by subtracting and by dividing the two vectors. The concatenation operation gave more successful results. 3 To keep a manageable parameter space, we picked 300 columns without tuning. This is the best value reported in many earlier studies, including classic LSA. Since SVD sometimes improves the semantic space (Landauer and Du28 \x0cvectors occupy a 300-dimensional space, the entailment pairs occupy a 600-dimensional space. An SVM with a polynomial kernel takes into account not only individual input features but also their interactions (Manning et al., 2008, chapter 15). Thus, our classifier can capture not just properties of individual dimensions of the antecedent and consequent pairs, but also properties of their combinations (e.g., the product of the first dimensions of the antecedent and the consequent). We conjecture that this property of SVMs is fundamental to their success at detecting entailment, where relations between the antecedent and the consequent should matter more than their independent characteristics. 4 Predicting lexical entailment from AN |= N evidence Since the contexts of AN must be a subset of the contexts of N, semantic v</context>
</contexts>
<marker>Manning, Raghavan, Schutze, 2008</marker>
<rawString>Chris Manning, Prabhakar Raghavan, and Hinrich Schutze. 2008. Introduction to Information Retrieval. Cambridge University Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeff Mitchell</author>
<author>Mirella Lapata</author>
</authors>
<title>Composition in distributional models of semantics.</title>
<date>2010</date>
<journal>Cognitive Science,</journal>
<volume>34</volume>
<issue>8</issue>
<contexts>
<context position="2772" citStr="Mitchell and Lapata, 2010" startWordPosition="394" endWordPosition="397">FS has provided sophisticated models of sentence meaning, but it has been largely limited to hand-coded models that do not scale up to real-life challenges by learning from data. Given these complementary strengths, we naturally ask if DS and FS can address each others limitations. Two recent strands of research are bringing DS closer to meeting core FS challenges. One strand attempts to model compositionality with DS methods, representing both primitive and composed linguistic expressions as distributional vectors (Baroni and Zamparelli, 2010; Grefenstette and Sadrzadeh, 2011; Guevara, 2010; Mitchell and Lapata, 2010). The other strand attempts to reformulate FSs notion of logical inference in terms that DS can capture (Erk, 2009; Geffet and Dagan, 2005; Kotlerman et al., 2010; Zhitomirsky-Geffet and Dagan, 2010). In keeping with the lexical emphasis of DS, this strand has focused on inference at the word level, or lexical entailment, that is, discovering from distributional vectors of hyponyms (dog) that they entail their hypernyms (animal). This paper brings these two strands of research together by demonstrating two ways in which the distributional vectors of composite expressions bear on inference. Her</context>
<context position="7046" citStr="Mitchell and Lapata, 2010" startWordPosition="1078" endWordPosition="1081">bution in a corpus, for example by counting co-occurrences of the word with other words. Since semantically similar words tend to share similar contexts, DS has been very successful in tasks that require quantifying semantic similarity among words, such as synonym detection and concept clustering (Turney and Pantel, 2010). Recently, there has been a flurry of interest in DS to model meaning composition: How can we derive the DS representation of a composite phrase from that of its constituents? Although the general focus in the area is to perform algebraic operations on word semantic vectors (Mitchell and Lapata, 2010), some researchers have also directly examined the corpus contexts of phrases. For example, Baldwin et al. (2003) studied vector extraction for phrases because they were interested in the decomposability of multiword expressions. Baroni and Zamparelli (2010) and Guevara (2010) look at corpus-harvested phrase vectors to learn composition functions that should derive such composite vectors automatically. Baroni and Zamparelli, in particular, showed qualitatively that directly corpus-harvested vectors for AN constructions are meaningful; for example, the vector of young husband has nearest neighb</context>
</contexts>
<marker>Mitchell, Lapata, 2010</marker>
<rawString>Jeff Mitchell and Mirella Lapata. 2010. Composition in distributional models of semantics. Cognitive Science, 34(8):13881429.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Montague</author>
</authors>
<date>1970</date>
<journal>Universal Grammar. Theoria,</journal>
<pages>36--373398</pages>
<contexts>
<context position="1890" citStr="Montague, 1970" startWordPosition="254" endWordPosition="256">n Distributional semantics (DS) approximates linguistic meaning with vectors summarizing the contexts where expressions occur. The success of DS in lexical semantics has validated the hypothesis that semantically similar expressions occur in similar contexts (Landauer and Dumais, 1997; Lund and Burgess, 1996; Sahlgren, 2006; Schutze, 1997; Turney and Pantel, 2010). Formal semantics (FS) represents linguistic meanings as symbolic formulas and assemble them via composition rules. FS has successfully modeled quantification and captured inferential relations between phrases and between sentences (Montague, 1970; Thomason, 1974; Heim and Kratzer, 1998). The strengths of DS and FS have been complementary to date: On one hand, DS has induced large-scale semantic representations from corpora, but it has been largely limited to the lexical domain. On the other hand, FS has provided sophisticated models of sentence meaning, but it has been largely limited to hand-coded models that do not scale up to real-life challenges by learning from data. Given these complementary strengths, we naturally ask if DS and FS can address each others limitations. Two recent strands of research are bringing DS closer to meet</context>
</contexts>
<marker>Montague, 1970</marker>
<rawString>Richard Montague. 1970. Universal Grammar. Theoria, 36:373398.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Pantel</author>
<author>Deepak Ravichandran</author>
</authors>
<title>Automatically labeliing semantic classes.</title>
<date>2004</date>
<booktitle>In Proceedings of HLT-NAACL</booktitle>
<pages>321328</pages>
<contexts>
<context position="10134" citStr="Pantel and Ravichandran, 2004" startWordPosition="1565" endWordPosition="1569">d |=QP differently as well. Empirical, corpus-based perspectives on entailment Until recently, the corpus-based research tradition has studied entailment mostly at the word level, with applied goals such as classifying lexical relations and building taxonomic WordNet-like resources automatically. The most popular approach, first adopted by Hearst (1992), extracts lexical relations from patterns in large corpora. For instance, from the pattern N1 such as N2 one learns that N2 |= N1 (from insects such as beetles, derive beetles|=insects). Several studies have refined and extended this approach (Pantel and Ravichandran, 2004; Snow et al., 2005; Snow et al., 2006; Turney, 2008). While empirically very successful, the patternbased method is mostly limited to single content words (or frequent content-word phrases). We are interested in entailment between phrases, where it is not obvious how to use lexico-syntactic patterns and cope with data sparsity. For instance, it seems hard to find a pattern that frequently connects one QP to another it entails, as in all beetles PATTERN many beetles. Hence, we aim to find a more general method and investigate whether DS vectors (whether corpus-harvested or compositionally deri</context>
</contexts>
<marker>Pantel, Ravichandran, 2004</marker>
<rawString>Patrick Pantel and Deepak Ravichandran. 2004. Automatically labeliing semantic classes. In Proceedings of HLT-NAACL 2004, pages 321328.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reinhard Rapp</author>
</authors>
<title>Word sense discovery based on sense descriptor dissimilarity.</title>
<date>2003</date>
<booktitle>In Proceedings of the 9th MT Summit,</booktitle>
<pages>315322</pages>
<location>New Orleans, LA.</location>
<contexts>
<context position="28598" citStr="Rapp, 2003" startWordPosition="4706" endWordPosition="4707">y, we tried two baseline classifiers. The first baseline (fq(N1) &lt; fq(N2)) guesses entailment if the first word is less frequent than the second. The second (cos(N1, N2)) applies a threshold (determined on the test set) to the cosine similarity of the pair. The results of these baselines shown in Table 2 use SVD; those without SVD are similar. Both baselines outperformed more trivial methods such as random guessing or fixed response, but they performed significantly worse than SVM and balAPinc. Both methods that generalize entailment from AN |= N to N1 |= N2 perform well, with 70% mais, 1997; Rapp, 2003; Schutze, 1997), we tried balAPinc on the SVD-reduced vectors as well, but results were consistently worse than with PMI vectors. P R F Accuracy (95% C.I.) SVMupper 88.6 88.6 88.5 88.6 (87.389.7) balAPincAN |= N 65.2 87.5 74.7 70.4 (68.772.1) balAPincupper 64.4 90.0 75.1 70.1 (68.471.8) SVMAN |= N 69.3 69.3 69.3 69.3 (67.671.0) cos(N1, N2) 57.7 57.6 57.5 57.6 (55.859.5) fq(N1) &lt; fq(N2) 52.1 52.1 51.8 53.3 (51.455.2) Table 2: Detecting lexical entailment. Results ranked by accuracy and expressed as percentages. 95% confidence intervals around accuracy calculated by binomial exact tests. accura</context>
</contexts>
<marker>Rapp, 2003</marker>
<rawString>Reinhard Rapp. 2003. Word sense discovery based on sense descriptor dissimilarity. In Proceedings of the 9th MT Summit, pages 315322, New Orleans, LA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Magnus Sahlgren</author>
</authors>
<title>The Word-Space Model. Dissertation,</title>
<date>2006</date>
<location>Stockholm University.</location>
<contexts>
<context position="1601" citStr="Sahlgren, 2006" startWordPosition="215" endWordPosition="216">es (many dogs|=some dogs) to entailment involving unseen quantifiers (all cats|=several cats). Moreover, nominal and quantifier phrase entailment appears to be cued by different distributional correlates, as predicted by the type-based view of entailment in formal semantics. 1 Introduction Distributional semantics (DS) approximates linguistic meaning with vectors summarizing the contexts where expressions occur. The success of DS in lexical semantics has validated the hypothesis that semantically similar expressions occur in similar contexts (Landauer and Dumais, 1997; Lund and Burgess, 1996; Sahlgren, 2006; Schutze, 1997; Turney and Pantel, 2010). Formal semantics (FS) represents linguistic meanings as symbolic formulas and assemble them via composition rules. FS has successfully modeled quantification and captured inferential relations between phrases and between sentences (Montague, 1970; Thomason, 1974; Heim and Kratzer, 1998). The strengths of DS and FS have been complementary to date: On one hand, DS has induced large-scale semantic representations from corpora, but it has been largely limited to the lexical domain. On the other hand, FS has provided sophisticated models of sentence meanin</context>
</contexts>
<marker>Sahlgren, 2006</marker>
<rawString>Magnus Sahlgren. 2006. The Word-Space Model. Dissertation, Stockholm University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Improvements in part-ofspeech tagging with an application to German.</title>
<date>1995</date>
<booktitle>In Proceedings of the EACL-SIGDAT Workshop,</booktitle>
<location>Dublin, Ireland.</location>
<contexts>
<context position="14606" citStr="Schmid, 1995" startWordPosition="2287" endWordPosition="2288">tailment not only between words but also between phrases, and we ask whether the DS view of entailment as feature inclusion, which captures entailment between nouns, also captures entailment between QPs. To this end, we complement balAPinc with a more flexible supervised classifier. 3 Data and methods 3.1 Semantic space We construct distributional semantic vectors from the 2.83-billion-token concatenation of the British National Corpus (http://www.natcorp. ox.ac.uk/), WackyPedia and ukWaC (http: //wacky.sslmit.unibo.it/). We tokenize and POS-tag this corpus, then lemmatize it with TreeTagger (Schmid, 1995) to merge singular and plural instances of words and phrases (some dogs is mapped to some dog). We process the corpus in two steps to compute semantic vectors representing our phrases of interest. We use phrases of interest as a general term to refer to both multiword phrases and single words, and more precisely to: those AN and QN sequences that are in the data sets (see next subsections), the adjectives, quantifiers and nouns contained in those sequences, and the most frequent (9.8K) nouns and (8.1K) adjectives in the corpus. The first step is to count the content words (more precisely, the </context>
</contexts>
<marker>Schmid, 1995</marker>
<rawString>Helmut Schmid. 1995. Improvements in part-ofspeech tagging with an application to German. In Proceedings of the EACL-SIGDAT Workshop, Dublin, Ireland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hinrich Schutze</author>
</authors>
<title>Ambiguity Resolution in Natural Language Learning.</title>
<date>1997</date>
<location>CSLI, Stanford, CA.</location>
<contexts>
<context position="1616" citStr="Schutze, 1997" startWordPosition="217" endWordPosition="218">ome dogs) to entailment involving unseen quantifiers (all cats|=several cats). Moreover, nominal and quantifier phrase entailment appears to be cued by different distributional correlates, as predicted by the type-based view of entailment in formal semantics. 1 Introduction Distributional semantics (DS) approximates linguistic meaning with vectors summarizing the contexts where expressions occur. The success of DS in lexical semantics has validated the hypothesis that semantically similar expressions occur in similar contexts (Landauer and Dumais, 1997; Lund and Burgess, 1996; Sahlgren, 2006; Schutze, 1997; Turney and Pantel, 2010). Formal semantics (FS) represents linguistic meanings as symbolic formulas and assemble them via composition rules. FS has successfully modeled quantification and captured inferential relations between phrases and between sentences (Montague, 1970; Thomason, 1974; Heim and Kratzer, 1998). The strengths of DS and FS have been complementary to date: On one hand, DS has induced large-scale semantic representations from corpora, but it has been largely limited to the lexical domain. On the other hand, FS has provided sophisticated models of sentence meaning, but it has b</context>
<context position="28614" citStr="Schutze, 1997" startWordPosition="4708" endWordPosition="4709">two baseline classifiers. The first baseline (fq(N1) &lt; fq(N2)) guesses entailment if the first word is less frequent than the second. The second (cos(N1, N2)) applies a threshold (determined on the test set) to the cosine similarity of the pair. The results of these baselines shown in Table 2 use SVD; those without SVD are similar. Both baselines outperformed more trivial methods such as random guessing or fixed response, but they performed significantly worse than SVM and balAPinc. Both methods that generalize entailment from AN |= N to N1 |= N2 perform well, with 70% mais, 1997; Rapp, 2003; Schutze, 1997), we tried balAPinc on the SVD-reduced vectors as well, but results were consistently worse than with PMI vectors. P R F Accuracy (95% C.I.) SVMupper 88.6 88.6 88.5 88.6 (87.389.7) balAPincAN |= N 65.2 87.5 74.7 70.4 (68.772.1) balAPincupper 64.4 90.0 75.1 70.1 (68.471.8) SVMAN |= N 69.3 69.3 69.3 69.3 (67.671.0) cos(N1, N2) 57.7 57.6 57.5 57.6 (55.859.5) fq(N1) &lt; fq(N2) 52.1 52.1 51.8 53.3 (51.455.2) Table 2: Detecting lexical entailment. Results ranked by accuracy and expressed as percentages. 95% confidence intervals around accuracy calculated by binomial exact tests. accuracy on the test s</context>
</contexts>
<marker>Schutze, 1997</marker>
<rawString>Hinrich Schutze. 1997. Ambiguity Resolution in Natural Language Learning. CSLI, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rion Snow</author>
<author>Daniel Juravsky</author>
<author>Andrew Y Ng</author>
</authors>
<title>Learning syntactic patterns for automatic hypernym discovery.</title>
<date>2005</date>
<booktitle>In Proceedings of NIPS 17.</booktitle>
<contexts>
<context position="10153" citStr="Snow et al., 2005" startWordPosition="1570" endWordPosition="1573">irical, corpus-based perspectives on entailment Until recently, the corpus-based research tradition has studied entailment mostly at the word level, with applied goals such as classifying lexical relations and building taxonomic WordNet-like resources automatically. The most popular approach, first adopted by Hearst (1992), extracts lexical relations from patterns in large corpora. For instance, from the pattern N1 such as N2 one learns that N2 |= N1 (from insects such as beetles, derive beetles|=insects). Several studies have refined and extended this approach (Pantel and Ravichandran, 2004; Snow et al., 2005; Snow et al., 2006; Turney, 2008). While empirically very successful, the patternbased method is mostly limited to single content words (or frequent content-word phrases). We are interested in entailment between phrases, where it is not obvious how to use lexico-syntactic patterns and cope with data sparsity. For instance, it seems hard to find a pattern that frequently connects one QP to another it entails, as in all beetles PATTERN many beetles. Hence, we aim to find a more general method and investigate whether DS vectors (whether corpus-harvested or compositionally derived) encode the inf</context>
</contexts>
<marker>Snow, Juravsky, Ng, 2005</marker>
<rawString>Rion Snow, Daniel Juravsky, and Andrew Y. Ng. 2005. Learning syntactic patterns for automatic hypernym discovery. In Proceedings of NIPS 17.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rion Snow</author>
<author>Daniel Juravsky</author>
<author>Andrew Y Ng</author>
</authors>
<title>Semantic taxonomy induction from heterogenous evidence.</title>
<date>2006</date>
<booktitle>In Proceedings of ACL</booktitle>
<pages>801808</pages>
<contexts>
<context position="10172" citStr="Snow et al., 2006" startWordPosition="1574" endWordPosition="1577">d perspectives on entailment Until recently, the corpus-based research tradition has studied entailment mostly at the word level, with applied goals such as classifying lexical relations and building taxonomic WordNet-like resources automatically. The most popular approach, first adopted by Hearst (1992), extracts lexical relations from patterns in large corpora. For instance, from the pattern N1 such as N2 one learns that N2 |= N1 (from insects such as beetles, derive beetles|=insects). Several studies have refined and extended this approach (Pantel and Ravichandran, 2004; Snow et al., 2005; Snow et al., 2006; Turney, 2008). While empirically very successful, the patternbased method is mostly limited to single content words (or frequent content-word phrases). We are interested in entailment between phrases, where it is not obvious how to use lexico-syntactic patterns and cope with data sparsity. For instance, it seems hard to find a pattern that frequently connects one QP to another it entails, as in all beetles PATTERN many beetles. Hence, we aim to find a more general method and investigate whether DS vectors (whether corpus-harvested or compositionally derived) encode the information needed to </context>
</contexts>
<marker>Snow, Juravsky, Ng, 2006</marker>
<rawString>Rion Snow, Daniel Juravsky, and Andrew Y. Ng. 2006. Semantic taxonomy induction from heterogenous evidence. In Proceedings of ACL 2006, pages 801808.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richmond H Thomason</author>
<author>editor</author>
</authors>
<title>Formal Philosophy: Selected Papers of Richard Montague.</title>
<date>1974</date>
<publisher>Yale University Press,</publisher>
<location>New York.</location>
<marker>Thomason, editor, 1974</marker>
<rawString>Richmond H. Thomason, editor. 1974. Formal Philosophy: Selected Papers of Richard Montague. Yale University Press, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Turney</author>
<author>Patrick Pantel</author>
</authors>
<title>From frequency to meaning: Vector space models of semantics.</title>
<date>2010</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>37--141188</pages>
<contexts>
<context position="1642" citStr="Turney and Pantel, 2010" startWordPosition="219" endWordPosition="222">tailment involving unseen quantifiers (all cats|=several cats). Moreover, nominal and quantifier phrase entailment appears to be cued by different distributional correlates, as predicted by the type-based view of entailment in formal semantics. 1 Introduction Distributional semantics (DS) approximates linguistic meaning with vectors summarizing the contexts where expressions occur. The success of DS in lexical semantics has validated the hypothesis that semantically similar expressions occur in similar contexts (Landauer and Dumais, 1997; Lund and Burgess, 1996; Sahlgren, 2006; Schutze, 1997; Turney and Pantel, 2010). Formal semantics (FS) represents linguistic meanings as symbolic formulas and assemble them via composition rules. FS has successfully modeled quantification and captured inferential relations between phrases and between sentences (Montague, 1970; Thomason, 1974; Heim and Kratzer, 1998). The strengths of DS and FS have been complementary to date: On one hand, DS has induced large-scale semantic representations from corpora, but it has been largely limited to the lexical domain. On the other hand, FS has provided sophisticated models of sentence meaning, but it has been largely limited to han</context>
<context position="6743" citStr="Turney and Pantel, 2010" startWordPosition="1027" endWordPosition="1031"> 1 In the sequel we will simply refer to a quantifying determiner as a quantifier. 2 Background 2.1 Distributional semantics above the word level DS models such as LSA (Landauer and Dumais, 1997) and HAL (Lund and Burgess, 1996) approximate the meaning of a word by a vector that summarizes its distribution in a corpus, for example by counting co-occurrences of the word with other words. Since semantically similar words tend to share similar contexts, DS has been very successful in tasks that require quantifying semantic similarity among words, such as synonym detection and concept clustering (Turney and Pantel, 2010). Recently, there has been a flurry of interest in DS to model meaning composition: How can we derive the DS representation of a composite phrase from that of its constituents? Although the general focus in the area is to perform algebraic operations on word semantic vectors (Mitchell and Lapata, 2010), some researchers have also directly examined the corpus contexts of phrases. For example, Baldwin et al. (2003) studied vector extraction for phrases because they were interested in the decomposability of multiword expressions. Baroni and Zamparelli (2010) and Guevara (2010) look at corpus-harv</context>
</contexts>
<marker>Turney, Pantel, 2010</marker>
<rawString>Peter Turney and Patrick Pantel. 2010. From frequency to meaning: Vector space models of semantics. Journal of Artificial Intelligence Research, 37:141188.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Turney</author>
</authors>
<title>A uniform approach to analogies, synonyms, antonyms and associations.</title>
<date>2008</date>
<booktitle>In Proceedings of COLING,</booktitle>
<pages>905912</pages>
<location>Manchester, UK.</location>
<contexts>
<context position="10187" citStr="Turney, 2008" startWordPosition="1578" endWordPosition="1579">ntailment Until recently, the corpus-based research tradition has studied entailment mostly at the word level, with applied goals such as classifying lexical relations and building taxonomic WordNet-like resources automatically. The most popular approach, first adopted by Hearst (1992), extracts lexical relations from patterns in large corpora. For instance, from the pattern N1 such as N2 one learns that N2 |= N1 (from insects such as beetles, derive beetles|=insects). Several studies have refined and extended this approach (Pantel and Ravichandran, 2004; Snow et al., 2005; Snow et al., 2006; Turney, 2008). While empirically very successful, the patternbased method is mostly limited to single content words (or frequent content-word phrases). We are interested in entailment between phrases, where it is not obvious how to use lexico-syntactic patterns and cope with data sparsity. For instance, it seems hard to find a pattern that frequently connects one QP to another it entails, as in all beetles PATTERN many beetles. Hence, we aim to find a more general method and investigate whether DS vectors (whether corpus-harvested or compositionally derived) encode the information needed to account for phr</context>
</contexts>
<marker>Turney, 2008</marker>
<rawString>Peter Turney. 2008. A uniform approach to analogies, synonyms, antonyms and associations. In Proceedings of COLING, pages 905912, Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julie Weeds</author>
<author>David Weir</author>
<author>Diana McCarthy</author>
</authors>
<date>2004</date>
<contexts>
<context position="13227" citStr="Weeds et al., 2004" startWordPosition="2083" endWordPosition="2086">e pairs with different quantifiers but the same noun. For instance, we aim to predict that all beetles |= many beetles but few beetles6|=all beetles. QPs, of course, have many well-known semantic properties besides entailment; we leave their analysis to future study. Entailment in DS Erk (2009) suggests that it may not be possible to induce lexical entailment directly from a vector space representation, but it is possible to encode the relation in this space after it has been derived through other means. On the other hand, recent studies (Geffet and Dagan, 25 \x0c2005; Kotlerman et al., 2010; Weeds et al., 2004) have pursued the intuition that entailment is the asymmetric ability of one term to substitute for another. For example, baseball contexts are also sport contexts but not vice versa, hence baseball is narrower than sport and baseball|=sport. On this view, entailment between vectors corresponds to inclusion of contexts or features, and can be captured by asymmetric measures of distribution similarity. In particular, Kotlerman et al. (2010) carefully crafted the balAPinc measure (see Section 3.5 below). We adopt this measure because it has been shown to outperform others in several tasks that r</context>
</contexts>
<marker>Weeds, Weir, McCarthy, 2004</marker>
<rawString>Julie Weeds, David Weir, and Diana McCarthy. 2004.</rawString>
</citation>
<citation valid="false">
<title>Characterising measures of lexical distributional similarity.</title>
<booktitle>In Proceedings of the 20th International Conference of Computational Linguistics, COLING-2004,</booktitle>
<pages>10151021</pages>
<marker></marker>
<rawString>Characterising measures of lexical distributional similarity. In Proceedings of the 20th International Conference of Computational Linguistics, COLING-2004, pages 10151021.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabio M Zanzotto</author>
<author>Marco Pennacchiotti</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Shallow semantics in fast textual entailment rule learners.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing.</booktitle>
<contexts>
<context position="11687" citStr="Zanzotto et al., 2007" startWordPosition="1817" endWordPosition="1820">d by taking common sense into account. Instead of a relation from the truth of the consequent to the truth of the antecedent in any circumstance, the applied view looks at entailment in terms of plausibility: |= if a human who reads (and trusts) would most likely infer that is also true. Entailment systems have been compared under this new perspective in various evaluation campaigns, the best known being the Recognizing Textual Entailment (RTE) initiative (Dagan et al., 2009). Most RTE systems are based on advanced NLP components, machine learning techniques, and/or syntactic transformations (Zanzotto et al., 2007; Kouleykov and Magnini, 2005). A few systems exploit deep FS analysis (Bos and Markert, 2006; Chambers et al., 2007). In particular, the FS results about QP properties that affect entailment have been exploited by Chambers et al, who complement a core broad-coverage system with a Natural Logic module to trade lower recall for higher precision. For instance, they exploit the monotonicity properties of no that cause the following reversal in entailment direction: some beetles |= some insects but no insects |= no beetles. To investigate entailment step by step, we address here a much simpler and</context>
</contexts>
<marker>Zanzotto, Pennacchiotti, Moschitti, 2007</marker>
<rawString>Fabio M. Zanzotto, Marco Pennacchiotti, and Alessandro Moschitti. 2007. Shallow semantics in fast textual entailment rule learners. In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maayan Zhitomirsky-Geffet</author>
<author>Ido Dagan</author>
</authors>
<title>Bootstrapping distributional feature vector quality.</title>
<date>2010</date>
<journal>Computational Linguistics,</journal>
<volume>35</volume>
<issue>3</issue>
<contexts>
<context position="2971" citStr="Zhitomirsky-Geffet and Dagan, 2010" startWordPosition="427" endWordPosition="430"> complementary strengths, we naturally ask if DS and FS can address each others limitations. Two recent strands of research are bringing DS closer to meeting core FS challenges. One strand attempts to model compositionality with DS methods, representing both primitive and composed linguistic expressions as distributional vectors (Baroni and Zamparelli, 2010; Grefenstette and Sadrzadeh, 2011; Guevara, 2010; Mitchell and Lapata, 2010). The other strand attempts to reformulate FSs notion of logical inference in terms that DS can capture (Erk, 2009; Geffet and Dagan, 2005; Kotlerman et al., 2010; Zhitomirsky-Geffet and Dagan, 2010). In keeping with the lexical emphasis of DS, this strand has focused on inference at the word level, or lexical entailment, that is, discovering from distributional vectors of hyponyms (dog) that they entail their hypernyms (animal). This paper brings these two strands of research together by demonstrating two ways in which the distributional vectors of composite expressions bear on inference. Here we focus on phrasal vectors harvested directly from the corpus rather than obtained compositionally. In a first experiment, we exploit the entailment properties of a class of composite expressions,</context>
</contexts>
<marker>Zhitomirsky-Geffet, Dagan, 2010</marker>
<rawString>Maayan Zhitomirsky-Geffet and Ido Dagan. 2010. Bootstrapping distributional feature vector quality. Computational Linguistics, 35(3):435461.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>