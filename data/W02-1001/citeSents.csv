 See (Collinsand Du\x0by 2001; Collins and Du\x0by 2002; CITATION) for other applications of the voted perceptronto NLP problems,,
 1 Introduction Maximum-entropy (ME) models are justi\x0cably a very popular choice for tagging problems in Natural Language Processing: for example see (Ratnaparkhi 96) for their use on part-of-speech tagging, and CITATION for their use on a FAQ segmentation task,,
 In maximum-entropy taggers (Ratnaparkhi 96; CITATION), the tagging problem is decomposed into sequence of decisions in tagging the problem in left-to-right fashion,,
 A real advantage of these models comes from the freedom in de\x0cning these features: for example, (Ratnaparkhi 96; CITATION) both describe feature sets which would be dicult to incorporate in a generative model,,
