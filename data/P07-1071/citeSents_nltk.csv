2 Shallow Semantic Parsing FrameNet CITATION and the Proposition Bank CITATION, or PropBank for short, are the two main systems currently developed for semantic role-labeling annotation.,,
The current version of the dataset gives semantic tags for the same sentences as in the Penn Treebank CITATION, which are excerpts from the Wall Street Journal.,,
This approach has already been used with great success in the domain of language models (CITATION; CITATION).,,
We could try to improve this representation by learning a language model from unlabeled data CITATION.,,
the ASSERT system CITATION.,,
This is rather slow, taking a few seconds per sentence at test time, partly because of the parse tree component, and partly because of the use of Support Vector Machines CITATION, which have linear complexity in testing time with respect to the number of training examples.,,
The authors of CITATION used a similar structure, but added more features, notably head word part-of-speech, the predicted named entity class of the argument, word sense disambiguation of the verb and verb clustering, and others (they add 25 variants of 12 new feature types overall.),,
Their system also uses a parser, as before, and then a polynomial Support Vector Machine (SVM) CITATION is used in two further stages: to classify each node in the tree as being a semantic argument or not for a given verb; and then to classify each semantic argument into one of the classes (ARG1, ARG2, etc.).,,
4.1.4 Learning class probabilities The last layer in our MLP is a classical linear layer as described in (1), with a softmax squashing function CITATION.,,
We trained on the training set of PropBank supplemented with the Brown corpus, resulting in a test accuracy on the test set of PropBank of 96.85% which compares to 96.66% using the Brill tagger CITATION.,,
We compared our system to the freely available ASSERT system CITATION.,,
In CITATION the authors presented a statistical approach to learning (for FrameNet), with some success.,,
They proposed to take advantage of the syntactic tree structure that can be predicted by a parser, such as Charniaks parser CITATION.,,
CITATION.,,
Many current solutions are complicated, consist of several stages and handbuilt features, and are too slow to be applied as part of real applications that require such semantic labels, partly because of their use of a syntactic parser (CITATION; CITATION).,,
In CITATION the authors presented a statistical approach to learning (for FrameNet), with some success.,,
They proposed to take advantage of the syntactic tree structure that can be predicted by a parser, such as Charniaks parser CITATION.,,
CITATION.,,
5.2 Argument Classification Accuracy So far we have not used the same accuracy measures as in previous work (CITATION; CITATION).,,
We measured the argument classification accuracy of our network, assuming the correct segmentation is given to our system, as in CITATION, by post-processing our per-word tags to form a majority vote over each segment.,,
For example, simply adding whether each word is part of a noun or verb phrase using the handannotated parse tree (the so-called GOV feature from CITATION) improves the performance of our system from 83.95% to 85.8%.,,
Previously, in CITATION, the authors tried to show that the parse tree is necessary for good generalization by showing that segments derived from a shallow syntactic parser or chunker do not perform as well for this goal.,,
A further analysis of using chunkers, with improved results was also given in CITATION, but still concluded the full parse tree is most useful.,,
For example, stateof-the-art syntactic parsers theoretically have cubic complexity in the sentence length CITATION1 and several semantic extraction algorithms use the parse tree as an initial feature.,,
We focus our experimental study on the semantic role labeling problem CITATION: being able to give a semantic role to a syn1 Even though some parsers effectively exhibit linear behavior in sentence length CITATION, fast statistical parsers such as CITATION still take around 1.5 seconds for sentences of length 35 in tests that we made.,,
the ASSERT system CITATION.,,
MLPs have been used for many years in the machine learning field and slowly abandoned for several reasons: partly because of the difficulty of solving the non-convex optimization problems associated with learning CITATION, and partly because of the difficulty of their theoretical analysis compared to alternative convex approaches.,,
2 Shallow Semantic Parsing FrameNet CITATION and the Proposition Bank CITATION, or PropBank for short, are the two main systems currently developed for semantic role-labeling annotation.,,
The current version of the dataset gives semantic tags for the same sentences as in the Penn Treebank CITATION, which are excerpts from the Wall Street Journal.,,
To achieve the goal of semantic understanding, the current consensus is to divide and conquer the [The company]ARG0 [bought]REL [sugar]ARG1 [on the world market]ARGM-LOC [to meet export commitments]ARGM-PNC Figure 1: Example of Semantic Role Labeling from the PropBank dataset CITATION.,,
2 Shallow Semantic Parsing FrameNet CITATION and the Proposition Bank CITATION, or PropBank for short, are the two main systems currently developed for semantic role-labeling annotation.,,
The current version of the dataset gives semantic tags for the same sentences as in the Penn Treebank CITATION, which are excerpts from the Wall Street Journal.,,
Many current solutions are complicated, consist of several stages and handbuilt features, and are too slow to be applied as part of real applications that require such semantic labels, partly because of their use of a syntactic parser (CITATION; CITATION).,,
parsers such as CITATION still take around 1.5 seconds for sentences of length 35 in tests that we made.,,
the ASSERT system CITATION.,,
This is rather slow, taking a few seconds per sentence at test time, partly because of the parse tree component, and partly because of the use of Support Vector Machines CITATION, which have linear complexity in testing time with respect to the number of training examples.,,
In CITATION the authors presented a statistical approach to learning (for FrameNet), with some success.,,
They proposed to take advantage of the syntactic tree structure that can be predicted by a parser, such as Charniaks parser CITATION.,,
CITATION.,,
The authors of CITATION used a similar structure, but added more features, notab,,
We trained on the training set of PropBank supplemented with the Brown corpus, resulting in a test accuracy on the test set of PropBank of 96.85% which compares to 96.66% using the Brill tagger CITATION.,,
We compared our system to the freely available ASSERT system CITATION.,,
Because ASSERT uses a parser, and because PropBank was built by labeling the nodes of a hand-annotated parse tree, pernode accuracy is usually reported in papers such as CITATION.,,
5.2 Argument Classification Accuracy So far we have not used the same accuracy measures as in previous work (CITATION; CITATION).,,
We measured the argument classification accuracy of our network, assuming the correct segmentation is given to our system, as in CITATION, by post-processing our per-word tags to form a majority vote over each segment.,,
Previously, in CITATION, the authors tried to show that the parse tree is necessary for good generalization by showing that segments derived from a shallow syntactic parser or chunker do not perform as well for this goal.,,
A further analysis of using chunkers, with improved results was also given in CITATION, but still concluded the full parse tree is most useful.,,
For example, stateof-the-art syntactic parsers theoretically have cubic complexity in the sentence length CITATION1 and several semantic extraction algorithms use the parse tree as an initial feature.,,
We focus our experimental study on the semantic role labeling problem CITATION: being able to give a semantic role to a syn1 Even though some parsers effectively exhibit linear behavior in sentence length CITATION, fast statistical parsers such as CITATION still take around 1.5 seconds for sentences of length 35 in tests that we made.,,
This approach has already been used with great success in the domain of language models (CITATION; CITATION).,,
For example, stateof-the-art syntactic parsers theoretically have cubic complexity in the sentence length CITATION1 and several semantic extraction algorithms use the parse tree as an initial feature.,,
We focus our experimental study on the semantic role labeling problem CITATION: being able to give a semantic role to a syn1 Even though some parsers effectively exhibit linear behavior in sentence length CITATION, fast statistical parsers such as CITATION still take around 1.5 seconds for sentences of length 35 in tests that we made.,,
