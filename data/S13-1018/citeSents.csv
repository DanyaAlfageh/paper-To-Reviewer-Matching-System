IDF based on Wikipedia, UKB CITATION and a more informed time similarity measure,,
2 UKB The semantic disambiguation UKB3 algorithm CITATION applies personalized PageRank on a graph generated from the English WordNet CITATION, or alternatively, from Wikipedia,,
 This algorithm has proven to be very competitive in word similarity tasks CITATION,,
2 UKB The semantic disambiguation UKB3 algorithm CITATION applies personalized PageRank on a graph generated from the English WordNet CITATION, or alternatively, from Wikipedia,,
 This algorithm has proven to be very competitive in word similarity tasks CITATION,,
 The similarity between a pair of items is estimated by comparing their topic distributions following the method proposed in CITATION; CITATION,,
 The similarity between a pair of items is estimated by comparing their topic distributions following the method proposed in CITATION; CITATION,,
 This approach can be improved giving more weight to words which occur in only a few documents, and less weight to words occurring in many documents CITATION,,
 In this section, we take those indicators as features, and use linear regression (as made available by Weka CITATION) to learn models that fit the features to the training data,,
 We generated further similarity scores for general similarity, including Latent Dirichlet Allocation (LDA) CITATION, UKB and Wikipedia Link Vector Model (WLVM)CITATION using information taken from all fields, as explained below,,
1 LDA LDA CITATION is a statistical method that learns a set of latent variables called topics from a training corpus,,
2 UKB The semantic disambiguation UKB3 algorithm CITATION applies personalized PageRank on a graph generated from the English WordNet CITATION, or alternatively, from Wikipedia,,
 This algorithm has proven to be very competitive in word similarity tasks CITATION,,
 We analysed the text in the metadata, performing lemmatization, PoS tagging, named entity recognition and classification (NERC) and date detection using Stanford CoreNLP (CITATION; CITATION),,
 In this section, we take those indicators as features, and use linear regression (as made available by Weka CITATION) to learn models that fit the features to the training data,,
 We generated further similarity scores for general similarity, including Latent Dirichlet Allocation (LDA) CITATION, UKB and Wikipedia Link Vector Model (WLVM)CITATION using information taken from all fields, as explained below,,
1 LDA LDA CITATION is a statistical method that learns a set of latent variables called topics from a training corpus,,
3 WLVM An algorithm described by CITATION associates Wikipedia articles which are likely to be relevant to a given text snippet using machine learning techniques,,
 Then, similarity between Wikipedia articles is measured using the Wikipedia Link Vector Model (WLVM) CITATION,,
 In this section, we take those indicators as features, and use linear regression (as made available by Weka CITATION) to learn models that fit the features to the training data,,
 We generated further similarity scores for general similarity, including Latent Dirichlet Allocation (LDA) CITATION, UKB and Wikipedia Link Vector Model (WLVM)CITATION using information taken from all fields, as explained below,,
1 LDA LDA CITATION is a statistical method that learns a set of latent variables called topics from a training corpus,,
3 WLVM An algorithm described by CITATION associates Wikipedia articles which are likely to be relevant to a given text snippet using machine learning techniques,,
 Then, similarity between Wikipedia articles is measured using the Wikipedia Link Vector Model (WLVM) CITATION,,
 We analysed the text in the metadata, performing lemmatization, PoS tagging, named entity recognition and classification (NERC) and date detection using Stanford CoreNLP (CITATION; CITATION),,
