3.1 Linear regression via DKPro Similarity For our baseline (MayoClinicNLPr1wtCDT), we used the UIMA-based DKPro Similarity system from STS 2012 CITATION,,
re 3 t other/RelativeInfoContentDifference n-grams/CharacterNGramMeasure 4 t other/NumbersSize string/GreedyStringTiling 3 t other/NumbersOverlap string/LongestCommonSubsequenceComparator t other/NumbersSubset string/LongestCommonSubsequenceNormComparator t other/SentenceSize string/LongestCommonSubstringComparator t other/CaseMatches t other/StocksSize t other/StocksOverlap matches S2, and how closely S2 matches S1: simneo(S1,S2) = 2 NE1 NE2 NE1 + NE2 (1) Additionally, we relax the constraint of requiring exact string matches between the two sentences by using the longest common subsequence CITATION and greedy string tiling CITATION algorithms,,
e parser described in CITATION with 1,000 headwords and 10 relational clusters, trained on the Wall Street Journal treebank,,
Aside from the large number of sound similarity measures, this provided linear regression through the WEKA package CITATION to combine all of the disparate similarity metrics into a single one, and some preprocessing,,
1 Introduction The Semantic Textual Similarity (STS) task (CITATION; CITATION) examines semantic similarity at a sentence-level,,
cs for STS as: simRI(S1,S2) = cos(vS1,vS2) (3) We used the semantic vectors package (CITATION; CITATION) in the default configuration for the standard model,,
Similar to LSA CITATION, an index is created that represents each term as a semantic vector,,
Thus we consider three different representations possible within Random Indexing (CITATION; CITATION),,
Also, we used UKPs existing implementation of LCS and GST CITATION for the latter two measures,,
Further detail is in our previous work (CITATION; CITATION),,
Thus, we follow previous work in greedily aligning these named entities (CITATION; CITATION) into pairs,,
2.3 Semantic vectorial semantics measures Structured vectorial semantics (SVS) composes distributional semantic representations in syntactic context CITATION,,
In our experiments, we performed named entity recognition with the Stanford NER tool using the standard English model CITATION,,
gestCommonSubstringComparator t other/CaseMatches t other/StocksSize t other/StocksOverlap matches S2, and how closely S2 matches S1: simneo(S1,S2) = 2 NE1 NE2 NE1 + NE2 (1) Additionally, we relax the constraint of requiring exact string matches between the two sentences by using the longest common subsequence CITATION and greedy string tiling CITATION algorithms,,
We define 4 separate similarity metrics for STS as: simRI(S1,S2) = cos(vS1,vS2) (3) We used the semantic vectors package (CITATION; CITATION) in the default configuration for the standard model,,
s/CharacterNGramMeasure 4 t other/NumbersSize string/GreedyStringTiling 3 t other/NumbersOverlap string/LongestCommonSubsequenceComparator t other/NumbersSubset string/LongestCommonSubsequenceNormComparator t other/SentenceSize string/LongestCommonSubstringComparator t other/CaseMatches t other/StocksSize t other/StocksOverlap matches S2, and how closely S2 matches S1: simneo(S1,S2) = 2 NE1 NE2 NE1 + NE2 (1) Additionally, we relax the constraint of requiring exact string matches between the two sentences by using the longest common subsequence CITATION and greedy string tiling CITATION algorithms,,
In our experiments, we used the parser described in CITATION with 1,000 headwords and 10 relational clusters, trained on the Wall Street Journal treebank,,
her/SentenceSize string/LongestCommonSubstringComparator t other/CaseMatches t other/StocksSize t other/StocksOverlap matches S2, and how closely S2 matches S1: simneo(S1,S2) = 2 NE1 NE2 NE1 + NE2 (1) Additionally, we relax the constraint of requiring exact string matches between the two sentences by using the longest common subsequence CITATION and greedy string tiling CITATION algorithms,,
The intuition for this means of dimensionality reduction is that these randomly-generated elemental vectors are like quasi-orthogonal bases in a traditional geometric semantic space, rather than, e.g., 300 fully orthogonal dimensions from singular value decomposition CITATION,,
The proposed MayoClinicNLP metrics are meant to complement DKPro CITATION and TakeLab CITATION metrics,,
Finally, because compositional distributional semantics is an important research topic (CITATION; CITATION), we sought to evaluate a principled composition strategy: structured vectorial semantics CITATION,,
2.2 Random indexing measures Random indexing (CITATION; CITATION) is another distributional semantics framework for representing terms as vectors,,
