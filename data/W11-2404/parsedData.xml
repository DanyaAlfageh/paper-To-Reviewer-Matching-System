<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000022">
<bodyText confidence="0.443097">
b&amp;apos;Proceedings of the TextInfer 2011 Workshop on Textual Entailment, EMNLP 2011, pages 3034,
Edinburgh, Scotland, UK, July 30, 2011. c
</bodyText>
<figure confidence="0.583849071428571">
2011 Association for Computational Linguistics
Is it Worth Submitting this Run?
Assess your RTE System with a Good Sparring Partner
Milen Kouylekov
CELI s.r.l.
Turin, Italy
kouylekov@celi.it
Yashar Mehdad
FBK-irst and University of Trento
Trento, Italy
mehdad@fbk.eu
Matteo Negri
FBK-irst
Trento, Italy
</figure>
<email confidence="0.916497">
negri@fbk.eu
</email>
<sectionHeader confidence="0.981537" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99979755">
We address two issues related to the devel-
opment of systems for Recognizing Textual
Entailment. The first is the impossibility to
capitalize on lessons learned over the different
datasets available, due to the changing nature
of traditional RTE evaluation settings. The
second is the lack of simple ways to assess
the results achieved by our system on a given
training corpus, and figure out its real potential
on unseen test data. Our contribution is the ex-
tension of an open-source RTE package with
an automatic way to explore the large search
space of possible configurations, in order to
select the most promising one over a given
dataset. From the developers point of view,
the efficiency and ease of use of the system,
together with the good results achieved on all
previous RTE datasets, represent a useful sup-
port, providing an immediate term of compar-
ison to position the results of their approach.
</bodyText>
<sectionHeader confidence="0.998187" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998700956521739">
Research on textual entailment (TE) has received a
strong boost by the Recognizing Textual Entailment
(RTE) Challenges, organized yearly to gather the
community around a shared evaluation framework.
Within such framework, besides the intrinsic diffi-
culties of the task (i.e. deciding, given a set of Text-
Hypothesis pairs, if the hypotheses can be inferred
from the meaning of the texts), the development of
RTE systems has to confront with a number of ad-
ditional problems and uncertainty factors. First of
all, since RTE systems are usually based on com-
plex architectures that integrate a variety of tools and
resources, it is per se very difficult to tune them and
define the optimal configuration given a new dataset.
In general, when participating to the evaluation chal-
lenges theres no warranty that the submitted runs
are those obtained with the best possible configura-
tion allowed by the system. Second, the evaluation
settings change along the years. Variations in the
length of the texts, the origin of the pairs, the bal-
ance between positive and negative examples, and
the type of entailment decisions allowed, reflect the
need to move from easier and more artificial settings
to more complex and natural ones. However, in con-
trast with other more stable tasks in terms of eval-
uation settings and metrics (e.g. machine transla-
tion), such changes make it difficult to capitalize on
the experience obtained by participants throughout
the years. Third, looking at RTE-related literature
and the outcomes of the six campaigns organised so
far, the conclusions that can be drawn are often con-
troversial. For instance, it is not clear whether the
availability of larger amounts of training data corre-
lates with better performance (Hickl et al., 2006) or
not (Zanzotto et al., 2007; Hickl and Bensley, 2007),
even within the same evaluation setting. In addi-
tion, ablation tests carried out in recent editions of
the challenge do not allow for definite conclusions
about the actual usefulness of tools and resources,
even the most popular ones (Bentivogli et al., 2009).
Finally, the best performing systems often have dif-
ferent natures from one year to another, showing al-
ternations of deep (Hickl and Bensley, 2007; Tatu
and Moldovan, 2007) and shallow approaches (Jia
et al., 2010) ranked at the top positions. In light
of these considerations, it would be useful for sys-
</bodyText>
<page confidence="0.996317">
30
</page>
<bodyText confidence="0.997089428571429">
\x0ctems developers to have: i) automatic ways to sup-
port systems tuning at a training stage, and ii) reli-
able terms of comparison to validate their hypothe-
ses, and position the results of their work before sub-
mitting runs for evaluation. In this paper we address
these needs by extending an open-source RTE pack-
age (EDITS1) with a mechanism that automatizes
the selection of the most promising configuration
over a training dataset. We prove the effectiveness
of such extension showing that it allows not only to
achieve good performance on all the available RTE
Challenge datasets, but also to improve the official
results, achieved with the same system, through ad
hoc configurations manually defined by the devel-
opers team. Our contribution is twofold. On one
side, in the spirit of the collaborative nature of open
source projects, we extend an existing tool with a
useful functionality that was still missing. On the
other side, we provide a good sparring partner for
system developers, to be used as a fast and free term
of comparison to position the results of their work.
</bodyText>
<sectionHeader confidence="0.515418" genericHeader="method">
2 Coping with configurability
EDITS (Kouylekov and Negri, 2010) is an open
</sectionHeader>
<bodyText confidence="0.989776954545455">
source RTE package, which offers a modular, flex-
ible, and adaptable working environment to experi-
ment with the RTE task over different datasets. The
package allows to: i) create an entailment engine
by defining its basic components (i.e. algorithms,
cost schemes, rules, and optimizers); ii) train such
entailment engine over an annotated RTE corpus to
learn a model; and iii) use the entailment engine and
the model to assign an entailment judgement and a
confidence score to each pair of an un-annotated test
corpus. A key feature of EDITS is represented by its
high configurability, allowed by the availability of
different algorithms, the possibility to integrate dif-
ferent sets of lexical entailment/contradiction rules,
and the variety of parameters for performance opti-
mization (see also Mehdad, 2009). Although config-
urability is per se an important aspect (especially for
an open-source and general purpose system), there
is another side of the coin. In principle, in order to
select the most promising configuration over a given
development set, one should exhaustively run a huge
number of training/evaluation routines. Such num-
</bodyText>
<equation confidence="0.656699">
1
http://edits.fbk.eu/
</equation>
<bodyText confidence="0.99903416">
ber corresponds to the total number of configura-
tions allowed by the system, which result from the
possible combinations of parameter settings. When
dealing with enlarging dataset sizes, and the tight
time constraints usually posed by the evaluation
campaigns, this problem becomes particularly chal-
lenging, as developers are hardly able to run exhaus-
tive training/evaluation routines. As recently shown
by the EDITS developers team, such situation re-
sults in running a limited number of experiments
with the most reasonable configurations, which
consequently might not lead to the optimal solution
(Kouylekov et al., 2010).
The need of a mechanism to automatically ob-
tain the most promising solution on one side, and
the constraints posed by the evaluation campaigns
on the other side, arise the necessity to optimize
this procedure. Along this direction, the objective
is good a trade-off between exhaustive experimen-
tation with all possible configurations (unfeasible),
and educated guessing (unreliable). The remainder
of this section tackles this issue introducing an op-
timization strategy based on genetic algorithms, and
describing its adaptation to extend EDITS with the
new functionality.
</bodyText>
<subsectionHeader confidence="0.945653">
2.1 Genetic algorithm
</subsectionHeader>
<bodyText confidence="0.997684333333333">
Genetic algorithms (GA) are well suited to effi-
ciently deal with large search spaces, and have been
recently applied with success to a variety of opti-
mization problems and specific NLP tasks (Figueroa
and Neumann, 2008; Otto and Riff, 2004; Aycinena
et al., 2003). GA are a direct stochastic method for
global search and optimization, which mimics natu-
ral evolution. To this aim, they work with a popu-
lation of individuals, representing possible solutions
to the given task. Traditionally, solutions are rep-
resented in binary as strings of 0s and 1s, but other
encodings (e.g. sequences of real values) are possi-
ble. The evolution usually starts from a population
of randomly generated individuals, and at each gen-
eration selects the best-suited individuals based on
a fitness function (which measures the optimality of
the solution obtained by the individual). Such selec-
tion is then followed by modifications of the selected
individuals obtained by recombining (crossover) and
performing random changes (mutation) to form a
new population, which will be used in the next iter-
</bodyText>
<page confidence="0.999015">
31
</page>
<bodyText confidence="0.98514">
\x0cation. Finally, the algorithm is terminated when the
maximum number of generations, or a satisfactory
fitness level has been reached for the population.
</bodyText>
<subsectionHeader confidence="0.993056">
2.2 EDITS-GA
</subsectionHeader>
<bodyText confidence="0.991673647058824">
Our extension to the EDITS package, EDITS-GA,
consists in an iterative process that starts with an
initial population of randomly generated configura-
tions. After a training phase with the generated con-
figurations, the process is evaluated by means of the
fitness function, which is manually defined by the
user2. This measure is used by the genetic algo-
rithm to iteratively build new populations of config-
urations, which are trained and evaluated. This pro-
cess can be seen as the combination of: i) a micro
training/evaluation routine for each generated con-
figuration of the entailment engine; and ii) a macro
evolutionary cycle, as illustrated in Figure 1. The
fitness function is an important factor for the evalu-
ation and the evolution of the generated configura-
tions, as it drives the evolutionary process by deter-
mining the best-suited individuals used to generate
</bodyText>
<listItem confidence="0.950882">
new populations. The procedure to estimate and op-
timize the best configuration applying the GA, can
be summarized as follows.
(1) Initialization: generate a random initial popula-
tion (i.e. a set of configurations).
(2) Selection:
2a. The fitness function (accuracy, or F-measure)
is evaluated for each individual in the population.
2b. The individuals are selected according to their
fitness function value.
(3) Reproduction: generate a new population of
configurations from the selected one, through ge-
netic operators (cross-over and mutation).
(4) Iteration: repeat the Selection and Reproduction
until Termination.
(5) Termination: end if the maximum number of
</listItem>
<bodyText confidence="0.989622833333333">
iterations has been reached, or the population has
converged towards a particular solution.
In order to extend EDITS with genetic algo-
rithms, we used a GA implementation available in
the JGAP tool3. In our settings, each individual con-
tains a sequence of boolean parameters correspond-
</bodyText>
<page confidence="0.950534">
2
</page>
<bodyText confidence="0.820040333333333">
For instance, working on the RTE Challenge Main task
data, the fitness function would be the accuracy for RTE1 to
RTE5, and the F-measure for RTE6.
</bodyText>
<page confidence="0.837622">
3
</page>
<figureCaption confidence="0.8057015">
http://jgap.sourceforge.net/
Figure 1: EDITS-GA framework.
</figureCaption>
<bodyText confidence="0.859025">
ing to the activation/de-activation of the systems
basic components (algorithms, cost schemes, rules,
and optimizers). The configurations corresponding
to such individuals constitute the populations itera-
tively evaluated by EDITS-GA on a given dataset.
</bodyText>
<sectionHeader confidence="0.999315" genericHeader="evaluation">
3 Experiments
</sectionHeader>
<bodyText confidence="0.999477375">
Our experiments were carried out over the datasets
used in the six editions of the RTE Challenge
(Main task data from RTE1 to RTE6). For each
dataset we obtained the best model by training
EDITS-GA over the development set, and evaluat-
ing the resulting model on the test pairs. To this
aim, the optimization process is iterated over all
the available algorithms in order to select the best
combination of parameters. As termination crite-
rion, we set to 20 the maximum number of itera-
tions. To increase efficiency, we extended EDITS
to pre-process each dataset using the tokenizer and
stemmer available in Lucene4. This pre-processing
phase is automatically activated when the EDITS-
GA has to process non-annotated datasets. How-
ever, we also annotated the RTE corpora with the
Stanford parser plugin (downloadable from the ED-
ITS websitein order to run the syntax-based algo-
rithms available (e.g. tree edit distance). The num-
ber of boolean parameters used to generate the con-
figurations is 18. In light of this figure, it becomes
evident that the number of possible configurations
is too large (218=262,144) for an exhaustive train-
ing/evaluation routine over each dataset5. However,
</bodyText>
<page confidence="0.877322">
4
</page>
<footnote confidence="0.399111">
http://lucene.apache.org/
</footnote>
<page confidence="0.963813">
5
</page>
<bodyText confidence="0.996743">
In an exploratory experiment we measured in around 4
days the time required to train EDITS, with all possible con-
</bodyText>
<page confidence="0.998237">
32
</page>
<table confidence="0.997936285714286">
\x0c# Systems Best Lowest Average EDITS (rank) EDITS-GA (rank) % Impr. Comp. Time
RTE1 15 0.586 0.495 0.544 0.559 (8) 0.5787 (3) +3.52% 8m 24s
RTE2 23 0.7538 0.5288 0.5977 0.605 (6) 0.6225 (5) +2.89% 9m 8s
RTE3 26 0.8 0.4963 0.6237 - 0.6875 (4) - 9m
RTE4 26 0.746 0.516 0.5935 0.57 (17) 0.595 (10) +4.38% 30m 54s
RTE5 20 0.735 0.5 0.6141 0.6017 (14) 0.6233 (9) +3.58% 8m 23s
RTE6 18 0.4801 0.116 0.323 0.4471 (4) 0.4673 (3) +4.51% 1h 54m 20s
</table>
<tableCaption confidence="0.999368">
Table 1: RTE results (acc. for RTE1-RTE5, F-meas. for RTE6). For each participant, only the best run is considered.
</tableCaption>
<bodyText confidence="0.996375057142857">
with an average of 5 reproductions on each iteration,
EDITS-GA makes an average of 100 configurations
for each algorithm. Thanks to EDITS-GA, the aver-
age number of evaluated configurations for a single
dataset is reduced to around 4006.
Our results are summarized in Table 1, showing
the total number of participating systems in each
RTE Challenge, together with the highest, lowest,
and average scores they achieved. Moreover, the of-
ficial results obtained by EDITS are compared with
the performance achieved with EDITS-GA on the
same data. We can observe that, for all datasets,
the results achieved by EDITS-GA significantly im-
prove (up to 4.51%) the official EDITS results. Its
also worth mentioning that such scores are always
higher than the average ones obtained by partici-
pants. This confirms that EDITS-GA can be poten-
tially used by RTE systems developers as a strong
term of comparison to assess the capabilities of
their own system. Since time is a crucial factor for
RTE systems, it is important to remark that EDITS-
GA allows to converge on a promising configura-
tion quite efficiently. As can be seen in Table 1,
the whole process takes around 9 minutes7 for the
smaller datasets (RTE1 to RTE5), and less than 2
hours for a very large dataset (RTE6). Such time
analysis further proves the effectiveness of the ex-
tended EDITS-GA framework. For the sake of com-
pleteness we gave a look at the differences between
the educated guessing done by the EDITS de-
velopers for the official RTE submissions, and the
optimal configuration automatically selected by
EDITS-GA. Surprisingly, in some cases, even a mi-
nor difference in the selected parameters leads to
figurations, over small datasets (RTE1 to RTE5).
</bodyText>
<page confidence="0.969257">
6
</page>
<bodyText confidence="0.98373">
With these settings, training EDITS-GA over small datasets
(RTE1 to RTE5) takes about 9 minutes each.
</bodyText>
<page confidence="0.980674">
7
</page>
<bodyText confidence="0.999345866666667">
All time figures are calculated on an Intel(R) Xeon(R),
CPU X3440 @ 2.53GHz, 8 cores with 8 GB RAM.
significant gaps in the results. For instance, in RTE6
dataset, the guessed configuration (Kouylekov et
al., 2010) was based on the lexical overlap algo-
rithm, setting the cost of replacing H terms with-
out an equivalent in T to the minimal Levenshtein
distance between such words and any word in T.
EDITS-GA estimated, as a more promising solution,
a combination of lexical overlap with a different cost
scheme (based on the IDF of the terms in T). In ad-
dition, in contrast with the guessed configuration,
stop-words filtering was selected as an option, even-
tually leading to a 4.51% improvement over the of-
ficial RTE6 result.
</bodyText>
<sectionHeader confidence="0.998865" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999812875">
Is it worth submitting this run?,How good is my
system?. These are the typical concerns of system
developers approaching the submission deadline of
an RTE evaluation campaign. We addressed these is-
sues by extending an open-source RTE system with
a functionality that allows to select the most promis-
ing configuration over an annotated training set. Our
contribution provides developers with a good spar-
ring partner (a free and immediate term of compar-
ison) to position the results of their approach. Ex-
perimental results prove the effectiveness of the pro-
posed extension, showing that it allows to: i) achieve
good performance on all the available RTE datasets,
and ii) improve the official results, achieved with the
same system, through ad hoc configurations manu-
ally defined by the developers team.
</bodyText>
<sectionHeader confidence="0.958082" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.792738333333333">
This work has been partially supported by the EC-
funded projects CoSyne (FP7-ICT-4-24853), and
Galateas (CIP-ICT PSP-2009-3-250430).
</bodyText>
<page confidence="0.96674">
33
</page>
<reference confidence="0.99342679245283">
\x0cReferences
Margaret Aycinena, Mykel J. Kochenderfer, and David
Carl Mulford. 2003. An Evolutionary Approach to
Natural Language Grammar Induction. Stanford CS
224N Natural Language Processing.
Luisa Bentivogli, Ido Dagan, Hoa Trang Dang, Danilo
Giampiccolo, Bernardo Magnini. 2009. The Fifth
PASCAL Recognizing Textual Entailment Challenge.
Proceedings of the TAC 2009 Workshop.
Ido Dagan and Oren Glickman. 2004. Probabilistic tex-
tual entailment: Generic applied modeling of language
variability. Proceedings of the PASCAL Workshop of
Learning Methods for Text Understanding and Min-
ing.
Alejandro G. Figueroa and Gunter Neumann. 2008. Ge-
netic Algorithms for Data-driven Web Question An-
swering. Evolutionary Computation 16(1) (2008) pp.
89-125.
Andrew Hickl, John Williams, Jeremy Bensley, Kirk
Roberts, Bryan Rink, and Ying Shi. 2006. Recog-
nizing Textual Entailment with LCCs Groundhog Sys-
tem. Proceedings of the Second PASCAL Challenges
Workshop.
Andrew Hickl and Jeremy Bensley. 2007. A discourse
commitment-based framework for recognizing textual
entailment. Proceedings of the ACL-PASCAL Work-
shop on Textual Entailment and Paraphrasing.
Houping Jia, Xiaojiang Huang, Tengfei Ma, Xiaojun
Wan, and Jianguo Xiao. 2010. PKUTM Participation
at TAC 2010 RTE and Summarization Track. Proceed-
ings of the Sixth Recognizing Textual Entailment Chal-
lenge.
Milen Kouylekov and Matteo Negri. 2010. An Open-
source Package for Recognizing Textual Entailment.
Proceedings of ACL 2010 Demo session.
Milen Kouylekov, Yashar Mehdad, Matteo Negri, and
Elena Cabrio. 2010. FBK Participation in RTE6:
Main and KBP Validation Task. Proceedings of the
Sixth Recognizing Textual Entailment Challenge.
Yashar Mehdad 2009. Automatic Cost Estimation for
Tree Edit Distance Using Particle Swarm Optimiza-
tion. Proceedings of ACL-IJCNLP 2009.
Eridan Otto and Mara Cristina Riff 2004. Towards an
efficient evolutionary decoding algorithm for statisti-
cal machine translation. LNAI, 2972:438447..
Marta Tatu and Dan Moldovan. 2007. COGEX at RTE3.
Proceedings of the ACL-PASCAL Workshop on Textual
Entailment and Paraphrasing.
Fabio Massimo Zanzotto, Marco Pennacchiotti and
Alessandro Moschitti. 2007. Shallow Semantics in
Fast Textual Entailment Rule Learners. Proceedings
of the Third Recognizing Textual Entailment Chal-
lenge.
</reference>
<page confidence="0.964327">
34
</page>
<figure confidence="0.265815">
\x0c&amp;apos;
</figure>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.131625">
<note confidence="0.8961815">b&amp;apos;Proceedings of the TextInfer 2011 Workshop on Textual Entailment, EMNLP 2011, pages 3034, Edinburgh, Scotland, UK, July 30, 2011. c 2011 Association for Computational Linguistics Is it Worth Submitting this Run?</note>
<title confidence="0.792043">Assess your RTE System with a Good Sparring Partner</title>
<author confidence="0.974029">Milen Kouylekov</author>
<affiliation confidence="0.824924">CELI s.r.l.</affiliation>
<address confidence="0.951498">Turin, Italy</address>
<email confidence="0.998159">kouylekov@celi.it</email>
<author confidence="0.890984">Yashar Mehdad</author>
<affiliation confidence="0.964801">FBK-irst and University of Trento</affiliation>
<address confidence="0.902846">Trento, Italy</address>
<email confidence="0.995546">mehdad@fbk.eu</email>
<author confidence="0.999928">Matteo Negri</author>
<email confidence="0.77388">FBK-irst</email>
<address confidence="0.821746">Trento, Italy</address>
<email confidence="0.994618">negri@fbk.eu</email>
<abstract confidence="0.992068238095238">We address two issues related to the development of systems for Recognizing Textual Entailment. The first is the impossibility to capitalize on lessons learned over the different datasets available, due to the changing nature of traditional RTE evaluation settings. The second is the lack of simple ways to assess the results achieved by our system on a given training corpus, and figure out its real potential on unseen test data. Our contribution is the extension of an open-source RTE package with an automatic way to explore the large search space of possible configurations, in order to select the most promising one over a given dataset. From the developers point of view, the efficiency and ease of use of the system, together with the good results achieved on all previous RTE datasets, represent a useful support, providing an immediate term of comparison to position the results of their approach.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>\x0cReferences Margaret Aycinena</author>
<author>Mykel J Kochenderfer</author>
<author>David Carl Mulford</author>
</authors>
<title>An Evolutionary Approach to Natural Language Grammar Induction.</title>
<date>2003</date>
<booktitle>Stanford CS 224N Natural Language Processing.</booktitle>
<contexts>
<context position="7561" citStr="Aycinena et al., 2003" startWordPosition="1199" endWordPosition="1202">objective is good a trade-off between exhaustive experimentation with all possible configurations (unfeasible), and educated guessing (unreliable). The remainder of this section tackles this issue introducing an optimization strategy based on genetic algorithms, and describing its adaptation to extend EDITS with the new functionality. 2.1 Genetic algorithm Genetic algorithms (GA) are well suited to efficiently deal with large search spaces, and have been recently applied with success to a variety of optimization problems and specific NLP tasks (Figueroa and Neumann, 2008; Otto and Riff, 2004; Aycinena et al., 2003). GA are a direct stochastic method for global search and optimization, which mimics natural evolution. To this aim, they work with a population of individuals, representing possible solutions to the given task. Traditionally, solutions are represented in binary as strings of 0s and 1s, but other encodings (e.g. sequences of real values) are possible. The evolution usually starts from a population of randomly generated individuals, and at each generation selects the best-suited individuals based on a fitness function (which measures the optimality of the solution obtained by the individual). S</context>
</contexts>
<marker>Aycinena, Kochenderfer, Mulford, 2003</marker>
<rawString>\x0cReferences Margaret Aycinena, Mykel J. Kochenderfer, and David Carl Mulford. 2003. An Evolutionary Approach to Natural Language Grammar Induction. Stanford CS 224N Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luisa Bentivogli</author>
</authors>
<title>Ido Dagan, Hoa Trang Dang, Danilo Giampiccolo, Bernardo Magnini.</title>
<date>2009</date>
<marker>Bentivogli, 2009</marker>
<rawString>Luisa Bentivogli, Ido Dagan, Hoa Trang Dang, Danilo Giampiccolo, Bernardo Magnini. 2009. The Fifth PASCAL Recognizing Textual Entailment Challenge.</rawString>
</citation>
<citation valid="false">
<booktitle>Proceedings of the TAC 2009 Workshop.</booktitle>
<marker></marker>
<rawString>Proceedings of the TAC 2009 Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Oren Glickman</author>
</authors>
<title>Probabilistic textual entailment: Generic applied modeling of language variability.</title>
<date>2004</date>
<booktitle>Proceedings of the PASCAL Workshop of Learning Methods for Text Understanding and Mining.</booktitle>
<marker>Dagan, Glickman, 2004</marker>
<rawString>Ido Dagan and Oren Glickman. 2004. Probabilistic textual entailment: Generic applied modeling of language variability. Proceedings of the PASCAL Workshop of Learning Methods for Text Understanding and Mining.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alejandro G Figueroa</author>
<author>Gunter Neumann</author>
</authors>
<title>Genetic Algorithms for Data-driven Web Question Answering.</title>
<date>2008</date>
<journal>Evolutionary Computation</journal>
<volume>16</volume>
<issue>1</issue>
<pages>89--125</pages>
<contexts>
<context position="7516" citStr="Figueroa and Neumann, 2008" startWordPosition="1191" endWordPosition="1194">timize this procedure. Along this direction, the objective is good a trade-off between exhaustive experimentation with all possible configurations (unfeasible), and educated guessing (unreliable). The remainder of this section tackles this issue introducing an optimization strategy based on genetic algorithms, and describing its adaptation to extend EDITS with the new functionality. 2.1 Genetic algorithm Genetic algorithms (GA) are well suited to efficiently deal with large search spaces, and have been recently applied with success to a variety of optimization problems and specific NLP tasks (Figueroa and Neumann, 2008; Otto and Riff, 2004; Aycinena et al., 2003). GA are a direct stochastic method for global search and optimization, which mimics natural evolution. To this aim, they work with a population of individuals, representing possible solutions to the given task. Traditionally, solutions are represented in binary as strings of 0s and 1s, but other encodings (e.g. sequences of real values) are possible. The evolution usually starts from a population of randomly generated individuals, and at each generation selects the best-suited individuals based on a fitness function (which measures the optimality o</context>
</contexts>
<marker>Figueroa, Neumann, 2008</marker>
<rawString>Alejandro G. Figueroa and Gunter Neumann. 2008. Genetic Algorithms for Data-driven Web Question Answering. Evolutionary Computation 16(1) (2008) pp. 89-125.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Hickl</author>
<author>John Williams</author>
<author>Jeremy Bensley</author>
<author>Kirk Roberts</author>
<author>Bryan Rink</author>
<author>Ying Shi</author>
</authors>
<title>Recognizing Textual Entailment with LCCs Groundhog System.</title>
<date>2006</date>
<booktitle>Proceedings of the Second PASCAL Challenges Workshop.</booktitle>
<contexts>
<context position="3135" citStr="Hickl et al., 2006" startWordPosition="498" endWordPosition="501">ed to move from easier and more artificial settings to more complex and natural ones. However, in contrast with other more stable tasks in terms of evaluation settings and metrics (e.g. machine translation), such changes make it difficult to capitalize on the experience obtained by participants throughout the years. Third, looking at RTE-related literature and the outcomes of the six campaigns organised so far, the conclusions that can be drawn are often controversial. For instance, it is not clear whether the availability of larger amounts of training data correlates with better performance (Hickl et al., 2006) or not (Zanzotto et al., 2007; Hickl and Bensley, 2007), even within the same evaluation setting. In addition, ablation tests carried out in recent editions of the challenge do not allow for definite conclusions about the actual usefulness of tools and resources, even the most popular ones (Bentivogli et al., 2009). Finally, the best performing systems often have different natures from one year to another, showing alternations of deep (Hickl and Bensley, 2007; Tatu and Moldovan, 2007) and shallow approaches (Jia et al., 2010) ranked at the top positions. In light of these considerations, it w</context>
</contexts>
<marker>Hickl, Williams, Bensley, Roberts, Rink, Shi, 2006</marker>
<rawString>Andrew Hickl, John Williams, Jeremy Bensley, Kirk Roberts, Bryan Rink, and Ying Shi. 2006. Recognizing Textual Entailment with LCCs Groundhog System. Proceedings of the Second PASCAL Challenges Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Hickl</author>
<author>Jeremy Bensley</author>
</authors>
<title>A discourse commitment-based framework for recognizing textual entailment.</title>
<date>2007</date>
<booktitle>Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing.</booktitle>
<contexts>
<context position="3191" citStr="Hickl and Bensley, 2007" startWordPosition="508" endWordPosition="511"> to more complex and natural ones. However, in contrast with other more stable tasks in terms of evaluation settings and metrics (e.g. machine translation), such changes make it difficult to capitalize on the experience obtained by participants throughout the years. Third, looking at RTE-related literature and the outcomes of the six campaigns organised so far, the conclusions that can be drawn are often controversial. For instance, it is not clear whether the availability of larger amounts of training data correlates with better performance (Hickl et al., 2006) or not (Zanzotto et al., 2007; Hickl and Bensley, 2007), even within the same evaluation setting. In addition, ablation tests carried out in recent editions of the challenge do not allow for definite conclusions about the actual usefulness of tools and resources, even the most popular ones (Bentivogli et al., 2009). Finally, the best performing systems often have different natures from one year to another, showing alternations of deep (Hickl and Bensley, 2007; Tatu and Moldovan, 2007) and shallow approaches (Jia et al., 2010) ranked at the top positions. In light of these considerations, it would be useful for sys30 \x0ctems developers to have: i)</context>
</contexts>
<marker>Hickl, Bensley, 2007</marker>
<rawString>Andrew Hickl and Jeremy Bensley. 2007. A discourse commitment-based framework for recognizing textual entailment. Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Houping Jia</author>
<author>Xiaojiang Huang</author>
<author>Tengfei Ma</author>
<author>Xiaojun Wan</author>
<author>Jianguo Xiao</author>
</authors>
<date>2010</date>
<booktitle>PKUTM Participation at TAC 2010 RTE and Summarization Track. Proceedings of the Sixth Recognizing Textual Entailment Challenge.</booktitle>
<contexts>
<context position="3667" citStr="Jia et al., 2010" startWordPosition="585" endWordPosition="588">rger amounts of training data correlates with better performance (Hickl et al., 2006) or not (Zanzotto et al., 2007; Hickl and Bensley, 2007), even within the same evaluation setting. In addition, ablation tests carried out in recent editions of the challenge do not allow for definite conclusions about the actual usefulness of tools and resources, even the most popular ones (Bentivogli et al., 2009). Finally, the best performing systems often have different natures from one year to another, showing alternations of deep (Hickl and Bensley, 2007; Tatu and Moldovan, 2007) and shallow approaches (Jia et al., 2010) ranked at the top positions. In light of these considerations, it would be useful for sys30 \x0ctems developers to have: i) automatic ways to support systems tuning at a training stage, and ii) reliable terms of comparison to validate their hypotheses, and position the results of their work before submitting runs for evaluation. In this paper we address these needs by extending an open-source RTE package (EDITS1) with a mechanism that automatizes the selection of the most promising configuration over a training dataset. We prove the effectiveness of such extension showing that it allows not o</context>
</contexts>
<marker>Jia, Huang, Ma, Wan, Xiao, 2010</marker>
<rawString>Houping Jia, Xiaojiang Huang, Tengfei Ma, Xiaojun Wan, and Jianguo Xiao. 2010. PKUTM Participation at TAC 2010 RTE and Summarization Track. Proceedings of the Sixth Recognizing Textual Entailment Challenge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Milen Kouylekov</author>
<author>Matteo Negri</author>
</authors>
<title>An Opensource Package for Recognizing Textual Entailment.</title>
<date>2010</date>
<contexts>
<context position="4904" citStr="Kouylekov and Negri, 2010" startWordPosition="792" endWordPosition="795">eve good performance on all the available RTE Challenge datasets, but also to improve the official results, achieved with the same system, through ad hoc configurations manually defined by the developers team. Our contribution is twofold. On one side, in the spirit of the collaborative nature of open source projects, we extend an existing tool with a useful functionality that was still missing. On the other side, we provide a good sparring partner for system developers, to be used as a fast and free term of comparison to position the results of their work. 2 Coping with configurability EDITS (Kouylekov and Negri, 2010) is an open source RTE package, which offers a modular, flexible, and adaptable working environment to experiment with the RTE task over different datasets. The package allows to: i) create an entailment engine by defining its basic components (i.e. algorithms, cost schemes, rules, and optimizers); ii) train such entailment engine over an annotated RTE corpus to learn a model; and iii) use the entailment engine and the model to assign an entailment judgement and a confidence score to each pair of an un-annotated test corpus. A key feature of EDITS is represented by its high configurability, al</context>
</contexts>
<marker>Kouylekov, Negri, 2010</marker>
<rawString>Milen Kouylekov and Matteo Negri. 2010. An Opensource Package for Recognizing Textual Entailment.</rawString>
</citation>
<citation valid="true">
<date>2010</date>
<booktitle>Proceedings of ACL</booktitle>
<note>Demo session.</note>
<marker>2010</marker>
<rawString>Proceedings of ACL 2010 Demo session.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Milen Kouylekov</author>
<author>Yashar Mehdad</author>
<author>Matteo Negri</author>
<author>Elena Cabrio</author>
</authors>
<date>2010</date>
<booktitle>FBK Participation in RTE6: Main and KBP Validation Task. Proceedings of the Sixth Recognizing Textual Entailment Challenge.</booktitle>
<contexts>
<context position="6701" citStr="Kouylekov et al., 2010" startWordPosition="1067" endWordPosition="1070">ber corresponds to the total number of configurations allowed by the system, which result from the possible combinations of parameter settings. When dealing with enlarging dataset sizes, and the tight time constraints usually posed by the evaluation campaigns, this problem becomes particularly challenging, as developers are hardly able to run exhaustive training/evaluation routines. As recently shown by the EDITS developers team, such situation results in running a limited number of experiments with the most reasonable configurations, which consequently might not lead to the optimal solution (Kouylekov et al., 2010). The need of a mechanism to automatically obtain the most promising solution on one side, and the constraints posed by the evaluation campaigns on the other side, arise the necessity to optimize this procedure. Along this direction, the objective is good a trade-off between exhaustive experimentation with all possible configurations (unfeasible), and educated guessing (unreliable). The remainder of this section tackles this issue introducing an optimization strategy based on genetic algorithms, and describing its adaptation to extend EDITS with the new functionality. 2.1 Genetic algorithm Gen</context>
<context position="14759" citStr="Kouylekov et al., 2010" startWordPosition="2358" endWordPosition="2361">ences between the educated guessing done by the EDITS developers for the official RTE submissions, and the optimal configuration automatically selected by EDITS-GA. Surprisingly, in some cases, even a minor difference in the selected parameters leads to figurations, over small datasets (RTE1 to RTE5). 6 With these settings, training EDITS-GA over small datasets (RTE1 to RTE5) takes about 9 minutes each. 7 All time figures are calculated on an Intel(R) Xeon(R), CPU X3440 @ 2.53GHz, 8 cores with 8 GB RAM. significant gaps in the results. For instance, in RTE6 dataset, the guessed configuration (Kouylekov et al., 2010) was based on the lexical overlap algorithm, setting the cost of replacing H terms without an equivalent in T to the minimal Levenshtein distance between such words and any word in T. EDITS-GA estimated, as a more promising solution, a combination of lexical overlap with a different cost scheme (based on the IDF of the terms in T). In addition, in contrast with the guessed configuration, stop-words filtering was selected as an option, eventually leading to a 4.51% improvement over the official RTE6 result. 4 Conclusion Is it worth submitting this run?,How good is my system?. These are the typi</context>
</contexts>
<marker>Kouylekov, Mehdad, Negri, Cabrio, 2010</marker>
<rawString>Milen Kouylekov, Yashar Mehdad, Matteo Negri, and Elena Cabrio. 2010. FBK Participation in RTE6: Main and KBP Validation Task. Proceedings of the Sixth Recognizing Textual Entailment Challenge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yashar Mehdad</author>
</authors>
<title>Automatic Cost Estimation for Tree Edit Distance Using Particle Swarm Optimization.</title>
<date>2009</date>
<booktitle>Proceedings of ACL-IJCNLP</booktitle>
<contexts>
<context position="5724" citStr="Mehdad, 2009" startWordPosition="923" endWordPosition="924">ine by defining its basic components (i.e. algorithms, cost schemes, rules, and optimizers); ii) train such entailment engine over an annotated RTE corpus to learn a model; and iii) use the entailment engine and the model to assign an entailment judgement and a confidence score to each pair of an un-annotated test corpus. A key feature of EDITS is represented by its high configurability, allowed by the availability of different algorithms, the possibility to integrate different sets of lexical entailment/contradiction rules, and the variety of parameters for performance optimization (see also Mehdad, 2009). Although configurability is per se an important aspect (especially for an open-source and general purpose system), there is another side of the coin. In principle, in order to select the most promising configuration over a given development set, one should exhaustively run a huge number of training/evaluation routines. Such num1 http://edits.fbk.eu/ ber corresponds to the total number of configurations allowed by the system, which result from the possible combinations of parameter settings. When dealing with enlarging dataset sizes, and the tight time constraints usually posed by the evaluat</context>
</contexts>
<marker>Mehdad, 2009</marker>
<rawString>Yashar Mehdad 2009. Automatic Cost Estimation for Tree Edit Distance Using Particle Swarm Optimization. Proceedings of ACL-IJCNLP 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eridan Otto</author>
<author>Mara Cristina Riff</author>
</authors>
<title>Towards an efficient evolutionary decoding algorithm for statistical machine translation.</title>
<date>2004</date>
<journal>LNAI,</journal>
<pages>2972--438447</pages>
<contexts>
<context position="7537" citStr="Otto and Riff, 2004" startWordPosition="1195" endWordPosition="1198"> this direction, the objective is good a trade-off between exhaustive experimentation with all possible configurations (unfeasible), and educated guessing (unreliable). The remainder of this section tackles this issue introducing an optimization strategy based on genetic algorithms, and describing its adaptation to extend EDITS with the new functionality. 2.1 Genetic algorithm Genetic algorithms (GA) are well suited to efficiently deal with large search spaces, and have been recently applied with success to a variety of optimization problems and specific NLP tasks (Figueroa and Neumann, 2008; Otto and Riff, 2004; Aycinena et al., 2003). GA are a direct stochastic method for global search and optimization, which mimics natural evolution. To this aim, they work with a population of individuals, representing possible solutions to the given task. Traditionally, solutions are represented in binary as strings of 0s and 1s, but other encodings (e.g. sequences of real values) are possible. The evolution usually starts from a population of randomly generated individuals, and at each generation selects the best-suited individuals based on a fitness function (which measures the optimality of the solution obtain</context>
</contexts>
<marker>Otto, Riff, 2004</marker>
<rawString>Eridan Otto and Mara Cristina Riff 2004. Towards an efficient evolutionary decoding algorithm for statistical machine translation. LNAI, 2972:438447..</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marta Tatu</author>
<author>Dan Moldovan</author>
</authors>
<date>2007</date>
<booktitle>COGEX at RTE3. Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing.</booktitle>
<contexts>
<context position="3625" citStr="Tatu and Moldovan, 2007" startWordPosition="578" endWordPosition="581">e, it is not clear whether the availability of larger amounts of training data correlates with better performance (Hickl et al., 2006) or not (Zanzotto et al., 2007; Hickl and Bensley, 2007), even within the same evaluation setting. In addition, ablation tests carried out in recent editions of the challenge do not allow for definite conclusions about the actual usefulness of tools and resources, even the most popular ones (Bentivogli et al., 2009). Finally, the best performing systems often have different natures from one year to another, showing alternations of deep (Hickl and Bensley, 2007; Tatu and Moldovan, 2007) and shallow approaches (Jia et al., 2010) ranked at the top positions. In light of these considerations, it would be useful for sys30 \x0ctems developers to have: i) automatic ways to support systems tuning at a training stage, and ii) reliable terms of comparison to validate their hypotheses, and position the results of their work before submitting runs for evaluation. In this paper we address these needs by extending an open-source RTE package (EDITS1) with a mechanism that automatizes the selection of the most promising configuration over a training dataset. We prove the effectiveness of s</context>
</contexts>
<marker>Tatu, Moldovan, 2007</marker>
<rawString>Marta Tatu and Dan Moldovan. 2007. COGEX at RTE3. Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabio Massimo Zanzotto</author>
<author>Marco Pennacchiotti</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Shallow Semantics in Fast Textual Entailment Rule Learners. Proceedings of the Third Recognizing Textual Entailment Challenge.</title>
<date>2007</date>
<contexts>
<context position="3165" citStr="Zanzotto et al., 2007" startWordPosition="504" endWordPosition="507">ore artificial settings to more complex and natural ones. However, in contrast with other more stable tasks in terms of evaluation settings and metrics (e.g. machine translation), such changes make it difficult to capitalize on the experience obtained by participants throughout the years. Third, looking at RTE-related literature and the outcomes of the six campaigns organised so far, the conclusions that can be drawn are often controversial. For instance, it is not clear whether the availability of larger amounts of training data correlates with better performance (Hickl et al., 2006) or not (Zanzotto et al., 2007; Hickl and Bensley, 2007), even within the same evaluation setting. In addition, ablation tests carried out in recent editions of the challenge do not allow for definite conclusions about the actual usefulness of tools and resources, even the most popular ones (Bentivogli et al., 2009). Finally, the best performing systems often have different natures from one year to another, showing alternations of deep (Hickl and Bensley, 2007; Tatu and Moldovan, 2007) and shallow approaches (Jia et al., 2010) ranked at the top positions. In light of these considerations, it would be useful for sys30 \x0ct</context>
</contexts>
<marker>Zanzotto, Pennacchiotti, Moschitti, 2007</marker>
<rawString>Fabio Massimo Zanzotto, Marco Pennacchiotti and Alessandro Moschitti. 2007. Shallow Semantics in Fast Textual Entailment Rule Learners. Proceedings of the Third Recognizing Textual Entailment Challenge.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>