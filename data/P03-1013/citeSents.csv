 and trained on the Penn Treebank CITATION, which raises the question whether these models generalize to other languages, and to annotation schemes that differ from the Penn Treebank markup,,
 The present paper addresses this question by proposing a probabilistic parsing model trained on Negra CITATION, a syntactically annotated corpus for German,,
 While Negra has been used to build probabilistic chunkers (CITATION; CITATION), the research reported in this paper is the first attempt to develop a probabilistic full parsing model for German trained on a treebank (to our knowledge),,
 Lexicalization can increase parsing performance dramatically for English (CITATION; CITATION, 2000; CITATION), and the lexicalized model proposed by CITATION has been successfully applied to Czech CITATION and Chinese CITATION,,
 CITATION used Negra to train a maximum entropy-based chunker, and report LR and LP of 84,,
 Using cascaded Markov models, CITATION reports an improved performance on the same task (LR 84,,
 CITATION train an unlexicalized PCFG on Negra to perform a different chunking task, viz,,
 The head-lexicalized model of CITATION has been applied to German by Beil et al,,
 3It is unclear what effect bi-lexical statistics have on the sister-head model; while CITATION shows bi-lexical statistics are sparse for some grammars, CITATION found they play a greater role in binarized grammars,,
roll and Rooths Head-Lexicalized Model The head-lexicalized PCFG model of CITATION is a minimal departure from the standard unlexicalized PCFG model, which makes it ideal for a direct comparison,,
 The rule probability is then defined as (see also CITATION): P(RHS|LHS) = Prule(C1 ,,
3 Collinss Head-Lexicalized Model In contrast to Carroll and Rooths (1998) approach, the model proposed by CITATION does not compute rule probabilities directly,,
 3It is unclear what effect bi-lexical statistics have on the sister-head model; while CITATION shows bi-lexical statistics are sparse for some grammars, CITATION found they play a greater role in binarized grammars,,
 CITATION report an evaluation using an NP chunking task, achieving 92% LR and LP,,
 The work by CITATION and CITATION has demonstrated the applicability of the CITATION model for Czech and Chinese,,
 While Negra has been used to build probabilistic chunkers (CITATION; CITATION), the research reported in this paper is the first attempt to develop a probabilistic full parsing model for German trained on a treebank (to our knowledge),,
 Lexicalization can increase parsing performance dramatically for English (CITATION; CITATION, 2000; CITATION), and the lexicalized model proposed by CITATION has been successfully applied to Czech CITATION and Chinese CITATION,,
 Neither CITATION nor CITATION compare the lexicalized model to an unlexicalized baseline model, leaving open the possibility that lexicalization is useful for English, but not for other languages,,
 Section 3 describes two standard lexicalized models (CITATION; CITATION), as well as an unlexical,,
1% CITATION Chinese 3,484 69,,
8% CITATION Czech 19,000 - 80,,
0% - CITATION Table 1: Results for the CITATION model for various languages (dependency precision for Czech) wordorder, i,,
 CITATION report an evaluation using an NP chunking task, achieving 92% LR and LP,,
 The work by CITATION and CITATION has demonstrated the applicability of the CITATION model for Czech and Chinese,,
 However, the learning curve for Negra (see Figure 1) indicates that the performance of the CITATION model is stable, even for small training sets,,
 CITATION and CITATION do not ,,
 We used TnT CITATION, trained on the Negra training set,,
 CITATION used Negra to train a maximum entropy-based chunker, and report LR and LP of 84,,
 Using cascaded Markov models, CITATION reports an improved performance on the same task (LR 84,,
 CITATION train an unlexicalized PCFG on Negra to perform a different chunking task, viz,,
 The head-lexicalized model of CITATION has been applied to German by Beil et al,,
 3It is unclear what effect bi-lexical statistics have on the sister-head model; while CITATION shows bi-lexical statistics are sparse for some grammars, CITATION found they play a greater role in bin,,
sing model trained on Negra CITATION, a syntactically annotated corpus for German,,
 While Negra has been used to build probabilistic chunkers (CITATION; CITATION), the research reported in this paper is the first attempt to develop a probabilistic full parsing model for German trained on a treebank (to our knowledge),,
 Lexicalization can increase parsing performance dramatically for English (CITATION; CITATION, 2000; CITATION), and the lexicalized model proposed by CITATION has been successfully applied to Czech CITATION and Chinese CITATION,,
 Neither CITATION nor CITATION compare the lexicalized model to an unlexicalized baseline model, leaving open the possibility that lexicalization is useful for English, but not for other languages,,
, CITATION; CITATION, 2000; CITATION),,
 More specifically, we used a standard probabilistic context-free grammar (PCFG; see CITATION),,
 We tested a variant of the CITATION model that takes this into account,,
 Grammar Induction For the unlexicalized PCFG model (henceforth baseline model), we used the probabilistic left-corner parser Lopar CITATION,,
 The head-lexicalized model of CITATION (henceforth C&R model) was again realized using Lopar, which in lexicalized mode implements the model in Section 3,,
 The lexicalized model proposed by CITATION (henceforth Collins model) was re-implemented by \x0cone of the authors,,
 sister head tag X Table 4: Linguistic features in the current model compared to the models of CITATION, CITATION, and CITATION Negra, based on Collinss (1997) model for nonrecursive NPs in the Penn Treebank (which are also flat),,
 For non-recursive NPs, CITATION does not use the probability function in (5), but instead substitutes Pr (and, by analogy, Pl) by: Pr(Ri,t(Ri),l(Ri)|P,Ri1,t(Ri1),l(Ri1),d(i)) (8) Here the head H is substituted by the sister Ri1 (and Li1),,
 CITATION used Negra to train a maximum entropy-based chunker, and report LR and LP of 84,,
 Using cascaded Markov models, CITATION reports an improved performance on the same task (LR 84,,
 CITATION train an unlexicalized PCFG on Negra to perform a different chunking task, viz,,
 The head-lexicalized model of CITATION has been applied to German by Beil et al,,
 3It is unclear what effect bi-lexical statistics have on the sister-head model; while CITATION shows bi-lexical statistics are sparse for some grammars, CITATION found they play a greater role in binarized grammars,,
, CITATION; CITATION, 2000; CITATION),,
 More specifically, we used a standard probabilistic context-free grammar (PCFG; see CITATION),,
2 Carroll and Rooths Head-Lexicalized Model The head-lexicalized PCFG model of CITATION is a minimal departure from the standard unlexicalized PCFG model, which makes it ideal for a direct comparison,,
ra CITATION, a syntactically annotated corpus for German,,
 While Negra has been used to build probabilistic chunkers (CITATION; CITATION), the research reported in this paper is the first attempt to develop a probabilistic full parsing model for German trained on a treebank (to our knowledge),,
 Lexicalization can increase parsing performance dramatically for English (CITATION; CITATION, 2000; CITATION), and the lexicalized model proposed by CITATION has been successfully applied to Czech CITATION and Chinese CITATION,,
 Neither CITATION nor CITATION compare the lexicalized model to an unlexicalized baseline model, leaving open the possibility that lexicalization is useful for English, but not for other languages,,
, CITATION; CITATION, 2000; CITATION),,
 More specifically, we used a standard probabilistic context-free grammar (PCFG; see CITATION),,
, CITATION; CITATION),,
 However, most of the existing models have been developed for English and trained on the Penn Treebank CITATION, which raises the question whether these models generalize to other languages, and to annotation schemes that differ from the Penn Treebank markup,,
 The present paper addresses this question by proposing a probabilistic parsing model trained on Negra CITATION, a syntactically annotated corpus for German,,
 sister head tag X Table 4: Linguistic features in the current model compared to the models of CITATION, CITATION, and CITATION Negra, based on Collinss (1997) model for nonrecursive NPs in the Penn Treebank (which are also flat),,
 For non-recursive NPs, CITATION does not use the probability function in (5), but instead substitutes Pr (and, by analogy, Pl) by: Pr(Ri,t(Ri),l(Ri)|P,Ri1,t(Ri1),l(Ri1),d(i)) (8) Here the head H is substituted by the sister Ri1 (and Li1),,
es CITATION and then add non-lexical sis2This result generalizes to Ss, which are also flat in Negra (see Section 2,,
02 Table 6: Change in performance when reverting to head-head statistics for individual categories ter information CITATION, as illustrated in Table 4,,
, CITATION; CITATION),,
 However, most of the existing models have been developed for English and trained on the Penn Treebank CITATION, which raises the question whether these models generalize to other languages, and to annotation schemes that differ from the Penn Treebank markup,,
 The present paper addresses this question by proposing a probabilistic parsing model trained on Negra CITATION, a syntactically annotated corpus for German,,
9) and Chinese CITATION,,
 Neither CITATION nor CITATION compare the lexicalized model to an unlexicalized baseline model, leaving open the possibility that lexicalization is useful for English, but not for other languages,,
 Section 3 describes two standard lexicalized models (CITATION; CITATION), as well as an unlexicalized baseline model,,
1% CITATION Chinese 3,484 69,,
8% CITATION Czech 19,000 - 80,,
0% - CITATION Table 1: Results for the CITATION model for various languages (dependency precision for Czech) wordorder, i,,
, CITATION; CITATION, 2000; CITATION),,
 More specifically, we used a standard probabilistic context-free grammar (PCFG; see CITATION),,
 The rule probability is then defined as (see also CITATION): P(RHS|LHS) = Prule(C1 ,,
3 Collinss Head-Lexicalized Model In contrast to Carroll and Rooths (1998) approach, the model proposed by CITATION does not compute rule probabilities directly,,
 The head-lexicalized model of CITATION (henceforth C&R model) was again realized using Lopar, which in lexicalized mode implements the model in Section 3,,
 The lexicalized model proposed by CITATION (henceforth Collins model) was re-implemented by \x0cone of the authors,,
 sister head tag X Table 4: Linguistic features in the current model compared to the models of CITATION, CITATION, and CITATION Negra, based on Collinss (1997) model for nonrecursive NPs in the Penn Treebank (which are also flat),,
 For non-recursive NPs, CITATION does not use the probability function in (5), but instead substitutes Pr (and, by analogy, Pl) by: Pr(Ri,t(Ri),l(Ri)|P,Ri1,t(Ri1),l(Ri1),d(i)) (8) Here the head H is substituted by the sister Ri1 (and Li1),,
 The progression in the probabilistic parsing literature has been to start with lexical head-head dependencies CITATION and then add non-lexical sis2This result generalizes to Ss, which are also flat in Negra (see Section 2,,
02 Table 6: Change in performance when reverting to head-head statistics for individual categories ter information CITATION, a,,
 CITATION report an evaluation using an NP chunking task, achieving 92% LR and LP,,
 The work by CITATION and CITATION has demonstrated the applicability of the CITATION model for Czech and Chinese,,
 However, the learning curve for Negra (see Figure 1) indicates that the performance of the CITATION model is stable, even for small training sets,,
 CITATION and CITATION do not compare their models with an unlexicalized baseline; henc,,
 While Negra has been used to build probabilistic chunkers (CITATION; CITATION), the research reported in this paper is the first attempt to develop a probabilistic full parsing model for German trained on a treebank (to our knowledge),,
 Lexicalization can increase parsing performance dramatically for English (CITATION; CITATION, 2000; CITATION), and the lexicalized model proposed by CITATION has been successfully applied to Czech CITATION and Chinese CITATION,,
 Neither CITATION nor CITATION compare the lexicalized model to an unlexicalized baseline model, leaving open the possibility that lexicalization is useful for English, but not for other languages,,
 Section 3 describes two standard lexicalized models (CITATION; Co,,
1% CITATION Chinese 3,484 69,,
8% CITATION Czech 19,000 - 80,,
0% - CITATION Table 1: Results for the CITATION model for various languages (dependency precision for Czech) wordorder, i,,
 CITATION report an evaluation using an NP chunking task, achieving 92% LR and LP,,
 The work by CITATION and CITATION has demonstrated the applicability of the CITATION model for Czech and Chinese,,
 However, the learning curve for Negra (see Figure 1) indicates that the performance of the CITATION model is stable, even for small training sets,,
 CITATION and Bik,,
 Using cascaded Markov models, CITATION reports an improved performance on the same task (LR 84,,
 CITATION train an unlexicalized PCFG on Negra to perform a different chunking task, viz,,
 The head-lexicalized model of CITATION has been applied to German by Beil et al,,
 3It is unclear what effect bi-lexical statistics have on the sister-head model; while CITATION shows bi-lexical statistics are sparse for some grammars, CITATION found they play a greater role in binarized grammars,,
 CITATION report an evaluation using an NP chunking task, achieving 92% LR and LP,,
 Using cascaded Markov models, CITATION reports an improved performance on the same task (LR 84,,
 CITATION train an unlexicalized PCFG on Negra to perform a different chunking task, viz,,
 The head-lexicalized model of CITATION has been applied to German by Beil et al,,
 3It is unclear what effect bi-lexical statistics have on the sister-head model; while CITATION shows bi-lexical statistics are sparse for some grammars, CITATION found they play a greater role in binarized grammars,,
 CITATION report an evaluation using an NP chunking task, achieving 92% LR and LP,,
, CITATION; CITATION),,
 However, most of the existing models have been developed for English and trained on the Penn Treebank CITATION, which raises the question whether these models generalize to other languages, and to annotation schemes that differ from the Penn Treebank markup,,
 The present paper addresses this question by proposing a probabilistic parsing model trained on Negra CITATION, a syntactically annotated corpus for German,,
 While Negra has been used to build probabilistic chunkers (CITATION; CITATION), the res,,
 The annotation scheme CITATION is modeled to a certain extent on that of the Penn Treebank CITATION, with crucial differences,,
 Grammar Induction For the unlexicalized PCFG model (henceforth baseline model), we used the probabilistic left-corner parser Lopar CITATION,,
 The head-lexicalized model of CITATION (henceforth C&R model) was again realized using Lopar, which in lexicalized mode implements the model in Section 3,,
 The reader is referred to CITATION and CITATION for details,,
 Treebank CITATION, which raises the question whether these models generalize to other languages, and to annotation schemes that differ from the Penn Treebank markup,,
 The present paper addresses this question by proposing a probabilistic parsing model trained on Negra CITATION, a syntactically annotated corpus for German,,
 While Negra has been used to build probabilistic chunkers (CITATION; CITATION), the research reported in this paper is the first attempt to develop a probabilistic full parsing model for German trained on a treebank (to our knowledge),,
 Lexicalization can increase parsing performance dramatically for English (CITATION; CITATION, 2000; CITATION), and the lexicalized model proposed by CITATION has been successfully applied to Czech CITATION and Chinese CITATION,,
 CITATION used Negra to train a maximum entropy-based chunker, and report LR and LP of 84,,
 Using cascaded Markov models, CITATION reports an improved performance on the same task (LR 84,,
 CITATION train an unlexicalized PCFG on Negra to perform a different chunking task, viz,,
 The head-lexicalized model of CITATION has been applied to German by Beil et al,,
, CITATION; CITATION),,
 However, most of the existing models have been developed for English and trained on the Penn Treebank CITATION, which raises the question whether these models generalize to other languages, and to annotation schemes that differ from the Penn Treebank markup,,
 The present paper addresses this question by proposing a probabilistic parsing model trained on Negra CITATION, a syntactically annotated corpus for German,,
 While Negra has been used to build probabilistic chunkers (CITATION; CITATION), the research reported in this paper is the first attempt to develop a probabilistic full parsing model for German trained on a treebank (to our knowledge),,
 Lexicalization can increase parsing performance dramatically for English (CITATION; CITATION, 2000; ,,
 The annotation scheme CITATION is modeled to a certain extent on that of the Penn Treebank CITATION, with crucial differences,,
, CITATION),,
