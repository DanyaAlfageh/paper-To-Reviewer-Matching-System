We found that features normalized by first turn were the best predictors of emotion CITATION,,
As a result of this mismatch, recent work motivated by spoken dialogue applications has started to use naturally-occurring speech to train emotion predictors (CITATION; CITATION; CITATION; CITATION; CITATION; CITATION; CITATION), but often predicts emotions using only acoustic-prosodic features that would be automatically available to a dialogue system in real-time,,
6 Adding Context-Level Features Research in other domains (CITATION; CITATION) has shown that features representing the di\x0calogue context can sometimes improve the accuracy of predicting negative user states, compared to the use of features computed from only the turn to be predicted,,
al emotional speech does not necessarily reflect natural speech CITATION, such as found in tutoring dialogues,,
Lexical information has been shown to improve speech-based emotion prediction in other domains (CITATION; CITATION; CITATION; CITATION; CITATION; CITATION), so our first non-acoustic-prosodic feature represents the transcription3 of each student turn as a word occurrence vector (indicating the lexical items that are present in the turn),,
