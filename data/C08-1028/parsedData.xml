<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<bodyText confidence="0.572654">
b&amp;apos;Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 217224
</bodyText>
<address confidence="0.69256">
Manchester, August 2008
</address>
<title confidence="0.834057">
Efficient Parsing with the Product-Free Lambek Calculus
</title>
<author confidence="0.960871">
Timothy A. D. Fowler
</author>
<affiliation confidence="0.9969685">
Department of Computer Science
University of Toronto
</affiliation>
<address confidence="0.990022">
10 Kings College Road, Toronto, ON, M5S 3G4, Canada
</address>
<email confidence="0.997043">
tfowler@cs.toronto.edu
</email>
<sectionHeader confidence="0.990804" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998611666666667">
This paper provides a parsing algorithm
for the Lambek calculus which is polyno-
mial time for a more general fragment of
the Lambek calculus than any previously
known algorithm. The algorithm runs in
worst-case time O(n5) when restricted to
a certain fragment of the Lambek calcu-
lus which is motivated by empirical anal-
ysis. In addition, a set of parameterized
inputs are given, showing why the algo-
rithm has exponential worst-case running
time for the Lambek calculus in general.
</bodyText>
<sectionHeader confidence="0.998267" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.995996583333333">
A wide variety of grammar formalisms have been
explored in the past for parsing natural language
sentences. The most prominent of these for-
malisms has been context free grammars (CFGs)
but a collection of formalisms known as categorial
grammar (CG) (Ajdukiewicz, 1935; Dowty et al.,
1981; Steedman, 2000) has received interest be-
cause of some significant advantages over CFGs.
First, CG is inherently lexicalized due to the fact
that all of the variation between grammars is cap-
tured by the lexicon. This is a result of the rich
categories which CG uses in its lexicon to specify
the functor-argument relationships between lexical
items. A distinct advantage of this lexicalization
is that the processing of sentences depends upon
only those categories contained in the string and
not some global set of rules. Second, CG has
the advantage that it centrally adopts the princi-
ple of compositionality, as outlined in Montague
c
2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
grammar (Montague, 1974), allowing the semantic
derivation to exactly parallel the syntactic deriva-
tion. This leads to a semantical form which is eas-
ily extractable from the syntactic parse.
A large number of CG formalisms have been
introduced including, among others, the Lambek
calculus (Lambek, 1958) and Combinatory Cat-
egorial Grammar (CCG) (Steedman, 2000). Of
these, CCG has received the most zealous com-
putational attention. Impressive results have been
achieved culminating in the state-of-the-art parser
of Clark and Curran (2004) which has been used as
the parser for the Pascal Rich Textual Entailment
Challenge entry of Bos and Markert (2005). The
appeal of CCG can be attributed to the existence of
efficient parsing algorithms for it and the fact that
it recognizes a mildly context-sensitive language
class (Joshi et al., 1989), a language class more
powerful than the context free languages (CFLs)
that has been argued to be necessary for natural
language syntax. The Lambek calculus provides
an ideal contrast between CCG and CFGs by be-
ing a CG formalism like CCG but by recognizing
the CFLs like CFGs (Pentus, 1997).
The primary goal of this paper is to provide
an algorithm for parsing with the Lambek calcu-
lus and to sketch its correctness. Furthermore, a
time bound of O(n5) will be shown for this algo-
rithm when restricted to product-free categories of
bounded order (see section 2 for a definition). The
restriction to bounded order is not a significant re-
striction, due to the fact that categories in CCG-
bank1 (Hockenmaier, 2003), a CCG corpus, have a
maximum order of 5 and an average order of 0.78
by token. In addition to the presentation of the al-
gorithm, we will provide a parameterized set of in-
</bodyText>
<page confidence="0.905267">
1
</page>
<bodyText confidence="0.9521435">
Although CCGbank was built for CCG, we believe that
transforming it into a Lambek calculus bank is feasible.
</bodyText>
<page confidence="0.992414">
217
</page>
<bodyText confidence="0.995310533333333">
\x0cputs (of unbounded order) on which the algorithm
has exponential running time.
The variant of the Lambek calculus considered
here is the product-free Lambek calculus chosen
for three reasons. First, it is the foundation of
all other non-associative variants of the Lambek
calculus including the original Lambek calculus
(Lambek, 1958) and the multi-modal Lambek cal-
culus (Moortgat, 1996). Second, the calculus with
product is NP-complete (Pentus, 2006), while the
sequent derivability in the product-free fragment
is still unknown. Finally, the only connectives in-
cluded are / and \\, which are the same connectives
as in CCG, providing a corpus for future work such
as building a probabilistic Lambek calculus parser.
</bodyText>
<sectionHeader confidence="0.954276" genericHeader="method">
2 Problem specification
</sectionHeader>
<bodyText confidence="0.997996303030303">
Parsing with the Lambek calculus is treated as a
logical derivation problem. First, the words of a
sentence are assigned categories which are built
from basic categories (e.g. NP and S) and the
connectives \\ and /. For example, the category for
transitive verbs is (NP\\S)/NP and the category
for adverbs is (S/NP)\\(S/NP)2. Intuitively, the
\\ and / operators specify the arguments of a word
and the direction in which those arguments need to
be found. Next, the sequent is built by combining
the sequence of the categories for the words with
the symbol and the sentence category (e.g. S).
Strictly speaking, this paper only considers the
parsing of categories without considering multi-
ple lexical entries per word. However, using tech-
niques such as supertagging, the results presented
here yield an efficient method for the broader prob-
lem of parsing sentences. Therefore, we can take
the size of the input n to be the number of basic
categories in the sequent.
A parse tree for the sentence corresponds to a
proof of its sequent and is restricted to rules fol-
lowing the templates in figure 1. In figure 1, lower-
case Greek letters represent categories and upper-
case Greek letters represent sequences of cate-
gories. A proof for the sentence Who loves him?
is given in figure 2.
The version of the Lambek calculus presented
above is known as the product-free Lambek calcu-
lus allowing empty premises and will be denoted
by L. In addition, we will consider the fragment
Lk, obtained by restricting L to categories of order
bounded by k. The order of a category, which can
</bodyText>
<page confidence="0.83206">
2
</page>
<bodyText confidence="0.587159">
We use Ajdukiewicz notation, not Steedman notation.
</bodyText>
<figure confidence="0.65673375">
\\
\\
/
/
</figure>
<figureCaption confidence="0.99883">
Figure 1: The sequent presentation of L.
</figureCaption>
<figure confidence="0.9956565">
NP NP
S S
NP NP S S
NP NP\\S S
NP\\S NP\\S
S/(NP\\S) NP\\S S
S/(NP\\S) (NP\\S)/NP NP S
Who loves him
</figure>
<figureCaption confidence="0.999259">
Figure 2: A derivation for Who loves him?.
</figureCaption>
<bodyText confidence="0.833272">
be viewed as the depth of the nesting of argument
implications, is defined as:
</bodyText>
<equation confidence="0.91589625">
o() = 0 for a basic category
o(/) = o(\\) = max(o(), o() + 1)
For example, o((NP\\S)/NP) = 1 and o((S/
NP)\\(S/NP)) = 2.
</equation>
<sectionHeader confidence="0.999083" genericHeader="method">
3 Related work
</sectionHeader>
<bodyText confidence="0.989808375">
Two other papers have provided algorithms similar
to the one presented here.
Carpenter and Morrill (2005) provided a graph
representation and a dynamic programming algo-
rithm for parsing in the Lambek calculus with
product. However, due to there use of the Lam-
bek calculus with product and to their choice of
correctness conditions, they did not obtain a poly-
nomial time algorithm for any significant fragment
of the calculus.
Aarts (1994) provided an algorithm for L2
which is not correct for L. Ours is polynomial time
for Lk, for any constant k, and is correct for L, al-
beit in exponential running time.
A number of authors have provided polynomial
time algorithms for parsing with CCG which gives
some insight into how good our bound of O(n5)
is. In particular, Vijay-Shanker and Weir (1994)
provided a chart parsing algorithm for CCG with a
time bound of O(n6).
4 An algorithm for parsing with L
This section presents a chart parsing algorithm
similar to CYK where entries in the chart are arcs
annotated with graphs. The graphs will be referred
</bodyText>
<page confidence="0.994863">
218
</page>
<bodyText confidence="0.9986886">
\x0cto as abstract term graphs (ATGs) since they are
graph representations of abstractions over seman-
tic terms. ATGs will be presented in this section
by construction. See section 5 for their connection
to the proof structures of Roorda (1991).
The algorithm consists of two steps. First, the
base case is computed by building the base ATG
B and determining the set of surface variables by
using the proof frames of Roorda (1991). Second,
the chart is filled in iteratively according to the al-
gorithms specified in the appendix. The details for
these two steps can be found in sections 4.1 and
4.2, respectively. Section 4.3 introduces a proce-
dure for culling extraneous ATGs which is nec-
essary for the polynomial time proof and section
</bodyText>
<subsectionHeader confidence="0.927509">
4.4 discusses recovery of proofs from the packed
</subsectionHeader>
<bodyText confidence="0.997246857142857">
chart. An example of the algorithm is given in fig-
ure 3.
For parsing with L, the input is a sequent and for
parsing with Lk, the input is a sequent with cate-
gories whose order is bounded by k. Upon com-
pletion, the algorithm outputs YES if there is an
arc from 0 to n 1 and NO otherwise.
</bodyText>
<subsectionHeader confidence="0.99331">
4.1 Computing the base case
</subsectionHeader>
<bodyText confidence="0.992184961538461">
Computing the base case consists of building the
proof frame and then translating it into a graph,
the base ATG B.
4.1.1 Building the proof frame
Proof frames are the part of the theory of proof
nets which we need to build the base ATG. The
proof frame for a sequent is a structure built on top
of the categories of the sentence. To build the proof
frame, all categories in the sequent are assigned
a polarity and labelled by a fresh variable. Cate-
gories to the left of are assigned negative polarity
and the category to the right of is assigned pos-
itive polarity. Then, the four decomposition rules
shown in table 1 are used to build a tree-like struc-
ture (see figure 3). The decomposition rules are
read from bottom to top and show how to decom-
pose a category based on its main connective and
polarity. In table 1, d is the label of the category
being decomposed, f, g and h are fresh variables
and order of premises is important.
The bottom of the proof frame consists of the
original sequents categories with labels and po-
larities. These are called terminal formulae. The
top of the proof frame consists of basic categories
with labels and polarities. These are called the ax-
iomatic formulae. In addition, we will distinguish
</bodyText>
<figure confidence="0.989504045454546">
+
: f
: df
\\
: d
+
: h
: g
\\
+
: d
: df
+
: f
/
: d
: g
+
: h
/
+
: d
</figure>
<tableCaption confidence="0.993365">
Table 1: The proof frame decomposition rules.
</tableCaption>
<bodyText confidence="0.995364">
the leftmost variable in the label of each axiomatic
formula as its surface variable. See figure 3 for an
example.
</bodyText>
<subsubsectionHeader confidence="0.875545">
4.1.2 Building the Base ATG
</subsubsectionHeader>
<bodyText confidence="0.9975775">
The base ATG B is built from the proof frame in
the following way. The vertices of the base ATG
are the surface variables plus a new special ver-
tex . The edges of ATGs come in two forms:
Labelled and unlabeled, specified as hs, d, li and
hs, di, respectively, where s is the source, d is the
destination and l, where present, is the label.
To define the edge set of B, we need the follow-
ing:
Definition. For a variable u that labels a positive
category in a proof frame, the axiomatic reflection,
(u), is the unique surface variable v such that on
the upward path from u and v in the proof frame,
there is no formula of negative polarity. For exam-
ple, in figure 3, (b) = c.
The edgeset E of the base ATG is as follows:
</bodyText>
<listItem confidence="0.887838857142857">
1. hm, (pi)i E for 1 i k where
mp1 . . . pk appears as the label of some nega-
tive axiomatic formula
2. h, (t)i E where t is the label of the posi-
tive terminal formula
3. For each rule with a positive conclusion,
negative premise labelled by g and positive
</listItem>
<bodyText confidence="0.997747416666667">
premise labelled by h, h(h), g, gi E
A labeled edge in an ATG specifies that its
source must eventually connect to its destination
to complete a path corresponding to its label. For
example, G1 contains the edge hc, e, di which in-
dicates that to complete the path from c to d, we
must connect c to e. In contrast, an unlabeled edge
in an ATG specifies that its source is already con-
nected to its destination. For example, in figure 3,
G3 contains the edge ha, fi which indicates that
there is some path, over previously deleted nodes,
which connects a to f.
</bodyText>
<page confidence="0.986436">
219
</page>
<figure confidence="0.95798532">
\x0c0 1 2 3 4 5 6 7
a c d g e f h i
S
: ab S
+
: c NP
: d
NP\\S
+
: b
S/(NP\\S)
: a
NP
+
: g S
: efg
NP\\S
: ef
NP
+
: f
(NP\\S)/NP
: e
NP
: h S
</figure>
<equation confidence="0.886583777777778">
+
: i
Who loves him ?
G6 =
i
a
G5 =
i
a f
h
G3 =
g
a c d
d
G4 =
i
a c e f
d
h
G1 =
i
a c d
d
e g
G2 =
B =
i
</equation>
<figure confidence="0.988393083333333">
a c d
d
e f
g
h
B B B B B B B
Sentence
Proof
Frame
Surface
Variables
Chart
</figure>
<figureCaption confidence="0.999902">
Figure 3: The algorithms final state on the sequent S/(NP\\S) (NP\\S)/NP NP S.
</figureCaption>
<bodyText confidence="0.88575075">
Note that all nodes in an ATG have unlabeled
in-degree of either 0 or 1 and that the vertices of
an ATG are the surface variables found outside its
arc.
</bodyText>
<subsectionHeader confidence="0.946172">
4.2 Filling in the chart
</subsectionHeader>
<bodyText confidence="0.999479275862069">
Once the base ATG and the sequence of surface
variables is determined, we can begin filling in the
chart. The term entry refers to the collection of
arcs beginning and ending at the same nodes of the
chart. An arcs length is the difference between
its beginning and end points, which is always odd.
Note that each entry in the example in figure 3 con-
tains only one arc. We will iterate across the en-
tries of the chart and at each entry, we will attempt
a Bracketing and a number of Adjoinings. If an at-
tempt results in a violation, no new ATG is inserted
into the chart. Otherwise, a new ATG is computed
and inserted at an appropriate entry.
Bracketing is an operation on a single ATG
where we attempt to extend its arc by connecting
two nodes with the same basic category and op-
posite polarity. For example, G3 is the result of
bracketing G1. Adjoining, on the other hand, is an
operation on two adjacent ATGs where we attempt
to unify their ATGs into one larger ATG. For ex-
ample, G5 is the result of adjoining G3 and G2.
The chart filling process is described by algo-
rithm 1 in the appendix. The chart in figure 3 is
filled by the graphs G1, . . . , G6, in that order. A
walk through of the example is given in the re-
mainder of this section. Arcs of length 1 are treated
specially, since they are derived directly from the
base ATG. To show this, the base ATG is shown at
pseudo-nodes, labeled by Bs.
</bodyText>
<subsubsectionHeader confidence="0.921338">
4.2.1 Inserting arcs of length 1
</subsubsectionHeader>
<bodyText confidence="0.998462583333333">
This section corresponds to lines 1-2 of algo-
rithm 1 in the appendix. For each arc from i to
i+1, we will attempt to bracket the base ATG from
axiomatic formula i to axiomatic formula i + 1.
To follow our example, the first step is to con-
sider inserting an arc from 0 to 1 by bracketing B.
Bracketing causes a positive surface variable to be
connected to a negative surface variable and in this
case, a cycle from a to c and back to a is formed
resulting in the violation on line 12 of algorithm 2.
Therefore, no arc is inserted.
Then, the second step considers inserting an arc
from 1 to 2. However, axiomatic formula 1 has cat-
egory S and axiomatic formula 2 has category NP
which results in the violation on line 3 of algorithm
2 since they are not the same.
Next, we attempt to insert an arc from 2 to 3.
In this case, no violations occur meaning that we
can insert the arc. The intuition is that the ATG
for this arc is obtained by connecting g to d in
the base ATG. Since c must eventually connect
to d (c d d), and now g connects to d, the in-
degree constraint on ATG nodes requires that the
path connecting c to d pass through g. Further-
</bodyText>
<figure confidence="0.91376575">
220
\x0c- -
i
a c e f
d
h
i
a c e f
h
i
a f
h
</figure>
<figureCaption confidence="0.999941">
Figure 4: The intuition for bracketing from c to e.
</figureCaption>
<bodyText confidence="0.99423825">
more, the only way to connect c to g is through e.
So c d e. Then, we delete d and g.
This procedure continues until we have consid-
ered all possible arcs of length 1.
</bodyText>
<subsubsectionHeader confidence="0.949327">
4.2.2 Inserting arcs of length 3 and greater
</subsubsectionHeader>
<bodyText confidence="0.9978468">
Next, we iterate across graphs in the chart and
for each, consider whether its ATG can be brack-
eted with the axiomatic formulae on either side of
it and whether it can be adjoined with any of the
other graphs in the chart. This process closely re-
sembles CYK parsing as described on lines 3-10
of algorithm 1. The choice of shortest to longest
is important because part of the invariant of our
dynamic program is that all derivable ATGs on
shorter arcs have already been added.
Following our example, the first graph to be con-
sidered is G1. First, we attempt to bracket it from
axiomatic formulae 1 to 4. As before, this intu-
itively involves connecting c to e in the ATG for
this arc. This is allowed because no cycles are
formed and no labelled edges are prohibited from
eventually being connected. Then, as before, we
delete the vertices c and e and as a result connect
a to f, resulting in G3. The bracketing process is
illustrated in figure 4.
Next, we consider all graphs to which G1 could
adjoin and there are none, since such graphs would
need to annotate arcs which either end at 1 or begin
at 4. After processing G1, we process G2, which
has a successful bracketing resulting in G4 and no
successful adjoinings.
Next, we process G3. Bracketing it is prohib-
ited, as it would result in a cycle from a to f and
back to a. However, it is possible to adjoin G3 with
G2, since they are adjacent.
The adjoining of two graphs can be viewed as a
kind of intersection of the two ATGs, in the sense
that we are combining the information in both
graphs to yield a single more concise graph. At-
tempting an adjoining involves traversing the two
graphs being adjoined and the base ATG in both a
forward and a backward direction as specified in
algorithms 4 and 5 in the appendix.
The intuition behind these traversals is to gen-
erate a picture of what the combination of the two
</bodyText>
<figure confidence="0.931012631578947">
@
@
R
\x12
-
i
a f
h
i
a c d
d
e g
i
a c e f
g
h
d
i
a
</figure>
<figureCaption confidence="0.845524">
Figure 5: The intuition for adjoining two ATGs.
graphs must look like as illustrated in figure 5. In
general, we can only reconstruct those parts of the
</figureCaption>
<bodyText confidence="0.9151987">
graph which are necessary for determining the re-
sultant ATG and no more. The dotted edges in-
dicate uncertainty about the edges present at this
stage of the algorithm. Adjoining G2 and G3 does
not fail and the resultant graph is G5.
Note that this example does not contain any
instances of two identical ATGs being inserted
multiple times into the chart which occurs often
in large examples yielding significant savings of
computation.
</bodyText>
<subsectionHeader confidence="0.999619">
4.3 Culling of extraneous ATGs
</subsectionHeader>
<bodyText confidence="0.999554454545455">
It often happens that an entry in the chart contains
two ATGs such that if one of them is extendable
to a complete proof then the other necessarily is as
well. In this case, the former can be discarded. We
will outline such a method here that is important
for the polynomial time proof.
Definition. ATGs G1 and G2 are equivalent if
some surjection of edge labels to edge labels ap-
plied to the those of G1 yields those of G2.
Then, if two ATGs in a chart are equivalent, one
can be discarded.
</bodyText>
<subsectionHeader confidence="0.921372">
4.4 Recovering proofs from a packed chart
</subsectionHeader>
<bodyText confidence="0.988739142857143">
The algorithm as described above is a method for
answering the decision problem for sequent deriv-
ability in the Lambek calculus. However, we can
annotate the ATGs with the ATGs they are derived
from so that a complete set of Roorda-style proof
nets, and thus the proofs themselves, can be recov-
ered.
</bodyText>
<sectionHeader confidence="0.968816" genericHeader="method">
5 Correctness
</sectionHeader>
<bodyText confidence="0.9097862">
Correctness of the algorithm is obtained by using
structural induction to prove the equivalence of the
constructive definition of ATGs outlined in section
4 and a definition based on semantic terms given
in this section:
</bodyText>
<page confidence="0.914792">
221
</page>
<figure confidence="0.996554458333333">
\x0cS
: ab
S
+
: c NP
: d
NP\\S
+
: b
S/(NP\\S)
: a
NP
+
: g S
: efg
NP\\S
: ef NP
+
: f
(NP\\S)/NP
: e NP
: h S
+
: i
</figure>
<figureCaption confidence="0.999911">
Figure 6: A proof structure for Who loves him?.
</figureCaption>
<bodyText confidence="0.987244137931034">
Definition. A partial proof structure is a proof
frame together with a matching of the axiomatic
formulae. A proof structure is a partial proof struc-
ture whose matching is complete.
An example is given in figure 6. Proof struc-
tures correspond to proofs under certain conditions
and our conditions will be based on the semantic
term of the proof given to us by the Curry-Howard
isomorphism for the Lambek calculus (Roorda,
1991). To do this, we interpret left rules as func-
tional application and right rules as functional ab-
straction of lambda terms. Under this interpreta-
tion, the semantic term obtained from the proof
structure in figure 6 is ad.ehd.
As in Roorda (1991), proof structures corre-
spond to a proof if the semantic term assigned to
the sentence category is a well formed lambda term
which includes all the terms assigned to the words
of the sentence. Then, ATGs are graph represen-
tations of abstractions of the undetermined portion
of semantic terms of partial proof structures. Unla-
beled edges correspond to functional applications
whose arguments must still be determined and la-
belled edges correspond to functional abstractions
whose body does not yet contain an instance of the
abstracted variable. The violations which occur
during the execution of the algorithm correspond
to the various ways in which a lambda term can be
ill formed.
</bodyText>
<sectionHeader confidence="0.939195" genericHeader="method">
6 Asymptotic Running Time Complexity
</sectionHeader>
<bodyText confidence="0.999035925925926">
In this section we provide proof sketches for the
runtime of the algorithm. Let f(n) be a bound
on the number of arcs occurring in an entry in the
chart where n is the number of axiomatic formu-
lae. Then, observe that the number of edges within
an ATG is O(n2) and the number of edges adja-
cent to a vertex is O(n), due to basic properties of
ATGs.
Then, it is not hard to prove that the worst case
running time of Bracketing is O(n2), which is
dominated by the for loops of lines 20-23 of al-
gorithm 2.
Next, with some effort, we can see that the worst
case running time of Adjoining is dominated by the
execution of the procedures Fore and Back. But,
since there are at most a linear number of labels l
and for each label l we need to visit each vertex in
G1 and G2 at most a constant number of times, the
worst case running time is O(n2).
Then, for each ATG, we attempt at most one
bracketing and adjoinings with at most 2n+1 other
entries for which there can be (2n+1)f(n) ATGs.
Therefore, each entry can be processed in worst
case time O(n3f(n)2).
Finally, there are O(n2) entries in the chart,
which means that the entire algorithm takes time
O(n5f(n)2) in the worst case. Sections 6.1 and
</bodyText>
<subsectionHeader confidence="0.998342">
6.2 discuss the function f(n).
6.1 Runtime for Lk
</subsectionHeader>
<bodyText confidence="0.9991868">
By structural induction on the proof frame decom-
position rules and the base ATG building algo-
rithm, it can be proven that in Lk the length of the
longest path in the base ATG is bounded by k.
Next, consider a partition of the surface vari-
ables into a pair of sets such that the axiomatic
formulae corresponding to the surface variables
within each set are contiguous. For the example in
figure 3, one such pair of sets is S1 = {a, c, d, g}
and S2 = {e, f, h, i}. Then, given such a partition,
it can be proven that there is at least one maximal
path P in the base ATG such that all vertices in
one set that are adjacent to a vertex in the other
set are either in P or adjacent to some vertex in
P. For example, a maximal path for S1 and S2 is
</bodyText>
<equation confidence="0.62409">
P = e g.
</equation>
<bodyText confidence="0.9991961">
An entry in the chart induces two such parti-
tions, one at the left edge of the entry and one at
the right edge. Therefore, we obtain two such max-
imal paths and for any ATG G in this entry and any
vertex v not in or adjacent to one of these paths, ei-
ther v is not in G or v has the same neighbourhood
in G as it has in the base ATG. Then, the number
of vertices adjacent to vertices in these paths can
be as many as n. However, if we put these vertices
into sets such that vertices in a set have identical
</bodyText>
<page confidence="0.987142">
222
</page>
<bodyText confidence="0.99889625">
\x0cneighbourhoods, the number of sets is dependant
only on k.
In the worst case, the out-neighbourhood of one
of these sets can be any set of these sets. So, we
get a bound for f(n) to be O(k24k). Therefore,
because k is constant in Lk, f(n) is constant and
the running time of the algorithm for Lk is O(n5)
in the worst case.
</bodyText>
<subsectionHeader confidence="0.875771">
6.2 Runtime for L
</subsectionHeader>
<bodyText confidence="0.98511375">
Despite the results of section 6.1, this algorithm
has an exponential running time for L. We demon-
strate this with the following set of parameterized
sequents:
</bodyText>
<equation confidence="0.999606333333333">
F(1) = ((A/A)\\A)\\A
F(i) = ((A/(A/Fi1))\\A)\\A for i &amp;gt; 1
U(n) = Fn Fn A\\A
</equation>
<bodyText confidence="0.980499">
Theorem. There are (2n1)!
n!(n1)! (4n) distinct
arcs in the entry from n to 3n 1 in the chart for
U(n).
Proof. By induction and a mapping from the pos-
sible matchings to the possible permutations of a
sequence of length 2n 1 such that two subse-
quences of length n and n 1 are in order.
</bodyText>
<sectionHeader confidence="0.994818" genericHeader="conclusions">
7 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999627545454545">
We have presented a novel algorithm for parsing in
the Lambek calculus, sketched its correctness and
shown that it is polynomial time in the bounded-
order case. Furthermore, we presented a set of pa-
rameterized sequents proving that the algorithm is
exponential time in the general case, which aids
future research in finding either a polynomial time
algorithm or an NP-completeness proof for L.
In addition, this algorithm provides another step
toward evaluating the Lambek calculus against
both CFGs (to evaluate the importance of Cate-
gorial Grammar) and CCG (to evaluate the impor-
tance of the mildly context-sensitive languages).
In the future, we plan on determining the run-
ning time of this algorithm on an actual corpus,
such as a modified version of CCGbank, and
then to empirically evaluate the Lambek calculus
for natural language processing. In addition, we
would like to investigate extending this algorithm
to more complex variants of the Lambek calculus
such as the multi-modal calculus using the proof
nets of Moot and Puite (2002).
</bodyText>
<sectionHeader confidence="0.966915" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.996479">
Many thanks to Gerald Penn, for his insightful
comments and for guiding this research.
</bodyText>
<sectionHeader confidence="0.986587" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997916068181818">
Aarts, Erik. 1994. Proving Theorems of the Second
Order Lambek Calculus in Polynomial Time. Studia
Logica, 53:373387.
Ajdukiewicz, Kazimierz. 1935. Die syntaktische Kon-
nexitat. Studia Philosophica, 1(1-27).
Bos, Johan and Katja Markert. 2005. Recognising tex-
tual entailment with logical inference. Proceedings
of HLT and EMNLP, pages 628635.
Carpenter, Bob and Glyn Morrill. 2005. Switch Graphs
for Parsing Type Logical Grammars. Proceedings of
IWPT 05, Vancouver.
Clark, Steven and James R. Curran. 2004. Parsing the
WSJ using CCG and log-linear models. Proceedings
of ACL 04, pages 104111.
Dowty, David R., Robert E. Wall, and Stanley Peters.
1981. Introduction to Montague Semantics. Reidel.
Hockenmaier, Julia. 2003. Data and Models for Sta-
tistical Parsing with Combinatory Categorial Gram-
mar. Ph.D. thesis, University of Edinburgh.
Joshi, Aravind K., K. Vijay-Shanker, and David J. Weir.
1989. The Convergence of Mildly Context-sensitive
Grammar Formalisms. University of Pennsylvania.
Lambek, Joachim. 1958. The mathematics of sen-
tence structure. American Mathematical Monthly,
65:154170.
Montague, Richard. 1974. Formal philosophy: se-
lected papers of Richard Montague. Yale University
Press New Haven.
Moortgat, Michael. 1996. Multimodal linguistic infer-
ence. Journal of Logic, Language and Information,
5(3):349385.
Moot, Richard and Quintijn Puite. 2002. Proof Nets for
the Multimodal Lambek Calculus. Studia Logica,
71(3):415442.
Pentus, Mati. 1997. Product-Free Lambek Calculus
and Context-Free Grammars. The Journal of Sym-
bolic Logic, 62(2):648660.
Pentus, Mati. 2006. Lambek calculus is NP-complete.
Theoretical Computer Science, 357(1-3):186201.
Roorda, Dirk. 1991. Resource Logics: Proof-
theoretical Investigations. Ph.D. thesis, Universiteit
van Amsterdam.
Steedman, Mark. 2000. The Syntactic Process. Brad-
ford Books.
</reference>
<page confidence="0.97693">
223
</page>
<reference confidence="0.8251623">
\x0cVijay-Shanker, K. and David J. Weir. 1994. Parsing
Some Constrained Grammar Formalisms. Computa-
tional Linguistics, 19(4):591636.
Appendix. Algorithm Pseudocode
The term source set refers to the out-
neighbourhood of . The term minus variable
refers to surface variables obtained from negative
axiomatic formulae plus . Xi refers to the ith
axiomatic formula.
Algorithm 1 Chart Iteration
</reference>
<listItem confidence="0.9825074">
1: for i = 0 to n 1 do
2: Bracketing(B, Xi, Xi+1)
3: for l = 1, 3, 5, . . . to n 1 do
4: for e = 0 to n l 1 do
5: for each arc from e to e + l with ATG G do
6: Bracketing(G, Xe1 to Xe+l+1)
7: Adjoin G to ATGs from e l 1 to e 1
8: for al = 1, 3, ..., l 2 do
9: Adjoin G to ATGs from e al 1 to e 1
10: Adjoin G to ATGs from e+l+1 to e+l+al+1
</listItem>
<figure confidence="0.872915461538462">
Algorithm 2 Bracketing(G, Xi, Xj)
1: Ci
pi
: li = Xi and Cj
pj
: lj = Xj
2: if Ci 6= Cj then
3: V iolation : Mismatched Basic Categories
4: if pi = pj then
5: V iolation : Mismatched Polarities
6: Let m, p {i, j} such that pm is negative and pp is
positive
7: if G is not from 1 to n 1 and the source set of G is the
</figure>
<bodyText confidence="0.959525384615385">
singleton lp and lm has out-degree 0 in G then
8: V iolation : Empty Source Set
9: if the edge hlm, lpi G then
10: V iolation : Cycle Exists
11: if lp is in the source set of G and there exists an in-edge
of m with label l such that no edge from p to m has label
l and no edge from a vertex other than p to a vertex other
than m has label l then
12: V iolation : Path Completion Impossible
13: if m has out-degree 0 and and there exists an out-edge
of p with label l such that no edge from p to m has label
l and no edge from a vertex other than p to a vertex other
than m has label l then
</bodyText>
<listItem confidence="0.721785375">
14: V iolation : Path Completion Impossible
15: Copy G to yield H
16: for each edge hlp, lm, li G do
17: Delete all edges from H with label l
18: Delete lm, lp and all their incident edges from H
19: Let inp be the in-neighbour of lp in G
20: for each q in the out-neighbourhood of lm in G do
21: Insert hinp, qi into H
</listItem>
<reference confidence="0.902280740740741">
22: for each edge hp, d, li in G do
23: Insert hq, d, li into H
24: for each edge hq, m, li in G do
25: Insert hq, inp, li into H
26: if H contains a cycle then
27: V iolation : Future Cycle Required
28: return H
Algorithm 3 Adjoining(G1, G2)
1: Let VH be the intersection of the vertices in G1 and G2
2: if VH 6= and Fore(, G1, G2) VH = then
3: V iolation : Empty Source Set
4: for each l such that l labels an edge in G1 and G2 do
5: Let hp, m, li be the unique edge labelled l in B
6: if Fore(p, G1, G2, l) Back(m, G1, G2) = then
7: if Fore(p) VH = then
8: V iolation : Path Completion Impossible
9: if Back(m) VH = then
10: V iolation : Path Completion Impossible
11: Let H be the graph with vertex set VH and no edges
12: for each minus variable m VH do
13: for each p Fore(m, G1, G2, ) do
14: Insert hm, pi into H
15: for each l such that l labels an edge in G1 and G2 do
16: Let hp, m, li be the unique edge labelled l in B
17: if Fore(p, G1, G2, l) Back(m, G1, G2) = then
18: for each q Fore(p, G1, G2, l) VH do
19: Insert hq, Back(m, G1, G2) VH, li into H
</reference>
<figure confidence="0.963423083333333">
20: return H
Algorithm 4 Fore(v, G1, G2, l)
1: if v G1 and v G2 then
2: return {v}
3: else
4: if v is a minus vertex then
5: S = i{1,2}Out-neighbourhoodGi
v
6: else if v is a plus vertex then
7: Let j be such that v Gj
8: S = eEdges labelled bylSource of e
F = S
</figure>
<listItem confidence="0.857865142857143">
9: while S is not empty do
10: Remove any element u from S
11: Let m be the in-neighbour of u in B
12: if u does not appear in one of G1, G2 and m does
not appear in the other then
13: Let i be such that m Gi
14: Let O be the out-neighbourhood of m in Gi
</listItem>
<figure confidence="0.966754486486487">
15: S = S O
16: F = F O
17: F = F {m}
18: return F
Algorithm 5 Back(m, G1, G2)
1: if m G1 and m G2 then
2: return {m}
3: else
4: Let i, j {1, 2} be such that m Gi and m /
Gj
5: Let m
be the destination of the edges labelled by m
in Gj
6: M = {m, m
}
7: while m
/
G1 and m
/
G2 do
8: Let i
, j
{1, 2} be such that m
Gi and m
/
Gj
9: Let p Gj be an out-neighbour of m
in B
10: Let m
be the in-neighbour of p in Gj
11: m
= m
12: M = M {m
}
13: return M
224
\x0c&amp;apos;
</figure>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.501153">
<note confidence="0.6902235">b&amp;apos;Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 217224 Manchester, August 2008</note>
<title confidence="0.994412">Efficient Parsing with the Product-Free Lambek Calculus</title>
<author confidence="0.999947">Timothy A D Fowler</author>
<affiliation confidence="0.9999295">Department of Computer Science University of Toronto</affiliation>
<address confidence="0.999502">10 Kings College Road, Toronto, ON, M5S 3G4, Canada</address>
<email confidence="0.999896">tfowler@cs.toronto.edu</email>
<abstract confidence="0.999707615384615">This paper provides a parsing algorithm for the Lambek calculus which is polynomial time for a more general fragment of the Lambek calculus than any previously known algorithm. The algorithm runs in worst-case time O(n5) when restricted to a certain fragment of the Lambek calculus which is motivated by empirical analysis. In addition, a set of parameterized inputs are given, showing why the algorithm has exponential worst-case running time for the Lambek calculus in general.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Erik Aarts</author>
</authors>
<date>1994</date>
<booktitle>Proving Theorems of the Second Order Lambek Calculus in Polynomial Time. Studia Logica,</booktitle>
<pages>53--373387</pages>
<contexts>
<context position="7003" citStr="Aarts (1994)" startWordPosition="1142" endWordPosition="1143">argument implications, is defined as: o() = 0 for a basic category o(/) = o(\\) = max(o(), o() + 1) For example, o((NP\\S)/NP) = 1 and o((S/ NP)\\(S/NP)) = 2. 3 Related work Two other papers have provided algorithms similar to the one presented here. Carpenter and Morrill (2005) provided a graph representation and a dynamic programming algorithm for parsing in the Lambek calculus with product. However, due to there use of the Lambek calculus with product and to their choice of correctness conditions, they did not obtain a polynomial time algorithm for any significant fragment of the calculus. Aarts (1994) provided an algorithm for L2 which is not correct for L. Ours is polynomial time for Lk, for any constant k, and is correct for L, albeit in exponential running time. A number of authors have provided polynomial time algorithms for parsing with CCG which gives some insight into how good our bound of O(n5) is. In particular, Vijay-Shanker and Weir (1994) provided a chart parsing algorithm for CCG with a time bound of O(n6). 4 An algorithm for parsing with L This section presents a chart parsing algorithm similar to CYK where entries in the chart are arcs annotated with graphs. The graphs will </context>
</contexts>
<marker>Aarts, 1994</marker>
<rawString>Aarts, Erik. 1994. Proving Theorems of the Second Order Lambek Calculus in Polynomial Time. Studia Logica, 53:373387.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kazimierz Ajdukiewicz</author>
</authors>
<date>1935</date>
<booktitle>Die syntaktische Konnexitat. Studia Philosophica,</booktitle>
<pages>1--1</pages>
<contexts>
<context position="1108" citStr="Ajdukiewicz, 1935" startWordPosition="166" endWordPosition="167">any previously known algorithm. The algorithm runs in worst-case time O(n5) when restricted to a certain fragment of the Lambek calculus which is motivated by empirical analysis. In addition, a set of parameterized inputs are given, showing why the algorithm has exponential worst-case running time for the Lambek calculus in general. 1 Introduction A wide variety of grammar formalisms have been explored in the past for parsing natural language sentences. The most prominent of these formalisms has been context free grammars (CFGs) but a collection of formalisms known as categorial grammar (CG) (Ajdukiewicz, 1935; Dowty et al., 1981; Steedman, 2000) has received interest because of some significant advantages over CFGs. First, CG is inherently lexicalized due to the fact that all of the variation between grammars is captured by the lexicon. This is a result of the rich categories which CG uses in its lexicon to specify the functor-argument relationships between lexical items. A distinct advantage of this lexicalization is that the processing of sentences depends upon only those categories contained in the string and not some global set of rules. Second, CG has the advantage that it centrally adopts th</context>
</contexts>
<marker>Ajdukiewicz, 1935</marker>
<rawString>Ajdukiewicz, Kazimierz. 1935. Die syntaktische Konnexitat. Studia Philosophica, 1(1-27).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan Bos</author>
<author>Katja Markert</author>
</authors>
<title>Recognising textual entailment with logical inference.</title>
<date>2005</date>
<booktitle>Proceedings of HLT and EMNLP,</booktitle>
<pages>628635</pages>
<contexts>
<context position="2597" citStr="Bos and Markert (2005)" startWordPosition="388" endWordPosition="391">ng the semantic derivation to exactly parallel the syntactic derivation. This leads to a semantical form which is easily extractable from the syntactic parse. A large number of CG formalisms have been introduced including, among others, the Lambek calculus (Lambek, 1958) and Combinatory Categorial Grammar (CCG) (Steedman, 2000). Of these, CCG has received the most zealous computational attention. Impressive results have been achieved culminating in the state-of-the-art parser of Clark and Curran (2004) which has been used as the parser for the Pascal Rich Textual Entailment Challenge entry of Bos and Markert (2005). The appeal of CCG can be attributed to the existence of efficient parsing algorithms for it and the fact that it recognizes a mildly context-sensitive language class (Joshi et al., 1989), a language class more powerful than the context free languages (CFLs) that has been argued to be necessary for natural language syntax. The Lambek calculus provides an ideal contrast between CCG and CFGs by being a CG formalism like CCG but by recognizing the CFLs like CFGs (Pentus, 1997). The primary goal of this paper is to provide an algorithm for parsing with the Lambek calculus and to sketch its correc</context>
</contexts>
<marker>Bos, Markert, 2005</marker>
<rawString>Bos, Johan and Katja Markert. 2005. Recognising textual entailment with logical inference. Proceedings of HLT and EMNLP, pages 628635.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bob Carpenter</author>
<author>Glyn Morrill</author>
</authors>
<title>Switch Graphs for Parsing Type Logical Grammars.</title>
<date>2005</date>
<booktitle>Proceedings of IWPT 05,</booktitle>
<location>Vancouver.</location>
<contexts>
<context position="6670" citStr="Carpenter and Morrill (2005)" startWordPosition="1085" endWordPosition="1088"> of order bounded by k. The order of a category, which can 2 We use Ajdukiewicz notation, not Steedman notation. \\ \\ / / Figure 1: The sequent presentation of L. NP NP S S NP NP S S NP NP\\S S NP\\S NP\\S S/(NP\\S) NP\\S S S/(NP\\S) (NP\\S)/NP NP S Who loves him Figure 2: A derivation for Who loves him?. be viewed as the depth of the nesting of argument implications, is defined as: o() = 0 for a basic category o(/) = o(\\) = max(o(), o() + 1) For example, o((NP\\S)/NP) = 1 and o((S/ NP)\\(S/NP)) = 2. 3 Related work Two other papers have provided algorithms similar to the one presented here. Carpenter and Morrill (2005) provided a graph representation and a dynamic programming algorithm for parsing in the Lambek calculus with product. However, due to there use of the Lambek calculus with product and to their choice of correctness conditions, they did not obtain a polynomial time algorithm for any significant fragment of the calculus. Aarts (1994) provided an algorithm for L2 which is not correct for L. Ours is polynomial time for Lk, for any constant k, and is correct for L, albeit in exponential running time. A number of authors have provided polynomial time algorithms for parsing with CCG which gives some </context>
</contexts>
<marker>Carpenter, Morrill, 2005</marker>
<rawString>Carpenter, Bob and Glyn Morrill. 2005. Switch Graphs for Parsing Type Logical Grammars. Proceedings of IWPT 05, Vancouver.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven Clark</author>
<author>James R Curran</author>
</authors>
<title>Parsing the WSJ using CCG and log-linear models.</title>
<date>2004</date>
<booktitle>Proceedings of ACL 04,</booktitle>
<pages>104111</pages>
<contexts>
<context position="2482" citStr="Clark and Curran (2004)" startWordPosition="368" endWordPosition="371"> license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. grammar (Montague, 1974), allowing the semantic derivation to exactly parallel the syntactic derivation. This leads to a semantical form which is easily extractable from the syntactic parse. A large number of CG formalisms have been introduced including, among others, the Lambek calculus (Lambek, 1958) and Combinatory Categorial Grammar (CCG) (Steedman, 2000). Of these, CCG has received the most zealous computational attention. Impressive results have been achieved culminating in the state-of-the-art parser of Clark and Curran (2004) which has been used as the parser for the Pascal Rich Textual Entailment Challenge entry of Bos and Markert (2005). The appeal of CCG can be attributed to the existence of efficient parsing algorithms for it and the fact that it recognizes a mildly context-sensitive language class (Joshi et al., 1989), a language class more powerful than the context free languages (CFLs) that has been argued to be necessary for natural language syntax. The Lambek calculus provides an ideal contrast between CCG and CFGs by being a CG formalism like CCG but by recognizing the CFLs like CFGs (Pentus, 1997). The </context>
</contexts>
<marker>Clark, Curran, 2004</marker>
<rawString>Clark, Steven and James R. Curran. 2004. Parsing the WSJ using CCG and log-linear models. Proceedings of ACL 04, pages 104111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David R Dowty</author>
<author>Robert E Wall</author>
<author>Stanley Peters</author>
</authors>
<title>Introduction to Montague Semantics.</title>
<date>1981</date>
<publisher>Reidel.</publisher>
<contexts>
<context position="1128" citStr="Dowty et al., 1981" startWordPosition="168" endWordPosition="171">n algorithm. The algorithm runs in worst-case time O(n5) when restricted to a certain fragment of the Lambek calculus which is motivated by empirical analysis. In addition, a set of parameterized inputs are given, showing why the algorithm has exponential worst-case running time for the Lambek calculus in general. 1 Introduction A wide variety of grammar formalisms have been explored in the past for parsing natural language sentences. The most prominent of these formalisms has been context free grammars (CFGs) but a collection of formalisms known as categorial grammar (CG) (Ajdukiewicz, 1935; Dowty et al., 1981; Steedman, 2000) has received interest because of some significant advantages over CFGs. First, CG is inherently lexicalized due to the fact that all of the variation between grammars is captured by the lexicon. This is a result of the rich categories which CG uses in its lexicon to specify the functor-argument relationships between lexical items. A distinct advantage of this lexicalization is that the processing of sentences depends upon only those categories contained in the string and not some global set of rules. Second, CG has the advantage that it centrally adopts the principle of compo</context>
</contexts>
<marker>Dowty, Wall, Peters, 1981</marker>
<rawString>Dowty, David R., Robert E. Wall, and Stanley Peters. 1981. Introduction to Montague Semantics. Reidel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia Hockenmaier</author>
</authors>
<title>Data and Models for Statistical Parsing with Combinatory Categorial Grammar.</title>
<date>2003</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Edinburgh.</institution>
<contexts>
<context position="3496" citStr="Hockenmaier, 2003" startWordPosition="543" endWordPosition="544">to be necessary for natural language syntax. The Lambek calculus provides an ideal contrast between CCG and CFGs by being a CG formalism like CCG but by recognizing the CFLs like CFGs (Pentus, 1997). The primary goal of this paper is to provide an algorithm for parsing with the Lambek calculus and to sketch its correctness. Furthermore, a time bound of O(n5) will be shown for this algorithm when restricted to product-free categories of bounded order (see section 2 for a definition). The restriction to bounded order is not a significant restriction, due to the fact that categories in CCGbank1 (Hockenmaier, 2003), a CCG corpus, have a maximum order of 5 and an average order of 0.78 by token. In addition to the presentation of the algorithm, we will provide a parameterized set of in1 Although CCGbank was built for CCG, we believe that transforming it into a Lambek calculus bank is feasible. 217 \x0cputs (of unbounded order) on which the algorithm has exponential running time. The variant of the Lambek calculus considered here is the product-free Lambek calculus chosen for three reasons. First, it is the foundation of all other non-associative variants of the Lambek calculus including the original Lambe</context>
</contexts>
<marker>Hockenmaier, 2003</marker>
<rawString>Hockenmaier, Julia. 2003. Data and Models for Statistical Parsing with Combinatory Categorial Grammar. Ph.D. thesis, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aravind K Joshi</author>
<author>K Vijay-Shanker</author>
<author>David J Weir</author>
</authors>
<title>The Convergence of Mildly Context-sensitive Grammar Formalisms.</title>
<date>1989</date>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="2785" citStr="Joshi et al., 1989" startWordPosition="419" endWordPosition="422">have been introduced including, among others, the Lambek calculus (Lambek, 1958) and Combinatory Categorial Grammar (CCG) (Steedman, 2000). Of these, CCG has received the most zealous computational attention. Impressive results have been achieved culminating in the state-of-the-art parser of Clark and Curran (2004) which has been used as the parser for the Pascal Rich Textual Entailment Challenge entry of Bos and Markert (2005). The appeal of CCG can be attributed to the existence of efficient parsing algorithms for it and the fact that it recognizes a mildly context-sensitive language class (Joshi et al., 1989), a language class more powerful than the context free languages (CFLs) that has been argued to be necessary for natural language syntax. The Lambek calculus provides an ideal contrast between CCG and CFGs by being a CG formalism like CCG but by recognizing the CFLs like CFGs (Pentus, 1997). The primary goal of this paper is to provide an algorithm for parsing with the Lambek calculus and to sketch its correctness. Furthermore, a time bound of O(n5) will be shown for this algorithm when restricted to product-free categories of bounded order (see section 2 for a definition). The restriction to </context>
</contexts>
<marker>Joshi, Vijay-Shanker, Weir, 1989</marker>
<rawString>Joshi, Aravind K., K. Vijay-Shanker, and David J. Weir. 1989. The Convergence of Mildly Context-sensitive Grammar Formalisms. University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joachim Lambek</author>
</authors>
<title>The mathematics of sentence structure.</title>
<date>1958</date>
<pages>65--154170</pages>
<publisher>American Mathematical Monthly,</publisher>
<contexts>
<context position="2246" citStr="Lambek, 1958" startWordPosition="336" endWordPosition="337">obal set of rules. Second, CG has the advantage that it centrally adopts the principle of compositionality, as outlined in Montague c 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. grammar (Montague, 1974), allowing the semantic derivation to exactly parallel the syntactic derivation. This leads to a semantical form which is easily extractable from the syntactic parse. A large number of CG formalisms have been introduced including, among others, the Lambek calculus (Lambek, 1958) and Combinatory Categorial Grammar (CCG) (Steedman, 2000). Of these, CCG has received the most zealous computational attention. Impressive results have been achieved culminating in the state-of-the-art parser of Clark and Curran (2004) which has been used as the parser for the Pascal Rich Textual Entailment Challenge entry of Bos and Markert (2005). The appeal of CCG can be attributed to the existence of efficient parsing algorithms for it and the fact that it recognizes a mildly context-sensitive language class (Joshi et al., 1989), a language class more powerful than the context free langua</context>
<context position="4121" citStr="Lambek, 1958" startWordPosition="647" endWordPosition="648">us, have a maximum order of 5 and an average order of 0.78 by token. In addition to the presentation of the algorithm, we will provide a parameterized set of in1 Although CCGbank was built for CCG, we believe that transforming it into a Lambek calculus bank is feasible. 217 \x0cputs (of unbounded order) on which the algorithm has exponential running time. The variant of the Lambek calculus considered here is the product-free Lambek calculus chosen for three reasons. First, it is the foundation of all other non-associative variants of the Lambek calculus including the original Lambek calculus (Lambek, 1958) and the multi-modal Lambek calculus (Moortgat, 1996). Second, the calculus with product is NP-complete (Pentus, 2006), while the sequent derivability in the product-free fragment is still unknown. Finally, the only connectives included are / and \\, which are the same connectives as in CCG, providing a corpus for future work such as building a probabilistic Lambek calculus parser. 2 Problem specification Parsing with the Lambek calculus is treated as a logical derivation problem. First, the words of a sentence are assigned categories which are built from basic categories (e.g. NP and S) and t</context>
</contexts>
<marker>Lambek, 1958</marker>
<rawString>Lambek, Joachim. 1958. The mathematics of sentence structure. American Mathematical Monthly, 65:154170.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Montague</author>
</authors>
<title>Formal philosophy: selected papers of Richard Montague.</title>
<date>1974</date>
<publisher>Yale University Press</publisher>
<location>New Haven.</location>
<contexts>
<context position="1967" citStr="Montague, 1974" startWordPosition="293" endWordPosition="294">esult of the rich categories which CG uses in its lexicon to specify the functor-argument relationships between lexical items. A distinct advantage of this lexicalization is that the processing of sentences depends upon only those categories contained in the string and not some global set of rules. Second, CG has the advantage that it centrally adopts the principle of compositionality, as outlined in Montague c 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. grammar (Montague, 1974), allowing the semantic derivation to exactly parallel the syntactic derivation. This leads to a semantical form which is easily extractable from the syntactic parse. A large number of CG formalisms have been introduced including, among others, the Lambek calculus (Lambek, 1958) and Combinatory Categorial Grammar (CCG) (Steedman, 2000). Of these, CCG has received the most zealous computational attention. Impressive results have been achieved culminating in the state-of-the-art parser of Clark and Curran (2004) which has been used as the parser for the Pascal Rich Textual Entailment Challenge e</context>
</contexts>
<marker>Montague, 1974</marker>
<rawString>Montague, Richard. 1974. Formal philosophy: selected papers of Richard Montague. Yale University Press New Haven.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Moortgat</author>
</authors>
<title>Multimodal linguistic inference.</title>
<date>1996</date>
<journal>Journal of Logic, Language and Information,</journal>
<volume>5</volume>
<issue>3</issue>
<contexts>
<context position="4174" citStr="Moortgat, 1996" startWordPosition="655" endWordPosition="656">of 0.78 by token. In addition to the presentation of the algorithm, we will provide a parameterized set of in1 Although CCGbank was built for CCG, we believe that transforming it into a Lambek calculus bank is feasible. 217 \x0cputs (of unbounded order) on which the algorithm has exponential running time. The variant of the Lambek calculus considered here is the product-free Lambek calculus chosen for three reasons. First, it is the foundation of all other non-associative variants of the Lambek calculus including the original Lambek calculus (Lambek, 1958) and the multi-modal Lambek calculus (Moortgat, 1996). Second, the calculus with product is NP-complete (Pentus, 2006), while the sequent derivability in the product-free fragment is still unknown. Finally, the only connectives included are / and \\, which are the same connectives as in CCG, providing a corpus for future work such as building a probabilistic Lambek calculus parser. 2 Problem specification Parsing with the Lambek calculus is treated as a logical derivation problem. First, the words of a sentence are assigned categories which are built from basic categories (e.g. NP and S) and the connectives \\ and /. For example, the category fo</context>
</contexts>
<marker>Moortgat, 1996</marker>
<rawString>Moortgat, Michael. 1996. Multimodal linguistic inference. Journal of Logic, Language and Information, 5(3):349385.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Moot</author>
<author>Quintijn Puite</author>
</authors>
<title>Proof Nets for the Multimodal Lambek Calculus.</title>
<date>2002</date>
<journal>Studia Logica,</journal>
<volume>71</volume>
<issue>3</issue>
<marker>Moot, Puite, 2002</marker>
<rawString>Moot, Richard and Quintijn Puite. 2002. Proof Nets for the Multimodal Lambek Calculus. Studia Logica, 71(3):415442.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mati Pentus</author>
</authors>
<title>Product-Free Lambek Calculus and Context-Free Grammars.</title>
<date>1997</date>
<journal>The Journal of Symbolic Logic,</journal>
<volume>62</volume>
<issue>2</issue>
<contexts>
<context position="3076" citStr="Pentus, 1997" startWordPosition="471" endWordPosition="472">k and Curran (2004) which has been used as the parser for the Pascal Rich Textual Entailment Challenge entry of Bos and Markert (2005). The appeal of CCG can be attributed to the existence of efficient parsing algorithms for it and the fact that it recognizes a mildly context-sensitive language class (Joshi et al., 1989), a language class more powerful than the context free languages (CFLs) that has been argued to be necessary for natural language syntax. The Lambek calculus provides an ideal contrast between CCG and CFGs by being a CG formalism like CCG but by recognizing the CFLs like CFGs (Pentus, 1997). The primary goal of this paper is to provide an algorithm for parsing with the Lambek calculus and to sketch its correctness. Furthermore, a time bound of O(n5) will be shown for this algorithm when restricted to product-free categories of bounded order (see section 2 for a definition). The restriction to bounded order is not a significant restriction, due to the fact that categories in CCGbank1 (Hockenmaier, 2003), a CCG corpus, have a maximum order of 5 and an average order of 0.78 by token. In addition to the presentation of the algorithm, we will provide a parameterized set of in1 Althou</context>
</contexts>
<marker>Pentus, 1997</marker>
<rawString>Pentus, Mati. 1997. Product-Free Lambek Calculus and Context-Free Grammars. The Journal of Symbolic Logic, 62(2):648660.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mati Pentus</author>
</authors>
<title>Lambek calculus is NP-complete.</title>
<date>2006</date>
<journal>Theoretical Computer Science,</journal>
<pages>357--1</pages>
<contexts>
<context position="4239" citStr="Pentus, 2006" startWordPosition="664" endWordPosition="665"> we will provide a parameterized set of in1 Although CCGbank was built for CCG, we believe that transforming it into a Lambek calculus bank is feasible. 217 \x0cputs (of unbounded order) on which the algorithm has exponential running time. The variant of the Lambek calculus considered here is the product-free Lambek calculus chosen for three reasons. First, it is the foundation of all other non-associative variants of the Lambek calculus including the original Lambek calculus (Lambek, 1958) and the multi-modal Lambek calculus (Moortgat, 1996). Second, the calculus with product is NP-complete (Pentus, 2006), while the sequent derivability in the product-free fragment is still unknown. Finally, the only connectives included are / and \\, which are the same connectives as in CCG, providing a corpus for future work such as building a probabilistic Lambek calculus parser. 2 Problem specification Parsing with the Lambek calculus is treated as a logical derivation problem. First, the words of a sentence are assigned categories which are built from basic categories (e.g. NP and S) and the connectives \\ and /. For example, the category for transitive verbs is (NP\\S)/NP and the category for adverbs is </context>
</contexts>
<marker>Pentus, 2006</marker>
<rawString>Pentus, Mati. 2006. Lambek calculus is NP-complete. Theoretical Computer Science, 357(1-3):186201.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dirk Roorda</author>
</authors>
<title>Resource Logics: Prooftheoretical Investigations.</title>
<date>1991</date>
<tech>Ph.D. thesis,</tech>
<institution>Universiteit van Amsterdam.</institution>
<contexts>
<context position="7862" citStr="Roorda (1991)" startWordPosition="1290" endWordPosition="1291">CCG which gives some insight into how good our bound of O(n5) is. In particular, Vijay-Shanker and Weir (1994) provided a chart parsing algorithm for CCG with a time bound of O(n6). 4 An algorithm for parsing with L This section presents a chart parsing algorithm similar to CYK where entries in the chart are arcs annotated with graphs. The graphs will be referred 218 \x0cto as abstract term graphs (ATGs) since they are graph representations of abstractions over semantic terms. ATGs will be presented in this section by construction. See section 5 for their connection to the proof structures of Roorda (1991). The algorithm consists of two steps. First, the base case is computed by building the base ATG B and determining the set of surface variables by using the proof frames of Roorda (1991). Second, the chart is filled in iteratively according to the algorithms specified in the appendix. The details for these two steps can be found in sections 4.1 and 4.2, respectively. Section 4.3 introduces a procedure for culling extraneous ATGs which is necessary for the polynomial time proof and section 4.4 discusses recovery of proofs from the packed chart. An example of the algorithm is given in figure 3. </context>
<context position="19434" citStr="Roorda, 1991" startWordPosition="3576" endWordPosition="3577"> this section: 221 \x0cS : ab S + : c NP : d NP\\S + : b S/(NP\\S) : a NP + : g S : efg NP\\S : ef NP + : f (NP\\S)/NP : e NP : h S + : i Figure 6: A proof structure for Who loves him?. Definition. A partial proof structure is a proof frame together with a matching of the axiomatic formulae. A proof structure is a partial proof structure whose matching is complete. An example is given in figure 6. Proof structures correspond to proofs under certain conditions and our conditions will be based on the semantic term of the proof given to us by the Curry-Howard isomorphism for the Lambek calculus (Roorda, 1991). To do this, we interpret left rules as functional application and right rules as functional abstraction of lambda terms. Under this interpretation, the semantic term obtained from the proof structure in figure 6 is ad.ehd. As in Roorda (1991), proof structures correspond to a proof if the semantic term assigned to the sentence category is a well formed lambda term which includes all the terms assigned to the words of the sentence. Then, ATGs are graph representations of abstractions of the undetermined portion of semantic terms of partial proof structures. Unlabeled edges correspond to funct</context>
</contexts>
<marker>Roorda, 1991</marker>
<rawString>Roorda, Dirk. 1991. Resource Logics: Prooftheoretical Investigations. Ph.D. thesis, Universiteit van Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>The Syntactic Process.</title>
<date>2000</date>
<publisher>Bradford Books.</publisher>
<contexts>
<context position="1145" citStr="Steedman, 2000" startWordPosition="172" endWordPosition="173">orithm runs in worst-case time O(n5) when restricted to a certain fragment of the Lambek calculus which is motivated by empirical analysis. In addition, a set of parameterized inputs are given, showing why the algorithm has exponential worst-case running time for the Lambek calculus in general. 1 Introduction A wide variety of grammar formalisms have been explored in the past for parsing natural language sentences. The most prominent of these formalisms has been context free grammars (CFGs) but a collection of formalisms known as categorial grammar (CG) (Ajdukiewicz, 1935; Dowty et al., 1981; Steedman, 2000) has received interest because of some significant advantages over CFGs. First, CG is inherently lexicalized due to the fact that all of the variation between grammars is captured by the lexicon. This is a result of the rich categories which CG uses in its lexicon to specify the functor-argument relationships between lexical items. A distinct advantage of this lexicalization is that the processing of sentences depends upon only those categories contained in the string and not some global set of rules. Second, CG has the advantage that it centrally adopts the principle of compositionality, as o</context>
</contexts>
<marker>Steedman, 2000</marker>
<rawString>Steedman, Mark. 2000. The Syntactic Process. Bradford Books.</rawString>
</citation>
<citation valid="false">
<authors>
<author>K \x0cVijay-Shanker</author>
<author>David J Weir</author>
</authors>
<title>Parsing Some Constrained Grammar Formalisms. Computational Linguistics, 19(4):591636. Appendix. Algorithm Pseudocode The term source set refers to the outneighbourhood of . The term minus variable refers to surface variables obtained from negative axiomatic formulae plus . Xi refers to the ith axiomatic formula. Algorithm 1 Chart Iteration 22: for each edge hp, d, li in G do 23: Insert hq, d, li into H 24: for each edge hq, m, li in G do 25: Insert hq, inp, li into H 26: if H contains a cycle then 27: V iolation : Future Cycle Required 28: return</title>
<date>1994</date>
<journal>H Algorithm</journal>
<booktitle>Adjoining(G1, G2) 1: Let VH be the intersection of the vertices in G1 and G2 2: if VH 6= and Fore(, G1, G2) VH = then</booktitle>
<volume>3</volume>
<marker>\x0cVijay-Shanker, Weir, 1994</marker>
<rawString>\x0cVijay-Shanker, K. and David J. Weir. 1994. Parsing Some Constrained Grammar Formalisms. Computational Linguistics, 19(4):591636. Appendix. Algorithm Pseudocode The term source set refers to the outneighbourhood of . The term minus variable refers to surface variables obtained from negative axiomatic formulae plus . Xi refers to the ith axiomatic formula. Algorithm 1 Chart Iteration 22: for each edge hp, d, li in G do 23: Insert hq, d, li into H 24: for each edge hq, m, li in G do 25: Insert hq, inp, li into H 26: if H contains a cycle then 27: V iolation : Future Cycle Required 28: return H Algorithm 3 Adjoining(G1, G2) 1: Let VH be the intersection of the vertices in G1 and G2 2: if VH 6= and Fore(, G1, G2) VH = then 3: V iolation : Empty Source Set 4: for each l such that l labels an edge in G1 and G2 do 5: Let hp, m, li be the unique edge labelled l in B 6: if Fore(p, G1, G2, l) Back(m, G1, G2) = then 7: if Fore(p) VH = then 8: V iolation : Path Completion Impossible 9: if Back(m) VH = then 10: V iolation : Path Completion Impossible 11: Let H be the graph with vertex set VH and no edges 12: for each minus variable m VH do 13: for each p Fore(m, G1, G2, ) do 14: Insert hm, pi into H 15: for each l such that l labels an edge in G1 and G2 do 16: Let hp, m, li be the unique edge labelled l in B 17: if Fore(p, G1, G2, l) Back(m, G1, G2) = then 18: for each q Fore(p, G1, G2, l) VH do 19: Insert hq, Back(m, G1, G2) VH, li into H</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>