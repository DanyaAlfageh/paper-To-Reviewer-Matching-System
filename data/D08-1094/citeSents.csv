 Expectations affect reading times CITATION, the interpretation of participles CITATION, and sentence processing generally (CITATION; CITATION),,
 Expectations exist both for verbs and nouns (CITATION; CITATION),,
 In linguistics, expectations, in the form of selectional restrictions and selectional preferences, have long been used in semantic theories (CITATION; CITATION), and more recently induced from corpora (CITATION; CITATION),,
 Attention has mostly been limited to selectional preferences of verbs, which have been used for example for syntactic disambiguation CITATION, word sense disambiguation CITATION and semantic role labeling CITATION,,
 Recently, a vectorspaced model of selectional preferences has been proposed that computes the typicality of an argument simply through similarity to previously seen arguments (CITATION; CITATION),,
to straightforwardly interpret c = a \x0c b as the meaning of the phrase a + b (CITATION; CITATION),,
 It is difficult to conceive how c could encode deeper semantic properties, like predicateargument structure (distinguishing dog bites man and man bites dog), that are crucial for sentencelevel semantic tasks such as the recognition of textual entailment CITATION,,
ng been used in semantic theories (CITATION; CITATION), and more recently induced from corpora (CITATION; CITATION),,
 Attention has mostly been limited to selectional preferences of verbs, which have been used for example for syntactic disambiguation CITATION, word sense disambiguation CITATION and semantic role labeling CITATION,,
 Recently, a vectorspaced model of selectional preferences has been proposed that computes the typicality of an argument simply through similarity to previously seen arguments (CITATION; CITATION),,
or space (SYN, CITATION),,
2 This space was built from BNC dependency parses obtained from Minipar CITATION,,
 We use a simple, knowledge-lean representation for selectional preferences inspired by CITATION, who models selectional preference through similarity to seen filler vectors ~ va: We compute the selectional preference vector for word b and relation r as the weighted 2 More specifically, we used the minimal context specification and plain weight function,,
 Expectations affect reading times CITATION, the interpretation of participles CITATION, and sentence processing generally (CITATION; CITATION),,
 Expectations exist both for verbs and nouns (CITATION; CITATION),,
 In linguistics, expectations, in the form of selectional restrictions and selectional preferences, have long been used in semantic theories (CITATION; CITATION), and more recently induced from corpora (CITATION; CITATION),,
 Attention has mostly been limited to selectional preferences of verbs, which have been used for example for syntactic disambiguation CITATION, word sen,,
 Expectations exist both for verbs and nouns (CITATION; CITATION),,
 In linguistics, expectations, in the form of selectional restrictions and selectional preferences, have long been used in semantic theories (CITATION; CITATION), and more recently induced from corpora (CITATION; CITATION),,
 Attention has mostly been limited to selectional preferences of verbs, which have been used for example for syntactic disambiguation CITATION, word sense disambiguation CITATION and semantic role labeling CITATION,,
 Recently, a vectorspaced model of selectional preferences has been proposed that computes the typicality of an argument simply through similarity to previously seen arguments (CITATION; CITATION),,
rticiples CITATION, and sentence processing generally (CITATION; CITATION),,
 Expectations exist both for verbs and nouns (CITATION; CITATION),,
 In linguistics, expectations, in the form of selectional restrictions and selectional preferences, have long been used in semantic theories (CITATION; CITATION), and more recently induced from corpora (CITATION; CITATION),,
 Attention has mostly been limited to selectional preferences of verbs, which have been used for example for syntactic disambiguation CITATION, word sense disambiguation CITATION and semantic role labeling CITATION,,
 Recently, a vectorspaced model of selectional preferences has been proposed that computes the typicality of an argument simply through similarity to previously seen arguments (CITATION; CITATION),,
 CITATION uses tensor product to combine two word vectors a and b into a vector c representing the expression a+b,,
 CITATION represent lemma meaning by using circular convolution to encode n-gram co-occurrence information into vectors of fixed dimensionality,,
 Expectations affect reading times CITATION, the interpretation of participles CITATION, and sentence processing generally (CITATION; CITATION),,
 Expectations exist both for verbs and nouns (CITATION; CITATION),,
 In linguistics, expectations, in the form of selectional restrictions and selectional preferences, have long been used in semantic theories (CITATION; CITATION), and more recently induced from corpora (CITATION; CITATION),,
 Attention has mostly been limited to selectional preferences of verbs, which have been used for example for syntactic disambiguation CITATION, word sense disambiguation CITATION and semantic role labeling CITATION,,
 Recently, a vectorspaced model of selectional preferences has been proposed that computes the typicality of an argument simply through similarity to previously seen arguments (CITATION; CITATION),,
 These vectors are able to provide a robust model of semantic similarity that has been used in NLP (CITATION; CITATION; CITATION) and to model experimental results in cognitive science (CITATION; CITATION),,
 Semantic spaces are attractive because they provide a model of word meaning that is independent of dictionary senses and their much-discussed problems (CITATION; CITATION),,
 In a default semantic space as described above, each vector represents one lemma, averaging over all its possible usages (CITATION; CITATION),,
 There have been several approaches in the literature (CITATION; CITATION; CITATION; CITATION; CITATION) that compute meaning in context from lemma vectors,,
ovide a model of word meaning that is independent of dictionary senses and their much-discussed problems (CITATION; CITATION),,
 In a default semantic space as described above, each vector represents one lemma, averaging over all its possible usages (CITATION; CITATION),,
 There have been several approaches in the literature (CITATION; CITATION; CITATION; CITATION; CITATION) that compute meaning in context from lemma vectors,,
 One proposal for scaling up is to straightforwardly interpret c = a \x0c b as the meaning of the phrase a + b (CITATION; CITATION),,
 It is difficult to conceive how c could encode deeper semantic properties, like predicateargument structure (distinguishing dog bites man and man bites dog), that are crucial for sentencelevel semantic tasks such as the recognition of textual entailment CITATION,,
 CITATION present a similar model,,
 CITATION uses vector representations of p and a to identify the set of words that are similar to both p and a,,
 CITATION propose a framework to represent the meaning of the combination p + a as a function f operating on four components: c = f(p, a, R, K) (3) R is the relation holding between p and a, and K additional knowledge,,
 These vectors are able to provide a robust model of semantic similarity that has been used in NLP (CITATION; CITATION; CITATION) and to model experimental results in cognitive science (CITATION; CITATION),,
 Semantic spaces are attractive because they provide a model of word meaning that is independent of dictionary senses and their much-discussed problems (CITATION; CITATION),,
 In a default semantic space as described above, each vector represents one lemma, averaging over all its possible usages (CITATION; CITATION),,
ce (BOW, CITATION),,
 We also consider a dependency-based vector space (SYN, CITATION),,
2 This space was built from BNC dependency parses obtained from Minipar CITATION,,
 We use a simple, knowledge-lean representation for selectional preferences inspired by CITATION, who models selectional preference through similarity to seen filler vectors ~ va: We compute the selectional preference vector for word b and relation r as the weighted 2 More specifically, we used the minimal context specification and plain we,,
 This corresponds to a beneficial effect of syntactic information found for other applications of semantic spaces (CITATION; CITATION),,
ide a robust model of semantic similarity that has been used in NLP (CITATION; CITATION; CITATION) and to model experimental results in cognitive science (CITATION; CITATION),,
 Semantic spaces are attractive because they provide a model of word meaning that is independent of dictionary senses and their much-discussed problems (CITATION; CITATION),,
 In a default semantic space as described above, each vector represents one lemma, averaging over all its possible usages (CITATION; CITATION),,
 There have been several approaches in the literature (CITATION; CITATION; CITATION; CITATION; CITATION) that compute meaning in context from lemma vectors,,
 In both experiments, we compare the SVS model against the state-of-theart model by CITATION (henceforth M&L; cf,,
 Our first space is a traditional bag-of-words vector space (BOW, CITATION),,
 We also consider a dependency-based vector space (SYN, CITATION),,
2 This space was built from BNC dependency parses obtained from Minipar CITATION,,
 These vectors are able to provide a robust model of semantic similarity that has been used in NLP (CITATION; CITATION; CITATION) and to model experimental results in cognitive science (CITATION; CITATION),,
 Semantic spaces are attractive because they provide a model of word meaning that is independent of dictionary senses and their much-discussed problems (CITATION; CITATION),,
 In a default semantic space as described above, each vector represents one lemma, averaging over all its possible usages (CITATION; CITATION),,
 These vectors are able to provide a robust model of semantic similarity that has been used in NLP (CITATION; CITATION; CITATION) and to model experimental results in cognitive science (CITATION; CITATION),,
 Semantic spaces are attractive because they provide a model of word meaning that is independent of dictionary senses and their much-discussed problems (CITATION; CITATION),,
 In a default semantic space as described above, each vector represents one lemma, averaging over all its possible usages (CITATION; CITATION),,
essing generally (CITATION; CITATION),,
 Expectations exist both for verbs and nouns (CITATION; CITATION),,
 In linguistics, expectations, in the form of selectional restrictions and selectional preferences, have long been used in semantic theories (CITATION; CITATION), and more recently induced from corpora (CITATION; CITATION),,
 Attention has mostly been limited to selectional preferences of verbs, which have been used for example for syntactic disambiguation CITATION, word sense disambiguation CITATION and semantic role labeling CITATION,,
 Recently, a vectorspaced model of selectional preferences has been proposed that computes the typicality of an argument simply through similarity to previously seen arguments (CITATION; CITATION),,
 These vectors are able to provide a robust model of semantic similarity that has been used in NLP (CITATION; CITATION; CITATION) and to model experimental results in cognitive science (CITATION; CITATION),,
 Semantic spaces are attractive because they provide a model of word meaning that is independent of dictionary senses and their much-discussed problems (CITATION; CITATION),,
 In a default semantic space as described above, each vector represents one lemma, averaging over all its possible usages (CITATION; CITATION),,
 There have been several approaches in the literature (CITATION; CITATION; CITATION; CITATION; CITATION) that compute meaning in context from lemma vectors,,
 For this experiment, we use the SemEval1 lexical substitution (lexsub) dataset CITATION, which contains 10 instances each of 200 target words in sentential contexts, drawn from Sharoffs (2006) English Internet Corpus,,
f word meaning that is independent of dictionary senses and their much-discussed problems (CITATION; CITATION),,
 In a default semantic space as described above, each vector represents one lemma, averaging over all its possible usages (CITATION; CITATION),,
 There have been several approaches in the literature (CITATION; CITATION; CITATION; CITATION; CITATION) that compute meaning in context from lemma vectors,,
 The best-known work in this category is CITATION,,
 CITATION present a similar model,,
 CITATION uses vector representations of p and a to identify the set of words that are similar to both p and a,,
 These vectors are able to provide a robust model of semantic similarity that has been used in NLP (CITATION; CITATION; CITATION) and to model experimental results in cognitive science (CITATION; CITATION),,
 Semantic spaces are attractive because they provide a model of word meaning that is independent of dictionary senses and their much-discussed problems (CITATION; CITATION),,
 In a default semantic space as described above, each vector represents one lemma, averaging over all its possible usages (CITATION; CITATION),,
 Expectations affect reading times CITATION, the interpretation of participles CITATION, and sentence processing generally (CITATION; CITATION),,
 Expectations exist both for verbs and nouns (CITATION; CITATION),,
 In linguistics, expectations, in the form of selectional restrictions and selectional preferences, have long been used in semantic theories (CITATION; CITATION), and more recently induced from corpora (CITATION; CITATION),,
 Expectations affect reading times CITATION, the interpretation of participles CITATION, and sentence processing generally (CITATION; CITATION),,
 Expectations exist both for verbs and nouns (CITATION; CITATION),,
 In linguistics, expectations, in the form of selectional restrictions and selectional preferences, have long been used in semantic theories (CITATION; CITATION), and more recently induced from corpora (CITATION; CITATION),,
 Attention has mostly been limited to selectional preferences of verbs, which have been used for example for syntactic disambiguation CITATION, word sense disambiguation CITATION and semantic role labeling CITATION,,
 However, their existence is supported in psycholinguistics by priming effects from nouns to typical verbs CITATION,,
dependent of dictionary senses and their much-discussed problems (CITATION; CITATION),,
 In a default semantic space as described above, each vector represents one lemma, averaging over all its possible usages (CITATION; CITATION),,
 There have been several approaches in the literature (CITATION; CITATION; CITATION; CITATION; CITATION) that compute meaning in context from lemma vectors,,
 One proposal for scaling up is to straightforwardly interpret c = a \x0c b as the meaning of the phrase a + b (CITATION; CITATION),,
 It is difficult to conceive how c could encode deeper semantic properties, like predicateargument structure (distinguishing dog bites man and man bites dog), that are crucial for sentencelevel semantic tasks such as the recognition of textual entailment CITATION,,
 CITATION uses vector representations of p and a to identify the set of words that are similar to both p and a,,
 CITATION propose a framework to represent the meaning of the combination p + a as a function f operating on four components: c = f(p, a, R, K) (3) R is the relation holding between p and a, and K additional knowledge,,
 In both experiments, we compare the SVS model against the state-of-theart model by CITATION (henceforth M&L; cf,,
 Our first space is a traditional bag-of-words vector space (BOW, CITATION),,
 Current kernels are mostly tree kernels that compare syntactic structure, and use semantic information mostly for smoothing syntactic similarity CITATION,,
 Expectations affect reading times CITATION, the interpretation of participles CITATION, and sentence processing generally (CITATION; CITATION),,
 Expectations exist both for verbs and nouns (CITATION; CITATION),,
 In linguistics, expectations, in the form of selectional restrictions and selectional preferences, have long been used in semantic theories (CITATION; CITATION), and more recently induced from corpora (CITATION; CITATION),,
 Attention has mostly been limited to selectional preferences of verbs, which have been used for example for syntactic disambiguation CITATION, word sense disambiguation CITATION and semantic role ,,
 Our first space is a traditional bag-of-words vector space (BOW, CITATION),,
 We also consider a dependency-based vector space (SYN, CITATION),,
2 This space was built from BNC dependency parses obtained from Minipar CITATION,,
 We use a simple, knowledge-lean representation for selectional preferences inspired by CITATION, who models selectional pre,,
 This corresponds to a beneficial effect of syntactic information found for other applications of semantic spaces (CITATION; CITATION),,
 Expectations affect reading times CITATION, the interpretation of participles CITATION, and sentence processing generally (CITATION; CITATION),,
 Expectations exist both for verbs and nouns (CITATION; CITATION),,
 In linguistics, expectations, in the form of selectional restrictions and selectional preferences, have long been used in semantic theories (CITATION; CITATION), and more recently induced from corpora (CITATION; CITATION),,
 Attention has mostly been limited to selectional preferences of verbs, which have been used for example for syntactic disambiguation CITATION, word sense disambiguation CITATION and semantic role labeling (Gildea and,,
d in semantic theories (CITATION; CITATION), and more recently induced from corpora (CITATION; CITATION),,
 Attention has mostly been limited to selectional preferences of verbs, which have been used for example for syntactic disambiguation CITATION, word sense disambiguation CITATION and semantic role labeling CITATION,,
 Recently, a vectorspaced model of selectional preferences has been proposed that computes the typicality of an argument simply through similarity to previously seen arguments (CITATION; CITATION),,
 Expectations affect reading times CITATION, the interpretation of participles CITATION, and sentence processing generally (CITATION; CITATION),,
 Expectations exist both for verbs and nouns (CITATION; CITATION),,
 In linguistics, expectations, in the form of selectional restrictions and selectional preferences, have long been used in semantic theories (CITATION; CITATION), and more recently induced from corpora (CITATION; CITATION),,
 Attention has mostly been limited to selectional preferences of verbs, which have been used for example for syntactic disambiguation CITATION, word sense disambiguation CITATION and semantic role labeling CITATION,,
 Recently, a vectorspaced model of selectional preferences has been proposed that computes the typicality of an argument simply through similarity to previously seen arguments (CITATION; CITATION),,
 These vectors are able to provide a robust model of semantic similarity that has been used in NLP (CITATION; CITATION; CITATION) and to model experimental results in cognitive science (CITATION; CITATION),,
 Semantic spaces are attractive because they provide a model of word meaning that is independent of dictionary senses and their much-discussed problems (CITATION; CITATION),,
 In a default semantic space as described above, each vector represents one lemma, averaging over all its possible usages (CITATION; CITATION),,
because they provide a model of word meaning that is independent of dictionary senses and their much-discussed problems (CITATION; CITATION),,
 In a default semantic space as described above, each vector represents one lemma, averaging over all its possible usages (CITATION; CITATION),,
 There have been several approaches in the literature (CITATION; CITATION; CITATION; CITATION; CITATION) that compute meaning in context from lemma vectors,,
 The best-known work in this category is CITATION,,
 CITATION present a similar model,,
s are attractive because they provide a model of word meaning that is independent of dictionary senses and their much-discussed problems (CITATION; CITATION),,
 In a default semantic space as described above, each vector represents one lemma, averaging over all its possible usages (CITATION; CITATION),,
 There have been several approaches in the literature (CITATION; CITATION; CITATION; CITATION; CITATION) that compute meaning in context from lemma vectors,,
 CITATION uses tensor product to combine two word vectors a and b into a vector c representing the expression a+b,,
 CITATION represent lemma meaning by using circular convolution to encode n-gram co-occurrence information into vectors of fixed dimensionality,,
 Expectations affect reading times CITATION, the interpretation of participles CITATION, and sentence processing generally (CITATION; CITATION),,
 Expectations exist both for verbs and nouns (CITATION; CITATION),,
 In linguistics, expectations, in the form of selectional restrictions and selectional preferences, have long been used in semantic theories (CITATION; CITATION), and more recently induced from corpora (CITATION; CITATION),,
 Attention has mostly been limited to selectional preferences of verbs, which have been used for example for syntactic disambiguation CITATION, word sense disambiguation CITATION and semantic role labeling CITATION,,
 Recently, a vectorspaced model of selectional preferences has been proposed that computes the typicality of an argument simply through similarity to previously seen arguments (CITATION; CITATION),,
 verb subject landmark sim judgment slump shoulder slouch high 7 slump shoulder decline low 2 slump value slouch low 3 slump value decline high 7 Figure 3: Experiment 1: Human similarity judgements for subject-verb pair with high- and low-similarity landmarks Differences between the performance of models were tested for significance using a stratified shuffling-based randomization test CITATION,,
