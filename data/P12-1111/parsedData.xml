<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<bodyText confidence="0.860027">
b&amp;apos;Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 10541062,
Jeju, Republic of Korea, 8-14 July 2012. c
</bodyText>
<sectionHeader confidence="0.587818" genericHeader="abstract">
2012 Association for Computational Linguistics
</sectionHeader>
<title confidence="0.7133225">
Exploring Deterministic Constraints: From a Constrained English POS
Tagger to an Efficient ILP Solution to Chinese Word Segmentation
</title>
<author confidence="0.957606">
Qiuye Zhao Mitch Marcus
</author>
<affiliation confidence="0.9929965">
Dept. of Computer &amp; Information Science
University of Pennsylvania
</affiliation>
<email confidence="0.960238">
qiuye, mitch@cis.upenn.edu
</email>
<sectionHeader confidence="0.990575" genericHeader="keywords">
Abstract
</sectionHeader>
<bodyText confidence="0.998721733333333">
We show for both English POS tagging and
Chinese word segmentation that with proper
representation, large number of deterministic
constraints can be learned from training exam-
ples, and these are useful in constraining prob-
abilistic inference. For tagging, learned con-
straints are directly used to constrain Viterbi
decoding. For segmentation, character-based
tagging constraints can be learned with the
same templates. However, they are better ap-
plied to a word-based model, thus an integer
linear programming (ILP) formulation is pro-
posed. For both problems, the corresponding
constrained solutions have advantages in both
efficiency and accuracy.
</bodyText>
<sectionHeader confidence="0.905166" genericHeader="introduction">
1 introduction
</sectionHeader>
<bodyText confidence="0.9988205">
In recent work, interesting results are reported for
applications of integer linear programming (ILP)
such as semantic role labeling (SRL) (Roth and Yih,
2005), dependency parsing (Martins et al., 2009)
and so on. In an ILP formulation, non-local de-
terministic constraints on output structures can be
naturally incorporated, such as a verb cannot take
two subject arguments for SRL, and the projectiv-
ity constraint for dependency parsing. In contrast
to probabilistic constraints that are estimated from
training examples, this type of constraint is usually
hand-written reflecting ones linguistic knowledge.
Dynamic programming techniques based on
Markov assumptions, such as Viterbi decoding, can-
not handle those non-local constraints as discussed
above. However, it is possible to constrain Viterbi
decoding by local constraints, e.g. assign label t
to word w for POS tagging. This type of constraint
may come from human input solicited in interactive
inference procedure (Kristjansson et al., 2004).
In this work, we explore deterministic constraints
for two fundamental NLP problems, English POS
tagging and Chinese word segmentation. We show
by experiments that, with proper representation,
large number of deterministic constraints can be
learned automatically from training data, which can
then be used to constrain probabilistic inference.
For POS tagging, the learned constraints are di-
rectly used to constrain Viterbi decoding. The cor-
responding constrained tagger is 10 times faster than
searching in a raw space pruned with beam-width 5.
Tagging accuracy is moderately improved as well.
For Chinese word segmentation (CWS), which
can be formulated as character tagging, analogous
constraints can be learned with the same templates
as English POS tagging. High-quality constraints
can be learned with respect to a special tagset, how-
ever, with this tagset, the best segmentation accuracy
is hard to achieve. Therefore, these character-based
constraints are not directly used for determining pre-
dictions as in English POS tagging. We propose an
ILP formulation of the CWS problem. By adopt-
ing this ILP formulation, segmentation F-measure
is increased from 0.968 to 0.974, as compared to
Viterbi decoding with the same feature set. More-
over, the learned constraints can be applied to reduce
the number of possible words over a character se-
quence, i.e. to reduce the number of variables to set.
This reduction of problem size immediately speeds
up an ILP solver by more than 100 times.
</bodyText>
<page confidence="0.991639">
1054
</page>
<address confidence="0.39433">
\x0c2 English POS tagging
</address>
<subsectionHeader confidence="0.938796">
2.1 Explore deterministic constraints
</subsectionHeader>
<bodyText confidence="0.966228355555556">
Suppose that, following (Chomsky, 1970), we dis-
tinguish major lexical categories (Noun, Verb, Ad-
jective and Preposition) by two binary features:
+ |N and + |V. Let (+N, V)=Noun, (N,
+V)=Verb, (+N, +V)=Adjective, and (N,
V)=preposition. A word occurring in between a
preceding word the and a following word of always
bears the feature +N. On the other hand, consider
the annotation guideline of English Treebank (Mar-
cus et al., 1993) instead. Part-of-speech (POS) tags
are used to categorize words, for example, the POS
tag VBG tags verbal gerunds, NNS tags nominal plu-
rals, DT tags determiners and so on. Following this
POS representation, there are as many as 10 possi-
ble POS tags that may occur in between theof, as
estimated from the WSJ corpus of Penn Treebank.
2.1.1 Templates of deterministic constraints
To explore determinacy in the distribution of POS
tags in Penn Treebank, we need to consider that
a POS tag marks the basic syntactic category of a
word as well as its morphological inflection. A con-
straint that may determine the POS category should
reflect both the context and the morphological fea-
ture of the corresponding word.
The practical difficulty in representing such de-
terministic constraints is that we do not have a per-
fect mechanism to analyze morphological features
of a word. Endings or prefixes of English words do
not deterministically mark their morphological in-
flections. We propose to compute the morph feature
of a word as the set of all of its possible tags, i.e.
all tag types that are assigned to the word in training
data. Furthermore, we approximate unknown words
in testing data by rare words in training data. For
a word that occurs less than 5 times in the training
corpus, we compute its morph feature as its last two
characters, which is also conjoined with binary fea-
tures indicating whether the rare word contains dig-
its, hyphens or upper-case characters respectively.
See examples of morph features in Table 1.
We consider bigram and trigram templates for
generating potentially deterministic constraints. Let
wi denote the ith word relative to the current word
w0; and mi denote the morph feature of wi. A
(frequent) (set of possible tags of the word)
</bodyText>
<table confidence="0.296852333333333">
w0=trades m0={NNS, VBZ}
(rare) (the last two characters...)
w0=time-shares m0={-es, HYPHEN}
</table>
<tableCaption confidence="0.96269">
Table 1: Morph features of frequent words and rare words
</tableCaption>
<bodyText confidence="0.6355878">
as computed from the WSJ Corpus of Penn Treebank.
bi- w1w0, w0w1, m1w0, w0m1
-gram w1m0, m0w1, m1m0, m0m1
tri- w1w0w1, m1w0w1, w1m0w1, m1m0w1
-gram w1w0m1, m1w0m1, w1m0m1, m1m0m1
</bodyText>
<tableCaption confidence="0.974562">
Table 2: The templates for generating potentially deter-
</tableCaption>
<bodyText confidence="0.942856333333333">
ministic constraints of English POS tagging.
bigram constraint includes one contextual word
(w1|w1) or the corresponding morph feature; and
a trigram constraint includes both contextual words
or their morph features. Each constraint is also con-
joined with w0 or m0, as described in Table 2.
</bodyText>
<subsectionHeader confidence="0.472993">
2.1.2 Learning of deterministic constraints
</subsectionHeader>
<bodyText confidence="0.985468818181818">
In the above section, we explore templates for
potentially deterministic constraints that may deter-
mine POS category. With respect to a training cor-
pus, if a constraint C relative to w0 always assigns
a certain POS category t to w0 in its context, i.e.
count(Ct0=t)
count(C) &amp;gt; thr, and this constraint occurs
more than a cutoff number, we consider it as a de-
terministic constraint. The threshold thr is a real
number just under 1.0 and the cutoff number is em-
pirically set to 5 in our experiments.
</bodyText>
<subsectionHeader confidence="0.49367">
2.1.3 Decoding of deterministic constraints
</subsectionHeader>
<bodyText confidence="0.9995315">
By the above definition, the constraint of w1 =
the, m0 = {NNS, VBZ} and w1 = of is determinis-
tic. It determines the POS category of w0 to be NNS.
There are at least two ways of decoding these con-
straints during POS tagging. Take the word trades
for example, whose morph feature is {NNS, VBZ}.
One alternative is that as long as trades occurs be-
tween the-of, it is tagged with NNS. The second al-
ternative is that the tag decision is made only if all
deterministic constraints relative to this occurrence
of trades agree on the same tag. Both ways of de-
coding are purely rule-based and involve no proba-
bilistic inference. In favor of a higher precision, we
adopt the latter one in our experiments.
</bodyText>
<page confidence="0.98662">
1055
</page>
<table confidence="0.8642188">
\x0craw input O(nT2) n = 23
The complex financing plan in the S&amp;L bailout law includes...
constrained input O(m1T + m2T2) m1 = 2, m2 = 1
The/DT complex/ financing/ plan/NN in/IN
the/DT S&amp;L/ bailout/NN law/NN includes/VBZ ...
</table>
<tableCaption confidence="0.999746">
Table 3: Comparison of raw input and constrained input.
</tableCaption>
<subsectionHeader confidence="0.995126">
2.2 Search in a constrained space
</subsectionHeader>
<bodyText confidence="0.99794675">
Following most previous work, we consider POS
tagging as a sequence classification problem and de-
compose the overall sequence score over the linear
structure, i.e. t = arg max
</bodyText>
<equation confidence="0.9351782">
ttagGEN(w)
n
X
i=1
score(ti) where
</equation>
<bodyText confidence="0.997570071428572">
function tagGEN maps input sentence w = w1...wn
to the set of all tag sequences that are of length n.
If a POS tagger takes raw input only, i.e. for every
word, the number of possible tags is a constant T,
the space of tagGEN is as large as Tn. On the other
hand, if we decode deterministic constraints first be-
fore a probabilistic search, i.e. for some words, the
number of possible tags is reduced to 1, the search
space is reduced to Tm, where m is the number of
(unconstrained) words that are not subject to any de-
terministic constraints.
Viterbi algorithm is widely used for tagging, and
runs in O(nT2) when searching in an unconstrained
space. On the other hand, consider searching in a
constrained space. Suppose that among the m un-
constrained words, m1 of them follow a word that
has been tagged by deterministic constraints and
m2 (=m-m1) of them follow another unconstrained
word. Viterbi decoder runs in O(m1T + m2T2)
while searching in such a constrained space. The
example in Table 3 shows raw and constrained input
with respect to a typical input sentence.
Lookahead features
The score of tag predictions are usually computed
in a high-dimensional feature space. We adopt the
basic feature set used in (Ratnaparkhi, 1996) and
(Collins, 2002). Moreover, when deterministic con-
straints have applied to contextual words of w0, it
is also possible to include some lookahead feature
templates, such as:
t0&amp;t1, t0&amp;t1&amp;t2, and t1&amp;t0&amp;t1
where ti represents the tag of the ith word relative
to the current word w0. As discussed in (Shen et
al., 2007), categorical information of neighbouring
words on both sides of w0 help resolve POS ambi-
guity of w0. In (Shen et al., 2007), lookahead fea-
tures may be available for use during decoding since
searching is bidirectional instead of left-to-right as
in Viterbi decoding. In this work, deterministic con-
straints are decoded before the application of prob-
abilistic models, therefore lookahead features are
made available during Viterbi decoding.
</bodyText>
<sectionHeader confidence="0.934" genericHeader="method">
3 Chinese Word Segmentation (CWS)
</sectionHeader>
<subsectionHeader confidence="0.958492">
3.1 Word segmentation as character tagging
</subsectionHeader>
<bodyText confidence="0.997616125">
Considering the ambiguity problem that a Chinese
character may appear in any relative position in a
word and the out-of-vocabulary (OOV) problem that
it is impossible to observe all words in training data,
CWS is widely formulated as a character tagging
problem (Xue, 2003). A character-based CWS de-
coder is to find the highest scoring tag sequence t
over the input character sequence c, i.e.
</bodyText>
<equation confidence="0.993583833333333">
t = arg max
ttagGEN(c)
n
X
i=1
score(ti) .
</equation>
<bodyText confidence="0.997710409090909">
This is the same formulation as POS tagging. The
Viterbi algorithm is also widely used for decoding.
The tag of each character represents its relative
position in a word. Two popular tagsets include 1)
IB: where B tags the beginning of a word and I
all other positions; and 2) BMES: where B, M and E
represent the beginning, middle and end of a multi-
character word respectively, and S tags a single-
character word. For example, after decoding with
BMES, 4 consecutive characters associated with the
tag sequence BMME compose a word. However, after
decoding with IB, characters associated with BIII
may compose a word if the following tag is B or only
form part of a word if the following tag is I. Even
though character tagging accuracy is higher with
tagset IB, tagset BMES is more popular in use since
better performance of the original problem CWS can
be achieved by this tagset.
Character-based feature templates
We adopt the non-lexical-target feature tem-
plates in (Jiang et al., 2008a). Let ci denote the ith
character relative to the current character c0 and t0
</bodyText>
<page confidence="0.977743">
1056
</page>
<bodyText confidence="0.9616835">
\x0cdenote the tag assigned to c0. The following tem-
plates are used:
</bodyText>
<equation confidence="0.929078">
ci&amp;t0 (i=-2...2), cici+1&amp;t0 (i=-2...1) and c1c1&amp;t0.
</equation>
<bodyText confidence="0.98424">
Character-based deterministic constraints
We can use the same templates as described in
Table 2 to generate potentially deterministic con-
straints for CWS character tagging, except that there
are no morph features computed for Chinese char-
acters. As we will show with experimental results
in Section 5.2, useful deterministic constraints for
CWS can be learned with tagset IB but not with
tagset BMES. It is interesting but not surprising to no-
tice, again, that the determinacy of a problem is sen-
sitive to its representation. Since it is hard to achieve
the best segmentations with tagset IB, we propose
an indirect way to use these constraints in the fol-
lowing section, instead of applying these constraints
as straightforwardly as in English POS tagging.
</bodyText>
<subsectionHeader confidence="0.995421">
3.2 Word-based word segmentation
</subsectionHeader>
<bodyText confidence="0.997478666666667">
A word-based CWS decoder finds the highest scor-
ing segmentation sequence w that is composed by
the input character sequence c, i.e.
</bodyText>
<equation confidence="0.993527">
w = arg max
wsegGEN(c)
|w|
X
i=1
score(wi) .
</equation>
<bodyText confidence="0.99912275">
where function segGEN maps character sequence c
to the set of all possible segmentations of c. For
example, w = (c1..cl1 )...(cnlk+1...cn) represents a
segmentation of k words and the lengths of the first
and last word are l1 and lk respectively.
In early work, rule-based models find words one
by one based on heuristics such as forward maxi-
mum match (Sproat et al., 1996). Exact search is
possible with a Viterbi-style algorithm, but beam-
search decoding is more popular as used in (Zhang
and Clark, 2007) and (Jiang et al., 2008a).
We propose an Integer Linear Programming (ILP)
formulation of word segmentation, which is nat-
urally viewed as a word-based model for CWS.
Character-based deterministic constraints, as dis-
cussed in Section 3.1, can be easily applied.
</bodyText>
<subsectionHeader confidence="0.994429">
3.3 ILP formulation of CWS
</subsectionHeader>
<bodyText confidence="0.966751666666667">
Given a character sequence c=c1...cn, there are s(=
n(n+1)/2) possible words that are contiguous sub-
sets of c, i.e. w1, ..., ws c. Our goal is to find
</bodyText>
<tableCaption confidence="0.96075">
Table 4: Comparison of raw input and constrained input.
an optimal solution x = x1...xs that maximizes
</tableCaption>
<equation confidence="0.98122125">
s
X
i=1
score(wi) xi, subject to
(1)
X
i:cwi
xi = 1, c c;
</equation>
<bodyText confidence="0.99305904">
(2) xi {0, 1}, 1 i s
The boolean value of xi, as guaranteed by constraint
(2), indicates whether wi is selected in the segmen-
tation solution or not. Constraint (1) requires ev-
ery character to be included in exactly one selected
word, thus guarantees a proper segmentation of the
whole sequence. This resembles the ILP formula-
tion of the set cover problem, though the first con-
straint is different. Take n = 2 for example, i.e.
c = c1c2, the set of possible words is {c1, c2, c1c2},
i.e. s = |x |= 3. There are only two possible so-
lutions subject to constraints (1) and (2), x = 110
giving an output set {c1, c2}, or x = 001 giving an
output set {c1c2}.
The efficiency of solving this problem depends on
the number of possible words (contiguous subsets)
over a character sequence, i.e. the number of vari-
ables in x. So as to reduce |x|, we apply determin-
istic constraints predicting IB tags first, which are
learned as described in Section 3.1. Possible words
are generated with respect to the partially tagged
character sequence. A character tagged with B al-
ways occurs at the beginning of a possible word. Ta-
ble 4 illustrates the constrained and raw input with
respect to a typical character sequence.
</bodyText>
<subsectionHeader confidence="0.945522">
3.4 Character- and word-based features
</subsectionHeader>
<bodyText confidence="0.997767">
As studied in previous work, word-based feature
templates usually include the word itself, sub-words
contained in the word, contextual characters/words
and so on. It has been shown that combining the
use of character- and word-based features helps im-
prove performance. However, in the character tag-
ging formulation, word-based features are non-local.
</bodyText>
<page confidence="0.944856">
1057
</page>
<bodyText confidence="0.99407112195122">
\x0cTo incorporate these non-local features and make the
search tractable, various efforts have been made. For
example, Jiang et al. (2008a) combine different lev-
els of knowledge in an outside linear model of a two-
layer cascaded model; Jiang et al. (2008b) uses the
forest re-ranking technique (Huang, 2008); and in
(Kruengkrai et al., 2009), only known words in vo-
cabulary are included in the hybrid lattice consisting
of both character- and word-level nodes.
We propose to incorporate character-based fea-
tures in word-based models. Consider a character-
based feature function (c, t, c) that maps a
character-tag pair to a high-dimensional feature
space, with respect to an input character sequence
c. For a possible word over c of length l , wi =
ci0 ...ci0+l1, tag each character cij in this word with
a character-based tag tij . Character-based features
of wi can be computed as {(cij , tij , c)|0 j &amp;lt; l}.
The first row of Table 5 illustrates character-based
features of a word of length 3, which is tagged with
tagset BMES. From this view, the character-based
feature templates defined in Section 3.1 are naturally
used in a word-based model.
When character-based features are incorporated
into word-based CWS models, some word-based
features are no longer of interest, such as the start-
ing character of a word, sub-words contained in
the word, contextual characters and so on. We
consider word counting features as a complemen-
tary to character-based features, following the idea
of using web-scale features in previous work, e.g.
(Bansal and Klein, 2011). For a possible word w, let
count(w) return the count of times that w occurs as
a legal word in training data. The word count num-
ber is further processed following (Bansal and Klein,
2011), wc(w) = floor(log(count(w)) 5)/5. In
addition to wc(wi), we also use corresponding word
count features of possible words that are composed
of the boundary and contextual characters of wi. The
specific word-based feature templates are illustrated
in the second row of Table 5.
</bodyText>
<sectionHeader confidence="0.996687" genericHeader="method">
4 Training
</sectionHeader>
<bodyText confidence="0.99851275">
We use the following linear model for scoring pre-
dictions: score(y)=T (x, y), where (y) is a high-
dimensional binary feature representation of y over
input x and contains weights of these features. For
</bodyText>
<equation confidence="0.733464666666667">
character-
(ci0 , B, c), (ci1 , M, c), (ci2 , E, c)
-based
word-
wc(ci0 ci1 ci2 ), wc(clci0 ), wc(ci2 cr)
-based
</equation>
<tableCaption confidence="0.7541855">
Table 5: Character- and word-based features of a possi-
ble word wi over the input character sequence c. Suppose
</tableCaption>
<equation confidence="0.852818333333333">
that wi = ci0
ci1
ci2
</equation>
<bodyText confidence="0.9986415">
, and its preceding and following char-
acters are cl and cr respectively.
parameter estimation of , we use the averaged per-
ceptron as described in (Collins, 2002). This train-
ing algorithm relies on the choice of decoding algo-
rithm. When we experiment with different decoders,
by default, the parameter weights in use are trained
with the corresponding decoding algorithm.
Especially, for experiments with lookahead fea-
tures of English POS tagging, we prepare training
data with the stacked learning technique, in order to
alleviate overfitting. More specifically, we divide the
training data into k folds, and tag each fold with the
deterministic model learned over the other k-1 folds.
The predicted tags of all folds are then merged into
the gold training data and used (only) as lookahead
features. Sun (2011) uses this technique to merge
different levels of predictors for word segmentation.
</bodyText>
<sectionHeader confidence="0.996473" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<subsectionHeader confidence="0.938116">
5.1 Data set
</subsectionHeader>
<bodyText confidence="0.999179363636364">
We run experiments on English POS tagging on the
WSJ corpus in the Penn Treebank. Following most
previous work, e.g. (Collins, 2002) and (Shen et al.,
2007), we divide this corpus into training set (sec-
tions 0-18), development set (sections 19-21) and
the final test set (sections 22-24).
We run experiments on Chinese word segmenta-
tion on the Penn Chinese Treebank 5.0. Following
(Jiang et al., 2008a), we divide this corpus into train-
ing set (chapters 1-260), development set (chapters
271-300) and the final test set (chapters 301-325).
</bodyText>
<subsectionHeader confidence="0.999397">
5.2 Deterministic constraints
</subsectionHeader>
<bodyText confidence="0.995833333333333">
Experiments in this section are carried out on the de-
velopment set. The cutoff number and threshold as
defined in 2.1.2, are fixed as 5 and 0.99 respectively.
</bodyText>
<page confidence="0.985411">
1058
</page>
<table confidence="0.999459">
\x0cprecision recall F1
bigram 0.993 0.841 0.911
trigram 0.996 0.608 0.755
bi+trigram 0.992 0.857 0.920
</table>
<tableCaption confidence="0.7434465">
Table 6: POS tagging with deterministic constraints.
The maximum in each column is bold.
</tableCaption>
<table confidence="0.762417">
m0={VBN, VBZ} &amp; m1={JJ, VBD, VBN} VBN
w0=also &amp; m1={VBD, VBN} RB
m0=es &amp; m1={IN, RB, RP} NNS
w0=last &amp; w1= the JJ
</table>
<tableCaption confidence="0.809259">
Table 7: Deterministic constraints for POS tagging.
Deterministic constraints for POS tagging
</tableCaption>
<bodyText confidence="0.991310363636364">
For English POS tagging, we evaluate the deter-
ministic constraints generated by the templates de-
scribed in Section 2.1.1. Since these deterministic
constraints are only applied to words that occur in
a constrained context, we report F-measure as the
accuracy measure. Precision p is defined as the per-
centage of correct predictions out of all predictions,
and recall r is defined as the percentage of gold pre-
dictions that are correctly predicted. F-measure F1
is computed by 2pr/(p + r).
As shown in Table 6, deterministic constraints
learned with both bigram and trigram templates are
all very accurate in predicting POS tags of words
in their context. Constraints generated by bigram
template alone can already cover 84.1% of the input
words with a high precision of 0.993. By adding the
constraints generated by trigram template, recall is
increased to 0.857 with little loss in precision. Since
these deterministic constraints are applied before the
decoding of probabilistic models, reliably high pre-
cision of their predictions is crucial.
There are 114589 bigram deterministic con-
straints and 130647 trigram constraints learned from
the training data. We show a couple of examples of
bigram deterministic constraints in Table 7. As de-
fined in Section 2.2, we use the set of all possible
POS tags for a word, e.g. {VBN, VBZ}, as its morph
feature if the word is frequent (occurring more than
5 times in training data). For a rare word, the last two
characters are used as its morph feature, e.g. es. A
constraint is composed of w1, w0 and w1, as well
as the morph features m1, m0 and m1. For ex-
tagset precision recall F1
</bodyText>
<table confidence="0.999348">
BMES 0.989 0.566 0.720
IB 0.996 0.686 0.812
</table>
<tableCaption confidence="0.997922">
Table 8: Character tagging with deterministic constraints.
</tableCaption>
<bodyText confidence="0.989504523809524">
ample, the first constraint in Table 7 determines the
tag VBN of w0. A deterministic constraint is aware
of neither the likelihood of each possible tag or the
relative rank of their likelihoods.
Deterministic constraints for character tagging
For the character tagging formulation of Chinese
word segmentation, we discussed two tagsets IB and
BMES in Section 3.1. With respect to either tagset,
we use both bigram and trigram templates to gen-
erate deterministic constraints for the corresponding
tagging problem. These constraints are also evalu-
ated by F-measure as defined above. As shown in
Table 8, when tagset IB is used for character tag-
ging, high precision predictions can be made by the
deterministic constraints that are learned with re-
spect to this tagset. However, when tagset BMES is
used, the learned constraints dont always make reli-
able predictions, and the overall precision is not high
enough to constrain a probabilistic model. There-
fore, we will only use the deterministic constraints
that predict IB tags in following CWS experiments.
</bodyText>
<subsectionHeader confidence="0.937535">
5.3 English POS tagging
</subsectionHeader>
<bodyText confidence="0.999399666666667">
For English POS tagging, as well as the CWS prob-
lem that will be discussed in the next section, we use
the development set to choose training iterations (=
5), set beam width etc. The following experiments
are done on the final test set.
As introduced in Section 2.2, we adopt a very
compact feature set used in (Ratnaparkhi, 1996)1.
While searching in a constrained space, we can also
extend this feature set with some basic lookahead
features as defined in Section 2.2. This replicates
the feature set B used in (Shen et al., 2007).
In this work, our main interest in the POS tag-
ging problem is on its efficiency. A well-known
technique to speed up Viterbi decoding is to con-
duct beam search. Based on experiments carried out
</bodyText>
<page confidence="0.888555">
1
</page>
<bodyText confidence="0.9961335">
Our implementation of this feature set is basically the same
as the version used in (Collins, 2002).
</bodyText>
<page confidence="0.987199">
1059
</page>
<table confidence="0.988918857142857">
\x0cRatnaparkhi (1996)s feature
Beam=1 Beam=5
raw 96.46%/3 97.16/1
constrained 96.80%/14 97.20/10
Feature B in (Shen et al., 2007)
(Shen et al., 2007) 97.15% (Beam=3)
constrained 97.03%/11 97.20/8
</table>
<tableCaption confidence="0.997435">
Table 9: POS tagging accuracy and speed. The maximum
</tableCaption>
<bodyText confidence="0.99976150877193">
in each column is bold. The baseline for speed in all cases
is the unconstrained tagger using (Ratnaparkhi, 1996)s
feature and conducting a beam (=5) search.
on the development set, we set beam-width of our
baseline model as 5. Our baseline model, which
uses Ratnaparkhi (1996)s feature set and conducts
a beam (=5) search in the unconstrained space,
achieves a tagging accuracy of 97.16%. Tagging
accuracy is measured by the percentage of correct
predictions out of all gold predictions. We consider
the speed of our baseline model as 1, and compare
other taggers with this one. The speed of a POS tag-
ger is measured by the number of input words pro-
cessed per second.
As shown in Table 9, when the beam-width is re-
duced from 5 to 1, the tagger (beam=1) is 3 times
faster but tagging accuracy is badly hurt. In contrast,
when searching in a constrained space rather than
the raw space, the constrained tagger (beam=5) is 10
times fast as the baseline and the tagging accuracy
is even moderately improved, increasing to 97.20%.
When we evaluate the speed of a constrained tag-
ger, the time of decoding deterministic constraints
is included. These constraints make more accurate
predictions than probabilistic models, thus besides
improving the overall tagging speed as we expect,
tagging accuracy also improves by a little.
In Viterbi decoding, all possible transitions be-
tween two neighbour states are evaluated, so the ad-
dition of locally lookahead features may have NO
impact on performance. When beam-width is set to
5, tagging accuracy is not improved by the use of
Feature B in (Shen et al., 2007); and because the
size of the feature model grows, efficiency is hurt.
On the other hand, when lookahead features are
used, Viterbi-style decoding is less affected by the
reduction of beam-width. As compared to the con-
strained greedy tagger using Ratnaparkhi (1996)s
feature set, with the additional use of three locally
lookahead feature templates, tagging accuracy is in-
creased from 96.80% to 97.02%.
When no further data is used other than training
data, the bidirectional tagger described in (Shen et
al., 2007) achives an accuracy of 97.33%, using a
much richer feature set (E) than feature set B, the
one we compare with here. As noted above, the
addition of three feature templates already has a
notable negative impact on efficiency, thus the use
of feature set E will hurt tagging efficiency much
worse. Rich feature sets are also widely used in
other work that pursue state-of-art tagging accuracy,
e.g. (Toutanova et al., 2003). In this work, we fo-
cus on the most compact feature sets, since tagging
efficiency is our main consideration in our work on
POS taging. The proposed constrained taggers as
described above can achieve near state-of-art POS
tagging accuracy in a much more efficient manner.
</bodyText>
<subsectionHeader confidence="0.950042">
5.4 Chinese word segmentation
</subsectionHeader>
<bodyText confidence="0.998670692307692">
Like other tagging problems, Viterbi-style decoding
is widely used for character tagging for CWS. We
transform tagged character sequences to word seg-
mentations first, and then evaluate word segmenta-
tions by F-measure, as defined in Section 5.2.
We proposed an ILP formulation of the CWS
problem in Section 3.3, where we present a word-
based model. In Section 3.4, we describe a way of
mapping words to a character-based feature space.
From this view, the highest scoring tagging sequence
is computed subject to structural constraints, giving
us an inference alternative to Viterbi decoding. For
example, recall the example of input character se-
quence c = c1c2 discussed in Section 3.3. The two
possible ILP solutions give two possible segmenta-
tions {c1, c2} and {c1c2}, thus there are 2 tag se-
quences evaluated by ILP, BB and BI. On the other
hand, there are 4 tag sequences evaluated by Viterbi
decoding: BI, BB, IB and II.
With the same feature templates as described in
Section 3.1, we now compare these two decoding
methods. Tagset BMES is used for character tagging
as well as for mapping words to character-based fea-
ture space. We use the same Viterbi decoder as im-
plemented for English POS tagging and use a non-
commercial ILP solver included in GNU Linear Pro-
</bodyText>
<page confidence="0.880031">
1060
</page>
<table confidence="0.9956236">
\x0cprecision recall F-measure
Viterbi 0.971 0.966 0.968
ILP 0.970 0.977 0.974
(Jiang et al., 2008a), POS- 0.971
(Jiang et al., 2008a), POS+ 0.973
</table>
<tableCaption confidence="0.973348">
Table 10: F-measure on Chinese word segmentation.
</tableCaption>
<bodyText confidence="0.997211921052631">
Only character-based features are used. POS-/+: percep-
tron trained without/with POS.
gramming Kit (GLPK), version 4.3. 2 As shown
in Table 10, optimal solutions returned by an ILP
solver are more accurate than optimal solutions re-
turned by a Viterbi decoder. The F-measure is im-
proved by a relative error reduction of 18.8%, from
0.968 to 0.974. These results are compared to the
core perceptron trained without POS in (Jiang et al.,
2008a). They only report results with lexical-target
features, a richer feature set than the one we use
here. As shown in Table 10, we achieve higher per-
formance even with more compact features.
Joint inference of CWS and Chinese POS tagging
is popularly studied in recent work, e.g. (Ng and
Low, 2004), (Jiang et al., 2008a), and (Kruengkrai et
al., 2009). It has been shown that better performance
can be achieved with joint inference, e.g. F-measure
0.978 by the cascaded model in (Jiang et al., 2008a).
We focus on the task of word segmentation only in
this work and show that a comparable F-measure is
achievable in a much more efficient manner. Sun
(2011) uses the stacked learning technique to merge
different levels of predictors, obtaining a combined
system that beats individual ones.
Word-based features can be easily incorporated,
since the ILP formulation is more naturally viewed
as a word-based model. We extend character-based
features with the word count features as described
in Section 3.4. Currently, we only use word counts
computed from training data, i.e. still a closed test.
The addition of these features makes a moderate im-
provement on the F-measure, from 0.974 to 0.975.
As discussed in Section 3.3, if we are able to
determine that some characters always start new
words, the number of possible words is reduced,
i.e. the number of variables in an ILP solution is
reduced. As shown in Table 11, when character se-
</bodyText>
<page confidence="0.87358">
2
</page>
<table confidence="0.9420635">
http://www.gnu.org/software/glpk
F-measure avg. |x |#char per sec.
raw 0.974 1290.4 113 (1)
constrained 0.974 83.75 12190 (107)
</table>
<tableCaption confidence="0.996709">
Table 11: ILP problem size and segmentation speed.
</tableCaption>
<bodyText confidence="0.9745344375">
quences are partially tagged by deterministic con-
straints, the number of possible words per sentence,
i.e. avg. |x|, is reduced from 1290.4 to 83.7. This re-
duction of ILP problem size has a very important im-
pact on the efficiency. As shown in Table 11, when
taking constrained input, the segmentation speed is
increased by 107 times over taking raw input, from
113 characters per second to 12,190 characters per
second on a dual-core 3.0HZ CPU.
Deterministic constraints predicting IB tags are
only used here for constraining possible words.
They are very accurate as shown in Section 5.2. Few
gold predictions are missed from the constrained set
of possible words. As shown in Table 11, F-measure
is not affected by applying these constraints, while
the efficiency is significantly improved.
</bodyText>
<sectionHeader confidence="0.956554" genericHeader="conclusions">
6 Conclusion and future work
</sectionHeader>
<bodyText confidence="0.999815095238095">
We have shown by experiments that large number of
deterministic constraints can be learned from train-
ing examples, as long as the proper representation is
used. These deterministic constraints are very use-
ful in constraining probabilistic search, for example,
they may be directly used for determining predic-
tions as in English POS tagging, or used for reduc-
ing the number of variables in an ILP solution as in
Chinese word segmentation. The most notable ad-
vantage in using these constraints is the increased ef-
ficiency. The two applications are both well-studied;
there isnt much space for improving accuracy. Even
so, we have shown that as tested with the same fea-
ture set for CWS, the proposed ILP formulation sig-
nificantly improves the F-measure as compared to
Viterbi decoding.
These two simple applications suggest that it is
of interest to explore data-driven deterministic con-
straints learnt from training examples. There are
more interesting ways in applying these constraints,
which we are going to study in future work.
</bodyText>
<page confidence="0.921125">
1061
</page>
<reference confidence="0.984507123595506">
\x0cReferences
M. Bansal and D. Klein. 2011. Web-scale features for
full-scale parsing. In Proceedings of the 49th Annual
Meeting of the Association for Computational Linguis-
tics: Human Language Technologies - Volume 1, pages
693702.
Noam Chomsky. 1970. Remarks on nominalization.
In R Jacobs and P Rosenbaum, editors, Readings in
English Transformational Grammar, pages 184221.
Ginn.
Michael Collins. 2002. Discriminative training meth-
ods for hidden markov models: theory and experi-
ments with perceptron algorithms. In Proceedings of
the ACL-02 conference on Empirical methods in natu-
ral language processing, EMNLP 02, pages 18.
L. Huang. 2008. Forest reranking: Discriminative pars-
ing with non-local features. In In Proceedings of the
46th Annual Meeting of the Association for Computa-
tional Linguistics.
W. Jiang, L. Huang, Q. Liu, and Y. Lu. 2008a. A cas-
caded linear model for joint chinese word segmenta-
tion and part-of-speech tagging. In In Proceedings of
the 46th Annual Meeting of the Association for Com-
putational Linguistics.
W. Jiang, H. Mi, and Q. Liu. 2008b. Word lattice rerank-
ing for chinese word segmentation and part-of-speech
tagging. In Proceedings of the 22nd International
Conference on Computational Linguistics - Volume 1,
COLING 08, pages 385392.
T. Kristjansson, A. Culotta, and P. Viola. 2004. Inter-
active information extraction with constrained condi-
tional random fields. In In AAAI, pages 412418.
C. Kruengkrai, K. Uchimoto, J. Kazama, Y. Wang,
K. Torisawa, and H. Isahara. 2009. An error-driven
word-character hybrid model for joint chinese word
segmentation and pos tagging. In Proceedings of the
Joint Conference of the 47th Annual Meeting of the
ACL and the 4th International Joint Conference on
Natural Language Processing of the AFNLP, ACL 09,
pages 513521.
Mitch Marcus, Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1993. Building a large annotated cor-
pus of english: The penn treebank. Computational lin-
guistics, 19(2):313330.
A. F. T. Martins, N. A. Smith, and E. P. Xing. 2009.
Concise integer linear programming formulations for
dependency parsing. In Proceedings of the Joint Con-
ference of the 47th Annual Meeting of the ACL and
the 4th International Joint Conference on Natural Lan-
guage Processing of the AFNLP (ACL-IJCNLP), pages
342350, Singapore.
H. T. Ng and J. K. Low. 2004. Chinese partof-speech
tagging: One-at-a-time or all-at-once? word-based or
character-based? In In Proceedings of the 2004 Con-
ference on Empirical Methods in Natural Language
Processing (EMNLP), page 277C284.
A. Ratnaparkhi. 1996. A maximum entropy model for
part-of-speech tagging. In In Proceedings of the Em-
pirical Methods in Natural Language Processing Con-
ference (EMNLP).
S. Ravi and K. Knight. 2009. Minimized models for
unsupervised part-of-speech tagging. In Proc. ACL.
D. Roth and W. Yih. 2005. Integer linear programming
inference for conditional random fields. In In Pro-
ceedings of the International Conference on Machine
Learning (ICML), pages 737744.
L. Shen, G. Satta, and A. K. Joshi. 2007. Guided learn-
ing for bidirectional sequence classification. In Pro-
ceedings of the 45th Annual Meeting of the Association
for Computational Linguistics.
R. Sproat, W. Gale, C. Shih, and N. Chang. 1996.
A stochastic finite-state word-segmentation algorithm
for chinese. Comput. Linguist., 22(3):377404.
W. Sun. 2011. A stacked sub-word model for joint chi-
nese word segmentation and part-of-speech tagging.
In Proceedings of the ACL-HLT 2011.
K. Toutanova, D. Klein, C. Manning, and Y. Singer.
2003. Feature-rich part-of-speech tagging with a
cyclic dependency network. In NAACL-2003.
N. Xue. 2003. Chinese word segmentation as character
tagging. International Journal of Computational Lin-
guistics and Chinese Language Processing, 9(1):29
48.
Y. Zhang and S. Clark. 2007. Chinese Segmentation with
a Word-Based Perceptron Algorithm. In Proceedings
of the 45th Annual Meeting of the Association of Com-
putational Linguistics, pages 840847.
1062
\x0c&amp;apos;
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.880424">
<note confidence="0.973447666666667">b&amp;apos;Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 10541062, Jeju, Republic of Korea, 8-14 July 2012. c 2012 Association for Computational Linguistics</note>
<title confidence="0.9876905">Exploring Deterministic Constraints: From a Constrained English POS Tagger to an Efficient ILP Solution to Chinese Word Segmentation</title>
<author confidence="0.996277">Qiuye Zhao Mitch Marcus</author>
<affiliation confidence="0.9992815">Dept. of Computer &amp; Information Science University of Pennsylvania</affiliation>
<email confidence="0.99984">qiuye,mitch@cis.upenn.edu</email>
<abstract confidence="0.9984825625">We show for both English POS tagging and Chinese word segmentation that with proper representation, large number of deterministic constraints can be learned from training examples, and these are useful in constraining probabilistic inference. For tagging, learned constraints are directly used to constrain Viterbi decoding. For segmentation, character-based tagging constraints can be learned with the same templates. However, they are better applied to a word-based model, thus an integer linear programming (ILP) formulation is proposed. For both problems, the corresponding constrained solutions have advantages in both efficiency and accuracy.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>\x0cReferences M Bansal</author>
<author>D Klein</author>
</authors>
<title>Web-scale features for full-scale parsing.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies -</booktitle>
<volume>1</volume>
<pages>693702</pages>
<contexts>
<context position="17304" citStr="Bansal and Klein, 2011" startWordPosition="2836" endWordPosition="2839">lustrates character-based features of a word of length 3, which is tagged with tagset BMES. From this view, the character-based feature templates defined in Section 3.1 are naturally used in a word-based model. When character-based features are incorporated into word-based CWS models, some word-based features are no longer of interest, such as the starting character of a word, sub-words contained in the word, contextual characters and so on. We consider word counting features as a complementary to character-based features, following the idea of using web-scale features in previous work, e.g. (Bansal and Klein, 2011). For a possible word w, let count(w) return the count of times that w occurs as a legal word in training data. The word count number is further processed following (Bansal and Klein, 2011), wc(w) = floor(log(count(w)) 5)/5. In addition to wc(wi), we also use corresponding word count features of possible words that are composed of the boundary and contextual characters of wi. The specific word-based feature templates are illustrated in the second row of Table 5. 4 Training We use the following linear model for scoring predictions: score(y)=T (x, y), where (y) is a highdimensional binary featur</context>
</contexts>
<marker>Bansal, Klein, 2011</marker>
<rawString>\x0cReferences M. Bansal and D. Klein. 2011. Web-scale features for full-scale parsing. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, pages 693702.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noam Chomsky</author>
</authors>
<title>Remarks on nominalization.</title>
<date>1970</date>
<booktitle>Readings in English Transformational Grammar,</booktitle>
<pages>184221</pages>
<editor>In R Jacobs and P Rosenbaum, editors,</editor>
<publisher>Ginn.</publisher>
<contexts>
<context position="3724" citStr="Chomsky, 1970" startWordPosition="549" endWordPosition="550">r determining predictions as in English POS tagging. We propose an ILP formulation of the CWS problem. By adopting this ILP formulation, segmentation F-measure is increased from 0.968 to 0.974, as compared to Viterbi decoding with the same feature set. Moreover, the learned constraints can be applied to reduce the number of possible words over a character sequence, i.e. to reduce the number of variables to set. This reduction of problem size immediately speeds up an ILP solver by more than 100 times. 1054 \x0c2 English POS tagging 2.1 Explore deterministic constraints Suppose that, following (Chomsky, 1970), we distinguish major lexical categories (Noun, Verb, Adjective and Preposition) by two binary features: + |N and + |V. Let (+N, V)=Noun, (N, +V)=Verb, (+N, +V)=Adjective, and (N, V)=preposition. A word occurring in between a preceding word the and a following word of always bears the feature +N. On the other hand, consider the annotation guideline of English Treebank (Marcus et al., 1993) instead. Part-of-speech (POS) tags are used to categorize words, for example, the POS tag VBG tags verbal gerunds, NNS tags nominal plurals, DT tags determiners and so on. Following this POS representation,</context>
</contexts>
<marker>Chomsky, 1970</marker>
<rawString>Noam Chomsky. 1970. Remarks on nominalization. In R Jacobs and P Rosenbaum, editors, Readings in English Transformational Grammar, pages 184221. Ginn.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative training methods for hidden markov models: theory and experiments with perceptron algorithms.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL-02 conference on Empirical methods in natural language processing, EMNLP 02,</booktitle>
<pages>18</pages>
<contexts>
<context position="9627" citStr="Collins, 2002" startWordPosition="1550" endWordPosition="1551">d space. On the other hand, consider searching in a constrained space. Suppose that among the m unconstrained words, m1 of them follow a word that has been tagged by deterministic constraints and m2 (=m-m1) of them follow another unconstrained word. Viterbi decoder runs in O(m1T + m2T2) while searching in such a constrained space. The example in Table 3 shows raw and constrained input with respect to a typical input sentence. Lookahead features The score of tag predictions are usually computed in a high-dimensional feature space. We adopt the basic feature set used in (Ratnaparkhi, 1996) and (Collins, 2002). Moreover, when deterministic constraints have applied to contextual words of w0, it is also possible to include some lookahead feature templates, such as: t0&amp;t1, t0&amp;t1&amp;t2, and t1&amp;t0&amp;t1 where ti represents the tag of the ith word relative to the current word w0. As discussed in (Shen et al., 2007), categorical information of neighbouring words on both sides of w0 help resolve POS ambiguity of w0. In (Shen et al., 2007), lookahead features may be available for use during decoding since searching is bidirectional instead of left-to-right as in Viterbi decoding. In this work, deterministic const</context>
<context position="18386" citStr="Collins, 2002" startWordPosition="3029" endWordPosition="3030"> Training We use the following linear model for scoring predictions: score(y)=T (x, y), where (y) is a highdimensional binary feature representation of y over input x and contains weights of these features. For character(ci0 , B, c), (ci1 , M, c), (ci2 , E, c) -based wordwc(ci0 ci1 ci2 ), wc(clci0 ), wc(ci2 cr) -based Table 5: Character- and word-based features of a possible word wi over the input character sequence c. Suppose that wi = ci0 ci1 ci2 , and its preceding and following characters are cl and cr respectively. parameter estimation of , we use the averaged perceptron as described in (Collins, 2002). This training algorithm relies on the choice of decoding algorithm. When we experiment with different decoders, by default, the parameter weights in use are trained with the corresponding decoding algorithm. Especially, for experiments with lookahead features of English POS tagging, we prepare training data with the stacked learning technique, in order to alleviate overfitting. More specifically, we divide the training data into k folds, and tag each fold with the deterministic model learned over the other k-1 folds. The predicted tags of all folds are then merged into the gold training data</context>
<context position="23919" citStr="Collins, 2002" startWordPosition="3942" endWordPosition="3943">on the final test set. As introduced in Section 2.2, we adopt a very compact feature set used in (Ratnaparkhi, 1996)1. While searching in a constrained space, we can also extend this feature set with some basic lookahead features as defined in Section 2.2. This replicates the feature set B used in (Shen et al., 2007). In this work, our main interest in the POS tagging problem is on its efficiency. A well-known technique to speed up Viterbi decoding is to conduct beam search. Based on experiments carried out 1 Our implementation of this feature set is basically the same as the version used in (Collins, 2002). 1059 \x0cRatnaparkhi (1996)s feature Beam=1 Beam=5 raw 96.46%/3 97.16/1 constrained 96.80%/14 97.20/10 Feature B in (Shen et al., 2007) (Shen et al., 2007) 97.15% (Beam=3) constrained 97.03%/11 97.20/8 Table 9: POS tagging accuracy and speed. The maximum in each column is bold. The baseline for speed in all cases is the unconstrained tagger using (Ratnaparkhi, 1996)s feature and conducting a beam (=5) search. on the development set, we set beam-width of our baseline model as 5. Our baseline model, which uses Ratnaparkhi (1996)s feature set and conducts a beam (=5) search in the unconstrained</context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>Michael Collins. 2002. Discriminative training methods for hidden markov models: theory and experiments with perceptron algorithms. In Proceedings of the ACL-02 conference on Empirical methods in natural language processing, EMNLP 02, pages 18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Huang</author>
</authors>
<title>Forest reranking: Discriminative parsing with non-local features. In</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="16052" citStr="Huang, 2008" startWordPosition="2631" endWordPosition="2632">plates usually include the word itself, sub-words contained in the word, contextual characters/words and so on. It has been shown that combining the use of character- and word-based features helps improve performance. However, in the character tagging formulation, word-based features are non-local. 1057 \x0cTo incorporate these non-local features and make the search tractable, various efforts have been made. For example, Jiang et al. (2008a) combine different levels of knowledge in an outside linear model of a twolayer cascaded model; Jiang et al. (2008b) uses the forest re-ranking technique (Huang, 2008); and in (Kruengkrai et al., 2009), only known words in vocabulary are included in the hybrid lattice consisting of both character- and word-level nodes. We propose to incorporate character-based features in word-based models. Consider a characterbased feature function (c, t, c) that maps a character-tag pair to a high-dimensional feature space, with respect to an input character sequence c. For a possible word over c of length l , wi = ci0 ...ci0+l1, tag each character cij in this word with a character-based tag tij . Character-based features of wi can be computed as {(cij , tij , c)|0 j &amp;lt; l}</context>
</contexts>
<marker>Huang, 2008</marker>
<rawString>L. Huang. 2008. Forest reranking: Discriminative parsing with non-local features. In In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Jiang</author>
<author>L Huang</author>
<author>Q Liu</author>
<author>Y Lu</author>
</authors>
<title>A cascaded linear model for joint chinese word segmentation and part-of-speech tagging. In</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="11868" citStr="Jiang et al., 2008" startWordPosition="1922" endWordPosition="1925">ctively, and S tags a singlecharacter word. For example, after decoding with BMES, 4 consecutive characters associated with the tag sequence BMME compose a word. However, after decoding with IB, characters associated with BIII may compose a word if the following tag is B or only form part of a word if the following tag is I. Even though character tagging accuracy is higher with tagset IB, tagset BMES is more popular in use since better performance of the original problem CWS can be achieved by this tagset. Character-based feature templates We adopt the non-lexical-target feature templates in (Jiang et al., 2008a). Let ci denote the ith character relative to the current character c0 and t0 1056 \x0cdenote the tag assigned to c0. The following templates are used: ci&amp;t0 (i=-2...2), cici+1&amp;t0 (i=-2...1) and c1c1&amp;t0. Character-based deterministic constraints We can use the same templates as described in Table 2 to generate potentially deterministic constraints for CWS character tagging, except that there are no morph features computed for Chinese characters. As we will show with experimental results in Section 5.2, useful deterministic constraints for CWS can be learned with tagset IB but not with tagset</context>
<context position="13571" citStr="Jiang et al., 2008" startWordPosition="2205" endWordPosition="2208">ed by the input character sequence c, i.e. w = arg max wsegGEN(c) |w| X i=1 score(wi) . where function segGEN maps character sequence c to the set of all possible segmentations of c. For example, w = (c1..cl1 )...(cnlk+1...cn) represents a segmentation of k words and the lengths of the first and last word are l1 and lk respectively. In early work, rule-based models find words one by one based on heuristics such as forward maximum match (Sproat et al., 1996). Exact search is possible with a Viterbi-style algorithm, but beamsearch decoding is more popular as used in (Zhang and Clark, 2007) and (Jiang et al., 2008a). We propose an Integer Linear Programming (ILP) formulation of word segmentation, which is naturally viewed as a word-based model for CWS. Character-based deterministic constraints, as discussed in Section 3.1, can be easily applied. 3.3 ILP formulation of CWS Given a character sequence c=c1...cn, there are s(= n(n+1)/2) possible words that are contiguous subsets of c, i.e. w1, ..., ws c. Our goal is to find Table 4: Comparison of raw input and constrained input. an optimal solution x = x1...xs that maximizes s X i=1 score(wi) xi, subject to (1) X i:cwi xi = 1, c c; (2) xi {0, 1}, 1 i s The</context>
<context position="15883" citStr="Jiang et al. (2008" startWordPosition="2601" endWordPosition="2604">ustrates the constrained and raw input with respect to a typical character sequence. 3.4 Character- and word-based features As studied in previous work, word-based feature templates usually include the word itself, sub-words contained in the word, contextual characters/words and so on. It has been shown that combining the use of character- and word-based features helps improve performance. However, in the character tagging formulation, word-based features are non-local. 1057 \x0cTo incorporate these non-local features and make the search tractable, various efforts have been made. For example, Jiang et al. (2008a) combine different levels of knowledge in an outside linear model of a twolayer cascaded model; Jiang et al. (2008b) uses the forest re-ranking technique (Huang, 2008); and in (Kruengkrai et al., 2009), only known words in vocabulary are included in the hybrid lattice consisting of both character- and word-level nodes. We propose to incorporate character-based features in word-based models. Consider a characterbased feature function (c, t, c) that maps a character-tag pair to a high-dimensional feature space, with respect to an input character sequence c. For a possible word over c of length</context>
<context position="19547" citStr="Jiang et al., 2008" startWordPosition="3214" endWordPosition="3217"> of all folds are then merged into the gold training data and used (only) as lookahead features. Sun (2011) uses this technique to merge different levels of predictors for word segmentation. 5 Experiments 5.1 Data set We run experiments on English POS tagging on the WSJ corpus in the Penn Treebank. Following most previous work, e.g. (Collins, 2002) and (Shen et al., 2007), we divide this corpus into training set (sections 0-18), development set (sections 19-21) and the final test set (sections 22-24). We run experiments on Chinese word segmentation on the Penn Chinese Treebank 5.0. Following (Jiang et al., 2008a), we divide this corpus into training set (chapters 1-260), development set (chapters 271-300) and the final test set (chapters 301-325). 5.2 Deterministic constraints Experiments in this section are carried out on the development set. The cutoff number and threshold as defined in 2.1.2, are fixed as 5 and 0.99 respectively. 1058 \x0cprecision recall F1 bigram 0.993 0.841 0.911 trigram 0.996 0.608 0.755 bi+trigram 0.992 0.857 0.920 Table 6: POS tagging with deterministic constraints. The maximum in each column is bold. m0={VBN, VBZ} &amp; m1={JJ, VBD, VBN} VBN w0=also &amp; m1={VBD, VBN} RB m0=es &amp; </context>
<context position="28386" citStr="Jiang et al., 2008" startWordPosition="4682" endWordPosition="4685">1, c2} and {c1c2}, thus there are 2 tag sequences evaluated by ILP, BB and BI. On the other hand, there are 4 tag sequences evaluated by Viterbi decoding: BI, BB, IB and II. With the same feature templates as described in Section 3.1, we now compare these two decoding methods. Tagset BMES is used for character tagging as well as for mapping words to character-based feature space. We use the same Viterbi decoder as implemented for English POS tagging and use a noncommercial ILP solver included in GNU Linear Pro1060 \x0cprecision recall F-measure Viterbi 0.971 0.966 0.968 ILP 0.970 0.977 0.974 (Jiang et al., 2008a), POS- 0.971 (Jiang et al., 2008a), POS+ 0.973 Table 10: F-measure on Chinese word segmentation. Only character-based features are used. POS-/+: perceptron trained without/with POS. gramming Kit (GLPK), version 4.3. 2 As shown in Table 10, optimal solutions returned by an ILP solver are more accurate than optimal solutions returned by a Viterbi decoder. The F-measure is improved by a relative error reduction of 18.8%, from 0.968 to 0.974. These results are compared to the core perceptron trained without POS in (Jiang et al., 2008a). They only report results with lexical-target features, a ri</context>
</contexts>
<marker>Jiang, Huang, Liu, Lu, 2008</marker>
<rawString>W. Jiang, L. Huang, Q. Liu, and Y. Lu. 2008a. A cascaded linear model for joint chinese word segmentation and part-of-speech tagging. In In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Jiang</author>
<author>H Mi</author>
<author>Q Liu</author>
</authors>
<title>Word lattice reranking for chinese word segmentation and part-of-speech tagging.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics - Volume 1, COLING 08,</booktitle>
<pages>385392</pages>
<contexts>
<context position="11868" citStr="Jiang et al., 2008" startWordPosition="1922" endWordPosition="1925">ctively, and S tags a singlecharacter word. For example, after decoding with BMES, 4 consecutive characters associated with the tag sequence BMME compose a word. However, after decoding with IB, characters associated with BIII may compose a word if the following tag is B or only form part of a word if the following tag is I. Even though character tagging accuracy is higher with tagset IB, tagset BMES is more popular in use since better performance of the original problem CWS can be achieved by this tagset. Character-based feature templates We adopt the non-lexical-target feature templates in (Jiang et al., 2008a). Let ci denote the ith character relative to the current character c0 and t0 1056 \x0cdenote the tag assigned to c0. The following templates are used: ci&amp;t0 (i=-2...2), cici+1&amp;t0 (i=-2...1) and c1c1&amp;t0. Character-based deterministic constraints We can use the same templates as described in Table 2 to generate potentially deterministic constraints for CWS character tagging, except that there are no morph features computed for Chinese characters. As we will show with experimental results in Section 5.2, useful deterministic constraints for CWS can be learned with tagset IB but not with tagset</context>
<context position="13571" citStr="Jiang et al., 2008" startWordPosition="2205" endWordPosition="2208">ed by the input character sequence c, i.e. w = arg max wsegGEN(c) |w| X i=1 score(wi) . where function segGEN maps character sequence c to the set of all possible segmentations of c. For example, w = (c1..cl1 )...(cnlk+1...cn) represents a segmentation of k words and the lengths of the first and last word are l1 and lk respectively. In early work, rule-based models find words one by one based on heuristics such as forward maximum match (Sproat et al., 1996). Exact search is possible with a Viterbi-style algorithm, but beamsearch decoding is more popular as used in (Zhang and Clark, 2007) and (Jiang et al., 2008a). We propose an Integer Linear Programming (ILP) formulation of word segmentation, which is naturally viewed as a word-based model for CWS. Character-based deterministic constraints, as discussed in Section 3.1, can be easily applied. 3.3 ILP formulation of CWS Given a character sequence c=c1...cn, there are s(= n(n+1)/2) possible words that are contiguous subsets of c, i.e. w1, ..., ws c. Our goal is to find Table 4: Comparison of raw input and constrained input. an optimal solution x = x1...xs that maximizes s X i=1 score(wi) xi, subject to (1) X i:cwi xi = 1, c c; (2) xi {0, 1}, 1 i s The</context>
<context position="15883" citStr="Jiang et al. (2008" startWordPosition="2601" endWordPosition="2604">ustrates the constrained and raw input with respect to a typical character sequence. 3.4 Character- and word-based features As studied in previous work, word-based feature templates usually include the word itself, sub-words contained in the word, contextual characters/words and so on. It has been shown that combining the use of character- and word-based features helps improve performance. However, in the character tagging formulation, word-based features are non-local. 1057 \x0cTo incorporate these non-local features and make the search tractable, various efforts have been made. For example, Jiang et al. (2008a) combine different levels of knowledge in an outside linear model of a twolayer cascaded model; Jiang et al. (2008b) uses the forest re-ranking technique (Huang, 2008); and in (Kruengkrai et al., 2009), only known words in vocabulary are included in the hybrid lattice consisting of both character- and word-level nodes. We propose to incorporate character-based features in word-based models. Consider a characterbased feature function (c, t, c) that maps a character-tag pair to a high-dimensional feature space, with respect to an input character sequence c. For a possible word over c of length</context>
<context position="19547" citStr="Jiang et al., 2008" startWordPosition="3214" endWordPosition="3217"> of all folds are then merged into the gold training data and used (only) as lookahead features. Sun (2011) uses this technique to merge different levels of predictors for word segmentation. 5 Experiments 5.1 Data set We run experiments on English POS tagging on the WSJ corpus in the Penn Treebank. Following most previous work, e.g. (Collins, 2002) and (Shen et al., 2007), we divide this corpus into training set (sections 0-18), development set (sections 19-21) and the final test set (sections 22-24). We run experiments on Chinese word segmentation on the Penn Chinese Treebank 5.0. Following (Jiang et al., 2008a), we divide this corpus into training set (chapters 1-260), development set (chapters 271-300) and the final test set (chapters 301-325). 5.2 Deterministic constraints Experiments in this section are carried out on the development set. The cutoff number and threshold as defined in 2.1.2, are fixed as 5 and 0.99 respectively. 1058 \x0cprecision recall F1 bigram 0.993 0.841 0.911 trigram 0.996 0.608 0.755 bi+trigram 0.992 0.857 0.920 Table 6: POS tagging with deterministic constraints. The maximum in each column is bold. m0={VBN, VBZ} &amp; m1={JJ, VBD, VBN} VBN w0=also &amp; m1={VBD, VBN} RB m0=es &amp; </context>
<context position="28386" citStr="Jiang et al., 2008" startWordPosition="4682" endWordPosition="4685">1, c2} and {c1c2}, thus there are 2 tag sequences evaluated by ILP, BB and BI. On the other hand, there are 4 tag sequences evaluated by Viterbi decoding: BI, BB, IB and II. With the same feature templates as described in Section 3.1, we now compare these two decoding methods. Tagset BMES is used for character tagging as well as for mapping words to character-based feature space. We use the same Viterbi decoder as implemented for English POS tagging and use a noncommercial ILP solver included in GNU Linear Pro1060 \x0cprecision recall F-measure Viterbi 0.971 0.966 0.968 ILP 0.970 0.977 0.974 (Jiang et al., 2008a), POS- 0.971 (Jiang et al., 2008a), POS+ 0.973 Table 10: F-measure on Chinese word segmentation. Only character-based features are used. POS-/+: perceptron trained without/with POS. gramming Kit (GLPK), version 4.3. 2 As shown in Table 10, optimal solutions returned by an ILP solver are more accurate than optimal solutions returned by a Viterbi decoder. The F-measure is improved by a relative error reduction of 18.8%, from 0.968 to 0.974. These results are compared to the core perceptron trained without POS in (Jiang et al., 2008a). They only report results with lexical-target features, a ri</context>
</contexts>
<marker>Jiang, Mi, Liu, 2008</marker>
<rawString>W. Jiang, H. Mi, and Q. Liu. 2008b. Word lattice reranking for chinese word segmentation and part-of-speech tagging. In Proceedings of the 22nd International Conference on Computational Linguistics - Volume 1, COLING 08, pages 385392.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Kristjansson</author>
<author>A Culotta</author>
<author>P Viola</author>
</authors>
<title>Interactive information extraction with constrained conditional random fields.</title>
<date>2004</date>
<booktitle>In In AAAI,</booktitle>
<pages>412418</pages>
<contexts>
<context position="2123" citStr="Kristjansson et al., 2004" startWordPosition="301" endWordPosition="304">r SRL, and the projectivity constraint for dependency parsing. In contrast to probabilistic constraints that are estimated from training examples, this type of constraint is usually hand-written reflecting ones linguistic knowledge. Dynamic programming techniques based on Markov assumptions, such as Viterbi decoding, cannot handle those non-local constraints as discussed above. However, it is possible to constrain Viterbi decoding by local constraints, e.g. assign label t to word w for POS tagging. This type of constraint may come from human input solicited in interactive inference procedure (Kristjansson et al., 2004). In this work, we explore deterministic constraints for two fundamental NLP problems, English POS tagging and Chinese word segmentation. We show by experiments that, with proper representation, large number of deterministic constraints can be learned automatically from training data, which can then be used to constrain probabilistic inference. For POS tagging, the learned constraints are directly used to constrain Viterbi decoding. The corresponding constrained tagger is 10 times faster than searching in a raw space pruned with beam-width 5. Tagging accuracy is moderately improved as well. Fo</context>
</contexts>
<marker>Kristjansson, Culotta, Viola, 2004</marker>
<rawString>T. Kristjansson, A. Culotta, and P. Viola. 2004. Interactive information extraction with constrained conditional random fields. In In AAAI, pages 412418.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Kruengkrai</author>
<author>K Uchimoto</author>
<author>J Kazama</author>
<author>Y Wang</author>
<author>K Torisawa</author>
<author>H Isahara</author>
</authors>
<title>An error-driven word-character hybrid model for joint chinese word segmentation and pos tagging.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, ACL 09,</booktitle>
<pages>513521</pages>
<contexts>
<context position="16086" citStr="Kruengkrai et al., 2009" startWordPosition="2635" endWordPosition="2638"> the word itself, sub-words contained in the word, contextual characters/words and so on. It has been shown that combining the use of character- and word-based features helps improve performance. However, in the character tagging formulation, word-based features are non-local. 1057 \x0cTo incorporate these non-local features and make the search tractable, various efforts have been made. For example, Jiang et al. (2008a) combine different levels of knowledge in an outside linear model of a twolayer cascaded model; Jiang et al. (2008b) uses the forest re-ranking technique (Huang, 2008); and in (Kruengkrai et al., 2009), only known words in vocabulary are included in the hybrid lattice consisting of both character- and word-level nodes. We propose to incorporate character-based features in word-based models. Consider a characterbased feature function (c, t, c) that maps a character-tag pair to a high-dimensional feature space, with respect to an input character sequence c. For a possible word over c of length l , wi = ci0 ...ci0+l1, tag each character cij in this word with a character-based tag tij . Character-based features of wi can be computed as {(cij , tij , c)|0 j &amp;lt; l}. The first row of Table 5 illustr</context>
<context position="29275" citStr="Kruengkrai et al., 2009" startWordPosition="4830" endWordPosition="4833">ned by an ILP solver are more accurate than optimal solutions returned by a Viterbi decoder. The F-measure is improved by a relative error reduction of 18.8%, from 0.968 to 0.974. These results are compared to the core perceptron trained without POS in (Jiang et al., 2008a). They only report results with lexical-target features, a richer feature set than the one we use here. As shown in Table 10, we achieve higher performance even with more compact features. Joint inference of CWS and Chinese POS tagging is popularly studied in recent work, e.g. (Ng and Low, 2004), (Jiang et al., 2008a), and (Kruengkrai et al., 2009). It has been shown that better performance can be achieved with joint inference, e.g. F-measure 0.978 by the cascaded model in (Jiang et al., 2008a). We focus on the task of word segmentation only in this work and show that a comparable F-measure is achievable in a much more efficient manner. Sun (2011) uses the stacked learning technique to merge different levels of predictors, obtaining a combined system that beats individual ones. Word-based features can be easily incorporated, since the ILP formulation is more naturally viewed as a word-based model. We extend character-based features with</context>
</contexts>
<marker>Kruengkrai, Uchimoto, Kazama, Wang, Torisawa, Isahara, 2009</marker>
<rawString>C. Kruengkrai, K. Uchimoto, J. Kazama, Y. Wang, K. Torisawa, and H. Isahara. 2009. An error-driven word-character hybrid model for joint chinese word segmentation and pos tagging. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, ACL 09, pages 513521.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitch Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of english: The penn treebank.</title>
<date>1993</date>
<booktitle>Computational linguistics,</booktitle>
<pages>19--2</pages>
<contexts>
<context position="4117" citStr="Marcus et al., 1993" startWordPosition="612" endWordPosition="616">number of variables to set. This reduction of problem size immediately speeds up an ILP solver by more than 100 times. 1054 \x0c2 English POS tagging 2.1 Explore deterministic constraints Suppose that, following (Chomsky, 1970), we distinguish major lexical categories (Noun, Verb, Adjective and Preposition) by two binary features: + |N and + |V. Let (+N, V)=Noun, (N, +V)=Verb, (+N, +V)=Adjective, and (N, V)=preposition. A word occurring in between a preceding word the and a following word of always bears the feature +N. On the other hand, consider the annotation guideline of English Treebank (Marcus et al., 1993) instead. Part-of-speech (POS) tags are used to categorize words, for example, the POS tag VBG tags verbal gerunds, NNS tags nominal plurals, DT tags determiners and so on. Following this POS representation, there are as many as 10 possible POS tags that may occur in between theof, as estimated from the WSJ corpus of Penn Treebank. 2.1.1 Templates of deterministic constraints To explore determinacy in the distribution of POS tags in Penn Treebank, we need to consider that a POS tag marks the basic syntactic category of a word as well as its morphological inflection. A constraint that may deter</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>Mitch Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1993. Building a large annotated corpus of english: The penn treebank. Computational linguistics, 19(2):313330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A F T Martins</author>
<author>N A Smith</author>
<author>E P Xing</author>
</authors>
<title>Concise integer linear programming formulations for dependency parsing.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP (ACL-IJCNLP),</booktitle>
<pages>342350</pages>
<contexts>
<context position="1323" citStr="Martins et al., 2009" startWordPosition="183" endWordPosition="186">r tagging, learned constraints are directly used to constrain Viterbi decoding. For segmentation, character-based tagging constraints can be learned with the same templates. However, they are better applied to a word-based model, thus an integer linear programming (ILP) formulation is proposed. For both problems, the corresponding constrained solutions have advantages in both efficiency and accuracy. 1 introduction In recent work, interesting results are reported for applications of integer linear programming (ILP) such as semantic role labeling (SRL) (Roth and Yih, 2005), dependency parsing (Martins et al., 2009) and so on. In an ILP formulation, non-local deterministic constraints on output structures can be naturally incorporated, such as a verb cannot take two subject arguments for SRL, and the projectivity constraint for dependency parsing. In contrast to probabilistic constraints that are estimated from training examples, this type of constraint is usually hand-written reflecting ones linguistic knowledge. Dynamic programming techniques based on Markov assumptions, such as Viterbi decoding, cannot handle those non-local constraints as discussed above. However, it is possible to constrain Viterbi </context>
</contexts>
<marker>Martins, Smith, Xing, 2009</marker>
<rawString>A. F. T. Martins, N. A. Smith, and E. P. Xing. 2009. Concise integer linear programming formulations for dependency parsing. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP (ACL-IJCNLP), pages 342350, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H T Ng</author>
<author>J K Low</author>
</authors>
<title>Chinese partof-speech tagging: One-at-a-time or all-at-once? word-based or character-based? In</title>
<date>2004</date>
<booktitle>In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>277--284</pages>
<contexts>
<context position="29221" citStr="Ng and Low, 2004" startWordPosition="4821" endWordPosition="4824">2 As shown in Table 10, optimal solutions returned by an ILP solver are more accurate than optimal solutions returned by a Viterbi decoder. The F-measure is improved by a relative error reduction of 18.8%, from 0.968 to 0.974. These results are compared to the core perceptron trained without POS in (Jiang et al., 2008a). They only report results with lexical-target features, a richer feature set than the one we use here. As shown in Table 10, we achieve higher performance even with more compact features. Joint inference of CWS and Chinese POS tagging is popularly studied in recent work, e.g. (Ng and Low, 2004), (Jiang et al., 2008a), and (Kruengkrai et al., 2009). It has been shown that better performance can be achieved with joint inference, e.g. F-measure 0.978 by the cascaded model in (Jiang et al., 2008a). We focus on the task of word segmentation only in this work and show that a comparable F-measure is achievable in a much more efficient manner. Sun (2011) uses the stacked learning technique to merge different levels of predictors, obtaining a combined system that beats individual ones. Word-based features can be easily incorporated, since the ILP formulation is more naturally viewed as a wor</context>
</contexts>
<marker>Ng, Low, 2004</marker>
<rawString>H. T. Ng and J. K. Low. 2004. Chinese partof-speech tagging: One-at-a-time or all-at-once? word-based or character-based? In In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing (EMNLP), page 277C284.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ratnaparkhi</author>
</authors>
<title>A maximum entropy model for part-of-speech tagging. In</title>
<date>1996</date>
<booktitle>In Proceedings of the Empirical Methods in Natural Language Processing Conference (EMNLP).</booktitle>
<contexts>
<context position="9607" citStr="Ratnaparkhi, 1996" startWordPosition="1547" endWordPosition="1548">ching in an unconstrained space. On the other hand, consider searching in a constrained space. Suppose that among the m unconstrained words, m1 of them follow a word that has been tagged by deterministic constraints and m2 (=m-m1) of them follow another unconstrained word. Viterbi decoder runs in O(m1T + m2T2) while searching in such a constrained space. The example in Table 3 shows raw and constrained input with respect to a typical input sentence. Lookahead features The score of tag predictions are usually computed in a high-dimensional feature space. We adopt the basic feature set used in (Ratnaparkhi, 1996) and (Collins, 2002). Moreover, when deterministic constraints have applied to contextual words of w0, it is also possible to include some lookahead feature templates, such as: t0&amp;t1, t0&amp;t1&amp;t2, and t1&amp;t0&amp;t1 where ti represents the tag of the ith word relative to the current word w0. As discussed in (Shen et al., 2007), categorical information of neighbouring words on both sides of w0 help resolve POS ambiguity of w0. In (Shen et al., 2007), lookahead features may be available for use during decoding since searching is bidirectional instead of left-to-right as in Viterbi decoding. In this work,</context>
<context position="23421" citStr="Ratnaparkhi, 1996" startWordPosition="3854" endWordPosition="3855"> is used, the learned constraints dont always make reliable predictions, and the overall precision is not high enough to constrain a probabilistic model. Therefore, we will only use the deterministic constraints that predict IB tags in following CWS experiments. 5.3 English POS tagging For English POS tagging, as well as the CWS problem that will be discussed in the next section, we use the development set to choose training iterations (= 5), set beam width etc. The following experiments are done on the final test set. As introduced in Section 2.2, we adopt a very compact feature set used in (Ratnaparkhi, 1996)1. While searching in a constrained space, we can also extend this feature set with some basic lookahead features as defined in Section 2.2. This replicates the feature set B used in (Shen et al., 2007). In this work, our main interest in the POS tagging problem is on its efficiency. A well-known technique to speed up Viterbi decoding is to conduct beam search. Based on experiments carried out 1 Our implementation of this feature set is basically the same as the version used in (Collins, 2002). 1059 \x0cRatnaparkhi (1996)s feature Beam=1 Beam=5 raw 96.46%/3 97.16/1 constrained 96.80%/14 97.20/</context>
<context position="26042" citStr="Ratnaparkhi (1996)" startWordPosition="4292" endWordPosition="4293">l tagging speed as we expect, tagging accuracy also improves by a little. In Viterbi decoding, all possible transitions between two neighbour states are evaluated, so the addition of locally lookahead features may have NO impact on performance. When beam-width is set to 5, tagging accuracy is not improved by the use of Feature B in (Shen et al., 2007); and because the size of the feature model grows, efficiency is hurt. On the other hand, when lookahead features are used, Viterbi-style decoding is less affected by the reduction of beam-width. As compared to the constrained greedy tagger using Ratnaparkhi (1996)s feature set, with the additional use of three locally lookahead feature templates, tagging accuracy is increased from 96.80% to 97.02%. When no further data is used other than training data, the bidirectional tagger described in (Shen et al., 2007) achives an accuracy of 97.33%, using a much richer feature set (E) than feature set B, the one we compare with here. As noted above, the addition of three feature templates already has a notable negative impact on efficiency, thus the use of feature set E will hurt tagging efficiency much worse. Rich feature sets are also widely used in other work</context>
</contexts>
<marker>Ratnaparkhi, 1996</marker>
<rawString>A. Ratnaparkhi. 1996. A maximum entropy model for part-of-speech tagging. In In Proceedings of the Empirical Methods in Natural Language Processing Conference (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Ravi</author>
<author>K Knight</author>
</authors>
<title>Minimized models for unsupervised part-of-speech tagging.</title>
<date>2009</date>
<booktitle>In Proc. ACL.</booktitle>
<marker>Ravi, Knight, 2009</marker>
<rawString>S. Ravi and K. Knight. 2009. Minimized models for unsupervised part-of-speech tagging. In Proc. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Roth</author>
<author>W Yih</author>
</authors>
<title>Integer linear programming inference for conditional random fields. In</title>
<date>2005</date>
<booktitle>In Proceedings of the International Conference on Machine Learning (ICML),</booktitle>
<pages>737744</pages>
<contexts>
<context position="1280" citStr="Roth and Yih, 2005" startWordPosition="177" endWordPosition="180"> constraining probabilistic inference. For tagging, learned constraints are directly used to constrain Viterbi decoding. For segmentation, character-based tagging constraints can be learned with the same templates. However, they are better applied to a word-based model, thus an integer linear programming (ILP) formulation is proposed. For both problems, the corresponding constrained solutions have advantages in both efficiency and accuracy. 1 introduction In recent work, interesting results are reported for applications of integer linear programming (ILP) such as semantic role labeling (SRL) (Roth and Yih, 2005), dependency parsing (Martins et al., 2009) and so on. In an ILP formulation, non-local deterministic constraints on output structures can be naturally incorporated, such as a verb cannot take two subject arguments for SRL, and the projectivity constraint for dependency parsing. In contrast to probabilistic constraints that are estimated from training examples, this type of constraint is usually hand-written reflecting ones linguistic knowledge. Dynamic programming techniques based on Markov assumptions, such as Viterbi decoding, cannot handle those non-local constraints as discussed above. Ho</context>
</contexts>
<marker>Roth, Yih, 2005</marker>
<rawString>D. Roth and W. Yih. 2005. Integer linear programming inference for conditional random fields. In In Proceedings of the International Conference on Machine Learning (ICML), pages 737744.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Shen</author>
<author>G Satta</author>
<author>A K Joshi</author>
</authors>
<title>Guided learning for bidirectional sequence classification.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="9926" citStr="Shen et al., 2007" startWordPosition="1598" endWordPosition="1601">earching in such a constrained space. The example in Table 3 shows raw and constrained input with respect to a typical input sentence. Lookahead features The score of tag predictions are usually computed in a high-dimensional feature space. We adopt the basic feature set used in (Ratnaparkhi, 1996) and (Collins, 2002). Moreover, when deterministic constraints have applied to contextual words of w0, it is also possible to include some lookahead feature templates, such as: t0&amp;t1, t0&amp;t1&amp;t2, and t1&amp;t0&amp;t1 where ti represents the tag of the ith word relative to the current word w0. As discussed in (Shen et al., 2007), categorical information of neighbouring words on both sides of w0 help resolve POS ambiguity of w0. In (Shen et al., 2007), lookahead features may be available for use during decoding since searching is bidirectional instead of left-to-right as in Viterbi decoding. In this work, deterministic constraints are decoded before the application of probabilistic models, therefore lookahead features are made available during Viterbi decoding. 3 Chinese Word Segmentation (CWS) 3.1 Word segmentation as character tagging Considering the ambiguity problem that a Chinese character may appear in any relat</context>
<context position="19303" citStr="Shen et al., 2007" startWordPosition="3174" endWordPosition="3177">aining data with the stacked learning technique, in order to alleviate overfitting. More specifically, we divide the training data into k folds, and tag each fold with the deterministic model learned over the other k-1 folds. The predicted tags of all folds are then merged into the gold training data and used (only) as lookahead features. Sun (2011) uses this technique to merge different levels of predictors for word segmentation. 5 Experiments 5.1 Data set We run experiments on English POS tagging on the WSJ corpus in the Penn Treebank. Following most previous work, e.g. (Collins, 2002) and (Shen et al., 2007), we divide this corpus into training set (sections 0-18), development set (sections 19-21) and the final test set (sections 22-24). We run experiments on Chinese word segmentation on the Penn Chinese Treebank 5.0. Following (Jiang et al., 2008a), we divide this corpus into training set (chapters 1-260), development set (chapters 271-300) and the final test set (chapters 301-325). 5.2 Deterministic constraints Experiments in this section are carried out on the development set. The cutoff number and threshold as defined in 2.1.2, are fixed as 5 and 0.99 respectively. 1058 \x0cprecision recall F</context>
<context position="23623" citStr="Shen et al., 2007" startWordPosition="3887" endWordPosition="3890">nstraints that predict IB tags in following CWS experiments. 5.3 English POS tagging For English POS tagging, as well as the CWS problem that will be discussed in the next section, we use the development set to choose training iterations (= 5), set beam width etc. The following experiments are done on the final test set. As introduced in Section 2.2, we adopt a very compact feature set used in (Ratnaparkhi, 1996)1. While searching in a constrained space, we can also extend this feature set with some basic lookahead features as defined in Section 2.2. This replicates the feature set B used in (Shen et al., 2007). In this work, our main interest in the POS tagging problem is on its efficiency. A well-known technique to speed up Viterbi decoding is to conduct beam search. Based on experiments carried out 1 Our implementation of this feature set is basically the same as the version used in (Collins, 2002). 1059 \x0cRatnaparkhi (1996)s feature Beam=1 Beam=5 raw 96.46%/3 97.16/1 constrained 96.80%/14 97.20/10 Feature B in (Shen et al., 2007) (Shen et al., 2007) 97.15% (Beam=3) constrained 97.03%/11 97.20/8 Table 9: POS tagging accuracy and speed. The maximum in each column is bold. The baseline for speed </context>
<context position="25777" citStr="Shen et al., 2007" startWordPosition="4248" endWordPosition="4251"> moderately improved, increasing to 97.20%. When we evaluate the speed of a constrained tagger, the time of decoding deterministic constraints is included. These constraints make more accurate predictions than probabilistic models, thus besides improving the overall tagging speed as we expect, tagging accuracy also improves by a little. In Viterbi decoding, all possible transitions between two neighbour states are evaluated, so the addition of locally lookahead features may have NO impact on performance. When beam-width is set to 5, tagging accuracy is not improved by the use of Feature B in (Shen et al., 2007); and because the size of the feature model grows, efficiency is hurt. On the other hand, when lookahead features are used, Viterbi-style decoding is less affected by the reduction of beam-width. As compared to the constrained greedy tagger using Ratnaparkhi (1996)s feature set, with the additional use of three locally lookahead feature templates, tagging accuracy is increased from 96.80% to 97.02%. When no further data is used other than training data, the bidirectional tagger described in (Shen et al., 2007) achives an accuracy of 97.33%, using a much richer feature set (E) than feature set </context>
</contexts>
<marker>Shen, Satta, Joshi, 2007</marker>
<rawString>L. Shen, G. Satta, and A. K. Joshi. 2007. Guided learning for bidirectional sequence classification. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Sproat</author>
<author>W Gale</author>
<author>C Shih</author>
<author>N Chang</author>
</authors>
<title>A stochastic finite-state word-segmentation algorithm for chinese.</title>
<date>1996</date>
<journal>Comput. Linguist.,</journal>
<volume>22</volume>
<issue>3</issue>
<contexts>
<context position="13414" citStr="Sproat et al., 1996" startWordPosition="2178" endWordPosition="2181">forwardly as in English POS tagging. 3.2 Word-based word segmentation A word-based CWS decoder finds the highest scoring segmentation sequence w that is composed by the input character sequence c, i.e. w = arg max wsegGEN(c) |w| X i=1 score(wi) . where function segGEN maps character sequence c to the set of all possible segmentations of c. For example, w = (c1..cl1 )...(cnlk+1...cn) represents a segmentation of k words and the lengths of the first and last word are l1 and lk respectively. In early work, rule-based models find words one by one based on heuristics such as forward maximum match (Sproat et al., 1996). Exact search is possible with a Viterbi-style algorithm, but beamsearch decoding is more popular as used in (Zhang and Clark, 2007) and (Jiang et al., 2008a). We propose an Integer Linear Programming (ILP) formulation of word segmentation, which is naturally viewed as a word-based model for CWS. Character-based deterministic constraints, as discussed in Section 3.1, can be easily applied. 3.3 ILP formulation of CWS Given a character sequence c=c1...cn, there are s(= n(n+1)/2) possible words that are contiguous subsets of c, i.e. w1, ..., ws c. Our goal is to find Table 4: Comparison of raw i</context>
</contexts>
<marker>Sproat, Gale, Shih, Chang, 1996</marker>
<rawString>R. Sproat, W. Gale, C. Shih, and N. Chang. 1996. A stochastic finite-state word-segmentation algorithm for chinese. Comput. Linguist., 22(3):377404.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Sun</author>
</authors>
<title>A stacked sub-word model for joint chinese word segmentation and part-of-speech tagging.</title>
<date>2011</date>
<contexts>
<context position="19036" citStr="Sun (2011)" startWordPosition="3132" endWordPosition="3133">choice of decoding algorithm. When we experiment with different decoders, by default, the parameter weights in use are trained with the corresponding decoding algorithm. Especially, for experiments with lookahead features of English POS tagging, we prepare training data with the stacked learning technique, in order to alleviate overfitting. More specifically, we divide the training data into k folds, and tag each fold with the deterministic model learned over the other k-1 folds. The predicted tags of all folds are then merged into the gold training data and used (only) as lookahead features. Sun (2011) uses this technique to merge different levels of predictors for word segmentation. 5 Experiments 5.1 Data set We run experiments on English POS tagging on the WSJ corpus in the Penn Treebank. Following most previous work, e.g. (Collins, 2002) and (Shen et al., 2007), we divide this corpus into training set (sections 0-18), development set (sections 19-21) and the final test set (sections 22-24). We run experiments on Chinese word segmentation on the Penn Chinese Treebank 5.0. Following (Jiang et al., 2008a), we divide this corpus into training set (chapters 1-260), development set (chapters 2</context>
<context position="29580" citStr="Sun (2011)" startWordPosition="4885" endWordPosition="4886">t features, a richer feature set than the one we use here. As shown in Table 10, we achieve higher performance even with more compact features. Joint inference of CWS and Chinese POS tagging is popularly studied in recent work, e.g. (Ng and Low, 2004), (Jiang et al., 2008a), and (Kruengkrai et al., 2009). It has been shown that better performance can be achieved with joint inference, e.g. F-measure 0.978 by the cascaded model in (Jiang et al., 2008a). We focus on the task of word segmentation only in this work and show that a comparable F-measure is achievable in a much more efficient manner. Sun (2011) uses the stacked learning technique to merge different levels of predictors, obtaining a combined system that beats individual ones. Word-based features can be easily incorporated, since the ILP formulation is more naturally viewed as a word-based model. We extend character-based features with the word count features as described in Section 3.4. Currently, we only use word counts computed from training data, i.e. still a closed test. The addition of these features makes a moderate improvement on the F-measure, from 0.974 to 0.975. As discussed in Section 3.3, if we are able to determine that </context>
</contexts>
<marker>Sun, 2011</marker>
<rawString>W. Sun. 2011. A stacked sub-word model for joint chinese word segmentation and part-of-speech tagging.</rawString>
</citation>
<citation valid="true">
<date>2011</date>
<booktitle>In Proceedings of the ACL-HLT</booktitle>
<contexts>
<context position="19036" citStr="(2011)" startWordPosition="3133" endWordPosition="3133">ce of decoding algorithm. When we experiment with different decoders, by default, the parameter weights in use are trained with the corresponding decoding algorithm. Especially, for experiments with lookahead features of English POS tagging, we prepare training data with the stacked learning technique, in order to alleviate overfitting. More specifically, we divide the training data into k folds, and tag each fold with the deterministic model learned over the other k-1 folds. The predicted tags of all folds are then merged into the gold training data and used (only) as lookahead features. Sun (2011) uses this technique to merge different levels of predictors for word segmentation. 5 Experiments 5.1 Data set We run experiments on English POS tagging on the WSJ corpus in the Penn Treebank. Following most previous work, e.g. (Collins, 2002) and (Shen et al., 2007), we divide this corpus into training set (sections 0-18), development set (sections 19-21) and the final test set (sections 22-24). We run experiments on Chinese word segmentation on the Penn Chinese Treebank 5.0. Following (Jiang et al., 2008a), we divide this corpus into training set (chapters 1-260), development set (chapters 2</context>
<context position="29580" citStr="(2011)" startWordPosition="4886" endWordPosition="4886">atures, a richer feature set than the one we use here. As shown in Table 10, we achieve higher performance even with more compact features. Joint inference of CWS and Chinese POS tagging is popularly studied in recent work, e.g. (Ng and Low, 2004), (Jiang et al., 2008a), and (Kruengkrai et al., 2009). It has been shown that better performance can be achieved with joint inference, e.g. F-measure 0.978 by the cascaded model in (Jiang et al., 2008a). We focus on the task of word segmentation only in this work and show that a comparable F-measure is achievable in a much more efficient manner. Sun (2011) uses the stacked learning technique to merge different levels of predictors, obtaining a combined system that beats individual ones. Word-based features can be easily incorporated, since the ILP formulation is more naturally viewed as a word-based model. We extend character-based features with the word count features as described in Section 3.4. Currently, we only use word counts computed from training data, i.e. still a closed test. The addition of these features makes a moderate improvement on the F-measure, from 0.974 to 0.975. As discussed in Section 3.3, if we are able to determine that </context>
</contexts>
<marker>2011</marker>
<rawString>In Proceedings of the ACL-HLT 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Toutanova</author>
<author>D Klein</author>
<author>C Manning</author>
<author>Y Singer</author>
</authors>
<title>Feature-rich part-of-speech tagging with a cyclic dependency network.</title>
<date>2003</date>
<booktitle>In NAACL-2003.</booktitle>
<contexts>
<context position="26715" citStr="Toutanova et al., 2003" startWordPosition="4402" endWordPosition="4405">cally lookahead feature templates, tagging accuracy is increased from 96.80% to 97.02%. When no further data is used other than training data, the bidirectional tagger described in (Shen et al., 2007) achives an accuracy of 97.33%, using a much richer feature set (E) than feature set B, the one we compare with here. As noted above, the addition of three feature templates already has a notable negative impact on efficiency, thus the use of feature set E will hurt tagging efficiency much worse. Rich feature sets are also widely used in other work that pursue state-of-art tagging accuracy, e.g. (Toutanova et al., 2003). In this work, we focus on the most compact feature sets, since tagging efficiency is our main consideration in our work on POS taging. The proposed constrained taggers as described above can achieve near state-of-art POS tagging accuracy in a much more efficient manner. 5.4 Chinese word segmentation Like other tagging problems, Viterbi-style decoding is widely used for character tagging for CWS. We transform tagged character sequences to word segmentations first, and then evaluate word segmentations by F-measure, as defined in Section 5.2. We proposed an ILP formulation of the CWS problem in</context>
</contexts>
<marker>Toutanova, Klein, Manning, Singer, 2003</marker>
<rawString>K. Toutanova, D. Klein, C. Manning, and Y. Singer. 2003. Feature-rich part-of-speech tagging with a cyclic dependency network. In NAACL-2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Xue</author>
</authors>
<title>Chinese word segmentation as character tagging.</title>
<date>2003</date>
<journal>International Journal of Computational Linguistics and Chinese Language Processing,</journal>
<volume>9</volume>
<issue>1</issue>
<pages>48</pages>
<contexts>
<context position="10717" citStr="Xue, 2003" startWordPosition="1722" endWordPosition="1723">ding since searching is bidirectional instead of left-to-right as in Viterbi decoding. In this work, deterministic constraints are decoded before the application of probabilistic models, therefore lookahead features are made available during Viterbi decoding. 3 Chinese Word Segmentation (CWS) 3.1 Word segmentation as character tagging Considering the ambiguity problem that a Chinese character may appear in any relative position in a word and the out-of-vocabulary (OOV) problem that it is impossible to observe all words in training data, CWS is widely formulated as a character tagging problem (Xue, 2003). A character-based CWS decoder is to find the highest scoring tag sequence t over the input character sequence c, i.e. t = arg max ttagGEN(c) n X i=1 score(ti) . This is the same formulation as POS tagging. The Viterbi algorithm is also widely used for decoding. The tag of each character represents its relative position in a word. Two popular tagsets include 1) IB: where B tags the beginning of a word and I all other positions; and 2) BMES: where B, M and E represent the beginning, middle and end of a multicharacter word respectively, and S tags a singlecharacter word. For example, after deco</context>
</contexts>
<marker>Xue, 2003</marker>
<rawString>N. Xue. 2003. Chinese word segmentation as character tagging. International Journal of Computational Linguistics and Chinese Language Processing, 9(1):29 48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Zhang</author>
<author>S Clark</author>
</authors>
<title>Chinese Segmentation with a Word-Based Perceptron Algorithm.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>840847--0</pages>
<contexts>
<context position="13547" citStr="Zhang and Clark, 2007" startWordPosition="2200" endWordPosition="2203">on sequence w that is composed by the input character sequence c, i.e. w = arg max wsegGEN(c) |w| X i=1 score(wi) . where function segGEN maps character sequence c to the set of all possible segmentations of c. For example, w = (c1..cl1 )...(cnlk+1...cn) represents a segmentation of k words and the lengths of the first and last word are l1 and lk respectively. In early work, rule-based models find words one by one based on heuristics such as forward maximum match (Sproat et al., 1996). Exact search is possible with a Viterbi-style algorithm, but beamsearch decoding is more popular as used in (Zhang and Clark, 2007) and (Jiang et al., 2008a). We propose an Integer Linear Programming (ILP) formulation of word segmentation, which is naturally viewed as a word-based model for CWS. Character-based deterministic constraints, as discussed in Section 3.1, can be easily applied. 3.3 ILP formulation of CWS Given a character sequence c=c1...cn, there are s(= n(n+1)/2) possible words that are contiguous subsets of c, i.e. w1, ..., ws c. Our goal is to find Table 4: Comparison of raw input and constrained input. an optimal solution x = x1...xs that maximizes s X i=1 score(wi) xi, subject to (1) X i:cwi xi = 1, c c; </context>
</contexts>
<marker>Zhang, Clark, 2007</marker>
<rawString>Y. Zhang and S. Clark. 2007. Chinese Segmentation with a Word-Based Perceptron Algorithm. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 840847. \x0c&amp;apos;</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>