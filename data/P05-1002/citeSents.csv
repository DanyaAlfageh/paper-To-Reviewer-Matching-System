Error-correcting output codes have been used for text classification, as in CITATION, on which the following is based,,
This can be done by randomly sampling the column space, in which case the probability of poor separation diminishes quickly as the number of columns increases CITATION,,
Algebraic codes, such as BCH codes, are an alternative coding scheme which can provide near-optimal error-correcting capability CITATION, however these codes provide no guarantee of good column separation,,
Error correcting output codes (ECOC) CITATION are used to train a community of CRFs on binary tasks, with each discriminating between a subset of the labels and its complement,,
We tested for statistical significance using the matched pairs test CITATION at p < 0.001,,
These results show that error-correcting CRF training achieves quite similar performance to the multiclass CRF on the task (which incidentally exceeds CITATIONs result of 89.0 using feature induction),,
1 Introduction Conditional random fields (CRFs) CITATION are probabilistic models for labelling sequential data,,
4.2 Part-of-speech Tagging CRFs have been applied to POS tagging, however only with a very simple feature set and small training sample CITATION,,
This can be done by randomly sampling the column space, in which case the probability of poor separation diminishes quickly as the number of columns increases CITATION,,
Algebraic codes, such as BCH codes, are an alternative coding scheme which can provide near-optimal error-correcting capability CITATION, however these codes provide no guarantee of good column separation,,
4.1 Named entity recognition CRFs have been used with strong results on the CoNLL 2003 NER task CITATION and thus this task is inc,,
In recent empirical studies on maximum entropy models and CRFs, limited memory variable metric (LMVM) has proven to be the most efficient method (CITATION; CITATION); accordingly, we have used LMVM for CRF estimation,,
CRFs have been applied with impressive empirical results to the tasks of named entity recognition CITATION, simplified part-of-speech (POS) tagging CITATION, noun phrase chunking CITATION and extraction of tabular data CITATION, among other tasks,,
capability CITATION, however these codes provide no guarantee of good column separation,,
4.1 Named entity recognition CRFs have been used with strong results on the CoNLL 2003 NER task CITATION and thus this task is included here as a benchmark,,
We tested for statistical significance using the matched pairs test CITATION at p < 0.001,,
These results show that error-correcting CRF training achieves quite similar performance to the multiclass CRF on the task (which incidentally exceeds CITATIONs result of 89.0 using feature induction),,
CITATION describes a technique for greedily adding those feature conjuncts to a CRF which significantly improve the models log-likelihood,,
CITATION have also employed feature selection to the huge task of language modelling with a CRF, by partially training a voted perceptron then removing all features that the are ignored by the perceptron,,
CRFs have been applied with impressive empirical results to the tasks of named entity recognition CITATION, simplified part-of-speech (POS) tagging CITATION, noun phrase chunking CITATION and extraction of tabular data CITATION, among other tasks,,
CITATION describes a technique for greedily adding those feature conjuncts to a CRF which significantly improve the models log-likelihood,,
CITATION have also employed feature selection to the huge task of language modelling with a CRF, by partially training a voted perceptron then removing all features that the are ignored by the perceptron,,
Error-correction codes could be applied to other sequence labelling methods, such as the voted perceptron CITATION,,
We have also shown how the errorcorrecting CRF scales when applied to the larger task of POS tagging the Penn Treebank and also the even larger task of simultaneously noun phrase chunking (NPC) and POS tagging using the CoNLL 2000 data-set CITATION,,
CRFs have been applied with impressive empirical results to the tasks of named entity recognition CITATION, simplified part-of-speech (POS) tagging CITATION, noun phrase chunking CITATION and extraction of tabular data CITATION, among other tasks,,
Note that this decoding is an equivalent formulation to a uniformly weighted logarithmic opinion pool, as described in CITATION,,
CITATION applied a variant of the CRF, the dynamic CRF (DCRF), to the same task, modelling the data with two interconnected chains where one chain predicted NPC tags and the other POS tags,,
This result exceeds Lafferty et al.s accuracy of 95.73% using a CRF but falls short of CITATIONs state-of-the-art 97.24%,,
In recent empirical studies on maximum entropy models and CRFs, limited memory variable metric (LMVM) has proven to be the most efficient method (CITATION; CITATION); accordingly, we have used LMVM for CRF estimation,,
