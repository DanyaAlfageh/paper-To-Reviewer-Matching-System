 CITATION have already argued that this is a highly critical requirement because the examples selected by AL are tuned to one particular classifier,,
 Whereas CITATION reports positive results, CITATION argue that AL based on uncertainty sampling may face serious performance degradation when labeled data is reused for training a classifier different from the one employed during AL,,
 CITATION),,
 reusability The examples AL selects for manual annotation are dependent on the model being used, up to a certain extent CITATION,,
ects of AL for real annotation projects in CITATION,,
 These findings stand in contrast to those supplied by CITATION who focused on parse selection,,
 In co-training CITATION, e,,
 CITATION have shown, however, that for tasks which require large numbers of labeled examples such as most NLP tasks cotraining might be inadequate because it tends to generate noisy data,,
 optimization approaches which aim at selecting those examples that optimize some (algorithm-dependent) objective function, such as prediction variance CITATION, and heuristic methods with uncertainty sampling CITATION and query-by-committee (QBC) CITATION just to name the most prominent ones,,
 AL has already been applied to several NLP tasks, such as document classification CITATION, POS tagging CITATION, chunking CITATION, statistical parsing (CITATION; CITATION), and information extraction (CITATION; CITATION),,
 In a more recent study, CITATION consider AL for entity recognition based on Support Vector Machines,,
 CITATION),,
 reusability The examples AL selects for manual annotation are dependent on the model being used, up to a certain extent CITATION,,
 optimization approaches which aim at selecting those examples that optimize some (algorithm-dependent) objective function, such as prediction variance CITATION, and heuristic methods with uncertainty sampling CITATION and query-by-committee (QBC) CITATION just to name the most prominent ones,,
 AL has already been applied to several NLP tasks, such as document classification CITATION, POS tagging CITATION, chunking CITATION, statistical parsing (CITATION; CITATION), and information extraction (CITATION; CITATION),,
 In a more recent study, CITATION consider AL for entity recognition based on Support Vector Machines,,
 Accordingly, we ruled out uncertainty sampling, another heuristic AL approach, because it was shown before that QBC is more efficient and robust CITATION,,
 QBC is based on the idea to select those examples for manual annotation on which a committee of classifiers disagree most in their predictions CITATION,,
, IL2 AA0, have aaaa) lexical and morphological prefix and suffix of length 3, stemmed version of each token syntactic the tokens part-of-speech tag contextual features of neighboring tokens Table 1: Features used for AL versity of a batch and representativeness of the respective example (to avoid outliers) CITATION,,
 CITATION confirm this observation that, in general, different (and even more refined) selection methods still yield similar results,,
 Accordingly, we ruled out uncertainty sampling, another heuristic AL approach, because it was shown before that QBC is more efficient and robust CITATION,,
 QBC is based on the idea to select those examples for manual annotation on which a committee of classifiers disagree most in their predictions CITATION,,
00), statistical parsing (CITATION; CITATION), and information extraction (CITATION; CITATION),,
 In a more recent study, CITATION consider AL for entity recognition based on Support Vector Machines,,
 CITATION propose a committee-based AL approach where the committees classifiers constitute multiple views on the data by employing different feature subsets,,
al parsing (CITATION; CITATION), and information extraction (CITATION; CITATION),,
 In a more recent study, CITATION consider AL for entity recognition based on Support Vector Machines,,
 CITATION propose a committee-based AL approach where the committees classifiers constitute multiple views on the data by employing different feature subsets,,
 optimization approaches which aim at selecting those examples that optimize some (algorithm-dependent) objective function, such as prediction variance CITATION, and heuristic methods with uncertainty sampling CITATION and query-by-committee (QBC) CITATION just to name the most prominent ones,,
 AL has already been applied to several NLP tasks, such as document classification CITATION, POS tagging CITATION, chunking CITATION, statistical parsing (CITATION; CITATION), and information extraction (CITATION; CITATION),,
 In a more recent study, CITATION consider AL for entity recognition based on Support Vector Machines,,
 CITATION propose a committee-based AL approach ,,
 Whereas CITATION reports positive results, CITATION argue that AL based on uncertainty sampling may face serious performance degradation when labeled data is reused for training a classifier different from the one employed during AL,,
 optimization approaches which aim at selecting those examples that optimize some (algorithm-dependent) objective function, such as prediction variance CITATION, and heuristic methods with uncertainty sampling CITATION and query-by-committee (QBC) CITATION just to name the most prominent ones,,
 AL has already been applied to several NLP tasks, such as document classification CITATION, POS tagging CITATION, chunking CITATION, statistical parsing (CITATION; CITATION), and information extraction (CITATION; CITATION),,
 In a more recent study, CITATION consider AL for entity recognition based on Support Vector Machines,,
 optimization approaches which aim at selecting those examples that optimize some (algorithm-dependent) objective function, such as prediction variance CITATION, and heuristic methods with uncertainty sampling CITATION and query-by-committee (QBC) CITATION just to name the most prominent ones,,
 AL has already been applied to several NLP tasks, such as document classification CITATION, POS tagging CITATION, chunking CITATION, statistical parsing (CITATION; CITATION), and information extraction (CITATION; CITATION),,
 In a more recent study, CITATION consider AL for entity recognition based on Support Vector Machines,,
 In co-training CITATION, e,,
 CITATION have shown, however, that for tasks which require large numbers of labeled examples such as most NLP tasks cotraining might be inadequate because it tends to generate noisy data,,
 optimization approaches which aim at selecting those examples that optimize some (algorithm-dependent) objective function, such as prediction variance CITATION, and heuristic methods with uncertainty sampling CITATION and query-by-committee (QBC) CITATION just to name the most prominent ones,,
 AL has already been applied to several NLP tasks, such as document classification CITATION, POS tagging CITATION, chunking CITATION, statistical parsing (CITATION; CITATION), and information extraction (CITATION; CITATION),,
 In a more recent study, CITATION consider AL for entity recognition based on Support Vector Machines,,
 optimization approaches which aim at selecting those examples that optimize some (algorithm-dependent) objective function, such as prediction variance CITATION, and heuristic methods with uncertainty sampling CITATION and query-by-committee (QBC) CITATION just to name the most prominent ones,,
 AL has already been applied to several NLP tasks, such as document classification CITATION, POS tagging CITATION, chunking CITATION, statistical parsing (CITATION; CITATION), and information extraction (CITATION; CITATION),,
 In a more recent study, CITATION consider AL for entity recognition based on Support Vector Machines,,
e some (algorithm-dependent) objective function, such as prediction variance CITATION, and heuristic methods with uncertainty sampling CITATION and query-by-committee (QBC) CITATION just to name the most prominent ones,,
 AL has already been applied to several NLP tasks, such as document classification CITATION, POS tagging CITATION, chunking CITATION, statistical parsing (CITATION; CITATION), and information extraction (CITATION; CITATION),,
 In a more recent study, CITATION consider AL for entity recognition based on Support Vector Machines,,
 CITATION propose a committee-based AL approach where the committees classifiers constitute multiple views on the data by employing different feature subsets,,
, IL2 AA0, have aaaa) lexical and morphological prefix and suffix of length 3, stemmed version of each token syntactic the tokens part-of-speech tag contextual features of neighboring tokens Table 1: Features used for AL versity of a batch and representativeness of the respective example (to avoid outliers) CITATION,,
 CITATION confirm this observation that, in general, different (and even more refined) selection methods still yield similar results,,
 optimization approaches which aim at selecting those examples that optimize some (algorithm-dependent) objective function, such as prediction variance CITATION, and heuristic methods with uncertainty sampling CITATION and query-by-committee (QBC) CITATION just to name the most prominent ones,,
 AL has already been applied to several NLP tasks, such as document classification CITATION, POS tagging CITATION, chunking CITATION, statistical parsing (CITATION; CITATION), and information extraction (CITATION; CITATION),,
 In a more recent study, CITATION consider AL for entity recognition based on Support Vector Machines,,
 CITATION propose a committee-based ,,
 We report on other aspects of AL for real annotation projects in CITATION,,
 These findings stand in contrast to those supplied by CITATION who focused on parse selection,,
