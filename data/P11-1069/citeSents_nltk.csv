07), logical form construction CITATION and surface realization CITATION.,,
From a parsing perspective, the C&C parser CITATION has been shown to be competitive with state-of-theart statistical parsers on a variety of test suites, including those consisting of grammatical relations CITATION, Penn Treebank phrasestructure trees CITATION, and unbounded dependencies CITATION.,,
The binary branching nature of CCG means that it is naturally compatible with bottom-up parsing algorithms such as shift-reduce and CKY (CITATION; CITATION).,,
However, the parsing work by CITATION, and also CITATION and CITATION, has only considered chart-parsing.,,
Shift-reduce parsers have become popular for dependency parsing, building on the initial work of CITATION and CITATION.,,
1 Introduction Combinatory Categorial Grammar (CCG; CITATION) is a lexicalised theory of grammar which has been successfully applied to a range of problems in NLP, including treebank creation CITATION, syntactic parsing (CITATION; CITATION), logical form construction CITATION and surface realization CITATION.,,
From a parsing perspective, the C&C parser CITATION has been shown to be competitive with state-of-theart statistical parsers on a variety of test suites, including those consisting of grammatical relations CITATION, Penn Treebank phrasestructure trees CITATION, and unbounded dependencies CITATION.,,
The binary branching nature of CCG means that it is naturally compatible with bottom-up parsing algorithms such as shift-reduce and CKY (CITATION; CITATION).,,
1 Introduction Combinatory Categorial Grammar (CCG; CITATION) is a lexicalised theory of grammar which has been successfully applied to a range of problems in NLP, including treebank creation CITATION, syntactic parsing (CITATION; CITATION), logical form construction CITATION and surface realization CITATION.,,
From a parsing perspective, the C&C parser CITATION has been shown to be competitive with state-of-theart statistical parsers on a variety of test suites, including those consisting of grammatical relations CITATION, Penn Treebank phrasestructure trees CITATION, and unbounded dependencies CITATION.,,
 (2003) and CITATION.,,
In addition, high accuracy can be maintained by using a model which utilises a rich set of features for making each local decision CITATION.,,
Following recent work applying global discriminative models to large-scale structured prediction problems (CITATION; CITATION; CITATION; Finkel et al., 2008), we build our shift-reduce parser using a global linear model, and compare it with the chartbased C&C parser.,,
Hence our work shows that 683 \x0ctransition-based parsing can be successfully applied to CCG, improving on earlier attempts such as CITATION.,,
2 CCG Parsing CCG, and the application of CCG to wide-coverage parsing, is described in detail elsewhere (CITATION; CITATION; CITATION).,,
CITATION and CITATION for chartbased parsers which can produce fragmentary analyses.,,
x0cmethod, which has the potential to produce a mildlycontext sensitive grammar (given the existence of certain combinatory rules) CITATION.,,
However, it is important to note that the advantages of CCG, in particular the tight relationship between syntax and semantic interpretation, are still maintained with the second approach, as CITATION argue.,,
Following CITATION, we assume that each input word has been assigned a POS-tag (from the Penn Treebank tagset) and a set of CCG lexical categories.,,
CITATION gives a more precise definition.,,
We ran the C&C parser using the normal-form model (we reproduced the numbers reported in CITATION), and copied the results of the hybrid model from CITATION, since the hybrid model is not part of the public release.,,
The numbers for C&C are for the hybrid model, copied from CITATION.,,
The numbers for the normal-form model are evaluated by running the publicly available parser, while those for the hybrid dependency model are from CITATION.,,
alised theory of grammar which has been successfully applied to a range of problems in NLP, including treebank creation CITATION, syntactic parsing (CITATION; CITATION), logical form construction CITATION and surface realization CITATION.,,
From a parsing perspective, the C&C parser CITATION has been shown to be competitive with state-of-theart statistical parsers on a variety of test suites, including those consisting of grammatical relations CITATION, Penn Treebank phrasestructure trees CITATION, and unbounded dependencies CITATION.,,
The binary branching nature of CCG means that it is naturally compatible with bottom-up parsing algorithms such as shift-reduce and CKY (CITATION; CITATION).,,
However, the parsing work by CITATION, and also CITATION and CITATION, has only considered chart-parsing.,,
Shift-reduce parsers have become popular for dependency parsing, building on the initial work of CITATION and N,,
lding on the initial work of CITATION and CITATION.,,
In addition, high accuracy can be maintained by using a model which utilises a rich set of features for making each local decision CITATION.,,
Following recent work applying global discriminative models to large-scale structured prediction problems (CITATION; CITATION; CITATION; Finkel et al., 2008), we build our shift-reduce parser using a global linear model, and compare it with the chartbased C&C parser.,,
Hence our work shows that 683 \x0ctransition-based parsing can be successfully applied to CCG, improving on earlier attempts such as CITATION.,,
5 Model and Training We use a global linear model to score candidate items, trained discriminatively with the averaged perceptron CITATION.,,
Following CITATION, we apply the early update strategy to perceptron training: at any step during decoding, if neither the candidate output nor any item in the agenda is correct, decoding is stopped and the parameters are updated using the current highest scored item in the agenda or the candidate output, whichever has the higher score.,,
5 Model and Training We use a global linear model to score candidate items, trained discriminatively with the averaged perceptron CITATION.,,
Following CITATION, we apply the early update strategy to perceptron training: at any step during decoding, if neither the candidate output nor any item in the agenda is correct, decoding is stopped and the parameters are updated using the current highest scored item in the agenda or the candidate output, whichever has the higher score.,,
, the C&C parser CITATION has been shown to be competitive with state-of-theart statistical parsers on a variety of test suites, including those consisting of grammatical relations CITATION, Penn Treebank phrasestructure trees CITATION, and unbounded dependencies CITATION.,,
The binary branching nature of CCG means that it is naturally compatible with bottom-up parsing algorithms such as shift-reduce and CKY (CITATION; CITATION).,,
However, the parsing work by CITATION, and also CITATION and CITATION, has only considered chart-parsing.,,
Shift-reduce parsers have become popular for dependency parsing, building on the initial work of CITATION and CITATION.,,
This is the method used by CITATION and is the method we adopt in this paper.,,
CITATION demonstrate that the second extraction method results in a context-free approximation to the grammar resulting from the first 2 Although the C&C default mode applies a restriction for efficiency reasons in which only rule instances seen in CCGbank can be applied, making the grammar of the second type.,,
684 \x0cmethod, which has the potential to produce a mildlycontext sensitive grammar (given the existence of certain combinatory rules) CITATION.,,
The last two rows in the table show the accuracies of CITATION (F&P), who applied the CFG parser of CITATION to CCG, and the corresponding accuracies for the C&C parser on the same test sentences.,,
prediction problems (CITATION; CITATION; CITATION; Finkel et al., 2008), we build our shift-reduce parser using a global linear model, and compare it with the chartbased C&C parser.,,
Hence our work shows that 683 \x0ctransition-based parsing can be successfully applied to CCG, improving on earlier attempts such as CITATION.,,
1 Introduction Combinatory Categorial Grammar (CCG; CITATION) is a lexicalised theory of grammar which has been successfully applied to a range of problems in NLP, including treebank creation CITATION, syntactic parsing (CITATION; CITATION), logical form construction CITATION and surface realization CITATION.,,
From a parsing perspective, the C&C parser CITATION has been shown to be competitive with state-of-theart statistical parsers on a variety of test suites, including those consisting of grammatical relations CITATION, Penn Treebank phrasestructure trees CITATION, and unbounded dependencies CITATION.,,
The resource used for building wide-coverage CCG parsers of English is CCGbank CITATION, a version of the Penn Treebank in which each phrase-structure tree has been transformed into a normal-form CCG derivation.,,
6 Experiments Our experiments were performed using CCGBank CITATION, which was split into three subsets for training (Sections 0221), development testing (Section 00) and the final test (Section 23).,,
1 Introduction Combinatory Categorial Grammar (CCG; CITATION) is a lexicalised theory of grammar which has been successfully applied to a range of problems in NLP, including treebank creation CITATION, syntactic parsing (CITATION; CITATION), logical form construction CITATION and surface realization CITATION.,,
From a parsing perspective, the C&C parser CITATION has been shown to be competitive with state-of-theart statistical parsers on a variety of test suites, including those consisting of grammatical relations CITATION, Penn Treebank phrasestructure trees CITATION, and unbounded dependencies CITATION.,,
2 CCG Parsing CCG, and the application of CCG to wide-coverage parsing, is described in detail elsewhere (CITATION; CITATION; CITATION).,,
CITATION and CITATION for chartbased parsers which can produce fragmentary analyses.,,
This is the method used by CITATION and is the method we adopt in this paper.,,
CITATION demonstrate that the second extraction method results in a context-free approximation to the grammar resulting from the first 2 Although the C&C default mode applies a restriction for efficiency reasons in which only rule instances seen in CCGbank can be applied, making the grammar of the second type.,,
684 \x0cmethod, which has the potential to produce a mildlycontext sensitive grammar (given the existence of certain combinatory rules) CITATION.,,
4 Decoding Greedy local search (CITATION; CITATION; CITATION) has typically been used for decoding in shift-reduce parsers, while beam-search has recently been applied as an alternative to reduce error-propagation (CITATION; CITATION; CITATION; CITATION).,,
4 Decoding Greedy local search (CITATION; CITATION; CITATION) has typically been used for decoding in shift-reduce parsers, while beam-search has recently been applied as an alternative to reduce error-propagation (CITATION; CITATION; CITATION; CITATION).,,
7 Related Work CITATIONa) describes a shift-reduce parser for the Penn Treebank parsing task which uses best-first search to allow some ambiguity into the parsing process.,,
Differences with our approach are that we use a beam, rather than best-first, search; we use a global model rather than local models chained together; and finally, our results surpass the best published results on the CCG parsing task, whereas CITATIONa) matched the best PTB results only by using a parser combination.,,
CITATION describes similar work to ours but using an automatically-extracted HPSG, rather than CCG, grammar.,,
One difference is that CITATION use an approximating CFG, in addition to the supertagger, to improve the efficiency of the parser.,,
690 \x0cCITATION (and CITATION) describe a greedy shift-reduce parser for HPSG, in which a single action is chosen at each parsing step, allowing the possibility of highly efficient parsing.,,
The comparison reported in this section is similar to the comparison between the chartbased MSTParser CITATION and shiftreduce MaltParser CITATION for dependency parsing.,,
We follow CITATION and characterize the errors of the two parsers by sentence and dependency length and dependency type.,,
The comparison reported in this section is similar to the comparison between the chartbased MSTParser CITATION and shiftreduce MaltParser CITATION for dependency parsing.,,
We follow CITATION and characterize the errors of the two parsers by sentence and dependency length and dependency type.,,
(2009) (and CITATION) describe a greedy shift-reduce parser for HPSG, in which a single action is chosen at each parsing step, allowing the possibility of highly efficient parsing.,,
Our approach to this problem was to allow the parser to return a fragmentary analysis; CITATION adopt a different approach based on default unification.,,
Finally, our work is similar to the comparison of the chart-based MSTParser CITATION and shift-reduce MaltParser CITATION for dependency parsing.,,
 of CITATION and CITATION.,,
In addition, high accuracy can be maintained by using a model which utilises a rich set of features for making each local decision CITATION.,,
Following recent work applying global discriminative models to large-scale structured prediction problems (CITATION; CITATION; CITATION; Finkel et al., 2008), we build our shift-reduce parser using a global linear model, and compare it with the chartbased C&C parser.,,
Hence our work shows that 683 \x0ctransition-based parsing can be successfully applied to CCG, improving on earlier attempts such as CITATION.,,
 we use a global model rather than local models chained together; and finally, our results surpass the best published results on the CCG parsing task, whereas CITATIONa) matched the best PTB results only by using a parser combination.,,
CITATION describes similar work to ours but using an automatically-extracted HPSG, rather than CCG, grammar.,,
One difference is that CITATION use an approximating CFG, in addition to the supertagger, to improve the efficiency of the parser.,,
690 \x0cCITATION (and CITATION) describe a greedy shift-reduce parser for HPSG, in which a single action is chosen at each parsing step, allowing the possibility of highly efficient parsing.,,
Our approach to this problem was to allow the parser to return a fragmentary analysis; CITATION adopt a different approach based on default unification.,,
r than local models chained together; and finally, our results surpass the best published results on the CCG parsing task, whereas CITATIONa) matched the best PTB results only by using a parser combination.,,
CITATION describes similar work to ours but using an automatically-extracted HPSG, rather than CCG, grammar.,,
One difference is that CITATION use an approximating CFG, in addition to the supertagger, to improve the efficiency of the parser.,,
690 \x0cCITATION (and CITATION) describe a greedy shift-reduce parser for HPSG, in which a single action is chosen at each parsing step, allowing the possibility of highly efficient parsing.,,
Our approach to this problem was to allow the parser to return a fragmentary analysis; CITATION adopt a different approach based on default unification.,,
Finally, our work is similar to the comparison of the chart-based MSTParser CITATION and shift-reduc,,
), and unbounded dependencies CITATION.,,
The binary branching nature of CCG means that it is naturally compatible with bottom-up parsing algorithms such as shift-reduce and CKY (CITATION; CITATION).,,
However, the parsing work by CITATION, and also CITATION and CITATION, has only considered chart-parsing.,,
Shift-reduce parsers have become popular for dependency parsing, building on the initial work of CITATION and CITATION.,,
In addition, high accuracy can be maintained by using a model which utilises a rich set of features for making each local decision CITATION.,,
Following recent work applying global discriminative models to large-scale structured prediction problems (CITATION; CITATION; CITATION; Finkel et a,,
4 Decoding Greedy local search (CITATION; CITATION; CITATION) has typically been used for decoding in shift-reduce parsers, while beam-search has recently been applied as an alternative to reduce error-propagation (CITATION; CITATION; CITATION; CITATION).,,
Shift-reduce parsers have become popular for dependency parsing, building on the initial work of CITATION and CITATION.,,
In addition, high accuracy can be maintained by using a model which utilises a rich set of features for making each local decision CITATION.,,
Following recent work applying global discriminative models to large-scale structured prediction problems (CITATION; CITATION; CITATION; Finkel et al., 2008), we build our shift-reduce parser using a global linear model, and compare it with the chartbased C&C parser.,,
Unlike the C&C parser, the shift-reduce parser naturally produces fragmentary analyses when appropriate CITATION, and can produce sensible local structures even when a full spanning analysis cannot be found.1 Finally, considering this work in the wider parsing context, it provides an interesting comparison between heuristic beam search using a rich set of features, and optimal dynamic programming search where the feature range is restricted.,,
A key difference with previous work on shiftreduce dependency CITATION and CFG (CITATIONb) parsing is that, for CCG, there are many more shift actions a shift action for each word-lexical category pair.,,
The comparison reported in this section is similar to the comparison between the chartbased MSTParser CITATION and shiftreduce MaltParser CITATION for dependency parsing.,,
We follow CITATION and characterize the errors of the two parsers by sentence and dependency length and dependency type.,,
Our approach to this problem was to allow the parser to return a fragmentary analysis; CITATION adopt a different approach based on default unification.,,
Finally, our work is similar to the comparison of the chart-based MSTParser CITATION and shift-reduce MaltParser CITATION for dependency parsing.,,
The last two rows in the table show the accuracies of CITATION (F&P), who applied the CFG parser of CITATION to CCG, and the corresponding accuracies for the C&C parser on the same test sentences.,,
2 CCG Parsing CCG, and the application of CCG to wide-coverage parsing, is described in detail elsewhere (CITATION; CITATION; CITATION).,,
CITATION and CITATION for chartbased parsers which can produce fragmentary analyses.,,
applied to a range of problems in NLP, including treebank creation CITATION, syntactic parsing (CITATION; CITATION), logical form construction CITATION and surface realization CITATION.,,
From a parsing perspective, the C&C parser CITATION has been shown to be competitive with state-of-theart statistical parsers on a variety of test suites, including those consisting of grammatical relations CITATION, Penn Treebank phrasestructure trees CITATION, and unbounded dependencies CITATION.,,
The binary branching nature of CCG means that it is naturally compatible with bottom-up parsing algorithms such as shift-reduce and CKY (CITATION; CITATION).,,
However, the parsing work by CITATION, and also CITATION and CITATION, has only considered chart-parsing.,,
Shift-reduce parsers have become popular for dependency parsing, building on the initial work of CITATION and CITATION.,,
4 Decoding Greedy local search (CITATION; CITATION; CITATION) has typically been used for decoding in shift-reduce parsers, while beam-search has recently been applied as an alternative to reduce error-propagation (CITATION; CITATION; CITATION; CITATION).,,
A key difference with previous work on shiftreduce dependency CITATION and CFG (CITATIONb) parsing is that, for CCG, there are many more shift actions a shift action for each word-lexical category pair.,,
7 Related Work CITATIONa) describes a shift-reduce parser for the Penn Treebank parsing task which uses best-first search to allow some ambiguity into the parsing process.,,
Differences with our approach are that we use a beam, rather than best-first, search; we use a global model rather than local models chained together; and finally, our results surpass the best published results on the CCG parsing task, whereas CITATIONa) matched the best PTB results only by using a parser combination.,,
CITATION describes similar work to ours but using an automatically-extracted HPSG, rather than CCG, gra,,
A key difference with previous work on shiftreduce dependency CITATION and CFG (CITATIONb) parsing is that, for CCG, there are many more shift actions a shift action for each word-lexical category pair.,,
7 Related Work CITATIONa) describes a shift-reduce parser for the Penn Treebank parsing task which uses best-first search to allow some ambiguity into the parsing process.,,
Differences with our approach are that we use a beam, rather than best-first, search; we use a global model rather than local models chained together; and finally, our results surpass the best published results on the CCG parsing task, whereas CITATIONa) matched the best PTB results only by using a parser combination.,,
CITATION describes similar work to ours but using an automatically-extracted HPSG, rather than CCG, gra,,
1 Introduction Combinatory Categorial Grammar (CCG; CITATION) is a lexicalised theory of grammar which has been successfully applied to a range of problems in NLP, including treebank creation CITATION, syntactic parsing (CITATION; CITATION), logical form construction CITATION and surface realization CITATION.,,
From a parsing perspective, the C&C parser CITATION has been shown to be competitive with state-of-theart statistical parsers on a variety of test suites, including those consisting of grammatical relations CITATION, Penn Treebank phrasestruc,,
2 CCG Parsing CCG, and the application of CCG to wide-coverage parsing, is described in detail elsewhere (CITATION; CITATION; CITATION).,,
CITATION and CITATION for chartbased parsers which can produce fragmentary analyses.,,
This is the method used by CITATION and is the method we adopt in this paper.,,
CITATION demonstrate that the second extraction method results in a context-free approximation to the grammar resulting from the first 2 Although the C&C default mode applies a restriction for efficiency reasons in which only rule instances seen in CCGbank can be applied, making the grammar of the second type.,,
684 \x0cmethod, which has the potential to produce a mildlycontext sensitive grammar (given the existence of certain combinatory rules) CITATION.,,
However, it is important to note that the advantages of CCG, in particular the tight relationship between syntax and semantic interpretation, are still maintained with the second approach, as CITATION argue.,,
Following CITATION, we assume that each input word has been assigned a POS-tag (from the Penn Treebank tagset) and a set of CCG lexical ca,,
1 Introduction Combinatory Categorial Grammar (CCG; CITATION) is a lexicalised theory of grammar which has been successfully applied to a range of problems in NLP, including treebank creation CITATION, syntactic parsing (CITATION; CITATION), logical form construction CITATION and surface realization CITATION.,,
From a parsing perspective, the C&C parser CITATION has been shown to be competitive with state-of-theart statistical parsers on a variety of test suites, including those consisting of grammatical relations CITATION, Penn Treebank phrasestructure trees CITATION, and unbounded dependencies CITATION.,,
The binary branching nature of CCG means that it is naturally compatible with bottom-up parsing algorithms such as shift-reduce and CKY (CITATION; CITATION).,,
However, the parsing work by CITATION, and,,
re trees CITATION, and unbounded dependencies CITATION.,,
The binary branching nature of CCG means that it is naturally compatible with bottom-up parsing algorithms such as shift-reduce and CKY (CITATION; CITATION).,,
However, the parsing work by CITATION, and also CITATION and CITATION, has only considered chart-parsing.,,
Shift-reduce parsers have become popular for dependency parsing, building on the initial work of CITATION and CITATION.,,
In addition, high accuracy can be maintained by using a model which utilises a rich set of features for making each local decision CITATION.,,
Following recent work applying global discriminative models to large-scale structured prediction problems (CITATION; CITATION; Clark a,,
4 Decoding Greedy local search (CITATION; CITATION; CITATION) has typically been used for decoding in shift-reduce parsers, while beam-search has recently been applied as an alternative to reduce error-propagation (CITATION; CITATION; CITATION; CITATION).,,
4 Decoding Greedy local search (CITATION; CITATION; CITATION) has typically been used for decoding in shift-reduce parsers, while beam-search has recently been applied as an alternative to reduce error-propagation (CITATION; CITATION; CITATION; CITATION).,,
4 Decoding Greedy local search (CITATION; CITATION; CITATION) has typically been used for decoding in shift-reduce parsers, while beam-search has recently been applied as an alternative to reduce error-propagation (CITATION; CITATION; CITATION; CITATION).,,
2 CCG Parsing CCG, and the application of CCG to wide-coverage parsing, is described in detail elsewhere (CITATION; CITATION; CITATION).,,
CITATION and CITATION for chartbased parsers which can produce fragmentary analyses.,,
