In line with CITATION, we define it as: s1(T, H) = X (wt,wh)A simw(wt, wh) idf(wh) X whWH idf(wh) (3) where idf(w) is the inverse document frequency of the word w,,
Unfortunately, a counterexample illustrated in CITATION shows that the max function does not produce valid kernels in general,,
- WordNet 2.0 CITATION to extract both the verbs in entailment, Ent set, and the derivationally related words, Der set,,
6.1 Experimental settings For the experiments, we used the Recognizing Textual Entailment Challenge data sets, which we name as follows: - D1, T1 and D2, T2, are the development and the test sets of the first CITATION and second (Bar CITATION) challenges, respectively,,
Although these implications are uncontroversial, their automatic recognition is complex if we rely on models based on lexical distance (or similarity) between hypothesis and text, e.g., CITATION,,
As the corresponding maximum quantifies the alignment degree, we could define a cross-pair similarity as follows: Ks((T0 , H0 ), (T00 , H00 )) = max cC \x10 KT (t(H0 , c), t(H00 , i)) +KT (t(T0 , c), t(T00 , i) \x11 , (6) where as KT (t1, t2) we use the tree kernel function defined in CITATION,,
As described in CITATION, can be computed in O(|Nt1 | |Nt2 |),,
t 2.0 CITATION to extract both the verbs in entailment, Ent set, and the derivationally related words, Der set,,
Our approach is in line with many other researches (e.g., (CITATION; Glickman et al., 2005)),,
These transformations are logical rules in CITATION or sequences of allowed rewrite rules in (de Salvo CITATION),,
- SVM-light-TK3 CITATION which encodes the basic tree kernel function, KT , in SVMlight CITATION,,
To reduce the number of placeholders, we consider the notion of chunk defined in CITATION, i.e., not recursive kernels of noun, verb, adjective, and adverb phrases,,
We also used the following resources: - The Charniak parser CITATION and the morpha lemmatiser CITATION to carry out the syntactic and morphological analysis,,
The comparative results show that (a) we have designed an effective way to automatically learn entailment rules from examples and (b) our approach is highly accurate and exceeds the accuracy of the current state-of-the-art 401 \x0cmodels (Glickman et al., 2005; CITATION) by about 4.4% (i.e,,
Second, we can use one of the WordNet CITATION similarities indicated with d(lw, lw0 ) (in line with what was done in CITATION) and different relation between words such as the lexical entailment between verbs (Ent) and derivationally relation between words (Der),,
This has been mainly due to the RTE challenge events (CITATION; Bar CITATION),,
- The wn::similarity package CITATION to compute the Jiang&Conrath (J&C) distance CITATION as in CITATION,,
- SVM-light-TK3 CITATION whi,,
The main reason is that the understanding of the basic entailment processes will allow us to model more accurate semantic theories of natural languages CITATION and design important applications CITATION, e.g., Question Answering and Information Extraction,,
We experimented with such kernel using Support Vector Machines CITATION on the test tests of the Recognizing Textual Entailment (RTE) challenges (CITATION; Bar CITATION),,
On the Train:D1-Test:T1 test set, it exceeds the accuracy of the current state-of-theart models (Glickman et al., 2005; CITATION) by about 4.4 absolute percent points (63% vs,,
58.6%) on the RTE 1 test set CITATION,,
58.6% (Glickman et al., 2005; CITATION), is not significantly different from the result obtained with K1 that uses the idf,,
However, we observe that: (1) Ks((T0, H0), (T00, H00)) is a symmetric function since the set of transformation C are always computed with respect to the pair that has the largest anchor set; (2) in CITATION, it is shown that when kernel functions are not positive semidefinite, SVMs still solve a data separation problem in pseudo Euclidean spaces,,
- Second, the dataset Train:D1-Test:T1 allows us to compare our models with the ones of the first RTE challenge CITATION,,
- Third, the dramatic improvement observed in CITATION on the dataset Train:D1-Test:T1 is given by the idf rather than the use of the J&C similarity (second vs,,
However, previous work (e.g., CITATION) suggests that determining whether or not a text T entails a hypothesis H is quite complex even when all the needed information is explicitly asserted,,
Indeed, if we encode such movements in the syntactic parse trees of texts and hypotheses, we can use interesting similarity measures defined for syntactic parsing, e.g., the tree kernel devised in CITATION,,
A first class of methods defines measures of the distance or similarity between T and H either assuming the independence between words (CITATION; Glickman et al., 2005) in a bag-of-word fashion or exploiting syntactic interpretations CITATION,,
