Unfortunately, as parallel corpora are expensive and not available for every domain, performance of SMT systems drops significantly when translating out-of-domain texts CITATION,,
(CITATIONb) have shown that one can use decipherment to learn a full translation model from non-parallel data,,
Is it possible to use domain specific monolingual data to improve an MT system trained on parallel texts from a different domain? Some researchers have attempted to do this by adding a domain specific dictionary CITATION, or mining unseen words CITATION using one of several translation lexicon induction techniques (CITATION; CITATION; CITATION),,
