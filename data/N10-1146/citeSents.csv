(CITATION; CITATION; CITATION),,
This is used inside the syntactic/semantic tree kernel defined in (CITATIONa; CITATIONb) to enhance the basic tree kernel functions,,
3.1 WordNet Similarities WordNet similarities have been heavily used in previous NLP work (CITATION; CITATION),,
For example, the following measures, that we use in this study, are based on path lengths between concepts in the Wordnet Hierarchy: Path the measure is equal to the inverse of the shortest path length (path length) between two synsets c1 and c2 in WordNet SimP ath = 1 path length(c1, c2) (1) WUP the Wu and Palmer CITATION similarity metric is based on the depth of two given synsets c1 and c2 in the WordNet taxonomy, and the depth of their least common sub,,
6.1 Experimental Setup We used the data from three recognizing textual entailment challenge: RTE2 CITATION, RTE3 CITATION, and RTE5, along with the standard split between training and test sets,,
We used the following publicly available tools: the Charniak Parser CITATION for parsing sentences and SVM-light-TK (CITATION; CITATION), in which we coded our new kernels for RTE,,
Additionally, we used the Jiang&Conrath (J&C) distance CITATION computed with wn::similarity package CITATION to measure the similarity betwee,,
2 Related work Lexical-syntactic rules are largely used in textual entailment recognition systems (e.g., (CITATION; CITATION)) as they conveniently encode world knowledge into linguistic structures,,
Given the importance of lexical-syntactic rules in RTE, many methods have been proposed for their extraction from large corpora (e.g., (CITATION; CITATION)),,
Early deep semantic models (e.g., CITATION) as well as more recent ones (e.g., (CITATION; CITATION; CITATION)) rely on specific world knowledge encoded in rules for drawing decisions,,
Shallower models exploit matching methods between syntactic/semantic graphs of texts and hypotheses CITATION,,
The matching step is carried out after the application of some lexical-syntactic rules that are used to transform the text T or the hypothesis H CITATION at surface form level,,
Lexical-syntactic rules can be automatically extracted from plain corpora (e.g., (CITATION; CITATION)) but the quality (also in terms of little noise) and the coverage is low,,
For example, WordNet similarities CITATION or Latent Semantic Analysis over a large corpus are widely used in many applications and for 1021 \x0cthe definition of kernel functions, e.g,,
(CITATION; CITATION; CITATION),,
This is used inside the syntactic/semantic tree kernel defined in (CITATIONa; CITATIONb) to enhance the basic tree kernel functions,,
3.1 WordNet Similarities WordNet similarities have been heavily used in previous NLP work (CITATION; CITATION),,
rk: especially with the method described in (Zanzotto and CITATION; CITATION),,
Moreover, our approach does not require any adaptation or tuning and uses a computation for the similarity function based on Wikipedia which is faster than the computation of tools based on WordNet or other resources CITATION,,
For example, WordNet similarities CITATION or Latent Semantic Analysis over a large corpus are widely used in many applications and for 1021 \x0cthe definition of kernel functions, e.g,,
(CITATION; CITATION; CITATION),,
This is used inside the syntactic/semantic tree kernel defined in (CITATIONa; CITATIONb) to enhance the basic tree kernel functions,,
3.1 WordNet Similarities WordNet similarities have been heavily used in previous NLP work (CITATION; CITATION),,
For example, WordNet similarities CITATION or Latent Semantic Analysis over a large corpus are widely used in many applications and for 1021 \x0cthe definition of kernel functions, e.g,,
(CITATION; CITATION; CITATION),,
This is used inside the syntactic/semantic tree kernel defined in (CITATIONa; CITATIONb) to enhance the basic tree kernel functions,,
3.1 WordNet Similarities WordNet similarities have been heavily used in previous NLP work (CITATION; CITATION),,
To tackle this problem the Syntactic Semantic Tree Kernel (SSTK) was defined in (CITATIONa); hereafter, we report its definition,,
For example, WordNet similarities CITATION or Latent Semantic Analysis over a large corpus are widely used in many applications and for 1021 \x0cthe definition of kernel functions, e.g,,
(CITATION; CITATION; CITATION),,
This is used inside the syntactic/semantic tree kernel defined in (CITATIONa; CITATIONb) to enhance the basic tree kernel functions,,
3.1 WordNet Similarities WordNet similarities have been heavily used in previous NLP work (CITATION; CITATION),,
To tackle this problem the Syntactic Semantic Tree Kernel (SSTK) was defined in (CITATIONa); hereafter, we report its definition,,
For example, WordNet similarities CITATION or Latent Semantic Analysis over a large corpus are widely used in many applications and for 1021 \x0cthe definition of kernel functions, e.g,,
(CITATION; CITATION; CITATION),,
This is used inside the syntactic/semantic tree kernel defined in (CITATIONa; CITATIONb) to enhance the basic tree kernel functions,,
3.1 WordNet Similarities WordNet similarities have been heavily used in previous NLP work (CITATION; CITATION),,
Early deep semantic models (e.g., CITATION) as well as more recent ones (e.g., (CITATION; CITATION; CITATION)) rely on specific world knowledge encoded in rules for drawing decisions,,
Shallower models exploit matching methods between syntactic/semantic graphs of texts and hypotheses CITATION,,
The matching step is carried out after the application of some lexical-syntactic rules that are used to transform the text T or the hypothesis H CITATION at surface form level,,
by using FrameNet semantics (e.g., like in CITATION), it is possible to encode a lexical-syntactic rule using the KILLING and the DEATH frames, i.e.: 7 = KILLING(Killer : X , V ictim : Y ) DEATH( P rotagonist : Y ) However, to use this model, specific rules and a semantic role labeler on the specific corpora are needed,,
For example, WordNet similarities CITATION or Latent Semantic Analysis over a large corpus are widely used in many applications and for 1021 \,,
Our system results are the best when compared with systems using semantic models based on FrameNet, indeed the best ranked system in this class, i.e., CITATION, scores only 62.5,,
(CITATION; CITATION; CITATION),,
This is used inside the syntactic/semantic tree kernel defined in (CITATIONa; CITATIONb) to enhance the basic tree kernel functions,,
3.1 WordNet Similarities WordNet similarities have been heavily used in previous NLP work (CITATION; CITATION),,
For example, the following measures, that we use in this study, are based on path lengths between concepts in the Wordnet Hierarchy: Path the measure is equal to the inverse of the shortest path length (path length) between two synsets c1 and c2 in WordNet SimP ath = 1 path length(c1, c2) (1) WUP the Wu and Palmer CITATION similarity metric is based on the depth of two given synsets c1 and c2 in the WordNet taxonomy, and the depth of ,,
6.1 Experimental Setup We used the data from three recognizing textual entailment challenge: RTE2 CITATION, RTE3 CITATION, and RTE5, along with the standard split between training and test sets,,
We used the following publicly available tools: the Charniak Parser CITATION for parsing sentences and SVM-light-TK (CITATION; CITATION), in which we coded our new kernels for RTE,,
Additionally, we used the Jiang&Conrath (J&C) distance CITATION computed with wn::similarity package CITATION to measure the similarity between T and H,,
The distributional semantics is captured by means of LSA: we used the java Latent Semantic Indexing (jLSI) tool CITATION,,
The standard definition of the STK, given in CITATION, allows for any set of nodes linked by one or more entire production rules to be valid substructures,,
The formal characterization is given in CITATION and is reported hereafter: Let F = {f1, f2, ,,
Finally, it should be noted that when a valid kernel is used in place of S, SSTK is a valid kernel for definition of convolution kernels CITATION,,
Since the matrix P derived by applying LSA produces a semi-definite matrix (see CITATION) we can always use the similarity matrix derived by LSA in SSTK,,
2 Related work Lexical-syntactic rules are largely used in textual entailment recognition systems (e.g., (CITATION; CITATION)) as they conveniently encode world knowledge into linguistic structures,,
Given the importance of lexical-syntactic rules in RTE, many methods have been proposed for their extraction from large corpora (e.g., (CITATION; CITATION)),,
6.1 Experimental Setup We used the data from three recognizing textual entailment challenge: RTE2 CITATION, RTE3 CITATION, and RTE5, along with the standard split between training and test sets,,
We used the following publicly available tools: the Charniak Parser CITATION for parsing sentences and SVM-light-TK (CITATION; CITATION), in which we coded our new kernels for RTE,,
Additionally, we used the Jiang&Conrath (J&C) distance CITATION computed with wn::similarity package CITATION to measure the similarity between T and H,,
For example, the best systems in RTE2 and RTE3 CITATION have an accuracy 10% higher than the others but they generally use resources that are not publicly available,,
We used the following publicly available tools: the Charniak Parser CITATION for parsing sentences and SVM-light-TK (CITATION; CITATION), in which we coded our new kernels for RTE,,
Additionally, we used the Jiang&Conrath (J&C) distance CITATION computed with wn::similarity package CITATION to measure the similarity between T and H,,
The distributional semantics is captured by means of LSA: we used the java Latent Semantic Indexing (jLSI) tool CITATION,,
Early deep semantic models (e.g., CITATION) as well as more recent ones (e.g., (CITATION; CITATION; CITATION)) rely on specific world knowledge encoded in rules for drawing decisions,,
Shallower models exploit matching methods between syntactic/semantic graphs of texts and hypotheses CITATION,,
The matching step is carried out after the application of some lexical-syntactic rules that are used to transform the text T or the hypothesis H CITATION at surface form level,,
Lexical-syntactic rules can be automatically extracted from plain corpora (e.g., (CITATION; CITATION)) but the quality (also in terms of little noise) and the coverage is low,,
Finally, it should be noted that when a valid kernel is used in place of S, SSTK is a valid kernel for definition of convolution kernels CITATION,,
Since the matrix P derived by applying LSA produces a semi-definite matrix (see CITATION) we can always use the similarity matrix derived by LSA in SSTK,,
 Experimental Setup We used the data from three recognizing textual entailment challenge: RTE2 CITATION, RTE3 CITATION, and RTE5, along with the standard split between training and test sets,,
We used the following publicly available tools: the Charniak Parser CITATION for parsing sentences and SVM-light-TK (CITATION; CITATION), in which we coded our new kernels for RTE,,
Additionally, we used the Jiang&Conrath (J&C) distance CITATION computed with wn::similarity package CITATION to measure the similarity between T and H,,
The distributional semantics is captured by means of LSA: we used the java Latent Semantic Indexing (jLSI) tool CITATION,,
6.1 Experimental Setup We used the data from three recognizing textual entailment challenge: RTE2 CITATION, RTE3 CITATION, and RTE5, along with the standard split between training and test sets,,
We used the following publicly available tools: the Charniak Parser CITATION for parsing sentences and SVM-light-TK (CITATION; CITATION), in which we coded our new kernels for RTE,,
Additionally, we used the Jiang&Conrath (J&C) distance CITATION computed with wn::similarity package CITATION to measure the similarity between T and H,,
The distributional semantics is captured by means of LSA: we used the java Latent Semantic Indexing (jLSI) tool CITATION,,
Shallower models exploit matching methods between syntactic/semantic graphs of texts and hypotheses CITATION,,
The matching step is carried out after the application of some lexical-syntactic rules that are used to transform the text T or the hypothesis H CITATION at surface form level,,
Lexical-syntactic rules can be automatically extracted from plain corpora (e.g., (CITATION; CITATION)) but the quality (also in terms of little noise) and the coverage is low,,
textual entailment recognition systems (e.g., (CITATION; CITATION)) as they conveniently encode world knowledge into linguistic structures,,
Given the importance of lexical-syntactic rules in RTE, many methods have been proposed for their extraction from large corpora (e.g., (CITATION; CITATION)),,
Supervised approaches were experimented in (Zanzotto and CITATION; CITATION), where lexical-syntactic rules were derived from examples in terms of complex relational features,,
In other words, the LSA similarity is computed in a lower dimensional space, in which second-order relations among words and documents are exploited CITATION,,
It is worth mentioning that the LSA similarity measure depends on the selected corpus but it benefits from a higher computation speed in comparison to the construction of the similarity matrix based on the WordNet Similarity package CITATION,,
To assess the benefit of our approach, we carried out comparative experiments with previous work: especially with the method described in (Zanzotto and CITATION; CITATION),,
Moreover, our approach does not require any adaptation or tuning and uses a computation for the similarity function based on Wikipedia which is faster than the computation of tools based on WordNet or other resources CITATION,,
Given the importance of lexical-syntactic rules in RTE, many methods have been proposed for their extraction from large corpora (e.g., (CITATION; CITATION)),,
Supervised approaches were experimented in (Zanzotto and CITATION; CITATION), where lexical-syntactic rules were derived from examples in terms of complex relational features,,
We build on the kernel described in (Zanzotto and CITATION; CITATION) that can model lexicalsyntactic rules with variables (i.e., first-order rules),,
6.1 Experimental Setup We used the data from three recognizing textual entailment challenge: RTE2 CITATION, RTE3 CITATION, and RTE5, along with the standard split between training and test sets,,
We used the following publicly available tools: the Charniak Parser CITATION for parsing sentences and SVM-light-TK (CITATION; CITATION), in which we coded our new kernels for RTE,,
Additionally, we used the Jiang&Conrath (J&C) distance CITATION computed with wn::similarity package CITATION to measure the similarity between T and H,,
The distributional semantics is captured by means of LSA: we used the java Latent Semantic Indexing (jLSI) tool CITATION,,
Early deep semantic models (e.g., CITATION) as well as more recent ones (e.g., (CITATION; CITATION; CITATION)) rely on specific world knowledge encoded in rules for drawing decisions,,
Shallower models exploit matching methods between syntactic/semantic graphs of texts and hypotheses CITATION,,
The matching step is carried out after the application of some lexical-syntactic rules that are used to transform the text T or the hypothesis H CITATION at surface form level,,
Finally, we measure the performance of our system with the standard accuracy and then we determine the statistical significance by using the model 1025 \x0cSTK SSTK maxSTK maxSSTK STK+maxSTK SSTK+maxSSTK RTE2 +WOK 61.5 61.12 63.88 64.12 63.12 63.50 60.62 52.62 52.75 61.25 59.38 61.25 58.75 - RTE3 +WOK 66.38 66.5 66.5 67.0 66.88 67.25 66.75 53.25 54.5 62.25 64.38 63.12 63.62 - RTE5 +WOK 62.0 62.0 64.83 64.83 65.5 66.5 60.67 54.33 57.33 63.33 62.67 61.83 62.67 - Table 2: Comparing different lexico-syntactic kernels with Wiki-based semantic kernels described in CITATION and implemented in CITATION,,
by using FrameNet semantics (e.g., like in CITATION), it is possible to encode a lexical-syntactic rule using the KILLING and the DEATH frames, i.e.: 7 = KILLING(Killer : X , V ictim : Y ) DEATH( P rotagonist : Y ) However, to use this model, specific rules and a semantic role labeler on the specific corpora are needed,,
For example, WordNet similarities CITATION or Latent Semantic Analysis over a large corpus are widely used in many applications and for 1021 \x0cthe definition of kernel functions, e.g,,
(CITATION; CITATION; CITATION),,
This is used inside the syntactic/semantic tree kernel defined in (CITATIONa; CITATIONb) to enhance the basic tree kernel functions,,
In other words, the LSA similarity is computed in a lower dimensional space, in which second-order relations among words and documents are exploited CITATION,,
It is worth mentioning that the LSA similarity measure depends on the selected corpus but it benefits from a higher computation speed in comparison to the construction of the similarity matrix based on the WordNet Similarity package CITATION,,
tual entailment challenge: RTE2 CITATION, RTE3 CITATION, and RTE5, along with the standard split between training and test sets,,
We used the following publicly available tools: the Charniak Parser CITATION for parsing sentences and SVM-light-TK (CITATION; CITATION), in which we coded our new kernels for RTE,,
Additionally, we used the Jiang&Conrath (J&C) distance CITATION computed with wn::similarity package CITATION to measure the similarity between T and H,,
The distributional semantics is captured by means of LSA: we used the java Latent Semantic Indexing (jLSI) tool CITATION,,
Moreover, Table 4 shows that the computation of the LSA matrix on Wikipedia is faster than using the WordNet similarity software CITATION,,
Early deep semantic models (e.g., CITATION) as well as more recent ones (e.g., (CITATION; CITATION; CITATION)) rely on specific world knowledge encoded in rules for drawing decisions,,
Shallower models exploit matching methods between syntactic/semantic graphs of texts and hypotheses CITATION,,
The matching step is carried out after the application of some lexical-syntactic rules that are used to transform the text T or the hypothesis H CITATION at surface form level,,
Shallower models exploit matching methods between syntactic/semantic graphs of texts and hypotheses CITATION,,
The matching step is carried out after the application of some lexical-syntactic rules that are used to transform the text T or the hypothesis H CITATION at surface form level,,
Lexical-syntactic rules can be automatically extracted from plain corpora (e.g., (CITATION; CITATION)) but the quality (also in terms of little noise) and the coverage is low,,
ognition systems (e.g., (CITATION; CITATION)) as they conveniently encode world knowledge into linguistic structures,,
Given the importance of lexical-syntactic rules in RTE, many methods have been proposed for their extraction from large corpora (e.g., (CITATION; CITATION)),,
Supervised approaches were experimented in (Zanzotto and CITATION; CITATION), where lexical-syntactic rules were derived from examples in terms of complex relational features,,
Early deep semantic models (e.g., CITATION) as well as more recent ones (e.g., (CITATION; CITATION; CITATION)) rely on specific world knowledge encoded in rules for drawing decisions,,
Shallower models exploit matching methods between syntactic/semantic graphs of texts and hypotheses CITATION,,
The matching step is carried out after the application of some lexical-syntactic rules that are used to transform the text T or the hypothesis H CITATION at surface form level,,
3.1 WordNet Similarities WordNet similarities have been heavily used in previous NLP work (CITATION; CITATION),,
For example, the following measures, that we use in this study, are based on path lengths between concepts in the Wordnet Hierarchy: Path the measure is equal to the inverse of the shortest path length (path length) between two synsets c1 and c2 in WordNet SimP ath = 1 path length(c1, c2) (1) WUP the Wu and Palmer CITATION similarity metric is based on the depth of two given synsets c1 and c2 in the WordNet taxonomy, and the depth of their least common subsumer (lcs),,
Finally, we measure the performance of our system with the standard accuracy and then we determine the statistical significance by using the model 1025 \x0cSTK SSTK maxSTK maxSSTK STK+maxSTK SSTK+maxSSTK RTE2 +WOK 61.5 61.12 63.88 64.12 63.12 63.50 60.62 52.62 52.75 61.25 59.38 61.25 58.75 - RTE3 +WOK 66.38 66.5 66.5 67.0 66.88 67.25 66.75 53.25 54.5 62.25 64.38 63.12 63.62 - RTE5 +WOK 62.0 62.0 64.83 64.83 65.5 66.5 60.67 54.33 57.33 63.33 62.67 61.83 62.67 - Table 2: Comparing different lexico-syntactic kernels with Wiki-based semantic kernels described in CITATION and implemented in CITATION,,
To assess the benefit of our approach, we carried out comparative experiments with previous work: especially with the method described in (Zanzotto and CITATION; CITATION),,
Moreover, our approach does not require any adaptation or tuning and uses a computation for the similarity function based on Wikipedia which is faster than the computation of tools based on WordNet or other resources CITATION,,
Given the importance of lexical-syntactic rules in RTE, many methods have been proposed for their extraction from large corpora (e.g., (CITATION; CITATION)),,
Supervised approaches were experimented in (Zanzotto and CITATION; CITATION), where lexical-syntactic rules were derived from examples in terms of complex relational features,,
We build on the kernel described in (Zanzotto and CITATION; CITATION) that can model lexicalsyntactic rules with variables (i.e., first-order rules),,
To assess the benefit of our approach, we carried out comparative experiments with previous work: especially with the method described in (Zanzotto and CITATION; CITATION),,
Moreover, our approach does not require any adaptation or tuning and uses a computation for the similarity function based on Wikipedia which is faster than the computation of tools based on WordNet or other resources CITATION,,
Given the importance of lexical-syntactic rules in RTE, many methods have been proposed for their extraction from large corpora (e.g., (CITATION; CITATION)),,
Supervised approaches were experimented in (Zanzotto and CITATION; CITATION), where lexical-syntactic rules were derived from examples in terms of complex relational features,,
We build on the kernel described in (Zanzotto and CITATION; CITATION) that can model lexicalsyntactic rules with variables (i.e., first-order rules),,
Note that the model presented in CITATION, our baseline, corresponds to the combination kernel: WOK+maxSTK,,
