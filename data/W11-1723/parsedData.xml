<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<bodyText confidence="0.4787475">
b&apos;Proceedings of the 2nd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis, ACL-HLT 2011, pages 175181,
24 June, 2011, Portland, Oregon, USA c
</bodyText>
<sectionHeader confidence="0.47044" genericHeader="abstract">
2011 Association for Computational Linguistics
</sectionHeader>
<category confidence="0.2124875">
Corporate News Classification and Valence Prediction: A Supervised
Approach
</category>
<author confidence="0.655895">
Syed Aqueel Haider Rishabh Mehrotra
</author>
<affiliation confidence="0.640280333333333">
Dept. of Computer Science &amp; Engineering Computer Science &amp; Information Systems
Group
MIT, Manipal University BITS,Pilani
</affiliation>
<address confidence="0.629912">
KA-576104, India. Rajasthan,India.
</address>
<email confidence="0.860939">
Aqueel.h.rizvi@gmail.com erishabh@gmail.com
</email>
<sectionHeader confidence="0.986713" genericHeader="keywords">
Abstract
</sectionHeader>
<bodyText confidence="0.993091265625">
News articles have always been a
prominent force in the formation of a
companys financial image in the minds
of the general public, especially the
investors. Given the large amount of
news being generated these days through
various websites, it is possible to mine the
general sentiment of a particular company
being portrayed by media agencies over a
period of time, which can be utilized to
gauge the long term impact on the
investment potential of the company.
However, given such a vast amount of
news data, we need to first separate
corporate news from other kinds namely,
sports, entertainment, science &amp;
technology, etc. We propose a system
which takes news as, checks whether it is
of corporate nature, and then identifies
the polarity of the sentiment expressed in
the news. The system is also capable of
distinguishing the company/organization
which is the subject of the news from
other organizations which find mention,
and this is used to pair the sentiment
polarity with the identified company.
Introduction
With the rapid advancements in the field of
information technology, the amount of information
available has increased tremendously. News
articles constitute the largest available portion of
factual information about events happening in the
world. Corporate news constitutes a major chunk
of these news articles.
Sentiment Mining applied to the corporate
domain would help in various ways like Automatic
Recommendation Systems, to help organizations
evaluate their market strategies help them frame
their advertisement campaigns. Our system tries to
address these issues by automating the entire
process of news collection, organization/product
detection and sentiment mining.
This paper is divided into two main parts. The first
part describes a way of identifying corporate news
from a collection of news articles and then pairing
the news with the organization/company which is
being talked about in the article. The second part
of our paper works on the output of the first part
(corporate news) and detects the valence of the
identified corporate news articles. It calculates an
overall score and identifies valence a s positive,
negative or neutral based on this score. The system
is immune to addition/mergers of companies, with
regards to their identification, as it does not use
any name lists.
The model uses a machine learning approach to do
this task. We extract a set of features from the
news and use them to train a set of classifiers. The
best model is then used to classify the test data.
One advantage of our approach described below is
that it only requires a very small amount of
annotated training data. We trained the model on
the NewsCorp dataset consisting of 860 annotated
news articles. The system has shown promising
</bodyText>
<page confidence="0.998487">
175
</page>
<bodyText confidence="0.97951725">
\x0cresults on test data with classification accuracy
being 92.05% and a f-measure of 92.00. The final
average valence detection accuracy measured was
79.93%.
</bodyText>
<subsectionHeader confidence="0.893707">
Related Work
</subsectionHeader>
<bodyText confidence="0.959161709677419">
Much work has been done on text
classification.(Barak, 2009; Sebastiani,2002) There
have been earlier attempts (Research on Sports
Game News Information Extraction, Yonggui
YANG,et al) However, they had focused mainly
on information extraction and not classification.
Earlier attempts on web news
classification(Krishnlal et al, 2010) concentrated
mainly on classification according to the domain of
the news articles. Not much work has been done in
the field of corporate news-company pairing. This
paper tries to address a more general problem of
detecting the main organization being talked about
in the articles.
Sentiment analysis in computational linguistics
has focused on examining what textual features
contribute to affective content of text and
automatically detecting these features to derive a
sentiment metric for a word, sentence or whole text.
Niederhoffer (1971) after classifying New York
Times headlines into 19 categories evaluated how
the markets react to good and bad news.
Davis et al (2006) investigate the effects of
optimistic or pessimistic language used in financial
press releases on future firm performance.
Sumbaly et al(2009) used k gram models to detect
sentiment in large news datasets. Devitt(2007)
improves upon and Melville(2009) have done work
on sentiment analysis of web blogs
PART I : News Classification
Steps involved in news classification
</bodyText>
<subsectionHeader confidence="0.995702">
3.1 News Pre-processing
</subsectionHeader>
<bodyText confidence="0.994215166666667">
The preprocessor merges all the files into one but
defines start/end delimiters for each file in the
merged file, to enable bulk processing. The merged
news file is acted upon by a log-linear part of
speech tagger we obtained from the Stanford NLP
webpage(Manning,2000).
</bodyText>
<subsectionHeader confidence="0.999115">
3.2 Organization detection
</subsectionHeader>
<bodyText confidence="0.96307864">
We follow a two step approach to organization
detection:
Step 1: We extract the NNP/NNPS1
clusters in
the POS-tagged file using reguar expressions. For
example, the pos-tagged version of General
Electric Co, is General_NNP Electric_NNP
Co_NNP which is detected as a likely candidate
for an organization.
Step 2: We use a Named Entity Recognizer[2] to
obtain organization names. They are sorted in
order of their frequencies and top three
organizations are stored for later use. This ensures
that even if some names have crept in as
organizations due to misclassification by NER
tagger, they end up at the bottom of the list and are
discarded.
Multiple Organization Focus: Let f1,f2 be the
frequencies of top 2 organizations. Now if f2&gt;f1/2
then the news article is paired with organizations
corresponding to both f1 and f2.
Baseline: Using just the frequency of top 3
organizations as features, we get an accuracy of
48.89% which is very low. Therefore, we add
additional features which are described below.
</bodyText>
<subsectionHeader confidence="0.995417">
3.3 Keyword Detection
</subsectionHeader>
<bodyText confidence="0.932711083333333">
The system matches each news article for
occurrence of a set of keywords like company,
share, asset, etc. which have been derived
from statistical observation of corporate news. We
have used POS tags to differentiate between the
contexts in which the keywords have been used.
For example, share (verb) is not a keyword but
share (noun) is a keyword. We calculate the net
keyword occurrence frequency as
N(key)= ) where N(key) is the total
keyword frequency and is the frequency
of each keyword.
</bodyText>
<subsectionHeader confidence="0.877132">
3.4 Headline Preprocessing
</subsectionHeader>
<bodyText confidence="0.9954892">
We process the headline and detect likely
candidates for organization names and then cross
check with the top 3 organization names detected
in the step 2.2. We introduce a new feature h_value
described as follows:
</bodyText>
<figure confidence="0.4865105">
1
Please refer Appendix A for details of the POS Tags.
</figure>
<page confidence="0.974474">
176
</page>
<footnote confidence="0.3283446">
\x0c3.5 Detection of Products
The system detects likely candidates for products
using three empirical rules:
1. _NNP followed by _POS followed by
_NNP cluster. Ex: Googles Wave
2.The followed by _NNP cluster. Example:
The new POWER7 processors from IBM
3._PRP$ followed by _NNP cluster.
Example: Apple announced that its iPhone
3G will not be launched in India.
</footnote>
<subsectionHeader confidence="0.971513">
3.6 Executives Detection
</subsectionHeader>
<bodyText confidence="0.9993275">
We follow a similar POS based approach to detect
executives, and store their frequency.
</bodyText>
<subsectionHeader confidence="0.97019">
3.7 Feature Generation
</subsectionHeader>
<bodyText confidence="0.987318">
We use a total of 9 features to train the SVM
classifier. They are described below:
</bodyText>
<listItem confidence="0.826384">
1-3: frequency of top 3 organizations
4: frequency of Executives in the news article
5-7: frequencies of top 3 products discussed in
the news.
8. The N(key) value defined above in section 3.3
9. h_value defined above in section 3.2.
4 Classification and training
</listItem>
<bodyText confidence="0.9875048">
We tested our method with several classifiers.
First we used Support Vector Machines using
LibSVM[**]. The results obtained were
satisfactory. However, we experimented with other
models to see model variation can lead to some
improvement.
We tried Logistic Regression which is a class
for building and using a multinomial logistic
regression model with a ridge estimator. We
trained our model with ridge parameter 1.0E-8.
We compared our classification results with
Naives Bayes classifier which uses estimator
classes for making the model. Numeric estimator
precision values are chosen based on analysis of
the training data.
We also tested our dataset with AdaBoost
(Adaptive Boosting) classifier. AdaBoost calls
a weak classifier repeatedly in a series of rounds to
correctly identify the weights of the parameters.
The detailed results of the classification algorithms
are discussed in the Experiments and Results
section.
PART II : Headline Sentiment tagging
We describe a lexical features based approach to
detect the sentiment polarity in a news article.
</bodyText>
<subsectionHeader confidence="0.993574">
5.1 Preprocessing
</subsectionHeader>
<bodyText confidence="0.995611083333333">
One of the features of the news headlines extracted
from the Internet was that many had all words
capitalized. The system detects the improperly
capitalized words and de-capitalizes their common
words. This task is accomplished by using the
following rule on the output given initially by the
POS Tagger in Part I of our framework.
Rule: Only the words with POS tags as NNP or
NNPS retain their capitalization, all others are
decapitalized. Headline processing helps the POS
Tagger to tag the words correctly and hence the
dependencies will now be correct.
</bodyText>
<subsectionHeader confidence="0.998248">
5.2 Stemming
</subsectionHeader>
<bodyText confidence="0.9988">
Words which might carry opinions may be present
in inflected forms which requires stemming of the
words before any rules can be applied on them.
Words that are identified to have the same root
form are grouped in a finite number of clusters
with the identified root word as cluster center. We
have used the Porter Stemmer(Porter 1980)for this
purpose.
</bodyText>
<subsectionHeader confidence="0.984273">
5.3 Noise Reduction
</subsectionHeader>
<bodyText confidence="0.975833">
The news article contains many parts of speech
which are irrelevant to sentiment detection in our
case, for example, prepositions, conjunctions, etc.
We give a list of Penn Treebank tags which we
eliminate:
</bodyText>
<page confidence="0.989925">
177
</page>
<bodyText confidence="0.9493885">
\x0cCC , CD, DT, EX, IN, PRP, PRP$, TO . Please refer
to the Appendix A for the meaning of each POS-tag.
</bodyText>
<subsectionHeader confidence="0.992193">
5.4 Polarity Estimation
</subsectionHeader>
<bodyText confidence="0.9743755">
We used the SentiWordNet (Sebastiani,2006) in
order to calculate the sentiment polarity(valence)
of all the words in the headline and the body.
We use WordNet to find sentiment polarity
value(SPV) of each word. In WordNet, nouns,
verbs, adjectives and adverbs are grouped into
synonym sets (synsets). Synsets represent terms or
concepts. For example, following is a synset from
WordNet:
stadium, bowl, arena, sports stadium (a large
structure for open-air sports or entertainments)
The synsets are related to other synsets higher or
lower in the hierarchy by different types of
relationships e.g.
</bodyText>
<table confidence="0.98448075">
Hyponym/Hypernym (Is-A relationships)
Meronym/Holonym (Part-Of relationships)
Nine noun and several verb Is-A hierarchies
Using WordNets word hierarchy we boosted
</table>
<bodyText confidence="0.980567857142857">
sentiment polarities of a word (synset in WordNet),
depending on whether a noun/verb, having a
particular sentiment polarity is a hyponym of the
given synset. The candidate synsets for polarity
detection were extracted using a bootstrapping
approach starting with some positive and negative
seed words.
</bodyText>
<figure confidence="0.97230675">
Parent synset Boosted Polarity
poor negative
good positive
rise positive
down negative
decrease negative
growth positive
loss negative
</figure>
<tableCaption confidence="0.7787225">
Table 1: Examples of hypernyms boosting
sentiment polarity
</tableCaption>
<subsectionHeader confidence="0.976855">
5.5 Overall Valence Classification
</subsectionHeader>
<bodyText confidence="0.949945666666667">
After valences for each word have been detected,
we proceed to find out the overall valence of the
news article. We follow 2 rules for this task:
</bodyText>
<listItem confidence="0.7633908">
1. Since each word can have several
meanings, to calculate the SPV of a word,
we assumed that the these values were the
average of all its possible meanings.
2. The SPV of words occurring in the
</listItem>
<bodyText confidence="0.917844903225806">
headline are given higher weightage, as
compared to those in the body. After
several experimental trials, we concluded
that a weight ratio of 4:1 was optimal.( 4
for words in headline).
The second rule is a direct consequence of the
fact that news writers always try to provide the
overall sentiment of the news in the headline
itself so as to ease the understanding of the
reader.
Now the overall valence score(OVS) is calculated
using the simple expression OVS=
where SP is the Sentiment polarity value of each
word in the news article.
Final decision:
OVS &gt; +k, positive polarity
OVS &lt; -k, negative polarity
-k OVS k, neutral polarity
We experimented with different values of k and
found out that a value of k=3 was most suitable for
our task. Also, we could have normalized k
according to the length of the news article to
account for larger number of polar words in
lengthier articles. However, we avoid doing so,
because the probability of occurrence of positive
polar words is the same as that of negative polar
words, hence, neutralizing the effect of each other.
Finally, the OVS value provides a metric for the
strength of the valence of news article. Higher
magnitudes of OVS correspond to more strongly
expressed sentiments.
</bodyText>
<page confidence="0.998164">
178
</page>
<sectionHeader confidence="0.618188" genericHeader="introduction">
\x0c6 Experiments and Results
</sectionHeader>
<bodyText confidence="0.991999666666667">
In this section we discuss the dataset used in our
experiments, the evaluation settings and the
classification results obtained with our model.
</bodyText>
<subsectionHeader confidence="0.999389">
6.1 The NewsCorp Dataset
</subsectionHeader>
<bodyText confidence="0.971631">
We obtained 860 news samples from different
news sites including:
</bodyText>
<sectionHeader confidence="0.54094175" genericHeader="method">
1.ABC news
2. Reuters
3. MSNBC
4. CBC News Online, etc.
</sectionHeader>
<bodyText confidence="0.985447076923077">
Our research team read these 860 news articles and
created files for each of the news articles which
contained details whether the article is corporate or
non-corporate and if it is corporate then other
details like main Organization being talked about
in the article, different products and/or executives
related to the organization mentioned in the article.
We used these metadata files to evaluate our
results regarding Organization, product and
executive detection.
This dataset is then used to train the model for
classification and also for sentiment mining task.
Sample metadata file:
</bodyText>
<subsectionHeader confidence="0.999373">
6.2 Evaluation Methodology
</subsectionHeader>
<bodyText confidence="0.999281285714286">
We evaluate our method via 10-fold cross-
validation, where we have sub-sampled the
training folds in order to (a) keep the
computational burden as low as possible and (b)
show that we can learn sensible parameterizations
based upon relatively low requirements in terms of
the preferences seen on previous users. We
evaluate the system in stages so that the
contribution of each stage in the overall result
becomes clear. We tested 860 news samples for
corporate news detection. There were 261 true
negative, 39 false positive, 83 false negative and
477 true positive articles. Precision, Recall and F-
score are computed as:
</bodyText>
<equation confidence="0.9567185">
Recall= TP / (TP+FN) Precision= TP / (TP+FP)
F-Score=(2.Precision.Recall)/(Precision+Recall)
</equation>
<bodyText confidence="0.999899">
We evaluated our results in three different stages.
We first used basic Organization detection using
NER tagger output as our baseline. Next we
incorporated headline processing and keyword
frequency detection in the second stage. Finally the
third stage included the Product and Executive
detection feature for result evaluation.
</bodyText>
<subsectionHeader confidence="0.998866">
6.3 Classification Results
</subsectionHeader>
<bodyText confidence="0.98974075">
In order to classify the news article as corporate
and non-corporate we used 4 different
classification algorithms and compared their
results. The four algorithms are:
</bodyText>
<listItem confidence="0.98488775">
1. Support Vector Machines
2. Logistic Regression
3. Naives Bayes
4. AdaBoost
</listItem>
<tableCaption confidence="0.741681">
Table 2 (Classification Results)
</tableCaption>
<table confidence="0.936506772727273">
Support Vector Machine gave us a third stage F
Value of 88.66% while Naives Bayes gave a F
Value of 88.3%.
Logistic Regression showed an improvement
factor of 1.7% over Naives Bayes by giving F
Value of 90.0%.
AdaBoost technique gave us the best classification
result of 92&amp; as the F value.
The different Precision, Recall, ROC Area and F
Measure of the four algorithms are tabulated in
Table 2 and Fig.2.
Algorithm Precision Recall F-Val ROC
Area
Naives Bayes 88.3 88.4 88.3 0.94
Support
Vector
Machine
85.81 92.44 85.17 0.94
Logistic
Regression
90.4 89.9 90.0 0.95
AdaBoost 92.0 92.1 92.0 0.937
</table>
<page confidence="0.995524">
179
</page>
<figureCaption confidence="0.705613">
\x0cFig. 1: Classification Results
</figureCaption>
<subsectionHeader confidence="0.997178">
6.4 Valence detection experimental results
</subsectionHeader>
<bodyText confidence="0.977168375">
The proposed system was tested with 608 articles
since out of 860, 608 were identified to be of
corporate type. The classification was 3 way,
namely POS, NEG and NEUT ( representing +ve, -
ve and neutral respectively). The results are shown
in Figure 1 in the form of a confusion matrix. Out
of a total 608 financial news articles, 264 were
tagged with positive sentiment, 162 with negative
sentiment and 182 were found to be neutral.
Fig 2. Confusion Matrix for Valence Detection
However, our proposed approach yields an
accuracy of 84.84, 91.35 and 62.35 for positive ,
negative and neutral news sentiments respectively .
A possible reason for a low accuracy in case of
neutral news articles could be because of the
presence of some stray polar words in the body of
the news, which might have added to a sum of
more than k in magnitude(as defined in Section
5.5), thereby leading to the development of an
unwanted polarity.
Also, we observe a higher accuracy in predicting
negative articles, the reason for which could not be
identified. However, as proposed by a colleague, it
could possibly be attributed to the fact that
negative sentiment is more strongly expressed by
Journalists in news articles, as compared to
positive sentiment, which might have aided in
better detection of words with negative polarity.
Finally, we calculated the overall prediction
accuracy by taking the average of accuracies for all
three sentiments, which comes out to be
79.93%(Table 4).
</bodyText>
<table confidence="0.9966765">
Precision Recall Accuracy
POS 80.58 84.85 84.84
NEG 86.05 91.46 91.35
NEUT 72.15 66.27 62.35
</table>
<tableCaption confidence="0.963798">
Table 3:Scores for Valence Detection
</tableCaption>
<sectionHeader confidence="0.987059" genericHeader="conclusions">
7 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.998929730769231">
A framework for valence identification and news
classification has been proposed. News articles
mined from the web by a crawler are fed to the
system to filter the financial news from other kinds
of news(sports, entertainment etc). Next, the
organization which is the subject of this news is
identified. Finally, we determine the sentiment
polarity of the news by utilizing several lexical
features and semantic relationships from WordNet.
We experiment with the system using our own
manually tagged corpus of 860 news articles to
fine tune various parameters like weights and
threshold values. The resulting system performs
well with identification of financial news as well as
detection of valence in those articles. The system
gives good result for positive and negative
sentiments but satisfactory results for neutral
sentiments. An overall accuracy of 79.93 % is
obtained.
In the near future, we intend to apply anaphora
resolution and use anaphoric distance to rank polar
words according to relevance. This will help us to
identify and give more weight to words which
describe the sentiment of the author, from other
stray words which are external references, not
determining the overall sentiment of the news.
</bodyText>
<figure confidence="0.474818090909091">
Predicted
POS NEG NEUT
Actual
POS 224 06 34
NEG 04 148 10
NEUT 50 18 114
180
\x0cReferences
A New Text Mining Approach Based on HMM-SVM
for Web News ClassificationLewis, D. D.: Reuters-
21578 Document Corpus V1.0
</figure>
<reference confidence="0.997123644067797">
Angela K. Davis, Jeremy M. Piger, and Lisa M. Sedor.
2006.Beyond the numbers: An analysis of optimistic
and pessimistic language in earnings press releases.
Technical report, Federal Reserve Bank of St Louis.
B. E. Boser, I. Guyon, and V. Vapnik. A training
algorithm for optimal margin classiers. In
Proceedings of the Fifth Annual Workshop on
Computational Learning Theory, pages 144{152.
ACM Press, 1992.
Barak and Dagan.2009. Text Categorization from
Category Name via Lexical Reference. Proceedings
of NAACL HLT 2009.
Chih-Chung Chang and Chih-Jen Lin, LIBSVM : a
library for support vector machines, 2001. Software
available at http://www.csie.ntu.edu.tw/~cjlin/libsvm
http://acl.ldc.upenn.edu/J/J93/J93-2004.pdf
Devitt et al,(2007) Sentiment Polarity Identification in
Financial News: A Cohesion-based Approach
George A. Miller (1995). WordNet: A Lexical Database
for English.Communications of the ACM Vol. 38,
No. 11: 39-41.
Jenny Rose Finkel, Trond Grenager, and Christopher
Manning. 2005. Incorporating Non-local Information
into Information Extraction Systems by Gibbs
Sampling. Proceedings of the 43nd Annual Meeting
of the Association for Computational Linguistics
(ACL 2005), pp. 363-370.
Kristina Toutanova and Christopher D. Manning. 2000.
Enriching the Knowledge Sources Used in a
Maximum Entropy Part-of-Speech Tagger. In
Proceedings of the Joint SIGDAT Conference on
Empirical Methods in Natural Language Processing
and Very Large Corpora (EMNLP/VLC-2000), pp.
63-70.
Melville et al.(2009) Sentiment Analysis of Blogs by
Combining. Lexical Knowledge with Text
Classification.
Ozgur, A.: Supervised and Unsupervised Machine
Learning Techniques for Text Document
Categorization. Masters Thesis (2004), Bogazici
University, Turkey.
Porter, M.F. (1980) An Algorithm for Suffix Stripping,
Program, 14(3): 130137
Sebastiani, F.: Machine Learning in Automated Text
Categorization. ACM Computing Surveys 34 no. 5
(2002)
Sentiment Mining in Large News Datasets. Roshan
Sumbaly, Shakti Sinha, May 10, 2009.
UPAR7: A knowledge-based system for headline
sentiment tagging. Francois-Regis Chaumartin
Lattice/Talana Universite Paris 7
U. Hahn and M. Romacker Content Management in the
SynDiKATe system How t
documents are automatically transformed to text
knowledge bases. Data &amp; Knowledge E
ing, 35, 2000, pages 137-159.
Victor Niederhoffer. 1971. The analysis of world events
and stock prices. Journal of Business, 44(2):193219.
Appendix A. POS Tags
</reference>
<bodyText confidence="0.7703995">
The POS tags used in Part I of the paper are described
as follows:
</bodyText>
<equation confidence="0.997721166666667">
NN = Noun
NNS = Plural Noun
NNP = Proper Noun
PRP = Personal Pronoun
PRP$ = Possessive Pronoun
JJ = Adjective
TO = to
CD = Cardinal Number
DT = Determiner
CC = Coordinating conjunction
EX = Existential there
IN = Preposition or subordinating conjunction
</equation>
<page confidence="0.875599">
181
</page>
<figure confidence="0.228362">
\x0c&apos;
</figure>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.206138">
<note confidence="0.8176675">b&apos;Proceedings of the 2nd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis, ACL-HLT 2011, pages 175181, 24 June, 2011, Portland, Oregon, USA c 2011 Association for Computational Linguistics Corporate News Classification and Valence Prediction: A Supervised</note>
<title confidence="0.731167">Corporate News Classification and Valence Prediction: A Supervised Approach</title>
<author confidence="0.916537">Syed Aqueel Haider Rishabh Mehrotra</author>
<affiliation confidence="0.996142333333333">Dept. of Computer Science &amp; Engineering Computer Science &amp; Information Systems Group MIT, Manipal University BITS,Pilani</affiliation>
<address confidence="0.770843">KA-576104, India. Rajasthan,India.</address>
<email confidence="0.951612">Aqueel.h.rizvi@gmail.comerishabh@gmail.com</email>
<abstract confidence="0.997065851851852">News articles have always been a prominent force in the formation of a companys financial image in the minds of the general public, especially the investors. Given the large amount of news being generated these days through various websites, it is possible to mine the general sentiment of a particular company being portrayed by media agencies over a period of time, which can be utilized to gauge the long term impact on the investment potential of the company. However, given such a vast amount of news data, we need to first separate corporate news from other kinds namely, sports, entertainment, science &amp; technology, etc. We propose a system which takes news as, checks whether it is of corporate nature, and then identifies the polarity of the sentiment expressed in the news. The system is also capable of distinguishing the company/organization which is the subject of the news from other organizations which find mention, and this is used to pair the sentiment polarity with the identified company.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Angela K Davis</author>
<author>Jeremy M Piger</author>
<author>Lisa M Sedor</author>
</authors>
<title>2006.Beyond the numbers: An analysis of optimistic and pessimistic language in earnings press releases.</title>
<booktitle>In Proceedings of the Fifth Annual Workshop on Computational Learning Theory,</booktitle>
<tech>Technical report,</tech>
<pages>144--152</pages>
<institution>Federal Reserve Bank of St</institution>
<marker>Davis, Piger, Sedor, </marker>
<rawString>Angela K. Davis, Jeremy M. Piger, and Lisa M. Sedor. 2006.Beyond the numbers: An analysis of optimistic and pessimistic language in earnings press releases. Technical report, Federal Reserve Bank of St Louis. B. E. Boser, I. Guyon, and V. Vapnik. A training algorithm for optimal margin classiers. In Proceedings of the Fifth Annual Workshop on Computational Learning Theory, pages 144{152.</rawString>
</citation>
<citation valid="false">
<date>1992</date>
<publisher>ACM Press,</publisher>
<marker>1992</marker>
<rawString>ACM Press, 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barak</author>
</authors>
<title>Dagan.2009. Text Categorization from Category Name via Lexical Reference.</title>
<date>2009</date>
<booktitle>Proceedings of NAACL HLT</booktitle>
<contexts>
<context position="3537" citStr="Barak, 2009" startWordPosition="542" endWordPosition="543">xtract a set of features from the news and use them to train a set of classifiers. The best model is then used to classify the test data. One advantage of our approach described below is that it only requires a very small amount of annotated training data. We trained the model on the NewsCorp dataset consisting of 860 annotated news articles. The system has shown promising 175 \x0cresults on test data with classification accuracy being 92.05% and a f-measure of 92.00. The final average valence detection accuracy measured was 79.93%. Related Work Much work has been done on text classification.(Barak, 2009; Sebastiani,2002) There have been earlier attempts (Research on Sports Game News Information Extraction, Yonggui YANG,et al) However, they had focused mainly on information extraction and not classification. Earlier attempts on web news classification(Krishnlal et al, 2010) concentrated mainly on classification according to the domain of the news articles. Not much work has been done in the field of corporate news-company pairing. This paper tries to address a more general problem of detecting the main organization being talked about in the articles. Sentiment analysis in computational lingui</context>
</contexts>
<marker>Barak, 2009</marker>
<rawString>Barak and Dagan.2009. Text Categorization from Category Name via Lexical Reference. Proceedings of NAACL HLT 2009.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Chih-Chung Chang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBSVM : a library for support vector machines,</title>
<date>2001</date>
<journal>English.Communications of the ACM</journal>
<volume>38</volume>
<pages>39--41</pages>
<marker>Chang, Lin, 2001</marker>
<rawString>Chih-Chung Chang and Chih-Jen Lin, LIBSVM : a library for support vector machines, 2001. Software available at http://www.csie.ntu.edu.tw/~cjlin/libsvm http://acl.ldc.upenn.edu/J/J93/J93-2004.pdf Devitt et al,(2007) Sentiment Polarity Identification in Financial News: A Cohesion-based Approach George A. Miller (1995). WordNet: A Lexical Database for English.Communications of the ACM Vol. 38, No. 11: 39-41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Trond Grenager</author>
<author>Christopher Manning</author>
</authors>
<title>Incorporating Non-local Information into Information Extraction Systems by Gibbs Sampling.</title>
<date>2005</date>
<booktitle>Proceedings of the 43nd Annual Meeting of the Association for Computational Linguistics (ACL</booktitle>
<pages>363--370</pages>
<marker>Finkel, Grenager, Manning, 2005</marker>
<rawString>Jenny Rose Finkel, Trond Grenager, and Christopher Manning. 2005. Incorporating Non-local Information into Information Extraction Systems by Gibbs Sampling. Proceedings of the 43nd Annual Meeting of the Association for Computational Linguistics (ACL 2005), pp. 363-370.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Christopher D Manning</author>
</authors>
<date>2000</date>
<marker>Toutanova, Manning, 2000</marker>
<rawString>Kristina Toutanova and Christopher D. Manning. 2000.</rawString>
</citation>
<citation valid="false">
<title>Enriching the Knowledge Sources Used in a Maximum Entropy Part-of-Speech Tagger.</title>
<booktitle>In Proceedings of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora (EMNLP/VLC-2000),</booktitle>
<pages>63--70</pages>
<marker></marker>
<rawString>Enriching the Knowledge Sources Used in a Maximum Entropy Part-of-Speech Tagger. In Proceedings of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora (EMNLP/VLC-2000), pp. 63-70.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Melville et</author>
</authors>
<title>al.(2009) Sentiment Analysis of Blogs by Combining. Lexical Knowledge with Text Classification.</title>
<marker>et, </marker>
<rawString>Melville et al.(2009) Sentiment Analysis of Blogs by Combining. Lexical Knowledge with Text Classification.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ozgur</author>
</authors>
<title>Supervised and Unsupervised Machine Learning Techniques for Text Document Categorization. Masters Thesis</title>
<date>2004</date>
<institution>Bogazici University, Turkey.</institution>
<marker>Ozgur, 2004</marker>
<rawString>Ozgur, A.: Supervised and Unsupervised Machine Learning Techniques for Text Document Categorization. Masters Thesis (2004), Bogazici University, Turkey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M F Porter</author>
</authors>
<title>An Algorithm for Suffix Stripping, Program, 14(3): 130137 Sebastiani, F.: Machine Learning in Automated Text Categorization.</title>
<date>1980</date>
<journal>ACM Computing Surveys</journal>
<volume>34</volume>
<contexts>
<context position="9838" citStr="Porter 1980" startWordPosition="1539" endWordPosition="1540"> POS Tagger in Part I of our framework. Rule: Only the words with POS tags as NNP or NNPS retain their capitalization, all others are decapitalized. Headline processing helps the POS Tagger to tag the words correctly and hence the dependencies will now be correct. 5.2 Stemming Words which might carry opinions may be present in inflected forms which requires stemming of the words before any rules can be applied on them. Words that are identified to have the same root form are grouped in a finite number of clusters with the identified root word as cluster center. We have used the Porter Stemmer(Porter 1980)for this purpose. 5.3 Noise Reduction The news article contains many parts of speech which are irrelevant to sentiment detection in our case, for example, prepositions, conjunctions, etc. We give a list of Penn Treebank tags which we eliminate: 177 \x0cCC , CD, DT, EX, IN, PRP, PRP$, TO . Please refer to the Appendix A for the meaning of each POS-tag. 5.4 Polarity Estimation We used the SentiWordNet (Sebastiani,2006) in order to calculate the sentiment polarity(valence) of all the words in the headline and the body. We use WordNet to find sentiment polarity value(SPV) of each word. In WordNet,</context>
</contexts>
<marker>Porter, 1980</marker>
<rawString>Porter, M.F. (1980) An Algorithm for Suffix Stripping, Program, 14(3): 130137 Sebastiani, F.: Machine Learning in Automated Text Categorization. ACM Computing Surveys 34 no. 5 (2002) Sentiment Mining in Large News Datasets. Roshan Sumbaly, Shakti Sinha, May 10, 2009.</rawString>
</citation>
<citation valid="true">
<title>UPAR7: A knowledge-based system for headline sentiment tagging. Francois-Regis Chaumartin Lattice/Talana Universite Paris 7 U. Hahn and M. Romacker Content Management in the SynDiKATe system How t documents are automatically transformed to text knowledge bases.</title>
<date>2000</date>
<journal>Data &amp; Knowledge E ing,</journal>
<volume>35</volume>
<pages>137--159</pages>
<marker>2000</marker>
<rawString>UPAR7: A knowledge-based system for headline sentiment tagging. Francois-Regis Chaumartin Lattice/Talana Universite Paris 7 U. Hahn and M. Romacker Content Management in the SynDiKATe system How t documents are automatically transformed to text knowledge bases. Data &amp; Knowledge E ing, 35, 2000, pages 137-159.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Victor Niederhoffer</author>
</authors>
<title>The analysis of world events and stock prices.</title>
<date>1971</date>
<journal>Journal of Business, 44(2):193219. Appendix A. POS Tags</journal>
<contexts>
<context position="4357" citStr="Niederhoffer (1971)" startWordPosition="660" endWordPosition="661">cation. Earlier attempts on web news classification(Krishnlal et al, 2010) concentrated mainly on classification according to the domain of the news articles. Not much work has been done in the field of corporate news-company pairing. This paper tries to address a more general problem of detecting the main organization being talked about in the articles. Sentiment analysis in computational linguistics has focused on examining what textual features contribute to affective content of text and automatically detecting these features to derive a sentiment metric for a word, sentence or whole text. Niederhoffer (1971) after classifying New York Times headlines into 19 categories evaluated how the markets react to good and bad news. Davis et al (2006) investigate the effects of optimistic or pessimistic language used in financial press releases on future firm performance. Sumbaly et al(2009) used k gram models to detect sentiment in large news datasets. Devitt(2007) improves upon and Melville(2009) have done work on sentiment analysis of web blogs PART I : News Classification Steps involved in news classification 3.1 News Pre-processing The preprocessor merges all the files into one but defines start/end de</context>
</contexts>
<marker>Niederhoffer, 1971</marker>
<rawString>Victor Niederhoffer. 1971. The analysis of world events and stock prices. Journal of Business, 44(2):193219. Appendix A. POS Tags</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>