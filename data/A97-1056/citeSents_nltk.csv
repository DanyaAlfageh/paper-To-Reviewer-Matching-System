They are characterized by the following properties (CITATIONb): 1,,
The significance of G 2 based on the exact conditional distribution does not rely on an asymptotic approximation and is accurate for sparse and skewed data samples CITATION 4.2 Information criteria The family of model evaluation criteria known as information criteria have the following expression: IC,~ = G 2 - ~ x dof (3) where G~ and dof are defined above,,
Maximum Entropy models have been used to express the interactions among multiple feature variables (e.g., CITATION), but within this framework no systematic study of interactions has been proposed,,
~ Alternative probabilistic approaches have involved using a single contextual feature to perform disambiguation (e.g., CITATION, CITATION, and CITATION present techniques for identifying the optimal feature to use in disambiguation),,
Because their joint distributions have such closed-form expressions, the parameters can be estimated directly from the training data without the need for an iterative fitting procedure (as is required, for example, to estimate the parameters of maximum entropy models; CITATION),,
However, the Naive Bayes classifier has been found to perform well for word-sense disambiguation both here and in a variety of other works (e.g., (CITATIONa), CITATION, CITATION, and CITATION),,
This paper considers two significance tests, the exact conditional test CITATION and the Log-likelihood ratio statistic G2 CITATION, and two information criteria, Akaike\'s Information Criterion (AIC) CITATION and the Bayesian Information Criterion (BIC) CITATION,,
2 Decomposable Models Decomposable models are a subset of the class of graphical models CITATION which are in turn a subset of the class of log-linear models CITATION,,
CITATION and CITATION),,
es classifier has been found to perform well for word-sense disambiguation both here and in a variety of other works (e.g., (CITATIONa), CITATION, CITATION, and CITATION),,
However, if the data sample can be adequately characterized by a less complex model, i.e., a model in which there are fewer interactions between variables, then more reliable parameter estimates can be obtained: In the case of decomposable models (CITATION; see below), the parameters of a less complex model are parameters of marginal distributions, so the MLEs involve frequencies of combinations of values of only subsets of the variables in the model,,
2An alternative feature set for this data is utilized with an exemplar-based learning algorithm in CITATION,,
Although there are far fewer decomposable models than log-linear models for a given set of feature variables, it has been shown that they have substantially the same expressive power CITATION,,
5 Experimental Data The sense-tagged text and feature set used in these experiments are the same as in CITATION,,
In order to utilize models with more complicated interactions among feature variables, (CITATIONb) introduce the use of sequential model selection and decomposable models for word-sense disambiguation,,
CITATION and CITATION) but, while it is a type of model selection, the models are not parametric,,
