Additionally, our approach makes it possible to do inference in just about twice the inference time with a single sequential CRF; in contrast, approaches like Gibbs Sampling that model the dependencies directly can increase inference time by a factor of 30 CITATION,,
At the same time, the simplicity of our two-stage approach keeps inference time down to just the inference time of two sequential CRFs, when compared to approaches such as those of CITATION who report that their inference time with Gibbs sampling goes up by a factor of about 30, compared to the Viterbi algorithm for the sequential CRF,,
We also compare our performance against CITATION and CITATION and find that we manage higher relative improvement than existing work despite starting from a very competitive baseline CRF,,
The simplicity of our approach makes it easy to incorporate dependencies across the whole corpus, which would be relatively much harder to incorporate in approaches like CITATION and CITATION,,
CITATION hand-set penalties for inconsistency in entity labeling at different occurrences in the text, based on some statistics from training data,,
The approach of CITATION makes it possible a to model a broader class of longdistance dependencies than CITATION, because they do not need to make any initial assumptions about which nodes should be connected and they too model dependencies between whole token sequences representing entities and between entity token sequences and their token supersequences that are entities,,
They then employ Gibbs sampling CITATION for dealing with their local feature weights and their non-local penalties to do approximate inference,,
Both these approaches use loopy belief propagation (CITATION; CITATION) for approximate inference,,
CITATION define a Relational Markov Network (RMN) which explicitly models long-distance dependencies, and use it to represent relations between entities,,
CITATION augment a sequential CRF with skip-edges i.e,,
Most existing work to capture labelconsistency, has attempted to create all n 2 \x01 pairwise dependencies between the different occurrences of an entity, (CITATION; CITATION), where n is the number of occurrences of the given entity,,
 randomization test CITATION for statistical significance of the difference between the basic sequential CRF and our second round CRF, which has additional features derived from the output of the first CRF,,
A very common case of this in the CoNLL dataset is that of documents containing references to both The China Daily, a newspaper, and China, the country CITATION,,
