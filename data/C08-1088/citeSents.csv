<<<<<<< HEAD
CITATION design a composite kernel consisting of an entity linear kernel and a standard CTK, obtaining the F-measure of 72.1 on the 7 relation types in the ACE CITATION corpus,,0
This tree setup is similar to linear entity kernel explored by CITATION,,0
CITATION point out that both SPT and the convolution tree kernel are context-free,,0
3.1 Constituent Dependencies in Parse Tree CITATION explore five kinds of tree spans and find that the Shortest Path-enclosed Tree (SPT) achieves the best performance,,0
CITATION further indicates that among these entity features, entity type, subtype, and mention type, as well as the base form of predicate verb, contribute most while the contribution of other features, such as entity class, headword and GPE role, can be ignored,,0
Although the first conjunct is always considered as the headword CITATION, actually all the conjuncts play an equal role in relation extraction,,0
all the constituents outside the linking path should be removed) and CS-CSPT CITATION further recovers part of necessary context-sensitive information outside SPT, this justifies that SPT performs well, while CS-SPT outperforms SPT,,0
se the ACE CITATION corpus as the benchmark data,,0
There exist a considerable number of constituent dependencies in CFG as described by CITATION,,0
CITATION define sever,,0
CITATION define several feature-based composite kernels to capture diverse linguistic knowledge and achieve the F-measure of 70.4 on the 7 relation types in the ACE CITATION corpus,,0
CITATION proposed a slightly generalized version of this kernel between dependency trees, in which a successful match of two relation instances requires the nodes to be at the same layer and in the identical path starting from the roots to the current nodes,,0
In the example sentence they re here, which is excerpted from the ACE CITATION corpus, there exists a relationship Physical.Located between the entities they [PER] and here [GPE.Population-Center],,0
CITATION describe a convolution tree kernel (CTK, CITATION) to investigate various structured information for relation extraction and find that the Shortest Pathenclosed Tree (SPT) achieves the F-measure of 67.7 on the 7 relation types of the ACE CITATION corpus,,0
CITATION further propose Context-Sensitive SPT (CS-SPT), which can dynamically determine the tree span by extending the necessary predicate-linked path information outside SPT,,0
CITATION further indicates that among these entity features, entity type, s,,0
CITATION proposed a slightly generalized version of this kernel between dependency trees, in which a successful match of two relation instances requires t,,0
polynomial degree d=2 and coefficient I=0.3), we get the so far best performance of 77.1 in F-measure for 7 relation types on the ACE CITATION data set,,0
Improvements of different tree setups over SPT on the ACE CITATION corpus Finally, Table 4 compares our system with other state-of-the-art kernel-based systems on the 7 relation types of the ACE CITATION corpus,,1
Thereafter, we employ the standard CTK CITATION to compute the similarity between two UPSTs, since this CTK and its variations are successfully applied in syntactic parsing, semantic role labeling CITATION and relation extraction (CITATION; CITATION) as well,,0
While kernel methods using the dependency tree CITATION and the shortest dependency path CITATION suffer from low recall performance, convolution tree kernels (CITATION; CITATION) over syntactic parse trees achieve comparable or even better ,,1
Experiments by CITATION show that lin,,0
Similar to CITATION, this method also suffers from high precision but low recall,,0
In fact, SPT CITATION can be arrived at by carrying out part of the above removal operations using a single rule (i.e,,0
Experiments by CITATION show that linear kernel using only entity features contributes much when combined with the convolution parse tree kernel,,0
Performance of Unified Parse and Semantic Trees (UPSTs) on the 7 relation types of the ACE CITATION corpus In Table 3 we summarize the improvements of different tree setups over SPT,,0
This dependency relationship offers a very condensed representation of the information needed to assess the relationship in the forms of the dependency tree CITATION or the shortest dependency path CITATION that includes both entities,,0
However, detailed research CITATION shows that its difficult to extract new effective features to further improve the extraction accuracy,,0
From prior work (Zelenko et al., 2003; CITATION; CITATION) to current research (CITATION; CITATION), kernel methods have been showing more and more potential in relation extraction,,0
However, detailed evaluation CITATION indicates that the UPST achieves the best performance when the feature nodes are attached under the top node,,0
Evaluation on the ACE CITATION corpus shows that our dynamic syntactic parse tree outperforms all previous tree spans, and the composite kernel combining this tree kernel with a linear state-of-the-art feature-based kernel, achieves the so far best performance,,0
It shows that our UPST outperforms all previous tree setups using one single kernel, and even better than two previous composite kernels (CITATION; CITATION),,1
It achieves the so far best F-measure of 75.8 on the 7 relation types in the ACE CITATION corpus,,0
In the example sentence they re here, which is excerpted from the ACE CITATION corpus, there exists a relations,,0
While kernel methods using the dependency tree CITATION and the shortest dependency path CITATION suffer from low recall performance, convolution tree kernels (CITATION; CITATION) over syntactic parse trees achieve,,0
CITATION develop a shortest path dependency tree kernel, which simply counts the number of common word classes at each node in the shortest paths between two entities in dependency trees,,0
5.1 Experimental Setting For evaluation, we use the ACE CITATION corpus as the benchmark data,,0
In our experimentations, SVMlight CITATION wit,,0
CITATION describe a composite kernel to integrate a context-sensitive CTK and a state-of-the-art linear kernel,,0
For those interested in feature-based methods, please refer to CITATION for more details,,0
While kernel methods using the dependency tree CITATION and the shortest dependency path CITATION suffer from low recall performance, convolution tree kernels (CITATION; CITATION) over syntactic parse trees achieve comparable or even better performance than feature-based methods,,0
Furthermore, when the UPST (FPT) kernel is combined with a linear state-of-the-state featurebased kernel CITATION into a composite one via polynomial interpolation in a setting similar to CITATION (i.e,,0
They expand SPT to CS-SPT by dynamically including necessary predicate-linked path information and extending the standard CTK to contextsensitive CTK, obtaining the F-measure of 73.2 on the 7 relation types of the ACE CITATION corpus,,0
In our experimentations, SVMlight CITATION with the tree kernel function CITATION 2 is selected as our classifier,,0
stituents outside the linking path should be removed) and CS-CSPT CITATION further recovers part of necessary context-sensitive information outside SPT, this justifies that SPT performs well, while CS-SPT outperforms SPT,,1
5.2 Experimental Results Table 1 evaluates the contributions of different kinds of constituent dependencies to extraction performance on the 7 relation types of the ACE CITATION corpus using the convolution parse tree kernel as depicted in Figure 1,,0
=======
 Evaluation on the ACE CITATION corpus shows that our dynamic syntactic parse tree outperforms all previous tree spans, and the composite kernel combining this tree kernel with a linear state-of-the-art feature-based kernel, achieves the so far best performance,,
 CITATION develop a shortest path dependency tree kernel, which simply counts the number of common word classes at each node in the shortest paths between two entities in dependency trees,,
 Similar to CITATION, this method also suffers from high precision but low recall,,
 CITATION describe a convolution tree kernel (CTK, CITATION) to investigate various structured information for relation extraction and find that the Shortest Pathenclosed Tree (SPT) achieves the F-measure of 67,,
7 on the 7 relation types of the ACE CITATION corpus,,
 CITATION point out that both SPT and the convolution tree kernel are context-free,,
2 on the 7 relation types of the ACE CITATION corpus,,
 CITATION define several feature-based composite kernels to capture diverse linguistic knowledge and achieve the F-measure of 70,,
4 on the 7 relation types in the ACE CITATION corpus,,
 CITATION design a composite kernel consisting of an entity linear kernel and a standard CTK, obtaining the F-measure of 72,,
1 on the 7 relation types in the ACE CITATION corpus,,
 CITATION describe a composite kernel to integrate a context-sensitive CTK and a state-of-the-art linear kernel,,
8 on the 7 relation types in the ACE CITATION corpus,,
 CITATION further indicates that among these entity features, entity type, subtype, and mention type, as well as the base form of predicate verb, contribute most while the contribution of other features, such as entity class, headword and GPE role, can be ignored,,
 In the example sentence they re here, which is excerpted from the ACE CITATION corpus, there exists a relationship Physical,,
 Thereafter, we employ the standard CTK CITATION to compute the similarity between two UPSTs, since this CTK and its variations are successfully applied in syntactic parsing, semantic role labeling CITATION and relation extraction (CITATION; CITATION) as well,,
1 Experimental Setting For evaluation, we use the ACE CITATION corpus as the benchmark data,,
 In our experimentations, SVMlight CITATION wit,,
 Performance of Unified Parse and Semantic Trees (UPSTs) on the 7 relation types of the ACE CITATION corpus In Table 3 we summarize the improvements of different tree setups over SPT,,
 However, detailed research CITATION shows that its difficult to extract new effective features to further improve the extraction accuracy,,
, 2003; CITATION; CITATION) to current research (CITATION; CITATION), kernel methods have been showing more and more potential in relation extraction,,
 While kernel methods using the dependency tree CITATION and the shortest dependency path CITATION suffer from low recall performance, convolution tree kernels (CITATION; CITATION) over syntactic parse trees achieve comparable or even better ,,
 CITATION proposed a slightly generalized version of this kernel between dependency trees, in which a successful match of two relation instances requires the nodes to be at the same layer and in the identical path starting from the roots to the current nodes,,
 CITATION develop a shortest path dependency tree kernel, which simply counts the number of common word classes at each node in the shortest paths between two entities in dependency trees,,
 Similar to CITATION, this method also suffers from high precision but low recall,,
 CITATION describe a convolution tree kernel (CTK, CITATION) to investigate various structured information for relation extraction and find that the Shortest Pathenclosed Tree (SPT) achieves the F-measure of 67,,
7 on the 7 relation types of the ACE CITATION corpus,,
 This dependency relationship offers a very condensed representation of the information needed to assess the relationship in the forms of the dependency tree CITATION or the shortest dependency path CITATION that includes both entities,,
 There exist a considerable number of constituent dependencies in CFG as described by CITATION,,
 Although the first conjunct is always considered as the headword CITATION, actually all the conjuncts play an equal role in relation extraction,,
 CITATION develop a shortest path dependency tree kernel, which simply counts the number of common word classes at each node in the shortest paths between two entities in dependency trees,,
 Similar to CITATION, this method also suffers from high precision but low recall,,
 CITATION describe a convolution tree kernel (CTK, CITATION) to investigate various structured information for relation extraction and find that the Shortest Pathenclosed Tree (SPT) achieves the F-measure of 67,,
7 on the 7 relation types of the ACE CITATION corpus,,
 CITATION point out that both SPT and the convolution tree kernel are context-free,,
 However, detailed evaluation CITATION indicates that the UPST achieves the best performance when the feature nodes are attached under the top node,,
 Thereafter, we employ the standard CTK CITATION to compute the similarity between two UPSTs, since this CTK and its variations are successfully applied in syntactic parsing, semantic role labeling CITATION and relation extraction (CITATION; CITATION) as well,,
1 Experimental Setting For evaluation, we use the ACE CITATION corpus as the benchmark data,,
 However, detailed research CITATION shows that its difficult to extract new effective features to further improve the extraction accuracy,,
, 2003; CITATION; CITATION) to current research (CITATION; CITATION), kernel methods have been showing more and more potential in relation extraction,,
 While kernel methods using the dependency tree CITATION and the shortest dependency path CITATION suffer from low recall performance, convolution tree kernels (CITATION; CITATION) over syntactic parse trees achieve,,
 For those interested in feature-based methods, please refer to CITATION for more details,,
 CITATION proposed a slightly generalized version of this kernel between dependency trees, in which a successful match of two relation instances requires the nodes to be at the same layer and in the identical path starting from the roots to the current nodes,,
 CITATION develop a shortest path dependency tree kernel, which simply counts the number of common word classes at each node in the shortest paths between two entities in dependency trees,,
 This dependency relationship offers a very condensed representation of the information needed to assess the relationship in the forms of the dependency tree CITATION or the shortest dependency path CITATION that includes both entities,,
se the ACE CITATION corpus as the benchmark data,,
 In our experimentations, SVMlight CITATION with the tree kernel function CITATION 2 is selected as our classifier,,
2 Experimental Results Table 1 evaluates the contributions of different kinds of constituent dependencies to extraction performance on the 7 relation types of the ACE CITATION corpus using the convolution parse tree kernel as depicted in Figure 1,,
 However, detailed evaluation CITATION indicates that the UPST achieves the best performance when the feature nodes are attached under the top node,,
 Thereafter, we employ the standard CTK CITATION to compute the similarity between two UPSTs, since this CTK and its variations are successfully applied in syntactic parsing, semantic role labeling CITATION and relation extraction (CITATION; CITATION) as well,,
1 Experimental Setting For evaluation, we use the ACE CITATION corpus as the benchmark data,,
stituents outside the linking path should be removed) and CS-CSPT CITATION further recovers part of necessary context-sensitive information outside SPT, this justifies that SPT performs well, while CS-SPT outperforms SPT,,
 Experiments by CITATION show that linear kernel using only entity features contributes much when combined with the convolution parse tree kernel,,
 CITATION further indicates that among these entity features, entity type, subtype, and mention type, as well as the base form of predicate verb, contribute most while the contribution of other features, such as entity class, headword and GPE role, can be ignored,,
 In the example sentence they re here, which is excerpted from the ACE CITATION corpus, there exists a relations,,
 However, detailed evaluation CITATION indicates that the UPST achieves the best performance when the feature nodes are attached under the top node,,
 Thereafter, we employ the standard CTK CITATION to compute the similarity between two UPSTs, since this CTK and its variations are successfully applied in syntactic parsing, semantic role labeling CITATION and relation extraction (CITATION; CITATION) as well,,
 However, detailed research CITATION shows that its difficult to extract new effective features to further improve the extraction accuracy,,
, 2003; CITATION; CITATION) to current research (CITATION; CITATION), kernel methods have been showing more and more potential in relation extraction,,
 While kernel methods using the dependency tree CITATION and the shortest dependency path CITATION suffer from low recall performance, convolution tree kernels (CITATION; CITATION) over syntactic parse trees achieve comparable or even better performance than feature-based methods,,
 CITATION develop a shortest path dependency tree kernel, which simply counts the number of common word classes at each node in the shortest paths between two entities in dependency trees,,
 Similar to CITATION, this method also suffers from high precision but low recall,,
 CITATION describe a convolution tree kernel (CTK, CITATION) to investigate various structured information for relation extraction and find that the Shortest Pathenclosed Tree (SPT) achieves the F-measure of 67,,
7 on the 7 relation types of the ACE CITATION corpus,,
 CITATION point out that both SPT and the convolution tree kernel are context-free,,
1 Constituent Dependencies in Parse Tree CITATION explore five kinds of tree spans and find that the Shortest Path-enclosed Tree (SPT) achieves the best performance,,
 CITATION further propose Context-Sensitive SPT (CS-SPT), which can dynamically determine the tree span by extending the necessary predicate-linked path information outside SPT,,
 In fact, SPT CITATION can be arrived at by carrying out part of the above removal operations using a single rule (i,,
 all the constituents outside the linking path should be removed) and CS-CSPT CITATION further recovers part of necessary context-sensitive information outside SPT, this justifies that SPT performs well, while CS-SPT outperforms SPT,,
 Experiments by CITATION show that lin,,
 This tree setup is similar to linear entity kernel explored by CITATION,,
 However, detailed evaluation CITATION indicates that the UPST achieves the best performance when the feature nodes are attached under the top node,,
 Thereafter, we employ the standard CTK CITATION to compute the similarity between two UPSTs, since this CTK and its variations are successfully applied in syntactic parsing, semantic role labeling CITATION and relation extraction (CITATION; CITATION) as well,,
1 Experimental Setting For evaluation, we use the ACE CITATION corpus as the benchmark data,,
 Improvements of different tree setups over SPT on the ACE CITATION corpus Finally, Table 4 compares our system with other state-of-the-art kernel-based systems on the 7 relation types of the ACE CITATION corpus,,
 It shows that our UPST outperforms all previous tree setups using one single kernel, and even better than two previous composite kernels (CITATION; CITATION),,
 Furthermore, when the UPST (FPT) kernel is combined with a linear state-of-the-state featurebased kernel CITATION into a composite one via polynomial interpolation in a setting similar to CITATION (i,,
1 in F-measure for 7 relation types on the ACE CITATION data set,,
 CITATION point out that both SPT and the convolution tree kernel are context-free,,
2 on the 7 relation types of the ACE CITATION corpus,,
 CITATION define several feature-based composite kernels to capture diverse linguistic knowledge and achieve the F-measure of 70,,
4 on the 7 relation types in the ACE CITATION corpus,,
 CITATION design a composite kernel consisting of an entity linear kernel and a standard CTK, obtaining the F-measure of 72,,
1 on the 7 relation types in the ACE CITATION corpus,,
 CITATION describe a composite kernel to integrate a context-sensitive CTK and a state-of-the-art linear kernel,,
8 on the 7 relation types in the ACE CITATION corpus,,
 Improvements of different tree setups over SPT on the ACE CITATION corpus Finally, Table 4 compares our system with other state-of-the-art kernel-based systems on the 7 relation types of the ACE CITATION corpus,,
 It shows that our UPST outperforms all previous tree setups using one single kernel, and even better than two previous composite kernels (CITATION; CITATION),,
 Furthermore, when the UPST (FPT) kernel is combined with a linear state-of-the-state featurebased kernel CITATION into a composite one via polynomial interpolation in a setting similar to CITATION (i,,
1 in F-measure for 7 relation types on the ACE CITATION data set,,
 However, detailed research CITATION shows that its difficult to extract new effective features to further improve the extraction accuracy,,
, 2003; CITATION; CITATION) to current research (CITATION; CITATION), kernel methods have been showing more and more potential in relation extraction,,
 For those interested in feature-based methods, please refer to CITATION for more details,,
 CITATION proposed a slightly generalized version of this kernel between dependency trees, in which a successful match of two relation instances requires t,,
 Improvements of different tree setups over SPT on the ACE CITATION corpus Finally, Table 4 compares our system with other state-of-the-art kernel-based systems on the 7 relation types of the ACE CITATION corpus,,
 It shows that our UPST outperforms all previous tree setups using one single kernel, and even better than two previous composite kernels (CITATION; CITATION),,
 Furthermore, when the UPST (FPT) kernel is combined with a linear state-of-the-state featurebased kernel CITATION into a composite one via polynomial interpolation in a setting similar to CITATION (i,,
1 in F-measure for 7 relation types on the ACE CITATION data set,,
 However, detailed research CITATION shows that its difficult to extract new effective features to further improve the extraction accuracy,,
, 2003; CITATION; CITATION) to current research (CITATION; CITATION), kernel methods have been showing more and more potential in relation extraction,,
 While kernel methods using the dependency tree CITATION and the shortest dependency path CITATION suffer from low recall performance, convolution tree kernels (CITATION; CITATION) over syntactic parse trees achieve comparable or even better performance than feature-based methods,,
 Similar to CITATION, this method also suffers from high precision but low recall,,
 CITATION describe a convolution tree kernel (CTK, CITATION) to investigate various structured information for relation extraction and find that the Shortest Pathenclosed Tree (SPT) achieves the F-measure of 67,,
7 on the 7 relation types of the ACE CITATION corpus,,
 CITATION point out that both SPT and the convolution tree kernel are context-free,,
2 on the 7 relation types of the ACE CITATION corpus,,
 CITATION define sever,,
1 Constituent Dependencies in Parse Tree CITATION explore five kinds of tree spans and find that the Shortest Path-enclosed Tree (SPT) achieves the best performance,,
 CITATION further propose Context-Sensitive SPT (CS-SPT), which can dynamically determine the tree span by extending the necessary predicate-linked path information outside SPT,,
 In fact, SPT CITATION can be arrived at by carrying out part of the above removal operations using a single rule (i,,
 all the constituents outside the linking path should be removed) and CS-CSPT CITATION further recovers part of necessary context-sensitive information outside SPT, this justifies that SPT performs well, while CS-SPT outperforms SPT,,
 Experiments by CITATION show that linear kernel using only entity features contributes much when combined with the convolution parse tree kernel,,
 CITATION further indicates that among these entity features, entity type, s,,
 However, detailed evaluation CITATION indicates that the UPST achieves the best performance when the feature nodes are attached under the top node,,
 Thereafter, we employ the standard CTK CITATION to compute the similarity between two UPSTs, since this CTK and its variations are successfully applied in syntactic parsing, semantic role labeling CITATION and relation extraction (CITATION; CITATION) as well,,
1 Experimental Setting For evaluation, we use the ACE CITATION corpus as the benchmark data,,
>>>>>>> 198ba63628f3d20f872eceed27271a167777efde
