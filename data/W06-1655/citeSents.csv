CRF) CITATION,,
CRFs using this technique have been shown to be very successful at the task of Chinese word segmentation (CWS), starting with the model of CITATION,,
In the Second International Chinese Word Segmentation Bakeoff CITATION, two of the highest scoring systems in the closed track competition were based on a CRF model,,
(CITATION; CITATION) While the CRF is quite effective compared with other models designed for CWS, one wonders whether it may be limited by its restrictive independence assumptions on non-adjacent labels: an order-M CRF satisfies the order-M Markov assumption that, globally conditioned on the input sequence, each label is independent of all other labels given the M labels to its left and right,,
For example, CITATION uses a discriminative classifier for choosing among the top N parse trees output by a generative baseline model, and uses the log-probability of a parse according to the baseline model as a feature in the reranker,,
Similarly, the machine translation system of Och and Ney uses log-probabilities of phrasal translations and other events as features in a log-linear model (CITATION; CITATION),,
4 Relation to Previous Work There is a significant volume of work exploring the use of CRFs for a variety of chunking tasks, including named-entity recognition, gene prediction, shallow parsing and others (Finkel et al., 2005; CITATION; CITATION),,
There have not been a large number of studies using the semi-CRF, but the few that have been done found only marginal improvements over pure CRF systems (CITATION; CITATION; Daume III and Marcu, 2005),,
for these tasks are the conditional random field (CRFs) CITATION and the semi-Markov conditional random field (semi-CRF) CITATION,,
CRFs using this technique have been shown to be very successful at the task of Chinese word segmentation (CWS), starting with the model of CITATION,,
In the Second International Chinese Word Segmentation Bakeoff CITATION, two of the highest scoring systems in the closed track competition were based on a CRF model,,
(CITATION; CITATION) While the CRF is quite effective compared with other models designed for CWS, one wonders whether it may be limited by its restrictive independence assumptions on non-adjacent labels: an order-M CRF satisfies the order-M Markov assumption that, globally conditioned on the input sequence, each label is independent of all other labels given the M labels to its left and right,,
The data used was the Microsoft Research Beijing corpus from the Second International Chinese Word Segmentation Bakeoff CITATION, and we used the same train/test split used in the competition,,
We did not explicitly test the utility of CRF-type features for improving recall on out-of-vocabulary items, but we note that in the Bakeoff, the model of CITATION, which was very similar to our CRF-only system (only containing a few more feature templates), was consistently among the best performing systems in terms of test OOV recall CITATION,,
Two popular discriminative models that have been proposed for these tasks are the conditional random field (CRFs) CITATION and the semi-Markov conditional random field (semi-CRF) CITATION,,
CRFs using this technique have been shown to be very successful at the task of Chinese word segmentation (CWS), starting with the model of CITATION,,
In the Second International Chinese Word Segmentation Bakeoff CITATION, two of the highest scoring systems in the closed track competit,,
Despite this, the only work of which we are aware exploring the use of a semi-Markov CRF for Chinese word segmentation did not find significant gains over the standard CRF CITATION,,
Indeed, neither CITATION nor CITATION nor any other system using a semi-Markov CRF on any task has included this type of feature to our knowledge,,
4 Relation to Previous Work There is a significant volume of work exploring the use of CRFs for a variety of chunking tasks, including named-entity recognition, gene prediction, shallow parsing and others (Finkel et al., 2005; CITATION; CITATION),,
There have not been a large number of studies using the semi-CRF, but the few that have been done found only marginal improvements over pure CRF systems (CITATION; CITATION; Daume III and Marcu, 2005),,
Similarly, the machine translation system of Och and Ney uses log-probabilities of phrasal translations and other events as features in a log-linear model (CITATION; CITATION),,
There are many reasons for incorporating these types of features, including the desire to combine the higher accuracy of a discriminative model with the simple parameter estimation and inference of a generative one, and also the fact that generative models are more robust in data sparse scenarios CITATION,,
For example, CITATION uses a discriminative classifier for choosing among the top N parse trees output by a generative baseline model, and uses the log-probability of a parse according to the baseline model as a feature in the reranker,,
Similarly, the machine translation system of Och and Ney uses log-probabilities of phrasal translations and other events as features in a log-linear model (CITATION; CITATION),,
There are many reasons for incorporating these types of features, including the desire to combine the higher accuracy of a discriminative model with the simple parameter estimation and inference of a generative one, and also the fact that generative models are more robust in data sparse scenarios CITATION,,
For example, CITATION uses a discriminative classifier for choosing among the top N parse trees output by a generative baseline model, and uses the log-probability of a parse according to the baseline model as a feature in the reranker,,
Similarly, the machine translation system of Och and Ney uses log-probabilities of phrasal translations and other events as features in a log-linear model (CITATION; CITATION),,
There are many reasons for incorporating these types of features, including the desire to combine the higher accuracy of a discriminative model with the simple parameter estimation and inference of a generative one, and also the fact that generative models are more robust in data sparse scenarios CITATION,,
Two popular discriminative models that have been proposed for these tasks are the conditional random field (CRFs) CITATION and the semi-Markov conditional random field (semi-CRF) CITATION,,
CRFs using this technique have been shown to be very successful at the task of Chinese word segmentation (CWS), starting with the model of CITATION,,
In the Second International Chinese Word Segmentation Bakeoff CITATION, two of the highest scoring systems in the closed track competition were based on a CRF model,,
(CITATION; CITATION) While the CRF is quite effective compared with other models designed for CWS, one wonders whether it may be limited by its restrictive independence assumptions on non-adjacent labels: an order-M CRF satisfies the order-M Markov assumption that, globally conditioned on the input sequence, each label is independent of all other labels given the M labels to its left and right,,
2.4 Generative Features in a Discriminative Model When using the output of a generative model as a feature in a discriminative model, CITATION provide a justification for the use of log conditional odds as opposed to log-probability: they show that using log conditional odds as features in a logistic regression model is equivalent to discriminatively training weights for the features of a Nave Bayes classifier to maximize conditional likelihood.6 They demonstrate that the resulting classifier, termed a hybrid generative/discriminative classifier, achieves lower test error than either pure Nave Bayes or pure logistic regression on a text classification task, regardless of training set size,,
Two popular discriminative models that have been proposed for these tasks are the conditional random field (CRFs) CITATION and the semi-Markov conditional random field (semi-CRF) CITATION,,
CRFs using this technique have been shown to be very successful at the task of Chinese word segmentation (CWS), starting with the model of CITATION,,
In the Second International Chinese Word Segmentation Bakeoff CITATION, two of the highest scoring systems in the closed track competition were based on a CRF model,,
(CITATION; CITATION) While the,,
Indeed, neither CITATION nor CITATION nor any other system using a semi-Markov CRF on any task has included this type of feature to our knowledge,,
4 Relation to Previous Work There is a significant volume of work exploring the use of CRFs for a variety of chunking tasks, including named-entity recognition, gene prediction, shallow parsing and others (Finkel et al., 2005; CITATION; CITATION),,
There have not been a large number of studies using the semi-CRF, but the few that have been done found only marginal improvements over pure CRF systems (CITATION; CITATION; Daume III and Marcu, 2005),,
4 Relation to Previous Work There is a significant volume of work exploring the use of CRFs for a variety of chunking tasks, including named-entity recognition, gene prediction, shallow parsing and others (Finkel et al., 2005; CITATION; CITATION),,
There have not been a large number of studies using the semi-CRF, but the few that have been done found only marginal improvements over pure CRF systems (CITATION; CITATION; Daume III and Marcu, 2005),,
 random field (semi-CRF) CITATION,,
CRFs using this technique have been shown to be very successful at the task of Chinese word segmentation (CWS), starting with the model of CITATION,,
In the Second International Chinese Word Segmentation Bakeoff CITATION, two of the highest scoring systems in the closed track competition were based on a CRF model,,
(CITATION; CITATION) While the CRF is quite effective compared with other models designed for CWS, one wonders whether it may be limited by its restrictive independence assumptions on non-adjacent labels: an order-M CRF satisfies the order-M Markov assumption that, globally conditioned on the input sequence, each label is independent of all other labels given the M labels to its left and right,,
The first two of these were also used by CITATION,,
Our best model, combining all features, resulted in an error reduction of 12% over the highest score on this dataset from the 2005 Sighan closed test competition (96.4%), achieved by the pure CRF system of CITATION,,
