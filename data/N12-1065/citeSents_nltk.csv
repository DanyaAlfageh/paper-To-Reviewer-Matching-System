2 Tools 2.1 Named entity recognition The Stanford named entity recognition (NER) software1 CITATION is an implementation of linear chain Conditional Random Field (CRF) sequence models, which includes a three class (person, organization, location and other) named entity recognizer for English.,,
2.2 Topic detection LDA CITATION is a generative probabilistic model where documents are viewed as mixtures over underlying topics, and each topic is a distribution over words.,,
Given a set of documents and a number of topics, the model returns i, the topic distribution for each document i, and ik, the word distribution for topic k. We employ the publicly available implementation of LDA, JGibbLDA2 CITATION, which has two main execution methods: parameter estimation (model building) and inference for new data (classificati,,
e Reuters corpus CITATION.3 1 http://nlp.stanford.edu/ner/index.shtml 2 http://jgibblda.sourceforge.net/ 3 LDA modeling can abstract a model from a relatively small corpus and a tenth of the original Reuters corpus is much more 2.3 Indexing To provide quick searching access to the large text collections, we utilize the high-performance search engine library Lucene.4 The stemmed and stoplisted documents are stored along with the frequency of occurrence of each word within a document.,,
2.4 Lemmatization / stemming English text is lemmatized using the lemmatizer available within RASP5 CITATION.,,
2 Tools 2.1 Named entity recognition The Stanford named entity recognition (NER) software1 CITATION is an implementation of linear chain Conditional Random Field (CRF) sequence models, which includes a three class (person, organization, location and other) named entity recognizer for English.,,
2.2 Topic detection LDA CITATION is a generative probabilistic model where documents are viewed as mixtures over underlying topics, and each topic is a distribution over words.,,
Clearly, texts need to contain some of the same data in order to be comparable CITATION, and we assume: To be similar, texts need to share some named entities, e.g., Toth et al., CITATION.,,
CITATION create bilingual topic models from (at least 25%) of parallel data.,,
CITATION start from tuples of equivalent documents to build models, and then the same distribution over topics holds in both source and target languages.,,
While CITATION used their topic models for,,
Clearly, texts need to contain some of the same data in order to be comparable CITATION, and we assume: To be similar, texts need to share some named entities, e.g., Toth et al., CITATION.,,
CITATION create bilingual topic models from (at least 25%) of parallel data.,,
CITATION start from tuples of equivalent documents to build models, and then the same distribution over topics holds in both source and target languages.,,
While CITATION used their topic models for word alignment from comparable corpora (combined with underlying parallel data), multilingual topic models are usually applied to data to automatically detect word translations based on parallel data, e.g., CITATION exploit a shared language independent topic distribution to measure the similarity between topics pertaining to words.,,
2.2 Topic detection LDA CITATION is a generative probabilistic model where documents are viewed as mixtures over underlying topics, and each topic is a distribution over words.,,
Given a set of documents and a number of topics, the model returns i, the topic distribution for each document i, and ik, the word distribution for topic k. We employ the publicly available implementation of LDA, JGibbLDA2 CITATION, which has two main execution methods: parameter estimation (model building) and inference for new data (classification of a new document).,,
Both invocations produce the following: ij: p(wordi|topicj) jk: p(topicj|documentk) tassign: a deterministic topic-word assignment for each word in every document The LDA topic models are created from a randomly selected tenth of the Reuters corpus CITATION.3 1 http://nlp.stanford.edu/ner/index.shtml 2 http://jgibblda.sourceforge.net/ 3 LDA modeling can abstract a model from a relatively small corpus and a tenth of the original Reuters corpus i,,
Clearly, texts need to contain some of the same data in order to be comparable CITATION, and we assume: To be similar, texts need to share some named entities, e.g., Toth et al., CITATION.,,
CITATION create bilingual topic models from (at least 25%) of parallel data.,,
CITATION start from tuples of equivalent documents to build models, and then the same distribution over topics holds in both source and target languages.,,
While CITATION used their topic models for word alignment from comparable corpora (combined with underlying parallel data), multilingual topi,,
mber of topics, the model returns i, the topic distribution for each document i, and ik, the word distribution for topic k. We employ the publicly available implementation of LDA, JGibbLDA2 CITATION, which has two main execution methods: parameter estimation (model building) and inference for new data (classification of a new document).,,
Both invocations produce the following: ij: p(wordi|topicj) jk: p(topicj|documentk) tassign: a deterministic topic-word assignment for each word in every document The LDA topic models are created from a randomly selected tenth of the Reuters corpus CITATION.3 1 http://nlp.stanford.edu/ner/index.shtml 2 http://jgibblda.sourceforge.net/ 3 LDA modeling can abstract a model from a relatively small corpus and a tenth of the original Reuters corpus is much more 2.3 Indexing To provide quick searching access to the large text collections, we utilize the high-performance search engine library Lucene.4 The stemmed and stoplisted documents are stored along with the frequency of occurrence of each word within a document.,,
2.4 Lemmatization / stemming English text is lemmatized using the lemmatizer available within RASP5 CITATION.,,
Clearly, texts need to contain some of the same data in order to be comparable CITATION, and we assume: To be similar, texts need to share some named entities, e.g., Toth et al., CITATION.,,
CITATION create bilingual topic models from (at least 25%) of parallel data.,,
CITATION start from tuples of equivalent documents to build models, and then the same distribution over topics holds in both source and target languages.,,
While CITATION used their topic models for word alignment from comparable corpora (combined with underlying parallel data), multilingual topi,,
CITATION create bilingual topic models from (at least 25%) of parallel data.,,
CITATION start from tuples of equivalent documents to build models, and then the same distribution over topics holds in both source and target languages.,,
While CITATION used their topic models for word alignment from comparable corpora (combined with underlying parallel data), multilingual topic models are usually applied to data to automatically detect word translations based on parallel data, e.g., CITATION exploit a shared language independent topic distribution to measure the similarity between topics pertaining to words.,,
Clearly, texts need to contain some of the same data in order to be comparable CITATION, and we assume: To be similar, texts need to share some named entities, e.g., Toth et al., CITATION.,,
CITATION create bilingual topic models from (at least 25%) of parallel data.,,
CITATION start from tuples of equivalent documents to build models, and then the same distribution over topics holds in both source and target languages.,,
While CITATION used their topic models for word alignment from comparable corpora (combined with underlying parallel data), multilingual topic models are usually applied to data to automatically detect word translations based on parallel data, e.g., CITATION exploit a shared language independent topic distribution to measure the similarity,,
