<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000023">
<bodyText confidence="0.602277">
b&amp;apos;Proceedings of the 15th Conference on Computational Natural Language Learning: Shared Task, pages 5660,
</bodyText>
<address confidence="0.512077">
Portland, Oregon, 23-24 June 2011. c
</address>
<title confidence="0.6098915">
2011 Association for Computational Linguistics
Unrestricted Coreference Resolution via Global Hypergraph Partitioning
</title>
<author confidence="0.605174">
Jie Cai and Eva Mujdricza-Maydt and Michael Strube
</author>
<affiliation confidence="0.5801615">
Natural Language Processing Group
Heidelberg Institute for Theoretical Studies gGmbH
</affiliation>
<address confidence="0.73169">
Heidelberg, Germany
</address>
<email confidence="0.697324">
(jie.cai|eva.mujdriczamaydt|michael.strube)@h-its.org
</email>
<sectionHeader confidence="0.979341" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999745230769231">
We present our end-to-end coreference res-
olution system, COPA, which implements a
global decision via hypergraph partitioning.
In constrast to almost all previous approaches,
we do not rely on separate classification and
clustering steps, but perform coreference res-
olution globally in one step. COPA represents
each document as a hypergraph and partitions
it with a spectral clustering algorithm. Various
types of relational features can be easily incor-
porated in this framwork. COPA has partici-
pated in the open setting of the CoNLL shared
task on modeling unrestricted coreference.
</bodyText>
<sectionHeader confidence="0.998229" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998974972222222">
Coreference resolution is the task of grouping men-
tions of entities into sets so that all mentions in
one set refer to the same entity. Most recent ap-
proaches to coreference resolution divide this task
into two steps: (1) a classification step which de-
termines whether a pair of mentions is coreferent or
which outputs a confidence value, and (2) a cluster-
ing step which groups mentions into entities based
on the output of step 1.
In this paper we present an end-to-end corefer-
ence resolution system, COPA, which avoids the di-
vision into two steps and instead performs a global
decision in one step. The system presents a doc-
ument as a hypergraph, where the vertices denote
mentions and the edges denote relational features
between mentions. Coreference resolution is then
performed globally in one step by partitioning the
hypergraph into subhypergraphs so that all mentions
in one subhypergraph refer to the same entity (Cai
and Strube, 2010). COPA assigns edge weights by
applying simple descriptive statistics on the tranin-
ing data. Since COPA does not need to learn an
explicit model, we used only 30% of the CoNLL
shared task training data. We did this not for effi-
ciency reasons, only for convenience.
While COPA has been developed originally to
perform coreference resolution on MUC and ACE
data (Cai and Strube, 2010), the move to the
OntoNotes data (Weischedel et al., 2011) required
mainly to update the mention detector and the fea-
ture set. Since several off-the-shelf preprocessing
components are used, COPA participated in the open
setting of the CoNLL shared task on modeling unre-
stricted coreference (Pradhan et al., 2011). We did
not make extensive use of information beyond infor-
mation from the closed class setting.
</bodyText>
<sectionHeader confidence="0.989266" genericHeader="introduction">
2 Preprocessing
</sectionHeader>
<bodyText confidence="0.997058357142857">
COPA is implemented on top of the BART-toolkit
(Versley et al., 2008). Documents are transformed
into the MMAX2-format (Muller and Strube, 2006)
which allows for easy visualization and (linguis-
tic) debugging. Each document is stored in several
XML-files representing different layers of annota-
tions. These annotations are created by a pipeline
of preprocessing components. We use the Stan-
ford MaxentTagger (Toutanova et al., 2003) for part-
of-speech tagging, and the Stanford Named En-
tity Recognizer (Finkel et al., 2005) for annotat-
ing named entities. In order to derive syntactic
information, we use the Charniak/Johnson rerank-
ing parser (Charniak and Johnson, 2005) com-
</bodyText>
<page confidence="0.986206">
56
</page>
<bodyText confidence="0.921915363636364">
\x0cbined with a constituent-to-dependency conversion
Tool (http://nlp.cs.lth.se/software/
treebank_converter). The preprocessing
models are not trained on CoNLL data, so we only
participated in the open task.
We have implemented an in-house mention detec-
tor, which makes use of the parsing output, the part-
of-speech tags, as well as the chunks from the Yam-
cha Chunker (Kudoh and Matsumoto, 2000). For
the OntoNotes data, the mention detector annotates
the biggest noun phrase spans.
</bodyText>
<sectionHeader confidence="0.944701" genericHeader="method">
3 COPA: Coreference Partitioner
</sectionHeader>
<bodyText confidence="0.997761857142857">
The COPA system consists of modules which derive
hyperedges from features and assign edge weights
indicating a positive correlation with the coreference
relation, and resolution modules which create a hy-
pergraph representation for the testing data and per-
form partitioning to produce subhypergraphs, each
of which represents an entity.
</bodyText>
<subsectionHeader confidence="0.997615">
3.1 HyperEdgeCreator
</subsectionHeader>
<bodyText confidence="0.9995911">
COPA needs training data only for computing the
hyperedge weights. Hyperedges represent features.
Each hyperedge corresponds to a feature instance
modeling a simple relation between two or more
mentions. This leads to initially overlapping sets of
mentions. Hyperedges are assigned weights which
are calculated on the training data as the percentage
of the initial edges being in fact coreferent. Due to
the simple strategy of assigning edge weights, only
a reasonable size of training data is needed.
</bodyText>
<subsectionHeader confidence="0.999531">
3.2 Coreference Resolution Modules
</subsectionHeader>
<bodyText confidence="0.94514">
Unlike pairwise models, COPA processes a docu-
ment globally in one step, taking care of the pref-
erence information among all the mentions simul-
taneously and clustering them into sets directly. A
document is represented as a single hypergraph with
multiple edges. The hypergraph resolver partitions
the hypergraph into several sub-hypergraphs, each
corresponding to one set of coreferent mentions.
</bodyText>
<subsubsectionHeader confidence="0.678399">
3.2.1 HGModelBuilder
</subsubsectionHeader>
<bodyText confidence="0.999823625">
A single document is represented in a hypergraph
with basic relational features. Each hyperedge in a
graph corresponds to an instance of one of those fea-
tures with the weight assigned by the HyperEdge-
Learner. Instead of connecting nodes with the tar-
get relation as usually done in graph models, COPA
builds the graph directly out of low dimensional fea-
tures without assuming a distance metric.
</bodyText>
<subsubsectionHeader confidence="0.826757">
3.2.2 HGResolver
</subsubsectionHeader>
<bodyText confidence="0.989804727272727">
In order to partition the hypergraph we adopt a
spectral clustering algorithm (Agarwal et al., 2005).
All experimental results are obtained using symmet-
ric Laplacians (Lsym) (von Luxburg, 2007).
We apply the recursive variant of spectral clus-
tering, recursive 2-way partitioning (R2 partitioner)
(Cai and Strube, 2010). This method does not need
any information about the number of target sets (the
number k of clusters). Instead a stopping criterion
has to be provided which is adjusted on develop-
ment data.
</bodyText>
<subsectionHeader confidence="0.996246">
3.3 Complexity of HGResolver
</subsectionHeader>
<bodyText confidence="0.997712769230769">
Since edge weights are assigned using simple de-
scriptive statistics, the time HGResolver needs for
building the graph Laplacian matrix is not substan-
tial. For eigensolving, we use an open source library
provided by the Colt project1which implements a
Householder-QL algorithm to solve the eigenvalue
decomposition. When applied to the symmetric
graph Laplacian, the complexity of the eigensolv-
ing is given by O(n3), where n is the number of
mentions in a hypergraph. Since there are only a
few hundred mentions per document in our data, this
complexity is not an issue. Spectral clustering gets
problematic when applied to millions of data points.
</bodyText>
<sectionHeader confidence="0.99935" genericHeader="method">
4 Features
</sectionHeader>
<bodyText confidence="0.9802543">
In our system, features are represented as types of
hyperedges. Any realized edge is an instance of the
corresponding edge type. All instances derived from
the same type have the same weight, but they may
get reweighed by the distance feature (see Cai and
Strube (2010)). We use three types of features:
negative: prevent edges between mentions;
positive: generate strong edges between mentions;
weak: add edges to an existing graph without intro-
ducing new vertices;
</bodyText>
<footnote confidence="0.4502595">
1
http://acs.lbl.gov/ hoschek/colt/
</footnote>
<page confidence="0.968649">
57
</page>
<bodyText confidence="0.991459">
\x0cIn the following subsections we describe the fea-
tures used in our experiments. Some of the fea-
tures described in Cai and Strube (2010) had to be
changed to cope with the OntoNotes data. We also
introduced a few more features (in particular in or-
der to deal with the dialogue section in the data).
</bodyText>
<subsectionHeader confidence="0.972036">
4.1 Negative Features
</subsectionHeader>
<bodyText confidence="0.9487477">
Negative features describe pairwise relations which
are most likely not coreferent. While we imple-
mented this information as weak positive features in
Cai and Strube (2010), here we apply these features
before graph construction as global variables.
When two mentions are connected by a negative
relation, no edges will be built between them in the
graph. For instance, no edges are allowed between
the mention Hillary Clinton and the mention he due
to incompatible gender.
</bodyText>
<listItem confidence="0.976901928571429">
(1) N Gender, (2) N Number: Two mentions do
not agree in gender or number.
(3) N SemanticClass: Two mentions do not
agree in semantic class (only the Object, Date and
Person top categories derived from WordNet (Fell-
baum, 1998) are used).
(4) N Mod: Two mentions have the same syntac-
tic heads, and the anaphor has a pre-modifier which
does not occur in the antecedent and does not con-
tradict the antecedent.
(5) N DSPrn: Two first person pronouns in direct
speeches assigned to different speakers.
(6) N ContraSubjObj: Two mentions are in the
subject and object positions of the same verb, and
</listItem>
<bodyText confidence="0.598784">
the anaphor is a non-possesive pronoun.
</bodyText>
<subsectionHeader confidence="0.94698">
4.2 Positive Features
</subsectionHeader>
<bodyText confidence="0.8616442">
The majority of well studied coreference features
(e.g. Stoyanov et al. (2009)) are actually positive
coreference indicators. In our system, the mentions
which participate in positive relations are included
in the graph representation.
</bodyText>
<listItem confidence="0.969695111111111">
(7) StrMatch Npron &amp; (8) StrMatch Pron: Af-
ter discarding stop words, if the strings of mentions
completely match and are not pronouns, they are put
into edges of the StrMatch Npron type. When the
matched mentions are pronouns, they are put into
the StrMatch Pron type edges.
(9) Alias: After discarding stop words, if men-
tions are aliases of each other (i.e. proper names with
partial match, full names and acronyms, etc.).
(10) HeadMatch: If the syntactic heads of men-
tions match.
(11) Nprn Prn: If the antecedent is not a pro-
noun and the anaphor is a pronoun. This feature is
restricted to a sentence distance of 2. Though it is
not highly weighted, it is crucial for integrating pro-
nouns into the graph.
(12) Speaker12Prn: If the speaker of the second
person pronoun is talking to the speaker of the first
person pronoun. The mentions contain only first or
second person pronouns.
(13) DSPrn: If one of the mentions is the subject
of a speak verb, and other mentions are first person
pronouns within the corresponding direct speech.
(14) ReflexivePrn: If the anaphor is a reflexive
pronoun, and the antecedent is subject of the sen-
tence.
(15) PossPrn: If the anaphor is a possesive pro-
noun, and the antecedent is the subject of the sen-
tence or the subclause.
(16) GPEIsA: If the antecedent is a Named Entity
of GPE entity type (i.e. one of the ACE entity type
(NIST, 2004)), and the anaphor is a definite expres-
sion of the same type.
(17) OrgIsA: If the antecedent is a Named En-
tity of Organization entity type, and the anaphor is a
definite expression of the same type.
</listItem>
<subsectionHeader confidence="0.998124">
4.3 Weak Features
</subsectionHeader>
<bodyText confidence="0.968633166666667">
Weak features are weak coreference indicators. Us-
ing them as positive features would introduce too
much noise to the graph (i.e. a graph with too many
singletons). We apply weak features only to men-
tions already integrated in the graph, so that weak
information provides it with a richer structure.
</bodyText>
<listItem confidence="0.9497182">
(18) W Speak: If mentions occur with a word
meaning to say in a window size of two words.
(19) W Subject: If mentions are subjects.
(20) W Synonym: If mentions are synonymous
as indicated by WordNet.
</listItem>
<sectionHeader confidence="0.997898" genericHeader="method">
5 Results
</sectionHeader>
<bodyText confidence="0.981908">
We submitted COPAs results to the open setting
in the CoNLL shared task on modeling unrestricted
coreference. We used only 30% of the training data
</bodyText>
<page confidence="0.99047">
58
</page>
<bodyText confidence="0.931491777777778">
\x0c(randomly selected) and the 20 features described in
Section 4.
The stopping criterion (see Section 3) is tuned
on development data to optimize the final corefer-
ence scores. A value of 0.06 is chosen for testing.
COPAs results on development set (which con-
sists of 202 files) and on testing set are displayed in
Table 1 and Table 2 respectively. The Overall num-
bers in both tables are the average scores of MUC,
</bodyText>
<table confidence="0.952510125">
BCUBED and CEAF(E).
Metric R P F1
MUC 52.69 57.94 55.19
BCUBED 64.26 73.39 68.52
CEAF(M) 54.44 54.44 54.44
CEAF(E) 45.73 40.92 43.19
BLANC 69.78 75.26 72.13
Overall 55.63
</table>
<tableCaption confidence="0.968545">
Table 1: COPAs results on CoNLL development set
</tableCaption>
<table confidence="0.998213428571429">
Metric R P F1
MUC 56.73 58.90 57.80
BCUBED 64.60 71.03 67.66
CEAF(M) 53.37 53.37 53.37
CEAF(E) 42.71 40.68 41.67
BLANC 69.77 73.96 71.62
Overall 55.71
</table>
<tableCaption confidence="0.992911">
Table 2: COPAs results on CoNLL testing set
</tableCaption>
<sectionHeader confidence="0.915847" genericHeader="method">
6 Mention Detection Errors
</sectionHeader>
<bodyText confidence="0.999538411764706">
As described in Section 2, our mention detection is
based on automatically extracted information, such
as syntactic parses and basic noun phrase chunks.
Since there is no minimum span information pro-
vided in the OntoNotes data (in constrast to the pre-
vious standard corpus, ACE), exact mention bound-
ary detection is required. A lot of the spurious
mentions in our system are generated due to mis-
matches of ending or starting punctuations, and the
OntoNotes annotation is also not consistent in this
regard. Our current mention detector does not ex-
tract verb phrases. Therefore it misses all the Event
mentions in the OntoNotes corpus.
We are planning to include idiomatic expression
identification into our mention detector, which will
help to avoid detecting a lot of spurious mentions,
such as God in the phrase for Gods sake.
</bodyText>
<sectionHeader confidence="0.989978" genericHeader="method">
7 COPA Errors
</sectionHeader>
<bodyText confidence="0.9988966">
Besides the fact that the current COPA is not resolv-
ing any event coreferences, our in-house mention de-
tector performs weakly in extracting date mentions
too. As a result, the system outputs several spuri-
ous coreference sets, for instance a set containing
the September from the mention 15th September.
A large amount of the recall loss in our system is
due to the lack of the world knowledge. For exam-
ple, COPA does not resolve the mention the Europe
station correctly into the entity Radio Free Europe,
for it has no knowledge that the entity is a station.
Some more difficult coreference phenomena in
OntoNotes data might require a reasoning mecha-
nism. To be able to connect the mention the vic-
tim with the mention the grooms brother, the event
of the brother being killed needs to be intepreted by
the system.
We also observed from the experiments that the
resolution of the it mentions are quite inaccurate.
Although our mention detector takes care of dis-
carding pleonastic its, there are still a lot of them
left which introduce wrong coreference sets. Since
the its do not contain enough information by them-
selves, more features exploring their local syntax are
necessary.
</bodyText>
<sectionHeader confidence="0.997904" genericHeader="conclusions">
8 Conclusions
</sectionHeader>
<bodyText confidence="0.9952266875">
In this paper we described a coreference resolution
system, COPA, which implements a global decision
in one step via hypergraph partitioning. COPAs
hypergraph-based strategy is a general preference
model, where the preference for one mention de-
pends on information on all other mentions.
The system implements three types of relational
features negative, positive and weak features, and
assigns the edge weights according to the statitics
from the training data. Since the weights are robust
with respect to the amount of training data we used
only 30% of the training data.
Acknowledgements. This work has been funded
by the Klaus Tschira Foundation, Heidelberg, Ger-
many. The first author has been supported by a HITS
PhD. scholarship.
</bodyText>
<page confidence="0.967702">
59
</page>
<reference confidence="0.9947591875">
\x0cReferences
Sameer Agarwal, Jonwoo Lim, Lihi Zelnik-Manor, Pietro
Perona, David Kriegman, and Serge Belongie. 2005.
Beyond pairwise clustering. In Proceedings of the
IEEE Computer Society Conference on Computer Vi-
sion and Pattern Recognition (CVPR05), volume 2,
pages 838845.
Jie Cai and Michael Strube. 2010. End-to-end coref-
erence resolution via hypergraph partitioning. In
Proceedings of the 23rd International Conference on
Computational Linguistics, Beijing, China, 2327 Au-
gust 2010, pages 143151.
Eugene Charniak and Mark Johnson. 2005. Coarse-
to-fine n-best parsing and MaxEent discriminative
reranking. In Proceedings of the 43rd Annual Meet-
ing of the Association for Computational Linguistics,
Ann Arbor, Mich., 2530 June 2005, pages 173180.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. MIT Press, Cambridge,
Mass.
Jenny Rose Finkel, Trond Grenager, and Christopher
Manning. 2005. Incorporating non-local informa-
tion into information extraction systems by Gibbs sam-
pling. In Proceedings of the 43rd Annual Meeting
of the Association for Computational Linguistics, Ann
Arbor, Mich., 2530 June 2005, pages 363370.
Taku Kudoh and Yuji Matsumoto. 2000. Use of Support
Vector Machines for chunk identification. In Proceed-
ings of the 4th Conference on Computational Natural
Language Learning, Lisbon, Portugal, 1314 Septem-
ber 2000, pages 142144.
Christoph Muller and Michael Strube. 2006. Multi-level
annotation of linguistic data with MMAX2. In Sabine
Braun, Kurt Kohn, and Joybrato Mukherjee, editors,
Corpus Technology and Language Pedagogy: New Re-
sources, New Tools, New Methods, pages 197214. Pe-
ter Lang: Frankfurt a.M., Germany.
NIST. 2004. The ACE evaluation plan:
Evaluation of the recognition of ACE en-
tities, ACE relations and ACE events.
http://www.itl.nist.gov/iad/mig//tests/ace/2004/doc/
ace04-evalplan-v7.pdf.
Sameer Pradhan, Lance Ramshaw, Mitchell Marcus,
Martha Palmer, Ralph Weischedel, and Nianwen Xue.
2011. CoNLL-2011 Shared Task: Modeling unre-
stricted coreference in OntoNotes. In Proceedings of
the Shared Task of 15th Conference on Computational
Natural Language Learning, Portland, Oreg., 2324
June 2011.
Veselin Stoyanov, Nathan Gilbert, Claire Cardie, and
Ellen Riloff. 2009. Conundrums in noun phrase coref-
erence resolution: Making sense of the state-of-the-
art. In Proceedings of the Joint Conference of the 47th
Annual Meeting of the Association for Computational
Linguistics and the 4th International Joint Conference
on Natural Language Processing, Singapore, 27 Au-
gust 2009, pages 656664.
Kristina Toutanova, Dan Klein, Christopher D. Manning,
and Yoram Singer. 2003. Feature-rich part-of-speech
tagging with a cyclic dependency network. In Pro-
ceedings of the Human Language Technology Confer-
ence of the North American Chapter of the Associ-
ation for Computational Linguistics, Edmonton, Al-
berta, Canada, 27 May 1 June 2003, pages 252259.
Yannick Versley, Simone Paolo Ponzetto, Massimo Poe-
sio, Vladimir Eidelman, Alan Jern, Jason Smith,
Xiaofeng Yang, and Alessandro Moschitti. 2008.
BART: A modular toolkit for coreference resolution.
In Companion Volume to the Proceedings of the 46th
Annual Meeting of the Association for Computational
Linguistics, Columbus, Ohio, 1520 June 2008, pages
912.
Ulrike von Luxburg. 2007. A tutorial on spectral cluster-
ing. Statistics and Computing, 17(4):395416.
Ralph Weischedel, Martha Palmer, Mitchell Marcus, Ed-
uard Hovy, Sameer Pradhan, Lance Ramshaw, Ni-
anwen Xue, Ann Taylor, Jeff Kaufman, Michelle
Franchini, Mohammed El-Bachouti, Robert Belvin,
and Ann Houston. 2011. OntoNotes release 4.0.
LDC2011T03, Philadelphia, Penn.: Linguistic Data
</reference>
<figure confidence="0.619088333333333">
Consortium.
60
\x0c&amp;apos;
</figure>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.647472">
<note confidence="0.968302">b&amp;apos;Proceedings of the 15th Conference on Computational Natural Language Learning: Shared Task, pages 5660, Portland, Oregon, 23-24 June 2011. c 2011 Association for Computational Linguistics</note>
<title confidence="0.855405">Unrestricted Coreference Resolution via Global Hypergraph Partitioning</title>
<author confidence="0.995359">Jie Cai</author>
<author confidence="0.995359">Eva Mujdricza-Maydt</author>
<author confidence="0.995359">Michael Strube</author>
<affiliation confidence="0.997661">Natural Language Processing Group Heidelberg Institute for Theoretical Studies gGmbH</affiliation>
<address confidence="0.974819">Heidelberg, Germany</address>
<email confidence="0.999023">(jie.cai|eva.mujdriczamaydt|michael.strube)@h-its.org</email>
<abstract confidence="0.976001285714285">We present our end-to-end coreference resolution system, COPA, which implements a global decision via hypergraph partitioning. In constrast to almost all previous approaches, we do not rely on separate classification and clustering steps, but perform coreference resolution globally in one step. COPA represents each document as a hypergraph and partitions it with a spectral clustering algorithm. Various types of relational features can be easily incorporated in this framwork. COPA has participated in the open setting of the CoNLL shared task on modeling unrestricted coreference.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>\x0cReferences Sameer Agarwal</author>
<author>Jonwoo Lim</author>
<author>Lihi Zelnik-Manor</author>
<author>Pietro Perona</author>
<author>David Kriegman</author>
<author>Serge Belongie</author>
</authors>
<title>Beyond pairwise clustering.</title>
<date>2005</date>
<booktitle>In Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR05),</booktitle>
<volume>2</volume>
<pages>838845</pages>
<contexts>
<context position="5844" citStr="Agarwal et al., 2005" startWordPosition="885" endWordPosition="888">raph into several sub-hypergraphs, each corresponding to one set of coreferent mentions. 3.2.1 HGModelBuilder A single document is represented in a hypergraph with basic relational features. Each hyperedge in a graph corresponds to an instance of one of those features with the weight assigned by the HyperEdgeLearner. Instead of connecting nodes with the target relation as usually done in graph models, COPA builds the graph directly out of low dimensional features without assuming a distance metric. 3.2.2 HGResolver In order to partition the hypergraph we adopt a spectral clustering algorithm (Agarwal et al., 2005). All experimental results are obtained using symmetric Laplacians (Lsym) (von Luxburg, 2007). We apply the recursive variant of spectral clustering, recursive 2-way partitioning (R2 partitioner) (Cai and Strube, 2010). This method does not need any information about the number of target sets (the number k of clusters). Instead a stopping criterion has to be provided which is adjusted on development data. 3.3 Complexity of HGResolver Since edge weights are assigned using simple descriptive statistics, the time HGResolver needs for building the graph Laplacian matrix is not substantial. For eig</context>
</contexts>
<marker>Agarwal, Lim, Zelnik-Manor, Perona, Kriegman, Belongie, 2005</marker>
<rawString>\x0cReferences Sameer Agarwal, Jonwoo Lim, Lihi Zelnik-Manor, Pietro Perona, David Kriegman, and Serge Belongie. 2005. Beyond pairwise clustering. In Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR05), volume 2, pages 838845.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jie Cai</author>
<author>Michael Strube</author>
</authors>
<title>End-to-end coreference resolution via hypergraph partitioning.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics,</booktitle>
<pages>143151</pages>
<location>Beijing, China, 2327</location>
<contexts>
<context position="2025" citStr="Cai and Strube, 2010" startWordPosition="298" endWordPosition="301">fidence value, and (2) a clustering step which groups mentions into entities based on the output of step 1. In this paper we present an end-to-end coreference resolution system, COPA, which avoids the division into two steps and instead performs a global decision in one step. The system presents a document as a hypergraph, where the vertices denote mentions and the edges denote relational features between mentions. Coreference resolution is then performed globally in one step by partitioning the hypergraph into subhypergraphs so that all mentions in one subhypergraph refer to the same entity (Cai and Strube, 2010). COPA assigns edge weights by applying simple descriptive statistics on the tranining data. Since COPA does not need to learn an explicit model, we used only 30% of the CoNLL shared task training data. We did this not for efficiency reasons, only for convenience. While COPA has been developed originally to perform coreference resolution on MUC and ACE data (Cai and Strube, 2010), the move to the OntoNotes data (Weischedel et al., 2011) required mainly to update the mention detector and the feature set. Since several off-the-shelf preprocessing components are used, COPA participated in the ope</context>
<context position="6062" citStr="Cai and Strube, 2010" startWordPosition="916" endWordPosition="919">orresponds to an instance of one of those features with the weight assigned by the HyperEdgeLearner. Instead of connecting nodes with the target relation as usually done in graph models, COPA builds the graph directly out of low dimensional features without assuming a distance metric. 3.2.2 HGResolver In order to partition the hypergraph we adopt a spectral clustering algorithm (Agarwal et al., 2005). All experimental results are obtained using symmetric Laplacians (Lsym) (von Luxburg, 2007). We apply the recursive variant of spectral clustering, recursive 2-way partitioning (R2 partitioner) (Cai and Strube, 2010). This method does not need any information about the number of target sets (the number k of clusters). Instead a stopping criterion has to be provided which is adjusted on development data. 3.3 Complexity of HGResolver Since edge weights are assigned using simple descriptive statistics, the time HGResolver needs for building the graph Laplacian matrix is not substantial. For eigensolving, we use an open source library provided by the Colt project1which implements a Householder-QL algorithm to solve the eigenvalue decomposition. When applied to the symmetric graph Laplacian, the complexity of </context>
<context position="7585" citStr="Cai and Strube (2010)" startWordPosition="1161" endWordPosition="1164"> are represented as types of hyperedges. Any realized edge is an instance of the corresponding edge type. All instances derived from the same type have the same weight, but they may get reweighed by the distance feature (see Cai and Strube (2010)). We use three types of features: negative: prevent edges between mentions; positive: generate strong edges between mentions; weak: add edges to an existing graph without introducing new vertices; 1 http://acs.lbl.gov/ hoschek/colt/ 57 \x0cIn the following subsections we describe the features used in our experiments. Some of the features described in Cai and Strube (2010) had to be changed to cope with the OntoNotes data. We also introduced a few more features (in particular in order to deal with the dialogue section in the data). 4.1 Negative Features Negative features describe pairwise relations which are most likely not coreferent. While we implemented this information as weak positive features in Cai and Strube (2010), here we apply these features before graph construction as global variables. When two mentions are connected by a negative relation, no edges will be built between them in the graph. For instance, no edges are allowed between the mention Hill</context>
</contexts>
<marker>Cai, Strube, 2010</marker>
<rawString>Jie Cai and Michael Strube. 2010. End-to-end coreference resolution via hypergraph partitioning. In Proceedings of the 23rd International Conference on Computational Linguistics, Beijing, China, 2327 August 2010, pages 143151.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
</authors>
<title>Coarseto-fine n-best parsing and MaxEent discriminative reranking.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>173180</pages>
<location>Ann Arbor, Mich.,</location>
<contexts>
<context position="3499" citStr="Charniak and Johnson, 2005" startWordPosition="531" endWordPosition="534">oolkit (Versley et al., 2008). Documents are transformed into the MMAX2-format (Muller and Strube, 2006) which allows for easy visualization and (linguistic) debugging. Each document is stored in several XML-files representing different layers of annotations. These annotations are created by a pipeline of preprocessing components. We use the Stanford MaxentTagger (Toutanova et al., 2003) for partof-speech tagging, and the Stanford Named Entity Recognizer (Finkel et al., 2005) for annotating named entities. In order to derive syntactic information, we use the Charniak/Johnson reranking parser (Charniak and Johnson, 2005) com56 \x0cbined with a constituent-to-dependency conversion Tool (http://nlp.cs.lth.se/software/ treebank_converter). The preprocessing models are not trained on CoNLL data, so we only participated in the open task. We have implemented an in-house mention detector, which makes use of the parsing output, the partof-speech tags, as well as the chunks from the Yamcha Chunker (Kudoh and Matsumoto, 2000). For the OntoNotes data, the mention detector annotates the biggest noun phrase spans. 3 COPA: Coreference Partitioner The COPA system consists of modules which derive hyperedges from features and</context>
</contexts>
<marker>Charniak, Johnson, 2005</marker>
<rawString>Eugene Charniak and Mark Johnson. 2005. Coarseto-fine n-best parsing and MaxEent discriminative reranking. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics, Ann Arbor, Mich., 2530 June 2005, pages 173180.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, Mass.</location>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database. MIT Press, Cambridge, Mass.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Trond Grenager</author>
<author>Christopher Manning</author>
</authors>
<title>Incorporating non-local information into information extraction systems by Gibbs sampling.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>363370</pages>
<location>Ann Arbor, Mich.,</location>
<contexts>
<context position="3352" citStr="Finkel et al., 2005" startWordPosition="509" endWordPosition="512">make extensive use of information beyond information from the closed class setting. 2 Preprocessing COPA is implemented on top of the BART-toolkit (Versley et al., 2008). Documents are transformed into the MMAX2-format (Muller and Strube, 2006) which allows for easy visualization and (linguistic) debugging. Each document is stored in several XML-files representing different layers of annotations. These annotations are created by a pipeline of preprocessing components. We use the Stanford MaxentTagger (Toutanova et al., 2003) for partof-speech tagging, and the Stanford Named Entity Recognizer (Finkel et al., 2005) for annotating named entities. In order to derive syntactic information, we use the Charniak/Johnson reranking parser (Charniak and Johnson, 2005) com56 \x0cbined with a constituent-to-dependency conversion Tool (http://nlp.cs.lth.se/software/ treebank_converter). The preprocessing models are not trained on CoNLL data, so we only participated in the open task. We have implemented an in-house mention detector, which makes use of the parsing output, the partof-speech tags, as well as the chunks from the Yamcha Chunker (Kudoh and Matsumoto, 2000). For the OntoNotes data, the mention detector ann</context>
</contexts>
<marker>Finkel, Grenager, Manning, 2005</marker>
<rawString>Jenny Rose Finkel, Trond Grenager, and Christopher Manning. 2005. Incorporating non-local information into information extraction systems by Gibbs sampling. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics, Ann Arbor, Mich., 2530 June 2005, pages 363370.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudoh</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Use of Support Vector Machines for chunk identification.</title>
<date>2000</date>
<booktitle>In Proceedings of the 4th Conference on Computational Natural Language Learning,</booktitle>
<pages>142144</pages>
<location>Lisbon,</location>
<contexts>
<context position="3902" citStr="Kudoh and Matsumoto, 2000" startWordPosition="591" endWordPosition="594">eech tagging, and the Stanford Named Entity Recognizer (Finkel et al., 2005) for annotating named entities. In order to derive syntactic information, we use the Charniak/Johnson reranking parser (Charniak and Johnson, 2005) com56 \x0cbined with a constituent-to-dependency conversion Tool (http://nlp.cs.lth.se/software/ treebank_converter). The preprocessing models are not trained on CoNLL data, so we only participated in the open task. We have implemented an in-house mention detector, which makes use of the parsing output, the partof-speech tags, as well as the chunks from the Yamcha Chunker (Kudoh and Matsumoto, 2000). For the OntoNotes data, the mention detector annotates the biggest noun phrase spans. 3 COPA: Coreference Partitioner The COPA system consists of modules which derive hyperedges from features and assign edge weights indicating a positive correlation with the coreference relation, and resolution modules which create a hypergraph representation for the testing data and perform partitioning to produce subhypergraphs, each of which represents an entity. 3.1 HyperEdgeCreator COPA needs training data only for computing the hyperedge weights. Hyperedges represent features. Each hyperedge correspond</context>
</contexts>
<marker>Kudoh, Matsumoto, 2000</marker>
<rawString>Taku Kudoh and Yuji Matsumoto. 2000. Use of Support Vector Machines for chunk identification. In Proceedings of the 4th Conference on Computational Natural Language Learning, Lisbon, Portugal, 1314 September 2000, pages 142144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christoph Muller</author>
<author>Michael Strube</author>
</authors>
<title>Multi-level annotation of linguistic data with MMAX2.</title>
<date>2006</date>
<booktitle>Corpus Technology and Language Pedagogy: New Resources,</booktitle>
<pages>197214</pages>
<editor>In Sabine Braun, Kurt Kohn, and Joybrato Mukherjee, editors,</editor>
<publisher>Peter</publisher>
<location>New Tools, New Methods,</location>
<contexts>
<context position="2976" citStr="Muller and Strube, 2006" startWordPosition="452" endWordPosition="455">e resolution on MUC and ACE data (Cai and Strube, 2010), the move to the OntoNotes data (Weischedel et al., 2011) required mainly to update the mention detector and the feature set. Since several off-the-shelf preprocessing components are used, COPA participated in the open setting of the CoNLL shared task on modeling unrestricted coreference (Pradhan et al., 2011). We did not make extensive use of information beyond information from the closed class setting. 2 Preprocessing COPA is implemented on top of the BART-toolkit (Versley et al., 2008). Documents are transformed into the MMAX2-format (Muller and Strube, 2006) which allows for easy visualization and (linguistic) debugging. Each document is stored in several XML-files representing different layers of annotations. These annotations are created by a pipeline of preprocessing components. We use the Stanford MaxentTagger (Toutanova et al., 2003) for partof-speech tagging, and the Stanford Named Entity Recognizer (Finkel et al., 2005) for annotating named entities. In order to derive syntactic information, we use the Charniak/Johnson reranking parser (Charniak and Johnson, 2005) com56 \x0cbined with a constituent-to-dependency conversion Tool (http://nlp</context>
</contexts>
<marker>Muller, Strube, 2006</marker>
<rawString>Christoph Muller and Michael Strube. 2006. Multi-level annotation of linguistic data with MMAX2. In Sabine Braun, Kurt Kohn, and Joybrato Mukherjee, editors, Corpus Technology and Language Pedagogy: New Resources, New Tools, New Methods, pages 197214. Peter Lang: Frankfurt a.M., Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>NIST</author>
</authors>
<title>The ACE evaluation plan: Evaluation of the recognition of</title>
<date>2004</date>
<booktitle>ACE entities, ACE relations and ACE events. http://www.itl.nist.gov/iad/mig//tests/ace/2004/doc/</booktitle>
<pages>04--7</pages>
<contexts>
<context position="10510" citStr="NIST, 2004" startWordPosition="1662" endWordPosition="1663">onoun is talking to the speaker of the first person pronoun. The mentions contain only first or second person pronouns. (13) DSPrn: If one of the mentions is the subject of a speak verb, and other mentions are first person pronouns within the corresponding direct speech. (14) ReflexivePrn: If the anaphor is a reflexive pronoun, and the antecedent is subject of the sentence. (15) PossPrn: If the anaphor is a possesive pronoun, and the antecedent is the subject of the sentence or the subclause. (16) GPEIsA: If the antecedent is a Named Entity of GPE entity type (i.e. one of the ACE entity type (NIST, 2004)), and the anaphor is a definite expression of the same type. (17) OrgIsA: If the antecedent is a Named Entity of Organization entity type, and the anaphor is a definite expression of the same type. 4.3 Weak Features Weak features are weak coreference indicators. Using them as positive features would introduce too much noise to the graph (i.e. a graph with too many singletons). We apply weak features only to mentions already integrated in the graph, so that weak information provides it with a richer structure. (18) W Speak: If mentions occur with a word meaning to say in a window size of two w</context>
</contexts>
<marker>NIST, 2004</marker>
<rawString>NIST. 2004. The ACE evaluation plan: Evaluation of the recognition of ACE entities, ACE relations and ACE events. http://www.itl.nist.gov/iad/mig//tests/ace/2004/doc/ ace04-evalplan-v7.pdf.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Pradhan</author>
<author>Lance Ramshaw</author>
<author>Mitchell Marcus</author>
<author>Martha Palmer</author>
<author>Ralph Weischedel</author>
<author>Nianwen Xue</author>
</authors>
<title>CoNLL-2011 Shared Task: Modeling unrestricted coreference in OntoNotes.</title>
<date>2011</date>
<booktitle>In Proceedings of the Shared Task of 15th Conference on Computational Natural Language Learning,</booktitle>
<location>Portland, Oreg., 2324</location>
<contexts>
<context position="2719" citStr="Pradhan et al., 2011" startWordPosition="412" endWordPosition="415">the tranining data. Since COPA does not need to learn an explicit model, we used only 30% of the CoNLL shared task training data. We did this not for efficiency reasons, only for convenience. While COPA has been developed originally to perform coreference resolution on MUC and ACE data (Cai and Strube, 2010), the move to the OntoNotes data (Weischedel et al., 2011) required mainly to update the mention detector and the feature set. Since several off-the-shelf preprocessing components are used, COPA participated in the open setting of the CoNLL shared task on modeling unrestricted coreference (Pradhan et al., 2011). We did not make extensive use of information beyond information from the closed class setting. 2 Preprocessing COPA is implemented on top of the BART-toolkit (Versley et al., 2008). Documents are transformed into the MMAX2-format (Muller and Strube, 2006) which allows for easy visualization and (linguistic) debugging. Each document is stored in several XML-files representing different layers of annotations. These annotations are created by a pipeline of preprocessing components. We use the Stanford MaxentTagger (Toutanova et al., 2003) for partof-speech tagging, and the Stanford Named Entity</context>
</contexts>
<marker>Pradhan, Ramshaw, Marcus, Palmer, Weischedel, Xue, 2011</marker>
<rawString>Sameer Pradhan, Lance Ramshaw, Mitchell Marcus, Martha Palmer, Ralph Weischedel, and Nianwen Xue. 2011. CoNLL-2011 Shared Task: Modeling unrestricted coreference in OntoNotes. In Proceedings of the Shared Task of 15th Conference on Computational Natural Language Learning, Portland, Oreg., 2324 June 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Veselin Stoyanov</author>
<author>Nathan Gilbert</author>
<author>Claire Cardie</author>
<author>Ellen Riloff</author>
</authors>
<title>Conundrums in noun phrase coreference resolution: Making sense of the state-of-theart.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the Association for Computational Linguistics and the 4th International Joint Conference on Natural Language Processing,</booktitle>
<pages>656664</pages>
<contexts>
<context position="8977" citStr="Stoyanov et al. (2009)" startWordPosition="1395" endWordPosition="1398"> not agree in semantic class (only the Object, Date and Person top categories derived from WordNet (Fellbaum, 1998) are used). (4) N Mod: Two mentions have the same syntactic heads, and the anaphor has a pre-modifier which does not occur in the antecedent and does not contradict the antecedent. (5) N DSPrn: Two first person pronouns in direct speeches assigned to different speakers. (6) N ContraSubjObj: Two mentions are in the subject and object positions of the same verb, and the anaphor is a non-possesive pronoun. 4.2 Positive Features The majority of well studied coreference features (e.g. Stoyanov et al. (2009)) are actually positive coreference indicators. In our system, the mentions which participate in positive relations are included in the graph representation. (7) StrMatch Npron &amp; (8) StrMatch Pron: After discarding stop words, if the strings of mentions completely match and are not pronouns, they are put into edges of the StrMatch Npron type. When the matched mentions are pronouns, they are put into the StrMatch Pron type edges. (9) Alias: After discarding stop words, if mentions are aliases of each other (i.e. proper names with partial match, full names and acronyms, etc.). (10) HeadMatch: If</context>
</contexts>
<marker>Stoyanov, Gilbert, Cardie, Riloff, 2009</marker>
<rawString>Veselin Stoyanov, Nathan Gilbert, Claire Cardie, and Ellen Riloff. 2009. Conundrums in noun phrase coreference resolution: Making sense of the state-of-theart. In Proceedings of the Joint Conference of the 47th Annual Meeting of the Association for Computational Linguistics and the 4th International Joint Conference on Natural Language Processing, Singapore, 27 August 2009, pages 656664.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
<author>Yoram Singer</author>
</authors>
<title>Feature-rich part-of-speech tagging with a cyclic dependency network.</title>
<date>2003</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<volume>1</volume>
<pages>252259</pages>
<location>Edmonton, Alberta,</location>
<contexts>
<context position="3262" citStr="Toutanova et al., 2003" startWordPosition="494" endWordPosition="497">he CoNLL shared task on modeling unrestricted coreference (Pradhan et al., 2011). We did not make extensive use of information beyond information from the closed class setting. 2 Preprocessing COPA is implemented on top of the BART-toolkit (Versley et al., 2008). Documents are transformed into the MMAX2-format (Muller and Strube, 2006) which allows for easy visualization and (linguistic) debugging. Each document is stored in several XML-files representing different layers of annotations. These annotations are created by a pipeline of preprocessing components. We use the Stanford MaxentTagger (Toutanova et al., 2003) for partof-speech tagging, and the Stanford Named Entity Recognizer (Finkel et al., 2005) for annotating named entities. In order to derive syntactic information, we use the Charniak/Johnson reranking parser (Charniak and Johnson, 2005) com56 \x0cbined with a constituent-to-dependency conversion Tool (http://nlp.cs.lth.se/software/ treebank_converter). The preprocessing models are not trained on CoNLL data, so we only participated in the open task. We have implemented an in-house mention detector, which makes use of the parsing output, the partof-speech tags, as well as the chunks from the Ya</context>
</contexts>
<marker>Toutanova, Klein, Manning, Singer, 2003</marker>
<rawString>Kristina Toutanova, Dan Klein, Christopher D. Manning, and Yoram Singer. 2003. Feature-rich part-of-speech tagging with a cyclic dependency network. In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics, Edmonton, Alberta, Canada, 27 May 1 June 2003, pages 252259.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yannick Versley</author>
<author>Simone Paolo Ponzetto</author>
<author>Massimo Poesio</author>
<author>Vladimir Eidelman</author>
<author>Alan Jern</author>
<author>Jason Smith</author>
<author>Xiaofeng Yang</author>
<author>Alessandro Moschitti</author>
</authors>
<title>BART: A modular toolkit for coreference resolution.</title>
<date>2008</date>
<contexts>
<context position="2901" citStr="Versley et al., 2008" startWordPosition="442" endWordPosition="445">venience. While COPA has been developed originally to perform coreference resolution on MUC and ACE data (Cai and Strube, 2010), the move to the OntoNotes data (Weischedel et al., 2011) required mainly to update the mention detector and the feature set. Since several off-the-shelf preprocessing components are used, COPA participated in the open setting of the CoNLL shared task on modeling unrestricted coreference (Pradhan et al., 2011). We did not make extensive use of information beyond information from the closed class setting. 2 Preprocessing COPA is implemented on top of the BART-toolkit (Versley et al., 2008). Documents are transformed into the MMAX2-format (Muller and Strube, 2006) which allows for easy visualization and (linguistic) debugging. Each document is stored in several XML-files representing different layers of annotations. These annotations are created by a pipeline of preprocessing components. We use the Stanford MaxentTagger (Toutanova et al., 2003) for partof-speech tagging, and the Stanford Named Entity Recognizer (Finkel et al., 2005) for annotating named entities. In order to derive syntactic information, we use the Charniak/Johnson reranking parser (Charniak and Johnson, 2005) c</context>
</contexts>
<marker>Versley, Ponzetto, Poesio, Eidelman, Jern, Smith, Yang, Moschitti, 2008</marker>
<rawString>Yannick Versley, Simone Paolo Ponzetto, Massimo Poesio, Vladimir Eidelman, Alan Jern, Jason Smith, Xiaofeng Yang, and Alessandro Moschitti. 2008. BART: A modular toolkit for coreference resolution.</rawString>
</citation>
<citation valid="true">
<date>1520</date>
<booktitle>In Companion Volume to the Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>912</pages>
<location>Columbus, Ohio,</location>
<marker>1520</marker>
<rawString>In Companion Volume to the Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics, Columbus, Ohio, 1520 June 2008, pages 912.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulrike von Luxburg</author>
</authors>
<title>A tutorial on spectral clustering.</title>
<date>2007</date>
<journal>Statistics and Computing,</journal>
<volume>17</volume>
<issue>4</issue>
<marker>von Luxburg, 2007</marker>
<rawString>Ulrike von Luxburg. 2007. A tutorial on spectral clustering. Statistics and Computing, 17(4):395416.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralph Weischedel</author>
<author>Martha Palmer</author>
<author>Mitchell Marcus</author>
<author>Eduard Hovy</author>
<author>Sameer Pradhan</author>
<author>Lance Ramshaw</author>
</authors>
<date>2011</date>
<booktitle>OntoNotes release 4.0. LDC2011T03,</booktitle>
<location>Nianwen Xue, Ann Taylor, Jeff Kaufman, Michelle Franchini, Mohammed El-Bachouti, Robert</location>
<contexts>
<context position="2465" citStr="Weischedel et al., 2011" startWordPosition="373" endWordPosition="376">tion is then performed globally in one step by partitioning the hypergraph into subhypergraphs so that all mentions in one subhypergraph refer to the same entity (Cai and Strube, 2010). COPA assigns edge weights by applying simple descriptive statistics on the tranining data. Since COPA does not need to learn an explicit model, we used only 30% of the CoNLL shared task training data. We did this not for efficiency reasons, only for convenience. While COPA has been developed originally to perform coreference resolution on MUC and ACE data (Cai and Strube, 2010), the move to the OntoNotes data (Weischedel et al., 2011) required mainly to update the mention detector and the feature set. Since several off-the-shelf preprocessing components are used, COPA participated in the open setting of the CoNLL shared task on modeling unrestricted coreference (Pradhan et al., 2011). We did not make extensive use of information beyond information from the closed class setting. 2 Preprocessing COPA is implemented on top of the BART-toolkit (Versley et al., 2008). Documents are transformed into the MMAX2-format (Muller and Strube, 2006) which allows for easy visualization and (linguistic) debugging. Each document is stored </context>
</contexts>
<marker>Weischedel, Palmer, Marcus, Hovy, Pradhan, Ramshaw, 2011</marker>
<rawString>Ralph Weischedel, Martha Palmer, Mitchell Marcus, Eduard Hovy, Sameer Pradhan, Lance Ramshaw, Nianwen Xue, Ann Taylor, Jeff Kaufman, Michelle Franchini, Mohammed El-Bachouti, Robert Belvin, and Ann Houston. 2011. OntoNotes release 4.0. LDC2011T03, Philadelphia, Penn.: Linguistic Data</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>