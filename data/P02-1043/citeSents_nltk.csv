The grammar contains a set of type-changing rules similar to the lexical rules described in CITATION,,
Furthermore, as noted by CITATION, it does not penalize equivalent analyses of multiple modiComputational Linguistics (ACL), Philadelphia, July 2002, pp,,
1 Introduction The currently best single-model statistical parser CITATION achieves Parseval scores of over 89% on the Penn Treebank,,
3 CCGbanka CCG treebank CCGbank is a corpus of CCG normal-form derivations obtained by translating the Penn Treebank trees using an algorithm described by CITATION,,
5.5 Limitations of the current model Unlike CITATION, our parser does not always model the dependencies in the logical form,,
o CITATION ,,
Instead, it is quite likely that we are facing an estimation problem similar to CITATION, who reports that the inclusion of the grandparent feature worsens performance of an MLE model, but improves performance if the individual distributions are modelled using Maximum Entropy,,
The inclusion of an additional grandparent feature gives CITATION a slight improvement in the Maximum Entropy inspired model, but a slight decrease in performance for an MLE model,,
ur parser (see CITATION) 4,,
5.2 Adding lexical information CITATION shows that removing the lexical dependencies in Model 1 of CITATION (that is, not conditioning on wh when generating ws) decreases labeled precision and recall by only 0.5%,,
5.6 Comparison with CITATION CITATION presents another statistical CCG parser, which is based on a conditional (rather than generative) model of the derived dependency structure, including non-surface dependencies,,
However, our model does not yet contain anything like the hard constraint on punctuation marks in CITATION,,
According to an evaluation of unlabeled word-word dependencies, our best model achieves a performance of 89.9%, comparable to the figures given by CITATION for a linguistically less expressive grammar,,
This model was originally described in CITATION, where it was applied to a preliminary version of CCGbank, and its definition is repeated here in the top row of Table 1,,
Like the models of CITATION, the additional features in our model are generated probabilistically, whereas in the parser of CITATION distance measures are assumed to be a function of the already generated structure and are not generated explicitly,,
Like CITATION, we assume that the test data is POStagged, and can therefore replace unknown words in the test data with their POS-tag, which is more appropriate for a formalism like CCG with a large set of lexical categories than one generic token for all unknown words,,
4Due to the smaller grammar and lexicon of Clark et al., our parser can only be evaluated on slightly over 94% of the sentences in section 23, whereas the figures for CITATION are on 97%,,
We therefore ran the \x0cdependency model on a test corpus tagged with the POS-tagger of CITATION, which is trained on the original Penn Treebank (see HWDep (+ tagger) in Table 3),,
In contrast to CITATION, we find a significant improvement from modeling wordword dependencies,,
We use Clark et al.s parser to generate these dependencies from the output of our parser (see CITATION) 4,,
In order to compare our performance with the parser of CITATION, we also evaluate our best model according to the dependency evaluation introduced for that parser,,
For further discussion we refer the reader to CITATION ,,
We present a number of models over syntactic derivations of Combinatory Categorial Grammar (CCG, see CITATION and CITATION, this conference, for introduction), estimated from and tested on a translation of the Penn Treebank to a corpus of CCG normal-form derivations,,
3,000 rules when instantiated with the above categories in sections 02-21, instead of &gt;12,400 in the original Treebank representation CITATION),,
The impact of the grandparent feature CITATION showed that a PCFG estimated from a version of the Penn Treebank in which the label of a nodes parent is attached to the nodes own label yields a substantial improvement (LP/LR: from 73.5%/69.7% to 80.0%/79.2%),,
The following table compares the two parsers according to the evaluation of surface and deep dependencies given in CITATION,,
\x0cDistance measures for CCG Our distance measures are related to those proposed by CITATION, which are appropriate for binary trees (unlike those of CITATION),,
2We compute in the same way as CITATION, p,,
Therefore, we also evaluate performance using a dependency evaluation reported by CITATION, which counts wordword dependencies as determined by local trees and their labels,,
The hP; H; Si labeled dependencies we report are not directly comparable with CITATION, since CCG categories encode subcategorization frames,,
5.6 Comparison with CITATION CITATION presents another statistical CCG parser, which is,,
