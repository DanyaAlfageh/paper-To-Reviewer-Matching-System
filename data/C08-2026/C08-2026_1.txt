b'Coling 2008: Companion volume  Posters and Demonstrations, pages 103106
Manchester, August 2008
Range concatenation grammars for translation
Anders Sgaard
University of Potsdam
soegaard@ling.uni-potsdam.de
Abstract
Positive and bottom-up non-erasing bi-
nary range concatenation grammars (Boul-
lier, 1998) with at most binary predicates
((2,2)-BRCGs) is a O(|G|n6) time strict
extension of inversion transduction gram-
mars (Wu, 1997) (ITGs). It is shown
that (2,2)-BRCGs induce inside-out align-
ments (Wu, 1997) and cross-serial discon-
tinuous translation units (CDTUs); both
phenomena can be shown to occur fre-
quently in many hand-aligned parallel cor-
pora. A CYK-style parsing algorithm is
introduced, and induction from aligment
structures is briefly discussed.
Range concatenation grammars (RCG) (Boul-
lier, 1998) mainly attracted attention in the for-
mal language community, since they recognize ex-
actly the polynomial time recognizable languages,
but recently they have been argued to be useful
for data-driven parsing too (Maier and Sgaard,
2008). Bertsch and Nederhof (2001) present the
only work to our knowledge on using RCGs for
translation. Both Bertsch and Nederhof (2001)
and Maier and Sgaard (2008), however, only
make use of so-called simple RCGs, known to be
equivalent to linear context-free rewrite systems
(LCFRSs) (Weir, 1988; Boullier, 1998). Our strict
extension of ITGs, on the other hand, makes use
of the ability to copy substrings in RCG deriva-
tions; one of the things that makes RCGs strictly
more expressive than LCFRSs. Copying enables
us to recognize the intersection of any two transla-
tions that we can recognize and induce the union
c

 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
of any two alignment structures that we can in-
duce. Our extension of ITGs in fact introduces
two things: (i) A clause may introduce any num-
ber of terminals. This enables us to induce mul-
tiword translation units. (ii) A clause may copy a
substring, i.e. a clause can associate two or more
nonterminals A1, . . . An with the same substring
and thereby check if the substring is in the inter-
section of the languages of the subgrammars with
start predicate names A1, . . . An.
The first point is motivated by studies such
as Zens and Ney (2003) and simply reflects
that in order to induce multiword translation
units in this kind of synchronous grammars, it
is useful to be able to introduce multiple ter-
minals simultaneously. The second point gives
us a handle on context-sensitivity. It means
that (2,2)-BRCGs can define translations such as
{hanbmcndm, anbmdmcni | m, n  0}, i.e. a
translation of cross-serial dependencies into nested
ones; but it also means that (2,2)-BRCGs induce
a larger class of alignment structures. In fact the
set of alignment structures that can be induced is
closed under union, i.e. any alignment structure
can be induced. The last point is of practical in-
terest. It is shown below that phenomena such as
inside-out alignments and CDTUs, which cannot
be induced by ITGs, but by (2,2)-BRCGs, occur
frequently in many hand-aligned parallel corpora.
1 (2,2)-BRCGs and ITGs
(2,2)-BRCGs are positive RCGs (Boullier, 1998)
with binary start predicate names, i.e. (S) = 2. In
RCG, predicates can be negated (for complemen-
tation), and the start predicate name is typically
unary. The definition is changed only for aesthetic
reasons; a positive RCG with a binary start predi-
cate name S is turned into a positive RCG with a
103
\x0cunary start predicate name S simply by adding a
clause S(X1X2)  S(X1, X2).
Definition 1.1 (Positive RCGs). A positive RCG
is a 5-tuple G = hN, T, V, P, Si. N is a finite
set of predicate names with an arity function :
N  Z, T and V are finite sets of, resp., ter-
minal and variables. P is a finite set of clauses
of the form 0  1 . . . m, where and each
of the i, 0  i  m, is a predicate of the
form A(1, . . . , (A)). Each j  (T  V ),
1  j  (A), is an argument. S  N is the
start predicate name with (S) = 2.
Note that the order of RHS predicates in a clause
is of no importance. Three subclasses of RCGs are
introduced for further reference: An RCG G =
hN, T, V, P, Si is simple iff for all c  P, it holds
that no variable X occurs more than once in the
LHS of c, and if X occurs in the LHS then it
occurs exactly once in the RHS, and each argu-
ment in the RHS of c contains exactly one vari-
able. An RCG G = hN, T, V, P, Si is a k-RCG
iff for all A  N, (A)  k. Finally, an RCG
G = hN, T, V, P, Si is said to be bottom-up non-
erasing iff for all c  P all variables that occur in
the RHS of c also occur in its LHS.
A positive RCG is a (2,2)-BRCG iff it is a 2-
RCG, if an argument of the LHS predicate contains
at most two variables, and if it is bottom-up non-
erasing.
The language of a (2,2)-BRCG is based
on the notion of range. For a string pair
hw1 . . . wn, vn+2 . . . vn+1+mi a range is a pair of
indices hi, ji with 0  i  j  n or n < i 
j  n + 1 + m, i.e. a string span, which de-
notes a substring wi+1 . . . wj in the source string
or a substring vi+1 . . . vj in the target string. Only
consequtive ranges can be concatenated into new
ranges. Terminals, variables and arguments in
a clause are bound to ranges by a substitution
mechanism. An instantiated clause is a clause in
which variables and arguments are consistently re-
placed by ranges; its components are instantiated
predicates. For example A(hg . . . hi, hi . . . ji) 
B(hg . . . hi, hi + 1 . . . j  1i) is an instantiation of
the clause A(X1, aY1b)  B(X1, Y1) if the tar-
get string is such that vi+1 = a and vj = b. A
derive relation = is defined on strings of instan-
tiated predicates. If an instantiated predicate is the
LHS of some instantiated clause, it can be replaced
by the RHS of that instantiated clause. The lan-
guage of a (2,2)-BRCG G = hN, T, V, P, Si is
the set L(G) = {hw1 . . . wn, vn+2 . . . vn+1+mi |
S(h0, ni, hn + 1, n + 1 + mi)

= o}, i.e. an
input string pair hw1 . . . wn, vn+2 . . . vn+1+mi is
recognized iff the empty string can be derived from
S(h0, ni, hn + 1, n + 1 + mi).
Theorem 1.2 ((Boullier, 2000)). The recognition
problem of bottom-up non-erasing k-RCG can be
solved in time O(|G|nd) where d = maxcjP (kj+
vj) where cj is the jth clause in P, kj is the arity of
its LHS predicate, and vj is the number of different
variables in that LHS predicate.
It follows immediately that the recognition
problem of (2,2)-BRCG can be solved in time
O(|G|n6), since kj can be at most 2, and vj can
be at most 4.
Example 1.3. Consider the (2,2)-BRCG G =
h{S0, S1, S2}, {a, b, c, d, e, f, g, h}, {X1, X2, Y1,
Y2}, P, S0i with P the following set of clauses:
S0(X1, Y1)  S1(X1, Y1)S2(X1, Y1)
S1(X1d, Y1Y2)  A0(X1, Y2)E(Y1)
A0(X1c, Y1h)  A1(X1, Y1)
A1(aX1, g)  B(X1)
S2(aX1, Y1Y2)  T0(X1, Y1)G(Y2)
T0(X1d, Y1f)  T1(X1, Y1)
T1(bX1, e)  C(X1)
B(b)  o C(c)  o
E(ef)  o G(gh)  o
which when words that are recognized simulta-
neously are aligned, induces the alignment:
a b c d
e f g h
by inducing the alignments in the, resp., S1 and
S2 derivations:
a b c d
e f g h
a b c d
e f g h
Example 1.4. Consider the (2,2)-BRCG G =
h{Ss, S0, S
0, S1, S
1, A, B, C, D}, {a, b, c, d}, {X1,
X2, Y1, Y2}, P, Ssi with P the following set of
clauses:
Ss(X1, Y1)  S0(X1, Y1)S
0(X1, Y1)
S0(X1X2, Y1)  S1(X1, Y1)D(X2)
S1(aX1c, abY1)  S1(X1, Y1)
S1(X1, Y1Y2)  B(X1)C(Y1)D(Y2)
S
0(X1X2, Y1)  S
1(X2, Y1)A(X1)
S
1(bX1d, Y1cd)  S
1(X1, Y1)
S
1(X1, Y1Y2)  C(X1)A(Y1)B(Y2)
A(aX1)  A(X1) A(o)  o
B(bX1)  B(X1) B(o)  o
C(cX1)  C(X1) C(o)  o
D(dX1)  D(X1) D(o)  o
Note that L(G) = {hanbmcndm, (ab)n(cd)mi |
m, n  0}.
104
\x0cSince the component grammars in ITGs are
context-free, Example 1.4 shows that there is at
least one translation not recognizable by ITGs that
is recognized by a (2,2)-BRCG; {anbmcndm |
m, n  0} is known to be non-context-free. ITGs
translate into simple (2,2)-BRCGs in the follow-
ing way; see Wu (1997) for a definition of ITGs.
The left column is ITG production rules; the right
column their translations in simple (2,2)-BRCGs.
A  [BC] A(X1X2, Y1Y2)  B(X1, Y1)C(X2, Y2)
A  hBCi A(X1X2, Y1Y2)  B(X1, Y2)C(X2, Y1)
A  e | f A(e, f)  o
A  e | o A(e, o)  o
A  o | f A(o, f)  o
It follows immediately that
Theorem 1.5. (2,2)-BRCGs are strictly more ex-
pressive than ITGs.
2 Alignment capacity
Zens and Ney (2003) identify a class of alignment
structures that cannot be induced by ITGs, but
that can be induced by a number of similar syn-
chronous grammar formalisms, e.g. synchronous
tree substitution grammar (STSG) (Eisner, 2003).
Inside-out alignments (Wu, 1997), such as the
one in Example 1.3, cannot be induced by any of
these theories; in fact, there seems to be no useful
synchronous grammar formalisms available that
handle inside-out alignments, with the possible
exceptions of synchronous tree-adjoining gram-
mars (Shieber and Schabes, 1990), Bertsch and
Nederhof (2001) and generalized multitext gram-
mars (Melamed et al., 2004), which are all way
more complex than ITG, STSG and (2,2)-BRCG.
Nevertheless, Wellington et al. (2006) report that
5% of the sentence pairs in an aligned paral-
lel ChineseEnglish corpus contained inside-out
alignments. Example 1.3 shows that (2,2)-BRCGs
induce inside-out alignments.
An even stronger motivation for using (2,2)-
BRCG for translation is the existence of cross-
serial DTUs (CDTUs). Informally, a CDTU is a
DTU such that there is a part of another DTU in its
gap. Heres a simple example:
a b c d
e f
Neither ITGs nor STSGs can induce CDTUs;
ITGs cannot induce DTUs with multiple gaps
(MDTUs) either. Our experiments are summarized
in Figure 1. Overall the results show that handling
CDTUs is important for alignment error rates.
3 Parsing and induction from alignments
A CYK-style algorithm is presented for (2,2)-
BRCG in Figure 2; it is assumed, w.l.o.g, that if
the same variable occurs twice in the LHS of a
clause, the clause is of the form A0(X1, Y1) 
A1(X1, Y1)A2(X1, Y1). It modifies the original
CYK algorithm (Younger, 1967) in four ways: (i)
It uses two charts; one for the source string (s) and
one for the target string (t). (ii) Pairs of nontermi-
nals and integers (A, ), rather than just nontermi-
nals, are stored in the cells of the chart (l. 2,4,6,7).
Integers represent derivation steps at which non-
terminals are inserted. (iii) Multiple terminals are
allowed (l. 2,6,7). (iv) If a clause is copying, the
same two cells in the chart are visited twice (l. 4).
Note that the variable  in insertion, e.g. in l. 4/1, is
the current derivation step, but i in look-up, e.g. in
l. 4/2, is the derivation step in which the associated
nonterminal was added to the chart.
The overall runtime of this algorithm is in
O(|G|n6), since it has, for branching clauses, six
embedded loops that iterate over the string, i.e. the
four for loops and the two s in Figure 2.
The induction problem from alignments can be
reduced to the induction problem for ITGs by sim-
ply unravelling the alignment structures. The sim-
plest algorithm for doing this assumes that align-
ments are sequences of translation units, and con-
siders each at a time. If a gap is found, the trans-
lation unit is a DTU and is moved to a new align-
ment structure. The complexity of the algorithm
is quadratic in the length of the input sentences,
i.e. linear in the size of the alignment structure,
and for a sentence pair hw1 . . . wn, v1 . . . vmi the
ITG induction algorithm has to consider at most
min(n+m)
2 aligment structures.
4 Conclusion
A new class of grammars for syntax-based ma-
chine translation was presented; while its recogni-
tion problem remains solvable in time O(|G|n6),
the grammars induce frequently occurring align-
ment configurations that cannot be induced by
comparable classes of grammars in the literature.
A parsing and an induction algorithm were pre-
sented.
105
\x0cSent. TUs DTUs CDTUs MDTUs CDTUs/Sent.
EnglishFrench: 100 937 95 36 11 36%
English-Portuguese: 100 939 100 52 3 52%
EnglishSpanish: 100 950 90 26 7 26%
PortugueseFrench: 100 915 77 19 3 19%
PortugueseSpanish: 100 991 80 40 3 40%
SpanishFrench: 100 975 74 24 8 24%
Figure 1: Statistics for six 100-sentence hand-aligned Europarl bitexts (Graca et al., 2008).
BUILD(s,[w1 . . . wn]), (t, [v1 . . . vm])
1 for j  1 to n, for j
 1 to m
2 do s(i  1, j), t(i
 1, j
)  {(A, ) | A(wi . . . wj , vi . . . vj )  o  P}
3 for k  (j  1) to 0, for k
 (j
 1) to 0
4 do s(k, j), t(k
, j
)  {(A, ) | A(X1, Y1)  B(X1, Y1)C(X1, Y1)  P,
(B, 1), (C, 2)  s(k, j), (B, 1), (C, 2)  t(k
, j
)}
5 for l  (j  2) to 0, for l
 (j
 2) to 0
6 do s(l, j), t(l
, j
)  {(A, ) | A(1X12X23, 1Y12Y23)  B(X1, Y1)C(X2, Y2)  P,
i.(B, 1)  s(l + |1|, i), (C, 2)  s(i + |2|, j  |3|), 1 = wl+1 . . . wl+|1|,
2 = wi+1 . . . wi+|2|, 3 = wj|3| . . . wj ,
i
.(B, 1)  t(l
+ |1|, i
), (C, 2)  t(i
+ |2|, j
 |3|), 1 = vl+1 . . . vl+|1|,
2 = vi+1 . . . vi+|2|, 3 = vj|3| . . . vj }
7 do s(l, j), t(l
, j
)  {(A, ) | A(1X12X23, 1Y12Y23)  B(X1, Y1)C(X2, Y2)  P,
i.(B, 1)  s(l + |1|, i), (C, 2)  s(i + |2|, j  |3|), 1 = wl+1 . . . wl+|1|,
2 = wi+1 . . . wi+|2|, 3 = wj|3| . . . wj ,
i
.(C, 2)  t(l
+ |1|, i
), (B, 1)  t(i
+ |2|, j
 |3|), 1 = vl+1 . . . vl+|1|,
2 = vi+1 . . . vi+|2|, 3 = vj|3| . . . vj }
8 if (S, 1)  s(0, n), (S, 1)  t(0, m) then return success else failure
Figure 2: CYK-style parsing algorithm for (2,2)-BRCG.
References
Bertsch, Eberhard and Mark-Jan Nederhof. 2001. On the
complexity of some extensions of RCG parsing. In Pro-
ceedings of the 7th International Workshop on Parsing
Technologies, pages 6677, Beijing, China.
Boullier, Pierre. 1998. Proposal for a natural language pro-
cessing syntactic backbone. Technical report, INRIA, Le
Chesnay, France.
Boullier, Pierre. 2000. A cubic time extension of context-free
grammars. Grammars, 3(23):111131.
Eisner, Jason. 2003. Learning non-isomorphic tree mappings
for machine translation. In Proceedings of the 41st Annual
Meeting of the Association for Computational Linguistics,
pages 205208, Sapporo, Japan.
Graca, Joao, Joana Pardal, Luisa Coheur, and Diamantino Ca-
seiro. 2008. Building a golden collection of parallel multi-
language word alignments. In Proceedings of the 6th In-
ternational Conference on Language Resources and Eval-
uation, Marrakech, Morocco.
Maier, Wolfgang and Anders Sgaard. 2008. Treebanks and
mild context-sensitivity. In Proceedings of the 13th Con-
ference on Formal Grammar, Hamburg, Germany.
Melamed, Dan, Giorgio Satta, and Benjamin Wellington.
2004. Generalized multitext grammars. In Proceedings
of the 42nd Annual Meeting of the Association for Compu-
tational Linguistics, pages 661668, Barcelona, Spain.
Shieber, Stuart and Yves Schabes. 1990. Synchronous tree-
adjoining grammars. In Proceedings of the 13th Con-
ference on Computational Linguistics, pages 253258,
Helsinki, Finland.
Weir, David. 1988. Characterizing mildly context-sensitive
grammar formalisms. Ph.D. thesis, University of Pennsyl-
vania, Philadelphia, Pennsylvania.
Wellington, Benjamin, Sonjia Waxmonsky, and Dan
Melamed. 2006. Empirical lower bounds on the complex-
ity of translational equivalence. In Proceedings of the 44th
Annual Conference of the Association for Computational
Linguistics, pages 977984, Sydney, Australia.
Wu, Dekai. 1997. Stochastic inversion transduction gram-
mars and bilingual parsing of parallel corpora. Computa-
tional Linguistics, 23(3):377403.
Younger, Daniel. 1967. Recognition and parsing of context-
free languages in time n3
. Information and Control,
10(2):189208.
Zens, Richard and Hermann Ney. 2003. A comparative study
on reordering constraints in statistical machine translation.
In Proceedings of the 41st Annual Meeting on Association
for Computational Linguistics, pages 144151, Sapporo,
Japan.
106
\x0c'