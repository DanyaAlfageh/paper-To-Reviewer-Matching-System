<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<bodyText confidence="0.49843">
b&quot;Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 806814,
</bodyText>
<figure confidence="0.680943272727273">
Beijing, August 2010
Recognition of Affect, Judgment, and Appreciation in Text
Alena Neviarouskaya
University of Tokyo
lena@mi.ci.i.u-
tokyo.ac.jp
Helmut Prendinger
Nat. Institute of Informatics
Tokyo
helmut@nii.ac.jp
Mitsuru Ishizuka
</figure>
<affiliation confidence="0.919721">
University of Tokyo
</affiliation>
<email confidence="0.6749315">
ishizuka@i.u-
tokyo.ac.jp
</email>
<sectionHeader confidence="0.970873" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999038615384615">
The main task we address in our research
is classification of text using fine-grained
attitude labels. The developed @AM sys-
tem relies on the compositionality prin-
ciple and a novel approach based on the
rules elaborated for semantically distinct
verb classes. The evaluation of our me-
thod on 1000 sentences, that describe
personal experiences, showed promising
results: average accuracy on the fine-
grained level (14 labels) was 62%, on the
middle level (7 labels) 71%, and on the
top level (3 labels) 88%.
</bodyText>
<sectionHeader confidence="0.985676" genericHeader="categories and subject descriptors">
1 Introduction and Related Work
</sectionHeader>
<bodyText confidence="0.996110709677419">
With rapidly growing online sources aimed at
encouraging and stimulating peoples discussions
concerning personal, public or social issues
(news, blogs, discussion forums, etc.), there is a
great need in development of a computational
tool for the analysis of peoples attitudes. Ac-
cording to the Appraisal Theory (Martin and
White, 2005), attitude types define the specifics
of appraisal being expressed: affect (personal
emotional state), judgment (social or ethical ap-
praisal of others behaviour), and appreciation
(evaluation of phenomena).
To analyse contextual sentiment of a phrase or
a sentence, rule-based approaches (Nasukawa
and Yi, 2003; Moilanen and Pulman, 2007; Sub-
rahmanian and Reforgiato, 2008), a machine-
learning method using not only lexical but also
syntactic features (Wilson et al., 2005), and a
model of integration of machine learning ap-
proach with compositional semantics (Choi and
Cardie, 2008) were proposed. With the aim to
recognize fine-grained emotions from text on the
level of distinct sentences, researchers have em-
ployed a keyword spotting technique (Chuang
and Wu, 2004; Strapparava et al., 2007), a tech-
nique calculating emotion scores using Pointwise
Mutual Information (PMI) (Kozareva et al.,
2007), an approach inspired by common-sense
knowledge (Liu et al., 2003), rule-based linguis-
tic approaches (Boucouvalas, 2003; Chaumartin,
2007), machine-learning methods (Alm, 2008;
Aman and Szpakowicz, 2008; Strapparava and
Mihalcea, 2008), and an ensemble based multi-
label classification technique (Bhowmick et al.,
2009).
Early attempts to focus on distinct attitude
types in the task of attitude analysis were made
by Taboada and Grieve (2004), who determined
a potential value of adjectives for affect, judge-
ment and appreciation by calculating the PMI
with the pronoun-copular pairs I was (affect),
He was (judgement), and It was (apprecia-
tion), and Whitelaw et al. (2005), who used a
machine learning technique (SVM) with fine-
grained semantic distinctions in features (attitude
type, orientation) in combination with bag of
words to classify movie reviews. However, the
concentration only on adjectives expressing ap-
praisal and their modifiers greatly narrows the
potential of the Whitelaw et al. (2005) approach.
In this paper we introduce our system @AM
(ATtitude Analysis Model), which (1) classifies
sentences according to the fine-grained attitude
labels (nine affect categories (Izard, 1971): an-
ger, disgust, fear, guilt, interest, joy,
sadness, shame, surprise; four polarity la-
bels for judgment and appreciation: POS jud,
NEG jud, POS app, NEG app; and neu-
tral); (2) assigns the strength of the attitude; and
(3) determines the level of confidence, with
which the attitude is expressed. @AM relies on a
compositionality principle and a novel approach
</bodyText>
<page confidence="0.995386">
806
</page>
<bodyText confidence="0.919137">
\x0cbased on the rules elaborated for semantically
distinct verb classes.
</bodyText>
<sectionHeader confidence="0.93285" genericHeader="method">
2 Lexicon for Attitide Analysis
</sectionHeader>
<bodyText confidence="0.62372575">
We built a lexicon for attitude analysis that in-
cludes: (1) attitude-conveying terms; (2) modifi-
ers; (3) functional words; and (4) modal opera-
tors.
</bodyText>
<subsectionHeader confidence="0.98005">
2.1 The Core of Lexicon
</subsectionHeader>
<bodyText confidence="0.999450105263158">
As a core of lexicon for attitude analysis, we em-
ploy an Affect database and extended version of
the SentiFul database developed by Neviar-
ouskaya et al. (2009). The affective features of
each emotion-related word are encoded using
nine emotion labels (anger, disgust, fear,
guilt, interest, joy, sadness, shame, and
surprise) and corresponding emotion intensities
that range from 0.0 to 1.0. The original version
of SentiFul database, which contains sentiment-
conveying adjectives, adverbs, nouns, and verbs
annotated by sentiment polarity, polarity scores
and weights, was manually extended using atti-
tude labels. Some examples of annotated atti-
tude-conveying words are listed in Table 1. It is
important to note here that some words may ex-
press different attitude types (affect, judgment,
appreciation) depending on context; such lexical
entries were annotated by all possible categories.
</bodyText>
<figure confidence="0.9929145">
POS Word Category Intensity
adjective honorable
unfriendly
POS jud
NEG aff (sadness)
NEG jud
NEG app
0.3
0.5
0.5
0.5
adverb gleefully POS aff (joy) 0.9
noun abnormality NEG app 0.25
verb frighten
desire
NEG aff (fear)
POS aff (interest)
POS aff (joy)
0.8
1.0
</figure>
<page confidence="0.619707">
0.5
</page>
<tableCaption confidence="0.903222">
Table 1. Examples of attitude-conveying words
</tableCaption>
<bodyText confidence="0.485631">
and their annotations.
</bodyText>
<subsectionHeader confidence="0.998156">
2.2 Modifiers and Functional Words
</subsectionHeader>
<bodyText confidence="0.893313272727273">
We collected 138 modifiers that have an impact
on contextual attitude features of related words,
phrases, or clauses. They include:
1. Adverbs of degree (e.g., significantly,
slightly etc.) and affirmation (e.g., absolutely,
seemingly) that have an influence on the
strength of the attitude of related words. Two
annotators gave coefficients for intensity degree
strengthening or weakening (from 0.0 to 2.0) to
each adverb, and the result was averaged (e.g.,
coeff(slightly) = 0.2).
</bodyText>
<listItem confidence="0.992640125">
2. Negation words (e.g., never, nothing
etc.) reversing the polarity of related statement.
3. Adverbs of doubt (e.g., scarcely,
hardly etc.) and falseness (e.g., wrongly etc.)
reversing the polarity of related statement.
4. Prepositions (e.g., without, despite etc.)
neutralizing the attitude of related words.
5. Condition operators (e.g., if, even
</listItem>
<bodyText confidence="0.775572416666667">
though etc.) that neutralize the attitude of related
words.
We distinguish two types of functional words
that influence contextual attitude and its strength:
1. Intensifying adjectives (e.g., rising, rap-
idly-growing), nouns (e.g., increase), and
verbs (e.g., to grow, to rocket) that increase
the strength of attitude of related words.
2. Reversing adjectives (e.g., reduced),
nouns (e.g., termination), and verbs (e.g., to
decrease, to limit, to diminish), which re-
verse the prior polarity of related words.
</bodyText>
<subsectionHeader confidence="0.998774">
2.3 Modal Operators
</subsectionHeader>
<bodyText confidence="0.998648636363636">
Consideration of the modal operators in the tasks
of opinion mining and attitude analysis is very
important, as they indicate a degree of persons
belief in the truth of the proposition, which is
subjective in nature (Hoye, 1997). Modals are
distinguished by their confidence level. We col-
lected modal operators of two categories: modal
verbs (13 verbs) and modal adverbs (61 adverbs).
Three human annotators assigned the confidence
level ranging from 0.0 to 1.0 to each modal verb
and adverb; these ratings were averaged (e.g.,
</bodyText>
<equation confidence="0.9869935">
conf(vaguely) = 0.17, conf(arguably) = 0.63,
conf(would) = 0.8, conf(veritably) = 1.0).
</equation>
<sectionHeader confidence="0.988954" genericHeader="method">
3 Compositionality Principle
</sectionHeader>
<bodyText confidence="0.996991454545455">
Our algorithm for attitude classification is de-
signed based on the compositionality principle,
according to which we determine the attitudinal
meaning of a sentence by composing the pieces
that correspond to lexical units or other linguistic
constituent types governed by the rules of polari-
ty reversal, aggregation (fusion), propagation,
domination, neutralization, and intensification, at
various grammatical levels.
Polarity reversal means that a phrase or
statement containing an attitude-conveying
</bodyText>
<page confidence="0.993894">
807
</page>
<bodyText confidence="0.9954674">
\x0cterm/phrase with prior positive polarity becomes
negative, and vice versa. The rule of polarity re-
versal is applied in three cases: (1) negation
word-modifier in relation with an attitude-
conveying statement (e.g., never &amp;
</bodyText>
<equation confidence="0.941174">
POS(succeed) =&gt; NEG(never succeed)); (2)
</equation>
<bodyText confidence="0.8401085">
adverb of doubt in relation with attitude-
conveying statement (e.g., scarcely &amp;
</bodyText>
<equation confidence="0.874389">
POS(relax) =&gt; NEG(scarcely relax)); (3)
</equation>
<bodyText confidence="0.964482772727273">
functional word of reversing type in relation with
attitude-conveying statement (e.g., adjective re-
duced &amp; POS(enthusiasm) =&gt; NEG(reduced
enthusiasm)). In the case of judgment and ap-
preciation, the use of the polarity reversal rule is
straightforward (POS jud &lt;=&gt; NEG jud,
POS app &lt;=&gt; NEG app). However, it is not
trivial to find pairs of opposite emotions in the
case of a fine-grained classification, except for
joy and sadness. Therefore, we assume that
(1) the opposite emotion for three positive emo-
tions, i.e. interest, joy, and surprise, is sad-
ness (POS aff =&gt; sadness); and (2) the oppo-
site emotion for six negative emotions, i.e. an-
ger, disgust, fear, guilt, sadness, and
shame, is joy (NEG aff =&gt; joy).
The rules of aggregation (fusion) are as fol-
lows: (1) if polarities of attitude-conveying terms
in adjective-noun, noun-noun, adverb-adjective,
adverb-verb phrases have opposite directions,
mixed polarity with dominant polarity of a pre-
modifier is assigned to the phrase (e.g.,
</bodyText>
<equation confidence="0.999150666666667">
POS(beautiful) &amp; NEG(fight) =&gt; POS-
neg(beautiful fight); NEG(shamelessly) &amp;
POS(celebrate) =&gt; NEG-pos(shamelessly
</equation>
<bodyText confidence="0.995623866666667">
celebrate)); otherwise (2) the resulting polarity
is based on the equal polarities of terms, and the
strength of attitude is measured as a maximum
between polarity scores (intensities) of terms
(max(score1,score2)).
The rule of propagation is useful, as proposed
in (Nasukawa and Yi, 2003), for the task of the
detection of local sentiments for given subjects.
Propagation verbs propagate the sentiment to-
wards the arguments; transfer verbs transmit
sentiments among the arguments. The rule of
propagation is applied when a verb of propaga-
tion or transfer type is used in a phrase/clause
and sentiment of an argument that has prior neu-
tral polarity needs to be investigated (e.g.,
</bodyText>
<equation confidence="0.946793666666667">
PROP-POS(to admire) &amp; his behaviour =&gt;
POS(his behaviour); Mr. X &amp;
TRANS(supports) &amp; NEG(crime business)
</equation>
<bodyText confidence="0.966837">
=&gt; NEG(Mr. X)).
The rules of domination are as follows: (1) if
polarities of a verb (this rule is applied only for
certain classes of verbs) and an object in a clause
have opposite directions, the polarity of verb is
prevailing (e.g., NEG(to deceive) &amp;
</bodyText>
<equation confidence="0.639375">
POS(hopes) =&gt; NEG(to deceive hopes)); (2)
</equation>
<bodyText confidence="0.982963142857143">
if compound sentence joints clauses using coor-
dinate connector but, the attitude features of a
clause following after the connector are domi-
nant (e.g., NEG(It was hard to climb a mountain
all night long), but POS(a magnificent view re-
warded the traveler at the morning). =&gt;
POS(whole sentence)).
The rule of neutralization is applied when
preposition-modifier or condition operator relate
to the attitude-conveying statement (e.g., de-
spite &amp; NEG(worries) =&gt; NEUT(despite
worries)).
The rule of intensification means strengthen-
ing or weakening of the polarity score (intensity),
</bodyText>
<listItem confidence="0.5944235">
and is applied when:
1. adverb of degree or affirmation relates to
attitude-conveying term (e.g.,
Pos_score(happy) &lt; Pos_score(extremely hap-
py));
2. adjective or adverb is used in a compara-
</listItem>
<bodyText confidence="0.965986782608696">
tive or superlative form (e.g., Neg_score(sad) &lt;
Neg_score(sadder) &lt; Neg_score (saddest)).
Our method is capable of processing sentences of
different complexity, including simple, com-
pound, complex (with complement and relative
clauses), and complex-compound sentences. We
employ Connexor Machinese Syntax parser
(http://www.connexor.eu/) that returns
lemmas, parts of speech, dependency functions,
syntactic function tags, and morphological tags.
When handling the parser output, we represent
the sentence as a set of primitive clauses. Each
clause might include Subject formation, Verb
formation and Object formation, each of which
may consist of a main element (subject, verb, or
object) and its attributives and complements. For
the processing of complex or compound sen-
tences, we build a so-called relation matrix,
which contains information about dependences
(e.g., coordination, subordination, condition,
contingency, etc.) between different clauses in a
sentence. While applying the compositionality
principle, we consecutively assign attitude fea-
</bodyText>
<page confidence="0.987827">
808
</page>
<bodyText confidence="0.932985368421053">
\x0ctures to words, phrases, formations, clauses, and
finally, to the whole sentence.
4 Consideration of the Semantics of
Verbs
All sentences must include a verb, because the
verb tells us what action the subject is perform-
ing and object is receiving. In order to elaborate
rules for attitude analysis based on the semantics
of verbs, we investigated VerbNet (Kipper et al.,
2007), the largest on-line verb lexicon that is or-
ganized into verb classes characterized by syn-
tactic and semantic coherence among members
of a class. Based on the thorough analysis of 270
first-level classes of VerbNet and their members,
73 verb classes (1) were found useful for the task
of attitude analysis, and (2) were further classi-
fied into 22 classes differentiated by the role that
members play in attitude analysis and by rules
applied to them. Our classification is shown in
</bodyText>
<tableCaption confidence="0.573827">
Table 2.
</tableCaption>
<bodyText confidence="0.977030833333333">
For each of our verb classes, we developed set
of rules that are applied to attitude analysis on
the phrase/clause-level. Some verb classes (e.g.,
Psychological state or emotional reaction,
Judgment, Bodily state and damage to the
body, Preservation etc.) include verbs anno-
tated by attitude type, prior polarity orientation,
and the strength of attitude. The attitude features
of phrases that involve positively or negatively
charged verbs from such classes are context-
sensitive and are defined by means of rules de-
signed for each of the class.
As an example, we provide short description
and rules elaborated for the subclass Object-
centered (oriented) emotional state.
Features: subject experiences emotions towards
some stimulus; verb prior polarity: positive or
negative; context-sensitive.
</bodyText>
<figure confidence="0.758350185185185">
Verb-Object rules (subject is ignored):
1. Interior perspective (subjects inner emotion
state or attitude):
S &amp; V+(admires) &amp; O+(his brave heart)
=&gt; (fusion, max(V_score,O_score)) =&gt; POS
aff.
S &amp; V+(admires) &amp; O-(mafia leader) =&gt;
(verb valence dominance, V_score) =&gt; POS
aff.
S &amp; V-(disdains) &amp; O+(his honesty) =&gt;
(verb valence dominance, V_score) =&gt; NEG
aff.
Verb class (verb samples)
1 Psychological state or emotional reaction
1.1 Object-centered (oriented) emotional state (adore)
1.2 Subject-driven change in emotional state (trans.)
(charm, inspire, bother)
1.3 Subject-driven change in emotional state (intrans.)
(appeal to, grate on)
2 Judgment
2.1 Positive judgment (bless, honor)
2.2 Negative judgment (blame, punish)
3 Favorable attitude (accept, allow, tolerate)
4 Adverse (unfavorable) attitude (discourage, forbid)
5 Favorable or adverse calibratable changes of state
(grow, decline)
6 Verbs of removing
</figure>
<subsectionHeader confidence="0.844753333333333">
6.1 Verbs of removing with neutral charge (delete)
6.2 Verbs of removing with negative charge (expel)
6.3 Verbs of removing with positive charge (evacuate)
</subsectionHeader>
<table confidence="0.811058409090909">
7 Negatively charged change of state (break, crush)
8 Bodily state and damage to the body (sicken, injure)
9 Aspectual verbs
9.1 Initiation, continuation of activity, and sustaining
(begin, continue, maintain)
9.2 Termination of activity (quit, finish)
10 Preservation (defend, insure)
11 Verbs of destruction and killing (damage, poison)
12 Disappearance (disappear, die)
13 Limitation and subjugation (confine, restrict)
14 Assistance (succor, help)
15 Obtaining (win, earn)
16 Communication indicator/reinforcement of attitude
(guess, complain, deny)
17 Verbs of leaving (abandon, desert)
18 Changes in social status or condition (canonize)
19 Success and failure
19.1 Success (succeed, manage)
19.2 Failure (fail, flub)
20 Emotional nonverbal expression (smile, weep)
21 Social interaction (marry, divorce)
22 Transmitting verbs (supply, provide)
</table>
<tableCaption confidence="0.893278">
Table 2. Verb classes for attitude analysis.
</tableCaption>
<table confidence="0.495373235294118">
S &amp; V-(disdains) &amp; O-(criminal activities)
=&gt; (fusion, max(V_score,O_score)) =&gt; NEG
aff.
2. Exterior perspective (social/ethical judg-
ment):
S &amp; V+(admires) &amp; O+(his brave heart)
=&gt; (fusion, max(V_score,O_score)) =&gt; POS
jud.
S &amp; V+(admires) &amp; O-(mafia leader) =&gt;
(verb valence reversal, max(V_score,O_score))
=&gt; NEG jud.
S &amp; V-(disdains) &amp; O+(his honesty) =&gt;
(verb valence dominance,
max(V_score,O_score)) =&gt; NEG jud.
S &amp; V-(disdains) &amp; O-(criminal activities)
=&gt; (verb valence reversal,
max(V_score,O_score)) =&gt; POS jud.
</table>
<page confidence="0.960605">
809
</page>
<footnote confidence="0.6028826">
\x0c3. In case of neutral object =&gt; attitude type and
prior polarity of verb, verb score (V_score).
Verb-PP (prepositional phrase) rules:
1. In case of negatively charged verb and PP
starting with from =&gt; verb dominance:
</footnote>
<equation confidence="0.699561666666667">
S &amp; V-(suffers) &amp; PP-(from illness) =&gt; in-
terior: NEG aff; exterior: NEG jud.
S &amp; V-(suffers) &amp; PP+ (from love) =&gt; inte-
</equation>
<bodyText confidence="0.8927565">
rior: NEG aff; exterior: NEG jud.
2. In case of positively charged verb and PP
starting with in/for =&gt; treat PP the same way
as object (see above):
</bodyText>
<equation confidence="0.768020333333333">
S &amp; V+(believes) &amp; PP-(in evil) =&gt; inte-
rior: POS aff; exterior: NEG jud.
S &amp; V+(believes) &amp; PP+(in kindness) =&gt;
</equation>
<bodyText confidence="0.98305355">
interior: POS aff; exterior: POS jud.
In the majority of rules the strength of attitude is
measured as a maximum between attitude scores
(for example, the attitude conveyed by to suffer
from grave illness is stronger than that of to
suffer from slight illness).
In contrast to the rules of Object-centered
(oriented) emotional state subclass, which ig-
nore attitude features of a subject in a sentence,
the rules elaborated for the Subject-driven
change in emotional state (trans.) disregard the
attitude features of object, as in sentences involv-
ing members of this subclass object experiences
emotion, and subject causes the emotional state.
For example (due to limitation of space, here and
below we provide only some cases):
S(Classical music) &amp; V+(calmed) &amp; O-
(disobedient child) =&gt; interior: POS aff; exte-
rior: POS app.
S-(Fatal consequences of GM food intake) &amp;
</bodyText>
<equation confidence="0.86026">
V-(frighten) &amp; O(me) =&gt; interior: NEG aff;
</equation>
<bodyText confidence="0.9964737">
exterior: NEG app.
The Verb-Object rules for the Judgment sub-
classes, namely Positive judgment and Nega-
tive judgment, are very close to those defined
for the subclass Object-centered (oriented)
emotional state. However, Verb-PP rules have
some specifics: for both positive and negative
judgment verbs, we treat PP starting with
for/of/as the same way as object in Verb-
Object rules. For example:
</bodyText>
<equation confidence="0.99879">
S(He) &amp; V-(blamed) &amp; O+(innocent per-
son) =&gt; interior: NEG jud; exterior: NEG
jud.
S(They) &amp; V-(punished) &amp; O(him) &amp; PP-
</equation>
<bodyText confidence="0.96688025">
(for his misdeed) =&gt; interior: NEG jud; exte-
rior: POS jud.
Verbs from classes Favorable attitude and
Adverse (unfavorable) attitude have prior neu-
tral polarity and positive or negative reinforce-
ment, correspondingly, that means that they only
impact on the polarity and strength of non-
neutral phrase (object in a sentence written in
</bodyText>
<listItem confidence="0.800559666666667">
active voice, or subject in a sentence written in
passive voice, or PP in case of some verbs). The
rules are:
1. If verb belongs to the Favorable attitude
class and the polarity of phrase is not neutral,
then the attitude score of the phrase is intensified
</listItem>
<equation confidence="0.910110833333333">
(symbol ^ means intensification):
S(They) &amp; [V pos. reinforcement](elected)
&amp; O+(fair judge) =&gt; POS app; O_score^.
S(They) &amp; [V pos. reinforcement](elected)
&amp; O-(corrupt candidate) =&gt; NEG app;
O_score^.
</equation>
<listItem confidence="0.776968">
2. If verb belongs to the Adverse (unfavorable)
attitude class and the polarity of phrase is not
</listItem>
<bodyText confidence="0.618246">
neutral, then the polarity of phrase is reversed
and score is intensified:
</bodyText>
<equation confidence="0.985205">
S(They) &amp; [V neg. reinforce-
ment](prevented) &amp; O-(the spread of disease)
=&gt; POS app; O_score^.
S+(His achievements) &amp; [V neg. reinforce-
ment](were overstated) =&gt; NEG app;
</equation>
<bodyText confidence="0.881604">
S_score^.
Below are examples of processing the sentences
with verbs from Verbs of removing class.
Verbs of removing with neutral charge:
</bodyText>
<equation confidence="0.697486642857143">
S(The tape-recorder) &amp; [V neutral
rem.](automatically ejects) &amp; O-neutral(the
tape) =&gt; neutral.
S(The safety invention) &amp; [V neutral
rem.](ejected) &amp; O(the pilot) &amp; PP-(from
burning plane) =&gt; POS app; PP_score^.
Verbs of removing with negative charge:
S(Manager) &amp; [V neg. rem.](fired) &amp; O-
(careless employee) &amp; PP(from the company)
=&gt; POS app; max(V_score,O_score).
Verbs of removing with positive charge:
S(They) &amp; [V pos. rem.](evacuated) &amp;
O(children) &amp; PP-(from dangerous place) =&gt;
POS app; max(V_score,PP_score).
</equation>
<bodyText confidence="0.554584">
Along with modal verbs and modal adverbs,
members of the Communication indica-
tor/reinforcement of attitude verb class also in-
</bodyText>
<page confidence="0.970102">
810
</page>
<bodyText confidence="0.988306875">
\x0cdicate the confidence level or degree of certainty
concerning given opinion. Features are: subject
(communicator) expresses statement
with/without attitude; statement is PP starting
with of, on, against, about, concerning,
regarding, that, how etc.; ground: positive
or negative; reinforcement: positive or negative.
The rules are:
</bodyText>
<listItem confidence="0.919682">
1. If the polarity of expressed statement is neu-
tral, then the attitude is neutral:
S(Professor) &amp; [V pos. ground, pos. rein-
forcement, confidence:0.83](dwelled) &amp; PP-
neutral(on a question) =&gt; neutral.
2. If the polarity of expressed statement is not
neutral and the reinforcement is positive, then the
score of the statement (PP) is intensified:
S(Jane) &amp; [V neg. ground, pos. reinforce-
ment, confidence:0.8](is complaining) &amp; PP-
(of a headache again) =&gt; NEG app;
PP_score^; confidence:0.8.
3. If the polarity of expressed statement is not
neutral and reinforcement is negative, then the
polarity of the statement (PP) is reversed and
score is intensified:
</listItem>
<equation confidence="0.418401">
S(Max) &amp; [V neg. ground, neg. reinforce-
ment, confidence:0.2](doubt) &amp; PP-{that
S+(his good fortune) &amp; [V termination](will
</equation>
<bodyText confidence="0.949083818181818">
ever end)} =&gt; POS app; PP_score^; confi-
dence:0.2.
In the last example, to measure the sentiment of
PP, we apply rule for the verb end from the
Termination of activity class, which reverses
the non-neutral polarity of subject (in intransitive
use of verb) or object (in transitive use of verb).
For example, the polarity of both sentences My
whole enthusiasm and excitement disappear like
a bubble touching a hot needle and They dis-
continued helping children is negative.
</bodyText>
<sectionHeader confidence="0.827022" genericHeader="method">
5 Decision on Attitude Label
</sectionHeader>
<bodyText confidence="0.824618615384615">
The decision on the most appropriate final label
for the clause, in case @AM annotates it using
different attitude types according to the words
with multiple annotations (e.g., see word un-
friendly in Table 1) or based on the availability
of the words conveying different attitude types,
is made based on the analysis of:
1) morphological tags of nominal heads and
their premodifiers in the clause (e.g., first person
pronoun, third person pronoun, demonstrative
pronoun, nominative or genitive noun, etc.);
2) the sequence of hypernymic semantic re-
lations of a particular noun in WordNet (Miller,
1990), which allows to determine its conceptual
domain (e.g., person, human being, artifact,
event, etc.);
3) the annotations from the Stanford
Named Entity Recognizer (Finkel et al. 2005)
that labels PERSON, ORGANIZATION, and
LOCATION entities.
For ex., I feel highly unfriendly attitude towards
me conveys emotion (NEG aff: sadness),
while The shop assistants behavior was really
unfriendly and Plastic bags are environment
unfriendly express judgment (NEG jud) and
appreciation (NEG app), correspondingly.
</bodyText>
<sectionHeader confidence="0.992904" genericHeader="evaluation">
6 Evaluation
</sectionHeader>
<bodyText confidence="0.999887">
For the experiments, we used our own data set,
as, to the best of our knowledge, there is no pub-
licly available data set of sentences annotated by
the fine-grained labels proposed in our work. In
order to evaluate the performance of our algo-
rithm, we created the data set of sentences ex-
tracted from personal stories about life expe-
riences that were anonymously published on the
</bodyText>
<subsectionHeader confidence="0.816619">
Experience Project website
</subsectionHeader>
<bodyText confidence="0.995849125">
(www.experienceproject.com), where
people share personal experiences, thoughts,
opinions, feelings, passions, and confessions
through the network of personal stories. With
over 4 million experiences accumulated (as of
February 2010), Experience Project is a perfect
source for researchers interested in studying dif-
ferent types of attitude expressed through text.
</bodyText>
<subsectionHeader confidence="0.998456">
6.1 Data Set Description
</subsectionHeader>
<bodyText confidence="0.9956555">
For our experiment we extracted 1000 sentences1
from various stories grouped by topics within 13
different categories, such as Arts and entertain-
ment, Current events, Education, Family
and friends, Health and wellness, Relation-
ships and romance and others, on the Expe-
rience Project website. Sentences were collected
from 358 distinct topic groups, such as I still
remember September 11, I am intelligent but
airheaded, I think bullfighting is cruel, I quit
smoking, I am a fashion victim, I was
adopted and others.
</bodyText>
<page confidence="0.759993">
1
</page>
<bodyText confidence="0.823922">
This annotated data set is freely available upon request.
</bodyText>
<page confidence="0.978196">
811
</page>
<bodyText confidence="0.986689380952381">
\x0cWe considered three hierarchical levels of atti-
tude labels in our experiment (see Figure 1).
Three independent annotators labeled the sen-
tences with one of 14 categories from the ALL
level and a corresponding score (the strength or
intensity value). These annotations were further
interpreted using labels from the MID and the
TOP levels. Fleiss Kappa coefficient was used
as a measure of reliability of human raters anno-
tations. The agreement coefficient on 1000 sen-
tences was 0.53 on ALL level, 0.57 on MID level,
and 0.73 on TOP level.
Only those sentences, on which at least two
out of three human raters completely agreed,
were included in the gold standards for our expe-
riment. Three gold standards were created ac-
cording to the hierarchy of attitude labels. Fleiss
Kappa coefficients are 0.62, 0.63, and 0.74 on
ALL, MID, and TOP levels, correspondingly.
Table 3 shows the distributions of labels in the
gold standards.
</bodyText>
<table confidence="0.991398176470588">
ALL level MID level
Label Number Label Number
anger 45 POS aff 233
disgust 21 NEG aff 332
fear 54 POS jud 66
guilt 22 NEG jud 78
interest 84 POS app 100
joy 95 NEG app 29
sadness 133 neutral 87
shame 18 total 925
surprise 36
POS jud 66 TOP level
NEG jud 78 Label Number
POS app 100 POS 437
NEG app 29 NEG 473
neutral 87 neutral 87
total 868 total 997
</table>
<tableCaption confidence="0.998341">
Table 3. Label distributions in gold standards.
</tableCaption>
<subsectionHeader confidence="0.7147">
6.2 Results
</subsectionHeader>
<bodyText confidence="0.997299571428572">
The results of a simple method selecting the atti-
tude label with the maximum intensity from the
annotations of sentence tokens found in the data-
base were considered as the baseline. After
processing each sentence from the data set by the
baseline method and our @AM system, we
measured averaged accuracy, precision, recall,
and F-score for each label in ALL, MID, and
TOP levels. The results are shown in Table 4.
As seen from the obtained results, our algo-
rithm performed with high accuracy significantly
surpassing the baselines in all levels of attitude
hierarchy, thus demonstrating the contribution of
the sentence parsing and our hand-crafted rules
to the reliable recognition of attitude from text.
Two-tailed t-tests with significance level of 0.05
showed that the differences in accuracy between
the baseline method and our @AM system are
statistically significant (p&lt;0.001) in fine-grained
as well as coarse-grained classifications.
In the case of fine-grained attitude recognition
(ALL level), the highest precision was obtained
for shame (0.923) and NEG jud (0.889),
while the highest recall was received for sad-
ness (0.917) and joy (0.905) emotions at the
cost of low precision (0.528 and 0.439, corre-
spondingly). The algorithm performed with the
worst results in recognition of NEG app and
neutral.
The analysis of a confusion matrix for the
ALL level revealed the following top confusions
of our system: (1) anger, fear, guilt, shame,
NEG jud, NEG app and neutral were pre-
dominantly incorrectly predicted as sadness
(for ex., @AM resulted in sadness for the sen-
tence I know we have several months left before
the election, but I am already sick and tired of
seeing the ads on TV, while human annotations
were anger/anger/disgust); (2) interest,
POS jud and POS app were mostly confused
with joy by our algorithm (e.g., @AM classi-
fied the sentence Its one of those life changing
artifacts that we must have in order to have hap-
pier, healthier lives as joy(-ful), while human
annotations were POS app/POS
app/interest).
Our system achieved high precision for all
categories on the MID level (Table 4), with the
exception of NEG app and neutral, although
</bodyText>
<figure confidence="0.990684043478261">
TOP POS NEG neutral
MID POS aff
POS
jud
POS
app
NEG aff
NEG
jud
NEG
app
neutral
ALL interest joy surprise
POS
jud
POS
app
anger disgust fear guilt sadness shame
NEG
jud
NEG
app
neutral
</figure>
<figureCaption confidence="0.999234">
Figure 1. Hierarchy of attitude labels.
</figureCaption>
<page confidence="0.994693">
812
</page>
<bodyText confidence="0.999351142857143">
\x0chigh recall was obtained only in the case of cate-
gories related to affect (POS aff, NEG aff).
These results indicate that affect sensing is easier
than recognition of judgment or appreciation
from text. TOP level results (Table 4) show that
our algorithm classifies sentences that convey
positive or negative sentiment with high accura-
cy (92% and 91%, correspondingly). On the oth-
er hand, neutral sentences still pose a challenge.
The analysis of errors revealed that system re-
quires common sense or additional context to
deal with sentences like All through my life Ive
felt like Im second fiddle (gold standard: sad-
ness; @AM: neutral) or For me every minute
on my horse is alike an hour in heaven! (gold
standard: joy; @AM: neutral).
We also evaluated the system performance
with regard to attitude intensity estimation. The
percentage of attitude-conveying sentences (not
considering neutral ones), on which the result of
our system conformed to the fine-grained gold
standard (ALL level), according to the measured
distance between intensities given by human ra-
ters (averaged values) and those obtained by our
system is shown in Table 5. As seen from the
table, our system achieved satisfactory results in
estimation of the strength of attitude expressed
through text.
</bodyText>
<figure confidence="0.633411888888889">
Range of intensity
difference
Percent of sen-
tences, %
[0.0 0.2] 55.5
(0.2 0.4] 29.5
(0.4 0.6] 12.2
(0.6 0.8] 2.6
(0.8 1.0] 0.2
</figure>
<tableCaption confidence="0.977578">
Table 5. Results on intensity.
</tableCaption>
<sectionHeader confidence="0.996858" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.995225615384616">
In this paper we introduced @AM, which is so
far, to the best of our knowledge, the only system
classifying sentences using fine-grained attitude
types, and extensively dealing with the semantics
of verbs in attitude analysis. Our composition
approach broadens the coverage of sentences
with complex contextual attitude. The evaluation
results indicate that @AM achieved reliable re-
sults in the task of textual attitude analysis. The
limitations include dependency on lexicon and
on accuracy of the parser. The primary objective
for the future research is to develop a method for
the extraction of reasons behind the expressed
</bodyText>
<figure confidence="0.729204666666667">
attitude.
Level Label
Baseline method @AM
Accuracy Precision Recall F-score Accuracy Precision Recall F-score
ALL
anger
0.437
0.742 0.511 0.605
0.621
</figure>
<table confidence="0.920963676470588">
0.818 0.600 0.692
disgust 0.600 0.857 0.706 0.818 0.857 0.837
fear 0.727 0.741 0.734 0.768 0.796 0.782
guilt 0.667 0.364 0.471 0.833 0.455 0.588
interest 0.380 0.357 0.368 0.772 0.524 0.624
joy 0.266 0.579 0.364 0.439 0.905 0.591
sadness 0.454 0.632 0.528 0.528 0.917 0.670
shame 0.818 0.500 0.621 0.923 0.667 0.774
surprise 0.625 0.694 0.658 0.750 0.833 0.789
POS jud 0.429 0.227 0.297 0.824 0.424 0.560
NEG jud 0.524 0.141 0.222 0.889 0.410 0.561
POS app 0.349 0.150 0.210 0.755 0.400 0.523
NEG app 0.250 0.138 0.178 0.529 0.310 0.391
neutral 0.408 0.483 0.442 0.559 0.437 0.490
MID
POS aff
0.524
0.464 0.695 0.557
0.709
0.668 0.888 0.762
NEG aff 0.692 0.711 0.701 0.765 0.910 0.831
POS jud 0.405 0.227 0.291 0.800 0.424 0.554
NEG jud 0.458 0.141 0.216 0.842 0.410 0.552
POS app 0.333 0.150 0.207 0.741 0.400 0.519
NEG app 0.222 0.138 0.170 0.474 0.310 0.375
neutral 0.378 0.483 0.424 0.514 0.437 0.472
TOP
POS
0.732
0.745 0.796 0.770
0.879
0.918 0.920 0.919
NEG 0.831 0.719 0.771 0.912 0.922 0.917
neutral 0.347 0.483 0.404 0.469 0.437 0.452
</table>
<tableCaption confidence="0.996599">
Table 4. Results of the evaluation of performance of the baseline method and @AM system.
</tableCaption>
<page confidence="0.996248">
813
</page>
<reference confidence="0.998813158415842">
\x0cReferences
Alm, Cecilia O. 2008. Affect in Text and Speech. PhD
Dissertation. University of Illinois at Urbana-
Champaign.
Aman, Saima, and Stan Szpakowicz. 2008. Using
Roget&apos;s Thesaurus for Fine-Grained Emotion Rec-
ognition. Proceedings of the Third International
Joint Conference on Natural Language Processing,
Hyderabad, India, pp. 296-302.
Bhowmick, Plaban K., Anupam Basu, and Pabitra
Mitra. 2009. Reader Perspective Emotion Analysis
in Text through Ensemble based Multi-Label Clas-
sification Framework. Computer and Information
Science, 2 (4): 64-74.
Boucouvalas, Anthony C. 2003. Real Time Text-to-
Emotion Engine for Expressive Internet Communi-
cations. Being There: Concepts, Effects and Mea-
surement of User Presence in Synthetic Environ-
ments, Ios Press, pp. 306-318.
Chaumartin, Francois-Regis. 2007. UPAR7: A Know-
ledge-based System for Headline Sentiment Tag-
ging. Proceedings of the SemEval-2007 Interna-
tional Workshop, pp. 422-425.
Choi, Yejin, and Claire Cardie. 2008. Learning with
Compositional Semantics as Structural Inference
for Subsentential Sentiment Analysis. Proceedings
of the Conference on Empirical Methods in Natural
Language Processing, pp. 793-801.
Chuang, Ze-Jing, and Chung-Hsien Wu. 2004. Multi-
modal Emotion Recognition from Speech and Text.
Computational Linguistic and Chinese Language
Processing, 9(2): 45-62.
Finkel, Jenny R., Trond Grenager, and Christopher
Manning. 2005. Incorporating Non-local Informa-
tion into Information Extraction Systems by Gibbs
Sampling. Proceedings of the 43nd Annual Meet-
ing of the ACL, pp. 363-370.
Hoye, Leo. 1997. Adverbs and Modality in English.
New York: Addison Wesley Longman Inc.
Izard, Carroll E. 1971. The Face of Emotion. New
York: Appleton-Century-Crofts.
Kipper, Karin, Anna Korhonen, Neville Ryant, and
Martha Palmer. 2007. A Large-scale Classification
of English Verbs. Language Resources and Evalu-
ation, 42 (1): 21-40.
Kozareva, Zornitsa, Borja Navarro, Sonia Vazquez,
and Andres Montoyo, A. 2007. UA-ZBSA: A
Headline Emotion Classification through Web In-
formation. Proceedings of the SemEval-2007 In-
ternational Workshop, pp. 334-337.
Liu, Hugo, Henry Lieberman, and Ted Selker. 2003.
A Model of Textual Affect Sensing Using Real-
World Knowledge. Proceedings of IUI-2003, pp.
125-132.
Martin, James R., and Peter R.R. White. 2005. The
Language of Evaluation: Appraisal in English.
Palgrave, London, UK.
Miller, George A. 1990. WordNet: An On-line Lexi-
cal Database. International Journal of Lexicogra-
phy, Special Issue, 3 (4): 235-312.
Moilanen, Karo, and Stephen Pulman. 2007. Senti-
ment Composition. Proceedings of the Recent Ad-
vances in Natural Language Processing Interna-
tional Conference, pp. 378-382.
Nasukawa, Tetsuya, and Jeonghee Yi. 2003. Senti-
ment Analysis: Capturing Favorability using Natu-
ral Language Processing. Proceedings of the 2nd
International Conference on Knowledge Capture,
pp. 70-77.
Neviarouskaya, Alena, Helmut Prendinger, and Mit-
suru Ishizuka. 2009. SentiFul: Generating a Relia-
ble Lexicon for Sentiment Analysis. Proceedings
of the International Conference on Affective Com-
puting and Intelligent Interaction, IEEE, Amster-
dam, Netherlands, pp. 363-368.
Strapparava, Carlo, and Rada Mihalcea. 2008. Learn-
ing to Identify Emotions in Text. Proceedings of
the 2008 ACM Symposium on Applied Computing,
Fortaleza, Brazil, pp. 1556-1560.
Strapparava, Carlo, Alessandro Valitutti, and Oliviero
Stock. 2007. Dances with Words. Proceedings of
the International Joint Conference on Artificial In-
telligence, pp. 1719-1724.
Subrahmanian, V.S., and Diego Reforgiato. 2008.
AVA: Adjective-Verb-Adverb Combinations for
Sentiment Analysis. Intelligent Systems, IEEE, 23
(4): 43-50.
Taboada, Maite, and Jack Grieve. 2004. Analyzing
Appraisal Automatically. Proceedings of AAAI
Spring Symposium on Exploring Attitude and Af-
fect in Text, pp.158-161.
Whitelaw, Casey, Navendu Garg, and Shlomo Arga-
mon. 2005. Using Appraisal Groups for Sentiment
Analysis. Proceedings of the 14th ACM Interna-
tional Conference on Information and Knowledge
Management, CIKM, Bremen, Germany, pp. 625-
631.
Wilson, Theresa, Janyce Wiebe, and Paul Hoffmann.
2005. Recognizing Contextual Polarity in Phrase-
level Sentiment Analysis. Proceedings of HLT-
EMNLP-2005, ACL, pp. 347-354.
</reference>
<page confidence="0.993816">
814
</page>
<figure confidence="0.243594">
\x0c&quot;
</figure>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.123538">
<note confidence="0.851258">b&quot;Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 806814, Beijing, August 2010</note>
<title confidence="0.944891">Recognition of Affect, Judgment, and Appreciation in Text</title>
<author confidence="0.997242">Alena Neviarouskaya</author>
<affiliation confidence="0.999594">University of Tokyo</affiliation>
<email confidence="0.886724">lena@mi.ci.i.utokyo.ac.jp</email>
<affiliation confidence="0.67456">Helmut Prendinger Nat. Institute of Informatics</affiliation>
<address confidence="0.763747">Tokyo</address>
<email confidence="0.96449">helmut@nii.ac.jp</email>
<author confidence="0.810346">Mitsuru Ishizuka</author>
<affiliation confidence="0.999456">University of Tokyo</affiliation>
<email confidence="0.875327">ishizuka@i.utokyo.ac.jp</email>
<abstract confidence="0.995650642857143">The main task we address in our research is classification of text using fine-grained attitude labels. The developed @AM system relies on the compositionality principle and a novel approach based on the rules elaborated for semantically distinct verb classes. The evaluation of our method on 1000 sentences, that describe personal experiences, showed promising results: average accuracy on the finegrained level (14 labels) was 62%, on the middle level (7 labels) 71%, and on the top level (3 labels) 88%.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>\x0cReferences Alm</author>
<author>O Cecilia</author>
</authors>
<title>Affect in Text and Speech.</title>
<date>2008</date>
<tech>PhD</tech>
<institution>Dissertation. University of Illinois at UrbanaChampaign.</institution>
<marker>Alm, Cecilia, 2008</marker>
<rawString>\x0cReferences Alm, Cecilia O. 2008. Affect in Text and Speech. PhD Dissertation. University of Illinois at UrbanaChampaign.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saima Aman</author>
<author>Stan Szpakowicz</author>
</authors>
<title>Using Roget&apos;s Thesaurus for Fine-Grained Emotion Recognition.</title>
<date>2008</date>
<booktitle>Proceedings of the Third International Joint Conference on Natural Language Processing,</booktitle>
<pages>296--302</pages>
<location>Hyderabad, India,</location>
<contexts>
<context position="2371" citStr="Aman and Szpakowicz, 2008" startWordPosition="340" endWordPosition="343"> a model of integration of machine learning approach with compositional semantics (Choi and Cardie, 2008) were proposed. With the aim to recognize fine-grained emotions from text on the level of distinct sentences, researchers have employed a keyword spotting technique (Chuang and Wu, 2004; Strapparava et al., 2007), a technique calculating emotion scores using Pointwise Mutual Information (PMI) (Kozareva et al., 2007), an approach inspired by common-sense knowledge (Liu et al., 2003), rule-based linguistic approaches (Boucouvalas, 2003; Chaumartin, 2007), machine-learning methods (Alm, 2008; Aman and Szpakowicz, 2008; Strapparava and Mihalcea, 2008), and an ensemble based multilabel classification technique (Bhowmick et al., 2009). Early attempts to focus on distinct attitude types in the task of attitude analysis were made by Taboada and Grieve (2004), who determined a potential value of adjectives for affect, judgement and appreciation by calculating the PMI with the pronoun-copular pairs I was (affect), He was (judgement), and It was (appreciation), and Whitelaw et al. (2005), who used a machine learning technique (SVM) with finegrained semantic distinctions in features (attitude type, orientation) in </context>
</contexts>
<marker>Aman, Szpakowicz, 2008</marker>
<rawString>Aman, Saima, and Stan Szpakowicz. 2008. Using Roget&apos;s Thesaurus for Fine-Grained Emotion Recognition. Proceedings of the Third International Joint Conference on Natural Language Processing, Hyderabad, India, pp. 296-302.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Plaban K Bhowmick</author>
<author>Anupam Basu</author>
<author>Pabitra Mitra</author>
</authors>
<title>Reader Perspective Emotion Analysis in Text through Ensemble based Multi-Label Classification Framework.</title>
<date>2009</date>
<journal>Computer and Information Science,</journal>
<volume>2</volume>
<issue>4</issue>
<pages>64--74</pages>
<contexts>
<context position="2487" citStr="Bhowmick et al., 2009" startWordPosition="356" endWordPosition="359">. With the aim to recognize fine-grained emotions from text on the level of distinct sentences, researchers have employed a keyword spotting technique (Chuang and Wu, 2004; Strapparava et al., 2007), a technique calculating emotion scores using Pointwise Mutual Information (PMI) (Kozareva et al., 2007), an approach inspired by common-sense knowledge (Liu et al., 2003), rule-based linguistic approaches (Boucouvalas, 2003; Chaumartin, 2007), machine-learning methods (Alm, 2008; Aman and Szpakowicz, 2008; Strapparava and Mihalcea, 2008), and an ensemble based multilabel classification technique (Bhowmick et al., 2009). Early attempts to focus on distinct attitude types in the task of attitude analysis were made by Taboada and Grieve (2004), who determined a potential value of adjectives for affect, judgement and appreciation by calculating the PMI with the pronoun-copular pairs I was (affect), He was (judgement), and It was (appreciation), and Whitelaw et al. (2005), who used a machine learning technique (SVM) with finegrained semantic distinctions in features (attitude type, orientation) in combination with bag of words to classify movie reviews. However, the concentration only on adjectives expressing ap</context>
</contexts>
<marker>Bhowmick, Basu, Mitra, 2009</marker>
<rawString>Bhowmick, Plaban K., Anupam Basu, and Pabitra Mitra. 2009. Reader Perspective Emotion Analysis in Text through Ensemble based Multi-Label Classification Framework. Computer and Information Science, 2 (4): 64-74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anthony C Boucouvalas</author>
</authors>
<title>Real Time Text-toEmotion Engine for Expressive Internet Communications. Being There: Concepts, Effects and Measurement of User Presence in Synthetic Environments,</title>
<date>2003</date>
<pages>306--318</pages>
<publisher>Ios Press,</publisher>
<contexts>
<context position="2288" citStr="Boucouvalas, 2003" startWordPosition="332" endWordPosition="333">ing not only lexical but also syntactic features (Wilson et al., 2005), and a model of integration of machine learning approach with compositional semantics (Choi and Cardie, 2008) were proposed. With the aim to recognize fine-grained emotions from text on the level of distinct sentences, researchers have employed a keyword spotting technique (Chuang and Wu, 2004; Strapparava et al., 2007), a technique calculating emotion scores using Pointwise Mutual Information (PMI) (Kozareva et al., 2007), an approach inspired by common-sense knowledge (Liu et al., 2003), rule-based linguistic approaches (Boucouvalas, 2003; Chaumartin, 2007), machine-learning methods (Alm, 2008; Aman and Szpakowicz, 2008; Strapparava and Mihalcea, 2008), and an ensemble based multilabel classification technique (Bhowmick et al., 2009). Early attempts to focus on distinct attitude types in the task of attitude analysis were made by Taboada and Grieve (2004), who determined a potential value of adjectives for affect, judgement and appreciation by calculating the PMI with the pronoun-copular pairs I was (affect), He was (judgement), and It was (appreciation), and Whitelaw et al. (2005), who used a machine learning technique (SVM) </context>
</contexts>
<marker>Boucouvalas, 2003</marker>
<rawString>Boucouvalas, Anthony C. 2003. Real Time Text-toEmotion Engine for Expressive Internet Communications. Being There: Concepts, Effects and Measurement of User Presence in Synthetic Environments, Ios Press, pp. 306-318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Francois-Regis Chaumartin</author>
</authors>
<title>UPAR7: A Knowledge-based System for Headline Sentiment Tagging.</title>
<date>2007</date>
<booktitle>Proceedings of the SemEval-2007 International Workshop,</booktitle>
<pages>422--425</pages>
<contexts>
<context position="2307" citStr="Chaumartin, 2007" startWordPosition="334" endWordPosition="335">l but also syntactic features (Wilson et al., 2005), and a model of integration of machine learning approach with compositional semantics (Choi and Cardie, 2008) were proposed. With the aim to recognize fine-grained emotions from text on the level of distinct sentences, researchers have employed a keyword spotting technique (Chuang and Wu, 2004; Strapparava et al., 2007), a technique calculating emotion scores using Pointwise Mutual Information (PMI) (Kozareva et al., 2007), an approach inspired by common-sense knowledge (Liu et al., 2003), rule-based linguistic approaches (Boucouvalas, 2003; Chaumartin, 2007), machine-learning methods (Alm, 2008; Aman and Szpakowicz, 2008; Strapparava and Mihalcea, 2008), and an ensemble based multilabel classification technique (Bhowmick et al., 2009). Early attempts to focus on distinct attitude types in the task of attitude analysis were made by Taboada and Grieve (2004), who determined a potential value of adjectives for affect, judgement and appreciation by calculating the PMI with the pronoun-copular pairs I was (affect), He was (judgement), and It was (appreciation), and Whitelaw et al. (2005), who used a machine learning technique (SVM) with finegrained se</context>
</contexts>
<marker>Chaumartin, 2007</marker>
<rawString>Chaumartin, Francois-Regis. 2007. UPAR7: A Knowledge-based System for Headline Sentiment Tagging. Proceedings of the SemEval-2007 International Workshop, pp. 422-425.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yejin Choi</author>
<author>Claire Cardie</author>
</authors>
<title>Learning with Compositional Semantics as Structural Inference for Subsentential Sentiment Analysis.</title>
<date>2008</date>
<booktitle>Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>793--801</pages>
<contexts>
<context position="1851" citStr="Choi and Cardie, 2008" startWordPosition="266" endWordPosition="269">ppraisal Theory (Martin and White, 2005), attitude types define the specifics of appraisal being expressed: affect (personal emotional state), judgment (social or ethical appraisal of others behaviour), and appreciation (evaluation of phenomena). To analyse contextual sentiment of a phrase or a sentence, rule-based approaches (Nasukawa and Yi, 2003; Moilanen and Pulman, 2007; Subrahmanian and Reforgiato, 2008), a machinelearning method using not only lexical but also syntactic features (Wilson et al., 2005), and a model of integration of machine learning approach with compositional semantics (Choi and Cardie, 2008) were proposed. With the aim to recognize fine-grained emotions from text on the level of distinct sentences, researchers have employed a keyword spotting technique (Chuang and Wu, 2004; Strapparava et al., 2007), a technique calculating emotion scores using Pointwise Mutual Information (PMI) (Kozareva et al., 2007), an approach inspired by common-sense knowledge (Liu et al., 2003), rule-based linguistic approaches (Boucouvalas, 2003; Chaumartin, 2007), machine-learning methods (Alm, 2008; Aman and Szpakowicz, 2008; Strapparava and Mihalcea, 2008), and an ensemble based multilabel classificati</context>
</contexts>
<marker>Choi, Cardie, 2008</marker>
<rawString>Choi, Yejin, and Claire Cardie. 2008. Learning with Compositional Semantics as Structural Inference for Subsentential Sentiment Analysis. Proceedings of the Conference on Empirical Methods in Natural Language Processing, pp. 793-801.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ze-Jing Chuang</author>
<author>Chung-Hsien Wu</author>
</authors>
<date>2004</date>
<booktitle>Multimodal Emotion Recognition from Speech and Text. Computational Linguistic and Chinese Language Processing,</booktitle>
<volume>9</volume>
<issue>2</issue>
<pages>45--62</pages>
<contexts>
<context position="2036" citStr="Chuang and Wu, 2004" startWordPosition="295" endWordPosition="298">rs behaviour), and appreciation (evaluation of phenomena). To analyse contextual sentiment of a phrase or a sentence, rule-based approaches (Nasukawa and Yi, 2003; Moilanen and Pulman, 2007; Subrahmanian and Reforgiato, 2008), a machinelearning method using not only lexical but also syntactic features (Wilson et al., 2005), and a model of integration of machine learning approach with compositional semantics (Choi and Cardie, 2008) were proposed. With the aim to recognize fine-grained emotions from text on the level of distinct sentences, researchers have employed a keyword spotting technique (Chuang and Wu, 2004; Strapparava et al., 2007), a technique calculating emotion scores using Pointwise Mutual Information (PMI) (Kozareva et al., 2007), an approach inspired by common-sense knowledge (Liu et al., 2003), rule-based linguistic approaches (Boucouvalas, 2003; Chaumartin, 2007), machine-learning methods (Alm, 2008; Aman and Szpakowicz, 2008; Strapparava and Mihalcea, 2008), and an ensemble based multilabel classification technique (Bhowmick et al., 2009). Early attempts to focus on distinct attitude types in the task of attitude analysis were made by Taboada and Grieve (2004), who determined a potent</context>
</contexts>
<marker>Chuang, Wu, 2004</marker>
<rawString>Chuang, Ze-Jing, and Chung-Hsien Wu. 2004. Multimodal Emotion Recognition from Speech and Text. Computational Linguistic and Chinese Language Processing, 9(2): 45-62.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny R Finkel</author>
<author>Trond Grenager</author>
<author>Christopher Manning</author>
</authors>
<title>Incorporating Non-local Information into Information Extraction Systems by Gibbs Sampling.</title>
<date>2005</date>
<booktitle>Proceedings of the 43nd Annual Meeting of the ACL,</booktitle>
<pages>363--370</pages>
<contexts>
<context position="22680" citStr="Finkel et al. 2005" startWordPosition="3432" endWordPosition="3435">ons (e.g., see word unfriendly in Table 1) or based on the availability of the words conveying different attitude types, is made based on the analysis of: 1) morphological tags of nominal heads and their premodifiers in the clause (e.g., first person pronoun, third person pronoun, demonstrative pronoun, nominative or genitive noun, etc.); 2) the sequence of hypernymic semantic relations of a particular noun in WordNet (Miller, 1990), which allows to determine its conceptual domain (e.g., person, human being, artifact, event, etc.); 3) the annotations from the Stanford Named Entity Recognizer (Finkel et al. 2005) that labels PERSON, ORGANIZATION, and LOCATION entities. For ex., I feel highly unfriendly attitude towards me conveys emotion (NEG aff: sadness), while The shop assistants behavior was really unfriendly and Plastic bags are environment unfriendly express judgment (NEG jud) and appreciation (NEG app), correspondingly. 6 Evaluation For the experiments, we used our own data set, as, to the best of our knowledge, there is no publicly available data set of sentences annotated by the fine-grained labels proposed in our work. In order to evaluate the performance of our algorithm, we created the dat</context>
</contexts>
<marker>Finkel, Grenager, Manning, 2005</marker>
<rawString>Finkel, Jenny R., Trond Grenager, and Christopher Manning. 2005. Incorporating Non-local Information into Information Extraction Systems by Gibbs Sampling. Proceedings of the 43nd Annual Meeting of the ACL, pp. 363-370.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leo Hoye</author>
</authors>
<title>Adverbs and Modality in English.</title>
<date>1997</date>
<publisher>Addison Wesley Longman Inc.</publisher>
<location>New York:</location>
<contexts>
<context position="6859" citStr="Hoye, 1997" startWordPosition="1027" endWordPosition="1028">s strength: 1. Intensifying adjectives (e.g., rising, rapidly-growing), nouns (e.g., increase), and verbs (e.g., to grow, to rocket) that increase the strength of attitude of related words. 2. Reversing adjectives (e.g., reduced), nouns (e.g., termination), and verbs (e.g., to decrease, to limit, to diminish), which reverse the prior polarity of related words. 2.3 Modal Operators Consideration of the modal operators in the tasks of opinion mining and attitude analysis is very important, as they indicate a degree of persons belief in the truth of the proposition, which is subjective in nature (Hoye, 1997). Modals are distinguished by their confidence level. We collected modal operators of two categories: modal verbs (13 verbs) and modal adverbs (61 adverbs). Three human annotators assigned the confidence level ranging from 0.0 to 1.0 to each modal verb and adverb; these ratings were averaged (e.g., conf(vaguely) = 0.17, conf(arguably) = 0.63, conf(would) = 0.8, conf(veritably) = 1.0). 3 Compositionality Principle Our algorithm for attitude classification is designed based on the compositionality principle, according to which we determine the attitudinal meaning of a sentence by composing the p</context>
</contexts>
<marker>Hoye, 1997</marker>
<rawString>Hoye, Leo. 1997. Adverbs and Modality in English. New York: Addison Wesley Longman Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carroll E Izard</author>
</authors>
<title>The Face of Emotion.</title>
<date>1971</date>
<location>New York: Appleton-Century-Crofts.</location>
<contexts>
<context position="3368" citStr="Izard, 1971" startWordPosition="492" endWordPosition="493">as (affect), He was (judgement), and It was (appreciation), and Whitelaw et al. (2005), who used a machine learning technique (SVM) with finegrained semantic distinctions in features (attitude type, orientation) in combination with bag of words to classify movie reviews. However, the concentration only on adjectives expressing appraisal and their modifiers greatly narrows the potential of the Whitelaw et al. (2005) approach. In this paper we introduce our system @AM (ATtitude Analysis Model), which (1) classifies sentences according to the fine-grained attitude labels (nine affect categories (Izard, 1971): anger, disgust, fear, guilt, interest, joy, sadness, shame, surprise; four polarity labels for judgment and appreciation: POS jud, NEG jud, POS app, NEG app; and neutral); (2) assigns the strength of the attitude; and (3) determines the level of confidence, with which the attitude is expressed. @AM relies on a compositionality principle and a novel approach 806 \x0cbased on the rules elaborated for semantically distinct verb classes. 2 Lexicon for Attitide Analysis We built a lexicon for attitude analysis that includes: (1) attitude-conveying terms; (2) modifiers; (3) functional words; and (</context>
</contexts>
<marker>Izard, 1971</marker>
<rawString>Izard, Carroll E. 1971. The Face of Emotion. New York: Appleton-Century-Crofts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karin Kipper</author>
<author>Anna Korhonen</author>
<author>Neville Ryant</author>
<author>Martha Palmer</author>
</authors>
<title>A Large-scale Classification of English Verbs.</title>
<date>2007</date>
<journal>Language Resources and Evaluation,</journal>
<volume>42</volume>
<issue>1</issue>
<pages>21--40</pages>
<contexts>
<context position="12560" citStr="Kipper et al., 2007" startWordPosition="1875" endWordPosition="1878"> which contains information about dependences (e.g., coordination, subordination, condition, contingency, etc.) between different clauses in a sentence. While applying the compositionality principle, we consecutively assign attitude fea808 \x0ctures to words, phrases, formations, clauses, and finally, to the whole sentence. 4 Consideration of the Semantics of Verbs All sentences must include a verb, because the verb tells us what action the subject is performing and object is receiving. In order to elaborate rules for attitude analysis based on the semantics of verbs, we investigated VerbNet (Kipper et al., 2007), the largest on-line verb lexicon that is organized into verb classes characterized by syntactic and semantic coherence among members of a class. Based on the thorough analysis of 270 first-level classes of VerbNet and their members, 73 verb classes (1) were found useful for the task of attitude analysis, and (2) were further classified into 22 classes differentiated by the role that members play in attitude analysis and by rules applied to them. Our classification is shown in Table 2. For each of our verb classes, we developed set of rules that are applied to attitude analysis on the phrase/</context>
</contexts>
<marker>Kipper, Korhonen, Ryant, Palmer, 2007</marker>
<rawString>Kipper, Karin, Anna Korhonen, Neville Ryant, and Martha Palmer. 2007. A Large-scale Classification of English Verbs. Language Resources and Evaluation, 42 (1): 21-40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zornitsa Kozareva</author>
<author>Borja Navarro</author>
<author>Sonia Vazquez</author>
<author>Andres Montoyo</author>
<author>A</author>
</authors>
<title>UA-ZBSA: A Headline Emotion Classification through Web Information.</title>
<date>2007</date>
<booktitle>Proceedings of the SemEval-2007 International Workshop,</booktitle>
<pages>334--337</pages>
<contexts>
<context position="2168" citStr="Kozareva et al., 2007" startWordPosition="314" endWordPosition="317">approaches (Nasukawa and Yi, 2003; Moilanen and Pulman, 2007; Subrahmanian and Reforgiato, 2008), a machinelearning method using not only lexical but also syntactic features (Wilson et al., 2005), and a model of integration of machine learning approach with compositional semantics (Choi and Cardie, 2008) were proposed. With the aim to recognize fine-grained emotions from text on the level of distinct sentences, researchers have employed a keyword spotting technique (Chuang and Wu, 2004; Strapparava et al., 2007), a technique calculating emotion scores using Pointwise Mutual Information (PMI) (Kozareva et al., 2007), an approach inspired by common-sense knowledge (Liu et al., 2003), rule-based linguistic approaches (Boucouvalas, 2003; Chaumartin, 2007), machine-learning methods (Alm, 2008; Aman and Szpakowicz, 2008; Strapparava and Mihalcea, 2008), and an ensemble based multilabel classification technique (Bhowmick et al., 2009). Early attempts to focus on distinct attitude types in the task of attitude analysis were made by Taboada and Grieve (2004), who determined a potential value of adjectives for affect, judgement and appreciation by calculating the PMI with the pronoun-copular pairs I was (affect),</context>
</contexts>
<marker>Kozareva, Navarro, Vazquez, Montoyo, A, 2007</marker>
<rawString>Kozareva, Zornitsa, Borja Navarro, Sonia Vazquez, and Andres Montoyo, A. 2007. UA-ZBSA: A Headline Emotion Classification through Web Information. Proceedings of the SemEval-2007 International Workshop, pp. 334-337.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hugo Liu</author>
<author>Henry Lieberman</author>
<author>Ted Selker</author>
</authors>
<date>2003</date>
<contexts>
<context position="2235" citStr="Liu et al., 2003" startWordPosition="324" endWordPosition="327">an and Reforgiato, 2008), a machinelearning method using not only lexical but also syntactic features (Wilson et al., 2005), and a model of integration of machine learning approach with compositional semantics (Choi and Cardie, 2008) were proposed. With the aim to recognize fine-grained emotions from text on the level of distinct sentences, researchers have employed a keyword spotting technique (Chuang and Wu, 2004; Strapparava et al., 2007), a technique calculating emotion scores using Pointwise Mutual Information (PMI) (Kozareva et al., 2007), an approach inspired by common-sense knowledge (Liu et al., 2003), rule-based linguistic approaches (Boucouvalas, 2003; Chaumartin, 2007), machine-learning methods (Alm, 2008; Aman and Szpakowicz, 2008; Strapparava and Mihalcea, 2008), and an ensemble based multilabel classification technique (Bhowmick et al., 2009). Early attempts to focus on distinct attitude types in the task of attitude analysis were made by Taboada and Grieve (2004), who determined a potential value of adjectives for affect, judgement and appreciation by calculating the PMI with the pronoun-copular pairs I was (affect), He was (judgement), and It was (appreciation), and Whitelaw et al.</context>
</contexts>
<marker>Liu, Lieberman, Selker, 2003</marker>
<rawString>Liu, Hugo, Henry Lieberman, and Ted Selker. 2003.</rawString>
</citation>
<citation valid="false">
<title>A Model of Textual Affect Sensing Using RealWorld Knowledge.</title>
<booktitle>Proceedings of IUI-2003,</booktitle>
<pages>125--132</pages>
<marker></marker>
<rawString>A Model of Textual Affect Sensing Using RealWorld Knowledge. Proceedings of IUI-2003, pp. 125-132.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James R Martin</author>
<author>Peter R R White</author>
</authors>
<title>The Language of Evaluation: Appraisal in English. Palgrave,</title>
<date>2005</date>
<location>London, UK.</location>
<contexts>
<context position="1269" citStr="Martin and White, 2005" startWordPosition="181" endWordPosition="184">classes. The evaluation of our method on 1000 sentences, that describe personal experiences, showed promising results: average accuracy on the finegrained level (14 labels) was 62%, on the middle level (7 labels) 71%, and on the top level (3 labels) 88%. 1 Introduction and Related Work With rapidly growing online sources aimed at encouraging and stimulating peoples discussions concerning personal, public or social issues (news, blogs, discussion forums, etc.), there is a great need in development of a computational tool for the analysis of peoples attitudes. According to the Appraisal Theory (Martin and White, 2005), attitude types define the specifics of appraisal being expressed: affect (personal emotional state), judgment (social or ethical appraisal of others behaviour), and appreciation (evaluation of phenomena). To analyse contextual sentiment of a phrase or a sentence, rule-based approaches (Nasukawa and Yi, 2003; Moilanen and Pulman, 2007; Subrahmanian and Reforgiato, 2008), a machinelearning method using not only lexical but also syntactic features (Wilson et al., 2005), and a model of integration of machine learning approach with compositional semantics (Choi and Cardie, 2008) were proposed. Wi</context>
</contexts>
<marker>Martin, White, 2005</marker>
<rawString>Martin, James R., and Peter R.R. White. 2005. The Language of Evaluation: Appraisal in English. Palgrave, London, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
</authors>
<title>WordNet: An On-line Lexical Database.</title>
<date>1990</date>
<journal>International Journal of Lexicography, Special Issue,</journal>
<volume>3</volume>
<issue>4</issue>
<pages>235--312</pages>
<contexts>
<context position="22497" citStr="Miller, 1990" startWordPosition="3407" endWordPosition="3408">tude Label The decision on the most appropriate final label for the clause, in case @AM annotates it using different attitude types according to the words with multiple annotations (e.g., see word unfriendly in Table 1) or based on the availability of the words conveying different attitude types, is made based on the analysis of: 1) morphological tags of nominal heads and their premodifiers in the clause (e.g., first person pronoun, third person pronoun, demonstrative pronoun, nominative or genitive noun, etc.); 2) the sequence of hypernymic semantic relations of a particular noun in WordNet (Miller, 1990), which allows to determine its conceptual domain (e.g., person, human being, artifact, event, etc.); 3) the annotations from the Stanford Named Entity Recognizer (Finkel et al. 2005) that labels PERSON, ORGANIZATION, and LOCATION entities. For ex., I feel highly unfriendly attitude towards me conveys emotion (NEG aff: sadness), while The shop assistants behavior was really unfriendly and Plastic bags are environment unfriendly express judgment (NEG jud) and appreciation (NEG app), correspondingly. 6 Evaluation For the experiments, we used our own data set, as, to the best of our knowledge, th</context>
</contexts>
<marker>Miller, 1990</marker>
<rawString>Miller, George A. 1990. WordNet: An On-line Lexical Database. International Journal of Lexicography, Special Issue, 3 (4): 235-312.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karo Moilanen</author>
<author>Stephen Pulman</author>
</authors>
<title>Sentiment Composition.</title>
<date>2007</date>
<booktitle>Proceedings of the Recent Advances in Natural Language Processing International Conference,</booktitle>
<pages>378--382</pages>
<contexts>
<context position="1606" citStr="Moilanen and Pulman, 2007" startWordPosition="228" endWordPosition="231">ouraging and stimulating peoples discussions concerning personal, public or social issues (news, blogs, discussion forums, etc.), there is a great need in development of a computational tool for the analysis of peoples attitudes. According to the Appraisal Theory (Martin and White, 2005), attitude types define the specifics of appraisal being expressed: affect (personal emotional state), judgment (social or ethical appraisal of others behaviour), and appreciation (evaluation of phenomena). To analyse contextual sentiment of a phrase or a sentence, rule-based approaches (Nasukawa and Yi, 2003; Moilanen and Pulman, 2007; Subrahmanian and Reforgiato, 2008), a machinelearning method using not only lexical but also syntactic features (Wilson et al., 2005), and a model of integration of machine learning approach with compositional semantics (Choi and Cardie, 2008) were proposed. With the aim to recognize fine-grained emotions from text on the level of distinct sentences, researchers have employed a keyword spotting technique (Chuang and Wu, 2004; Strapparava et al., 2007), a technique calculating emotion scores using Pointwise Mutual Information (PMI) (Kozareva et al., 2007), an approach inspired by common-sense</context>
</contexts>
<marker>Moilanen, Pulman, 2007</marker>
<rawString>Moilanen, Karo, and Stephen Pulman. 2007. Sentiment Composition. Proceedings of the Recent Advances in Natural Language Processing International Conference, pp. 378-382.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tetsuya Nasukawa</author>
<author>Jeonghee Yi</author>
</authors>
<title>Sentiment Analysis: Capturing Favorability using Natural Language Processing.</title>
<date>2003</date>
<booktitle>Proceedings of the 2nd International Conference on Knowledge Capture,</booktitle>
<pages>70--77</pages>
<contexts>
<context position="1579" citStr="Nasukawa and Yi, 2003" startWordPosition="224" endWordPosition="227">ne sources aimed at encouraging and stimulating peoples discussions concerning personal, public or social issues (news, blogs, discussion forums, etc.), there is a great need in development of a computational tool for the analysis of peoples attitudes. According to the Appraisal Theory (Martin and White, 2005), attitude types define the specifics of appraisal being expressed: affect (personal emotional state), judgment (social or ethical appraisal of others behaviour), and appreciation (evaluation of phenomena). To analyse contextual sentiment of a phrase or a sentence, rule-based approaches (Nasukawa and Yi, 2003; Moilanen and Pulman, 2007; Subrahmanian and Reforgiato, 2008), a machinelearning method using not only lexical but also syntactic features (Wilson et al., 2005), and a model of integration of machine learning approach with compositional semantics (Choi and Cardie, 2008) were proposed. With the aim to recognize fine-grained emotions from text on the level of distinct sentences, researchers have employed a keyword spotting technique (Chuang and Wu, 2004; Strapparava et al., 2007), a technique calculating emotion scores using Pointwise Mutual Information (PMI) (Kozareva et al., 2007), an approa</context>
<context position="9562" citStr="Nasukawa and Yi, 2003" startWordPosition="1426" endWordPosition="1429">olarities of attitude-conveying terms in adjective-noun, noun-noun, adverb-adjective, adverb-verb phrases have opposite directions, mixed polarity with dominant polarity of a premodifier is assigned to the phrase (e.g., POS(beautiful) &amp; NEG(fight) =&gt; POSneg(beautiful fight); NEG(shamelessly) &amp; POS(celebrate) =&gt; NEG-pos(shamelessly celebrate)); otherwise (2) the resulting polarity is based on the equal polarities of terms, and the strength of attitude is measured as a maximum between polarity scores (intensities) of terms (max(score1,score2)). The rule of propagation is useful, as proposed in (Nasukawa and Yi, 2003), for the task of the detection of local sentiments for given subjects. Propagation verbs propagate the sentiment towards the arguments; transfer verbs transmit sentiments among the arguments. The rule of propagation is applied when a verb of propagation or transfer type is used in a phrase/clause and sentiment of an argument that has prior neutral polarity needs to be investigated (e.g., PROP-POS(to admire) &amp; his behaviour =&gt; POS(his behaviour); Mr. X &amp; TRANS(supports) &amp; NEG(crime business) =&gt; NEG(Mr. X)). The rules of domination are as follows: (1) if polarities of a verb (this rule is appli</context>
</contexts>
<marker>Nasukawa, Yi, 2003</marker>
<rawString>Nasukawa, Tetsuya, and Jeonghee Yi. 2003. Sentiment Analysis: Capturing Favorability using Natural Language Processing. Proceedings of the 2nd International Conference on Knowledge Capture, pp. 70-77.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alena Neviarouskaya</author>
<author>Helmut Prendinger</author>
<author>Mitsuru Ishizuka</author>
</authors>
<title>SentiFul: Generating a Reliable Lexicon for Sentiment Analysis.</title>
<date>2009</date>
<booktitle>Proceedings of the International Conference on Affective Computing and Intelligent Interaction, IEEE,</booktitle>
<pages>363--368</pages>
<location>Amsterdam, Netherlands,</location>
<contexts>
<context position="4171" citStr="Neviarouskaya et al. (2009)" startWordPosition="621" endWordPosition="625">) assigns the strength of the attitude; and (3) determines the level of confidence, with which the attitude is expressed. @AM relies on a compositionality principle and a novel approach 806 \x0cbased on the rules elaborated for semantically distinct verb classes. 2 Lexicon for Attitide Analysis We built a lexicon for attitude analysis that includes: (1) attitude-conveying terms; (2) modifiers; (3) functional words; and (4) modal operators. 2.1 The Core of Lexicon As a core of lexicon for attitude analysis, we employ an Affect database and extended version of the SentiFul database developed by Neviarouskaya et al. (2009). The affective features of each emotion-related word are encoded using nine emotion labels (anger, disgust, fear, guilt, interest, joy, sadness, shame, and surprise) and corresponding emotion intensities that range from 0.0 to 1.0. The original version of SentiFul database, which contains sentimentconveying adjectives, adverbs, nouns, and verbs annotated by sentiment polarity, polarity scores and weights, was manually extended using attitude labels. Some examples of annotated attitude-conveying words are listed in Table 1. It is important to note here that some words may express different att</context>
</contexts>
<marker>Neviarouskaya, Prendinger, Ishizuka, 2009</marker>
<rawString>Neviarouskaya, Alena, Helmut Prendinger, and Mitsuru Ishizuka. 2009. SentiFul: Generating a Reliable Lexicon for Sentiment Analysis. Proceedings of the International Conference on Affective Computing and Intelligent Interaction, IEEE, Amsterdam, Netherlands, pp. 363-368.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlo Strapparava</author>
<author>Rada Mihalcea</author>
</authors>
<title>Learning to Identify Emotions in Text.</title>
<date>2008</date>
<booktitle>Proceedings of the 2008 ACM Symposium on Applied Computing,</booktitle>
<pages>1556--1560</pages>
<location>Fortaleza, Brazil,</location>
<contexts>
<context position="2404" citStr="Strapparava and Mihalcea, 2008" startWordPosition="344" endWordPosition="347">machine learning approach with compositional semantics (Choi and Cardie, 2008) were proposed. With the aim to recognize fine-grained emotions from text on the level of distinct sentences, researchers have employed a keyword spotting technique (Chuang and Wu, 2004; Strapparava et al., 2007), a technique calculating emotion scores using Pointwise Mutual Information (PMI) (Kozareva et al., 2007), an approach inspired by common-sense knowledge (Liu et al., 2003), rule-based linguistic approaches (Boucouvalas, 2003; Chaumartin, 2007), machine-learning methods (Alm, 2008; Aman and Szpakowicz, 2008; Strapparava and Mihalcea, 2008), and an ensemble based multilabel classification technique (Bhowmick et al., 2009). Early attempts to focus on distinct attitude types in the task of attitude analysis were made by Taboada and Grieve (2004), who determined a potential value of adjectives for affect, judgement and appreciation by calculating the PMI with the pronoun-copular pairs I was (affect), He was (judgement), and It was (appreciation), and Whitelaw et al. (2005), who used a machine learning technique (SVM) with finegrained semantic distinctions in features (attitude type, orientation) in combination with bag of words to </context>
</contexts>
<marker>Strapparava, Mihalcea, 2008</marker>
<rawString>Strapparava, Carlo, and Rada Mihalcea. 2008. Learning to Identify Emotions in Text. Proceedings of the 2008 ACM Symposium on Applied Computing, Fortaleza, Brazil, pp. 1556-1560.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlo Strapparava</author>
<author>Alessandro Valitutti</author>
<author>Oliviero Stock</author>
</authors>
<title>Dances with Words.</title>
<date>2007</date>
<booktitle>Proceedings of the International Joint Conference on Artificial Intelligence,</booktitle>
<pages>1719--1724</pages>
<contexts>
<context position="2063" citStr="Strapparava et al., 2007" startWordPosition="299" endWordPosition="302">preciation (evaluation of phenomena). To analyse contextual sentiment of a phrase or a sentence, rule-based approaches (Nasukawa and Yi, 2003; Moilanen and Pulman, 2007; Subrahmanian and Reforgiato, 2008), a machinelearning method using not only lexical but also syntactic features (Wilson et al., 2005), and a model of integration of machine learning approach with compositional semantics (Choi and Cardie, 2008) were proposed. With the aim to recognize fine-grained emotions from text on the level of distinct sentences, researchers have employed a keyword spotting technique (Chuang and Wu, 2004; Strapparava et al., 2007), a technique calculating emotion scores using Pointwise Mutual Information (PMI) (Kozareva et al., 2007), an approach inspired by common-sense knowledge (Liu et al., 2003), rule-based linguistic approaches (Boucouvalas, 2003; Chaumartin, 2007), machine-learning methods (Alm, 2008; Aman and Szpakowicz, 2008; Strapparava and Mihalcea, 2008), and an ensemble based multilabel classification technique (Bhowmick et al., 2009). Early attempts to focus on distinct attitude types in the task of attitude analysis were made by Taboada and Grieve (2004), who determined a potential value of adjectives for</context>
</contexts>
<marker>Strapparava, Valitutti, Stock, 2007</marker>
<rawString>Strapparava, Carlo, Alessandro Valitutti, and Oliviero Stock. 2007. Dances with Words. Proceedings of the International Joint Conference on Artificial Intelligence, pp. 1719-1724.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V S Subrahmanian</author>
<author>Diego Reforgiato</author>
</authors>
<title>AVA: Adjective-Verb-Adverb Combinations for Sentiment Analysis.</title>
<date>2008</date>
<journal>Intelligent Systems, IEEE,</journal>
<volume>23</volume>
<issue>4</issue>
<pages>43--50</pages>
<contexts>
<context position="1642" citStr="Subrahmanian and Reforgiato, 2008" startWordPosition="232" endWordPosition="236">oples discussions concerning personal, public or social issues (news, blogs, discussion forums, etc.), there is a great need in development of a computational tool for the analysis of peoples attitudes. According to the Appraisal Theory (Martin and White, 2005), attitude types define the specifics of appraisal being expressed: affect (personal emotional state), judgment (social or ethical appraisal of others behaviour), and appreciation (evaluation of phenomena). To analyse contextual sentiment of a phrase or a sentence, rule-based approaches (Nasukawa and Yi, 2003; Moilanen and Pulman, 2007; Subrahmanian and Reforgiato, 2008), a machinelearning method using not only lexical but also syntactic features (Wilson et al., 2005), and a model of integration of machine learning approach with compositional semantics (Choi and Cardie, 2008) were proposed. With the aim to recognize fine-grained emotions from text on the level of distinct sentences, researchers have employed a keyword spotting technique (Chuang and Wu, 2004; Strapparava et al., 2007), a technique calculating emotion scores using Pointwise Mutual Information (PMI) (Kozareva et al., 2007), an approach inspired by common-sense knowledge (Liu et al., 2003), rule-</context>
</contexts>
<marker>Subrahmanian, Reforgiato, 2008</marker>
<rawString>Subrahmanian, V.S., and Diego Reforgiato. 2008. AVA: Adjective-Verb-Adverb Combinations for Sentiment Analysis. Intelligent Systems, IEEE, 23 (4): 43-50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maite Taboada</author>
<author>Jack Grieve</author>
</authors>
<title>Analyzing Appraisal Automatically.</title>
<date>2004</date>
<booktitle>Proceedings of AAAI Spring Symposium on Exploring Attitude and Affect in Text,</booktitle>
<pages>158--161</pages>
<contexts>
<context position="2611" citStr="Taboada and Grieve (2004)" startWordPosition="377" endWordPosition="380"> a keyword spotting technique (Chuang and Wu, 2004; Strapparava et al., 2007), a technique calculating emotion scores using Pointwise Mutual Information (PMI) (Kozareva et al., 2007), an approach inspired by common-sense knowledge (Liu et al., 2003), rule-based linguistic approaches (Boucouvalas, 2003; Chaumartin, 2007), machine-learning methods (Alm, 2008; Aman and Szpakowicz, 2008; Strapparava and Mihalcea, 2008), and an ensemble based multilabel classification technique (Bhowmick et al., 2009). Early attempts to focus on distinct attitude types in the task of attitude analysis were made by Taboada and Grieve (2004), who determined a potential value of adjectives for affect, judgement and appreciation by calculating the PMI with the pronoun-copular pairs I was (affect), He was (judgement), and It was (appreciation), and Whitelaw et al. (2005), who used a machine learning technique (SVM) with finegrained semantic distinctions in features (attitude type, orientation) in combination with bag of words to classify movie reviews. However, the concentration only on adjectives expressing appraisal and their modifiers greatly narrows the potential of the Whitelaw et al. (2005) approach. In this paper we introduce</context>
</contexts>
<marker>Taboada, Grieve, 2004</marker>
<rawString>Taboada, Maite, and Jack Grieve. 2004. Analyzing Appraisal Automatically. Proceedings of AAAI Spring Symposium on Exploring Attitude and Affect in Text, pp.158-161.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Casey Whitelaw</author>
<author>Navendu Garg</author>
<author>Shlomo Argamon</author>
</authors>
<title>Using Appraisal Groups for Sentiment Analysis.</title>
<date>2005</date>
<booktitle>Proceedings of the 14th ACM International Conference on Information and Knowledge Management, CIKM,</booktitle>
<pages>625--631</pages>
<location>Bremen, Germany,</location>
<contexts>
<context position="2842" citStr="Whitelaw et al. (2005)" startWordPosition="414" endWordPosition="417">u et al., 2003), rule-based linguistic approaches (Boucouvalas, 2003; Chaumartin, 2007), machine-learning methods (Alm, 2008; Aman and Szpakowicz, 2008; Strapparava and Mihalcea, 2008), and an ensemble based multilabel classification technique (Bhowmick et al., 2009). Early attempts to focus on distinct attitude types in the task of attitude analysis were made by Taboada and Grieve (2004), who determined a potential value of adjectives for affect, judgement and appreciation by calculating the PMI with the pronoun-copular pairs I was (affect), He was (judgement), and It was (appreciation), and Whitelaw et al. (2005), who used a machine learning technique (SVM) with finegrained semantic distinctions in features (attitude type, orientation) in combination with bag of words to classify movie reviews. However, the concentration only on adjectives expressing appraisal and their modifiers greatly narrows the potential of the Whitelaw et al. (2005) approach. In this paper we introduce our system @AM (ATtitude Analysis Model), which (1) classifies sentences according to the fine-grained attitude labels (nine affect categories (Izard, 1971): anger, disgust, fear, guilt, interest, joy, sadness, shame, surprise; fo</context>
</contexts>
<marker>Whitelaw, Garg, Argamon, 2005</marker>
<rawString>Whitelaw, Casey, Navendu Garg, and Shlomo Argamon. 2005. Using Appraisal Groups for Sentiment Analysis. Proceedings of the 14th ACM International Conference on Information and Knowledge Management, CIKM, Bremen, Germany, pp. 625-631.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Paul Hoffmann</author>
</authors>
<title>Recognizing Contextual Polarity in Phraselevel Sentiment Analysis.</title>
<date>2005</date>
<booktitle>Proceedings of HLTEMNLP-2005, ACL,</booktitle>
<pages>347--354</pages>
<contexts>
<context position="1741" citStr="Wilson et al., 2005" startWordPosition="249" endWordPosition="252"> great need in development of a computational tool for the analysis of peoples attitudes. According to the Appraisal Theory (Martin and White, 2005), attitude types define the specifics of appraisal being expressed: affect (personal emotional state), judgment (social or ethical appraisal of others behaviour), and appreciation (evaluation of phenomena). To analyse contextual sentiment of a phrase or a sentence, rule-based approaches (Nasukawa and Yi, 2003; Moilanen and Pulman, 2007; Subrahmanian and Reforgiato, 2008), a machinelearning method using not only lexical but also syntactic features (Wilson et al., 2005), and a model of integration of machine learning approach with compositional semantics (Choi and Cardie, 2008) were proposed. With the aim to recognize fine-grained emotions from text on the level of distinct sentences, researchers have employed a keyword spotting technique (Chuang and Wu, 2004; Strapparava et al., 2007), a technique calculating emotion scores using Pointwise Mutual Information (PMI) (Kozareva et al., 2007), an approach inspired by common-sense knowledge (Liu et al., 2003), rule-based linguistic approaches (Boucouvalas, 2003; Chaumartin, 2007), machine-learning methods (Alm, 2</context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2005</marker>
<rawString>Wilson, Theresa, Janyce Wiebe, and Paul Hoffmann. 2005. Recognizing Contextual Polarity in Phraselevel Sentiment Analysis. Proceedings of HLTEMNLP-2005, ACL, pp. 347-354.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>