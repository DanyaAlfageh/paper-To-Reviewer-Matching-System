Although the effect of lexicalization has been discussed in several studies recently (CITATION; CITATION; Arun and Keller 2005), it is often investigated as an all-or-nothing affair, except for a few studies that analyze the distributions of lexical items, for example, CITATION and CITATION,,
The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser (CITATION, 1999), is applied to a new language, which often leads to a significant decrease in the measured accuracy (CITATION; CITATION; CITATION; CITATION; CITATION),,
 been based on constituency-based representations, partly influenced by the availability of data resources such as the Penn Treebank (Marcus, Santorini, and Marcinkiewicz 1993), it has been argued that free constituent order languages can be analyzed more adequately using dependency-based representations, which is also the kind of annotation found, for example, in the Prague Dependency Treebank of Czech CITATION,,
Recently, dependency-based parsing has been applied to 13 different languages in the shared task of the 2006 Conference on Computational Natural Language Learning (CoNLL) CITATION,,
Using data from the recently released Turkish Treebank CITATION, we investigate the impact of different design choices in developing data-driven parsers,,
Inflectional features (INF) r Dependency type to the head if available (DEP) To predict parser actions from histories, represented as feature vectors, we use support vector machines (SVMs), which combine the maximum margin strategy introduced by CITATION with the use of kernel functions to map the original feature space to a higher-dimensional space,,
This type of classifier has been used successfully in deterministic parsing by CITATION, CITATION, and Sagae and Lavie (2005), among others,,
To be more specific, we use the LIBSVM library for SVM learning CITATION, with a polynomial kernel of degree 2, with binarization of symbolic features, and with the one-versus-one strategy for multiclass classification.19 This approach has some advantages over the probabilistic parser, in that r it can process both left-to-right and right-to-left dependencies due to its parsing algorithm, r it assigns dependency labels simultaneously with dependencies and can use these as features in the history-based model, and r it does not necessarily require expert knowledge about the choice of linguistically relevant features to use in the representations because SVM training,,
A parsing algorithm for building the dependency analyses (CITATION; Sekine, Uchimoto, and Isahara 2000) 2,,
A conditional probability model to score the analyses CITATION Table 1 Unlabeled attachment scores and unlabeled word-to-word scores for the baseline parsers,,
Maximum likelihood estimation to make inferences about the underlying probability models (CITATION; CITATION) 4.1 Methodology The aim of our probabilistic model is to assign a probability to each candidate dependency link by using the frequencies of similar dependencies computed from a training set,,
For the probability model, we adopt the approach by CITATION, which itself is a modified version of the statistical model used in CITATION.8 In this model in Equation (2), the probability of a dependency link P(dep (ui, uH(i)) |S) linking ui to a head uH(i) is approximated with the product of two probabilities: P(dep (ui, uH(i)) |S) P(link(ui, uH(i)) |i H(i)) (2) P(ui links to some head dist(i, H(i)) away |i) 7 The rules check for enclitics such as de, ki, mi, written on the right side of and separately from the word they attach to, for the verb degil, which gives a negative meaning to the word coming before it and for nominals which do not have ,,
A parsing algorithm for building the dependency analyses (CITATION; Sekine, Uchimoto, and Isahara 2000) 2,,
A conditional probability model to score the analyses CITATION Table 1 Unlabeled attachment scores and unlabeled word-to-word scores for the baseline parsers,,
Maximum likelihood estimation to make inferences about the underlying probability models (CITATION; CITATION) 4.1 Methodology The aim of our probabilistic model is to assign a probability to each candidate dependency link by using the frequencies of similar dependencies computed from a training set,,
For the probability model, we adopt the approach by CITATION, which itself is a modified version of the statistical model used in CITATION.8 In this model in Equation (2), the probability of a dependency link P(dep (ui, uH(i)) |S) linking ui to a head uH(i) is approximated with the product of two probabilities: P(dep (ui, uH(i)) |S) P(link(ui, uH(i)) |i H(i)) (2) P(ui links to some head dist(i, H(i)) away |i) 7 The rules check for enclitics such as de, ki, mi, written on the right side of and separately from the word they attach to, for the verb degil, which gives a negative meaning to the word coming before it and for nominals which do not have any verbs on their right side,,
8 The statistical model in CITATION is actually,,
In all of the following models, dist(i, H(i)) is taken as the number of actual word boundaries between the dependent and the head unit regardless of whether full words or IGs were used as units of parsing.9 To alleviate the data sparseness, we use the interpolation of other estimates while calculating the probabilities in Equation (2).10 We use a strategy similar to CITATION and we interpolate with estimates based on less context: P(x|y) P1(x|y) + (1 ) P2(x) (3) where = /( + 1) and is the count of the x occurrences During the actual runs, the smoothed probability P(link(ui, uH(i)) |i H(i)) is estimated by interpolating two unsmoothed empirical estimates extracted from the treebank: P1(link(ui, uH(i)) |i H(i)) and P2(link(ui, uH(i))),,
The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser (CITATION, 1999), is applied to a new language, which often leads to a significant decrease in the measured accuracy (CITATION; CITATION; CITATION; CITATION; CITATION),,
1992; CITATION; CITATION; CITATION) 3,,
Discriminative classifiers to map histories to parser actions (CITATION; CITATION; Nivre, Hall, and Nilsson 2004) A system of this kind employs no grammar but relies completely on inductive learning from treebank data for the analysis of new sentences, and on deterministic parsing for disambiguation,,
The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser (CITATION, 1999), is applied to a new language, which often leads to a significant decrease in the measured accuracy (CITATION; CITATION; CITATION; CITATION; CITATION),,
The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser (CITATION, 1999), is applied to a new language, which often leads to a significant decrease in the measured accuracy (CITATION; CITATION; CITATION; CITATION; CITATION),,
19 Experiments have also been performed using memory-based learning CITATION,,
20 Because the frequency of non-projective dependencies in the Turkish Treebank is not high enough to learn such dependencies and mostly due to the unconnected punctuations with which we are dealing by adding an extra dependency label, we did not observe any improvement when applying the pseudo-projective processing of CITATION, which is reported to improve accuracy for other languages,,
The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser (CITATION, 1999), is applied to a new language, which often leads to a significant decrease in the measured accuracy (CITATION; CITATION; CITATION; CITATION; CITATION),,
d units rather than word forms as the basic units of syntactic structure CITATION,,
Whereas the best performing parsers for English all make use of lexical information, the real benefits of lexicalization for English as well as other languages remains controversial (CITATION; CITATION; Arun and Keller 2005),,
Although the effect of lexicalization has been discussed in several studies recently (CITATION; CITATION; Arun and Keller 2005), it is often investigated as an all-or-nothing affair, except for a few studies that analyze the distributions of lexical items, for example, CITATION and CITATION,,
A parsing algorithm for building the dependency analyses (CITATION; Sekine, Uchimoto, and Isahara 2000) 2,,
A conditional probability model to score the analyses CITATION Table 1 Unlabeled attachment scores and unlabeled word-to-word scores for the baseline parsers,,
Maximum likelihood estimation to make inferences about the underlying probability models (CITATION; CITATION) 4.1 Methodology The aim of our probabilistic model is to assign a probability to each candidate dep,,
Even though in written texts the constituent order predominantly conforms to the SOV order, constituents may freely change their position depending on the requirements of the discourse context (CITATION; CITATION),,
Previous work on Turkish (HakkaniTur, Oflazer, and Tur 2002; CITATION; Oflazer ,,
The third baseline parser is a rule-based parser that uses a modified version of the deterministic parsing algorithm by CITATION,,
In the rule-based baseline parser, the next parsing action is determined according to 31 predefined hand-written rules (CITATION; Eryigit, Adal, and Oflazer 2006),,
The third baseline parser is a rule-based parser that uses a modified version of the deterministic parsing algorithm by CITATION,,
In the rule-based baseline parser, the next parsing action is determined according to 31 predefined hand-written rules (CITATION; Eryigit, Adal, and Oflazer 2006),,
Thus, for Turkish, it has previously been shown that parsing accuracy can be improved by taking morphologically defined units rather than word forms as the basic units of syntactic structure CITATION,,
Whereas the best performing parsers for English all make use of lexical information, the real benefits of lexicalization for English as well as other languages remains controversial (CITATION; CITATION; Arun and Keller 2005),,
Previous work on Turkish (HakkaniTur, Oflazer, and Tur 2002; CITATION; CITATION; CITATION) has represented the morphological structure of Turkish words by splitting them into inflectional groups (IGs),,
Although the effect of lexicalization has been discussed in several studies recently (CITATION; CITATION; Arun and Keller 2005), it is often investigated as an all-or-nothing affair, except for a few studies that analyze the distributions of lexical items, for example, CITATION and CITATION,,
Whereas most of the work on English has been based on constituency-based representations, partly influenced by the availability of data resources such as the Penn Treebank (Marcus, Santorini, and Marcinkiewicz 1993), it has been argued that free constituent order languages can be analyzed more adequately using dependency-based representations, which is also the kind of annotation found, for example, in the Prague Dependency Treebank of Czech CITATION,,
Recently, dependency-based parsing has been applied to 13 different languages in the shared task of the 2006 Conference on Computational Natural Language Learning (CoNLL) CITATION,,
Even though in written texts the constituent order predominantly conforms to the SOV order, constituents may freely change their position depending on the requirements of the discourse context (CITATION; CITATION),,
Previous work on Turkish (HakkaniTur, Oflazer, and Tur 2002; CITATION; CITATION; Er,,
 forms as the basic units of syntactic structure CITATION,,
Whereas the best performing parsers for English all make use of lexical information, the real benefits of lexicalization for English as well as other languages remains controversial (CITATION; CITATION; Arun and Keller 2005),,
Although the effect of lexicalization has been discussed in several studies recently (CITATION; CITATION; Arun and Keller 2005), it is often investigated as an all-or-nothing affair, except for a few studies that analyze the distributions of lexical items, for example, CITATION and CITATION,,
Of all the dependencies in the treebank, 95% are head-final5 and 97.5% are projective.6 Even though the number of sentences in the Turkish Treebank is in the same range as for many other available treebanks for languages such as Danish CITATION, Swedish (Nivre, Nilsson, and Hall 2006), and Bulgarian (Simov, Popova, and Osenova 2002), the number of words is considerably smaller (54K as opposed to 70100K for the other treebanks),,
Classifier-Based Dependency Parser Our second data-driven parser is based on a parsing strategy that has achieved a high parsing accuracy across a variety of different languages (CITATION, 2007),,
Deterministic parsing algorithms for building dependency graphs (CITATION; CITATION; CITATION) Table 3 Unlabeled attachment scores for different choices for morphological features,,
The linguistic attributes available for a given token are the following: r Lexical form (root) (LEX) r Part-of-speech category (POS) r Inflectional features (INF) r Dependency type to the head if available (DEP) To predict parser actions from histories, represented as feature vectors, we use support vector machines (SVMs), which combine the maximum margin strategy introduced by CITATION with the use of kernel functions to map the original feature space to a higher-dimensional space,,
This type of classifier has been used successfully in deterministic parsing by CITATION, CITATION, and Sagae and Lavie (2005), among others,,
To be more specific, we use the LIBSVM library for SVM learning CITATION, with a polynomial kernel of degree 2, with binarization of symbolic features, and with the one-versus-one strategy for multiclass classification.19 This approach has some advantages over the probabilistic parser, in that r it can process both left-to-right and right-to-left dependencies due to its parsing algorithm, r it assigns dependency labels simultaneously with dependencies and can use these as features in the history-based model, a,,
The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser (CITATION, 1999), is applied to a new language, which often leads to a significant decrease in the measured accuracy (CITATION; CITATION; CITATION; CITATION; CITATION),,
1992; CITATION; CITATION; CITATION) 3,,
Discriminative classifiers to map histories to parser actions (CITATION; CITATION; Nivre, Hall, and Nilsson 2004) A system of this kind employs no grammar but relies completely on inductive learning from treebank data for the analysis of new sentences, and on deterministic parsing for disambiguation,,
Classifier-Based Dependency Parser Our second data-driven parser is based on a parsing strategy that has achieved a high parsing accuracy across a variety of different languages (CITATION, 2007),,
Deterministic parsing algorithms for building dependency graphs (CITATION; CITATION; CITATION) Table 3 Unlabeled attachment scores for different choices for morphological features,,
All experiments are performed using the freely available implementation MaltParser.18 5.1 Methodology For the experiments in this article, we use a variant of the parsing algorithm proposed by CITATION, 2006), a linear-time algorithm that derives a labeled dependency graph in one left-to-right pass over the input, using a stack to store partially processed tokens and a list to store remaining input tokens,,
However, in contrast to the original arc-eager parsing strategy, we use an arc-standard bottom-up algorithm, as described in CITATION,,
All experiments are performed using the freely available implementation MaltParser.18 5.1 Methodology For the experiments in this article, we use a variant of the parsing algorithm proposed by CITATION, 2006), a linear-time algorithm that derives a labeled dependency graph in one left-to-right pass over the input, using a stack to store partially processed tokens and a list to store remaining input tokens,,
However, in contrast to the original arc-eager parsing strategy, we use an arc-standard bottom-up algorithm, as described in CITATION,,
The third baseline parser is a rule-based parser that uses a modified version of the deterministic parsing algorithm by CITATION,,
In the rule-based baseline parser, the next parsing action is determined according to 31 predefined hand-written rules (CITATION; Eryigit, Adal, and Oflazer 2006),,
Classifier-Based Dependency Parser Our second data-driven parser is based on a parsing strategy that has achieved a high parsing accuracy across a variety of different languages (CITATION, 2007),,
Deterministic parsing algorithms for building dependency graphs (CITATION; CITATION; CITATION) Table 3 Unlabeled attachment scores for different choices for morphological features,,
19 Experiments have also been performed using memory-based learning CITATION,,
20 Because the frequency of non-projective dependencies in the Turkish Treebank is not high enough to learn such dependencies and mostly due to the unconnected punctuations with which we are dealing by adding an extra dependency label, we did not observe any improvement when applying the pseudo-projective processing of CITATION, which is reported to improve accuracy for other languages,,
Classifier-Based Dependency Parser Our second data-driven parser is based on a parsing strategy that has achieved a high parsing accuracy across a variety of different languages (CITATION, 2007),,
Deterministic parsing algorithms for building dependency graphs (CITATION; CITATION; CITATION) Table 3 Unlabeled attachment scores for different choices for morphological features,,
context (CITATION; CITATION),,
Previous work on Turkish (HakkaniTur, Oflazer, and Tur 2002; CITATION; CITATION; CITATION) has represented the morphological structure of Turkish words by splitting them into inflectional groups (IGs),,
 to 13 different languages in the shared task of the 2006 Conference on Computational Natural Language Learning (CoNLL) CITATION,,
Using data from the recently released Turkish Treebank CITATION, we investigate the impact of different design choices in developing data-driven parsers,,
anl 1979; CITATION),,
Previous work on Turkish (HakkaniTur, Oflazer, and Tur 2002; CITATION; CITATION; CITATION) has represented the morphological structure of Turkish words by splitting them into inflectional groups (IGs),,
2.2 The Turkish Treebank We have used the Turkish Treebank CITATION, created by the Middle East Technical University and Sabanc University, in the experiments we report in this article,,
1992; CITATION; CITATION; CITATION) 3,,
Discriminative classifiers to map histories to parser actions (CITATION; CITATION; Nivre, Hall, and Nilsson 2004) A system of this kind employs no grammar but relies completely on inductive learning from treebank data for the analysis of new sentences, and on deterministic parsing for disambiguation,,
The linguistic attributes available for a given token are the following: r Lexical form (root) (LEX) r Part-of-speech category (POS) r Inflectional features (INF) r Dependency type to the head if available (DEP) To predict parser actions from histories, represented as feature vectors, we use support vector machines (SVMs), which combine the maximum margin strategy introduced by CITATION with the use of kernel functions to map the original feature space to a higher-dimensional space,,
This type of classifier has been used successfully in deterministic parsing by CITATION, CITATION, and Sagae and Lavie (2005), among others,,
To be more specific, we use the LIBSVM library for SVM learning CITATION, with a polynomial kernel of degree 2, with binarization of symbolic features, and with the one-versus-one strategy for multiclass classification.19 This approach has some advantages over the probabilistic parser, in that r it can process ,,
Classifier-Based Dependency Parser Our second data-driven parser is based on a parsing strategy that has achieved a high parsing accuracy across a variety of different languages (CITATION, 2007),,
Deterministic parsing algorithms for building dependency graphs (CITATION; CITATION; CITATION) Table 3 Unlabeled attachment scores for different choices for morphological features,,
 The linguistic attributes available for a given token are the following: r Lexical form (root) (LEX) r Part-of-speech category (POS) r Inflectional features (INF) r Dependency type to the head if available (DEP) To predict parser actions from histories, represented as feature vectors, we use support vector machines (SVMs), which combine the maximum margin strategy introduced by CITATION with the use of kernel functions to map the original feature space to a higher-dimensional space,,
This type of classifier has been used successfully in deterministic parsing by CITATION, CITATION, and Sagae and Lavie (2005), among others,,
To be more specific, we use the LIBSVM library for SVM learning CITATION, with a polynomial kernel of degree 2, with binarization of symbolic features, and with the one-versus-one strategy for multiclass classification.19 This approach has some advantages over the probabilistic parser, in that r it can process both left-to-right and right-to-left dependencies due to its parsing algorithm, r it assigns dependency labels simultaneously with dependencies and can use these as features in the history-based model, and r it does not necessarily ,,
