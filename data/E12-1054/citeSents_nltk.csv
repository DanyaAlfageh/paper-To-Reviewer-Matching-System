1 Introduction Measuring the contextual fitness of a term in its context is a key component in different NLP applications like speech recognition CITATION, optical character recognition CITATION, co-reference resolution CITATION, or malapropism detection CITATION.,,
the quality of the optical character recognition module CITATION.,,
1 Introduction Measuring the contextual fitness of a term in its context is a key component in different NLP applications like speech recognition CITATION, optical character recognition CITATION, co-reference resolution CITATION, or malapropism detection CITATION.,,
the quality of the optical character recognition module CITATION.,,
Existing measures of contextual fitness can be categorized into knowledge-based CITATION and statistical methods (Mays et al., 1991; CITATION).,,
For that purpose, knowledge-based approaches employ the structural knowledge encoded in lexical-semantic networks like WordNet CITATION, while statistical approaches rely on co-occurrence counts collected from large corpora, e.g.,,
the Google Web1T corpus CITATION.,,
So far, evaluation of contextual fitness measures relied on artificial datasets (Mays et al., 1991; CITATION) which are created by taking a sentence that is known to be correct, and replacing a word with a similar word from the vocabulary.,,
Thus, we use a frequency filter based on the Google Web1T n-gram counts CITATION.,,
For this purpose, we applied the Stanford NER CITATION.,,
006) used a characteristic gap in the standard evaluation dataset by CITATION that separates unrelated from related word pairs.,,
5.1 Statistical Approach Table 1 summarizes the results obtained by the statistical approach using a trigram model based on the Google Web1T data CITATION.,,
Another possible source of real-word spelling errors are learner corpora CITATION, e.g.,,
the Cambridge Learner Corpus CITATION.,,
However, annotation of errors is difficult and costly CITATION, only a small fraction of observed errors will be real-word spelling errors, and learners are likely to make dif535 \x0cferent mistakes than proficient language users.,,
CITATION presented another statistical approach using the Google Web1T data CITATION to create the n-gram model.,,
(1991), CITATION found that it ou,,
In the experiments by CITATION, the measure by CITATION yields the best results.,,
CITATION.,,
Some measures using a wider definition of semantic relatedness (CITATION; CITATIONb) instead of only using taxonomic relations in a knowledge source.,,
CITATION used a characteristic gap in the standard evaluation dataset by Rube,,
Influence of the Relatedness Measure As was pointed out before, CITATION 534 \x0cDataset Measure P R F Art-En JiangConrath 0.5 .26 .15 .19 Lin 0.5 .22 .17 .19 Lesk 0.5 .19 .16 .17 ESA-Wikipedia 0.05 .43 .13 .20 ESA-Wiktionary 0.05 .35 .20 .25 ESA-Wordnet 0.05 .33 .15 .21 Nat-En JiangConrath 0.5 .29 .18 .23 Lin 0.5 .26 .21 .23 Lesk 0.5 .19 .19 .19 ESA-Wikipedia 0.05 .48 .14 .22 ESA-Wiktionary 0.05 .39 .21 .27 ESA-Wordnet 0.05 .36 .15 .21 Table 4: Performance of knowledge-based approach using different relatedness measures.,,
show that the measure by CITATION yields the best results in their experiments on malapropism detection.,,
However, real-word spelling correction has also been tackled by supervised approaches (CITATION; CITATION; CITATION).,,
Existing measures of contextual fitness can be categorized into knowledge-based CITATION and statistical methods (Mays et al., 1991; CITATION).,,
For that purpose, knowledge-based approaches employ the structural knowledge encoded in lexical-semantic networks like WordNet CITATION, while statistical approaches rely on co-occurrence counts collected from large corpora, e.g.,,
the Google Web1T corpus CITATION.,,
So far, evaluation of contextual fitness measures relied on artificial datasets (Mays et al., 1991; CITATION) which are created by taking a sentence that is known to be correct, and replacing a word with a similar word from the vocabulary.,,
For this purpose, we applied the Stanford NER CITATION.,,
For this purpose, we use WordNet CITATION for English and GermaNet CITATION for German.,,
2.1 Accessing the Revision Data We access the Wikipedia revision data using the freely available Wikipedia Revision Toolkit CITATION together with the JWPL Wikipedia API (CITATIONa).3 The API outputs plain text converted from Wiki-Markup, but the text still contains a small portion of leftover markup and other artifacts.,,
 based on the Google Web1T n-gram counts CITATION.,,
For this purpose, we applied the Stanford NER CITATION.,,
For this purpose, we use WordNet CITATION for English and GermaNet CITATION for German.,,
Previous work on evaluating real-word spelling correction (CITATION; WilcoxOHearn et al., 2008; CITATION) used a dataset sampled from the Wall Street Journal corpus which is not freely available.,,
Thus, we created a comparable English dataset of 1,000 artificial errors based on the easily available Brown corpus (Francis W. CITATION).8 Additionally, we created a German dataset with 1,000 artificial errors based on the TIGER corpus.9 4 Measuring Contextual Fitness There are two main approaches for measuring the contextual fitness of a word in its context: the statistical (Mays et al., 1991) and the knowledgebased approach CITATION.,,
In the experiments by CITATION, the measure by CITATION yields the best results.,,
CITATION.,,
Some measures using a wider definition of semantic relatedness (CITATION; CITATIONb) instead of only using taxonomic relations in a knowledge source.,,
CITATION used a characteristic gap in the standard evaluation dataset by CITATION that separates unrelated from related word pairs.,,
show that the measure by CITATION yields the best results in their experiments on malapropism detection.,,
In addition, we test another path-based measure by CITATION, the gloss-based measure by CITATION, and the ESA measure CITATION based on concept vectors from Wikipedia, Wiktionary, and WordNet.,,
In contrast to the findings of CITATION, JiangConrath is not the best path-based measure, as Lin provides equal or better performance.,,
However, real-word spelling correction has also been tackled by supervised approaches (CITATION; CITATION; CITATION).,,
CITATION used similar techniques to create a dataset of errors from the French Wikipedia.,,
Another possible source of real-word spelling errors are learner corpora CITATION, e.g.,,
the Cambridge Learner Corpus CITATION.,,
However, annotation of errors is difficult and costly CITATION, only a small fraction of observed errors will be real-word spelling errors, and learners are likely to make dif535 \x0cferent mistakes than proficient language users.,,
CITATION presented another statistical approach using the Google Web1T data CITATION to create the n-gram model.,,
the quality of the optical character recognition module CITATION.,,
Besides typing mistakes, a major source of such errors is the failed attempt of automatic spelling correctors to correct a misspelled word CITATION.,,
Existing measures of contextual fitness can be categorized into knowledge-based CITATION and statistical methods (Mays et al., 1991; CITATION).,,
Previous work on evaluating real-word spelling correction (CITATION; WilcoxOHearn et al., 2008; CITATION) used a dataset sampled from the Wall Street Journal corpus which is not freely available.,,
Thus, we created a comparable English dataset of 1,000 artificial errors based on the easily available Brown corpus (Francis W. CITATION).8 Additionally, we created a German dataset with 1,000 artificial errors based on the TIGER corpus.9 4 Measuring Contextual Fitness There are two main approaches for measuring the contextual fitness of a word in its context: the statistical (Mays et al., 1991) and the knowledgebased approach (Hirst and,,
4.2 Knowledge Based Approach CITATION introduced a knowledge-based approach that detects real-word spelling errors by checking the semantic relations of a target word with its context.,,
(1991), CITATION found that it outperformed the knowledge-based method by CITATION when evaluated on a corpus of artificial errors based on the WSJ corpus.,,
(1991) and the knowledge-based approach by CITATION on the task of detecting realword spelling errors.,,
1 Introduction Measuring the contextual fitness of a term in its context is a key component in different NLP applications like speech recognition CITATION, optical character recognition CITATION, co-reference resolution CITATION, or malapropism detection CITATION.,,
Previous work on evaluating real-word spelling correction (CITATION; WilcoxOHearn et al., 2008; CITATION) used a dataset sampled from the Wall Street Journal corpus which is not freely available.,,
Thus, we created a comparable English dataset of 1,000 artificial errors based on the easily available Brown corpus (Francis W. CITATION).8 Additionally, we created a German dataset with 1,000 artificial errors based on the TIGER corpus.9 4 Measuring Contextual Fitness There are two main approaches for measuring the contextual fitness of a word in its context: the statistical (Mays et al., 1991) and the knowledgebased approach CITATION.,,
Another possible source of real-word spelling errors are learner corpora CITATION, e.g.,,
the Cambridge Learner Corpus CITATION.,,
However, annotation of errors is difficult and costly CITATION, only a small fraction of observed errors will be real-word spelling errors, and learners are likely to make dif535 \x0cferent mistakes than proficient language users.,,
CITATION presented another statistical approach using the Google Web1T data CITATION to create the n-gram model.,,
For the resulting much smaller subset of sentence pairs, we compute the Jaro distance CITATION between each pair.,,
In the experiments by CITATION, the measure by CITATION yields the best results.,,
CITATION.,,
Some measures using a wider definition of semantic relatedness (CITATION; CITATIONb) instead of only using taxonomic relations in a knowledge source.,,
CITATION used a characteristic gap in the standard evaluation dataset by CITATION that separate,,
Influence of the Relatedness Measure As was pointed out before, CITATION 534 \x0cDataset Measure P R F Art-En JiangConrath 0.5 .26 .15 .19 Lin 0.5 .22 .17 .19 Lesk 0.5 .19 .16 .17 ESA-Wikipedia 0.05 .43 .13 .20 ESA-Wiktionary 0.05 .35 .20 .25 ESA-Wordnet 0.05 .33 .15 .21 Nat-En JiangConrath 0.5 .29 .18 .23 Lin 0.5 .26 .21 .23 Lesk 0.5 .19 .19 .19 ESA-Wikipedia 0.05 .48 .14 .22 ESA-Wiktionary 0.05 .39 .21 .27 ESA-Wordnet 0.05 .36 .15 .21 Table 4: Performance of knowledge-based approach using different relatedness measures.,,
show that the measure by CITATION yields the best results in their experiments on malapropism detection.,,
In addition, we test another path-based measure by CITATION, the gloss-based measure by CITATION, and the ESA measure CITATION based on concept vectors from Wikipedia, Wiktionary, and WordNet.,,
In contrast to the findings of CITATION, JiangConrath is not the best path-based measure, as Lin provides equal or better performance.,,
However, real-word spelling correction has also been tackled by supervised approaches (CITATION; CITATION; CITATION).,,
Both - the statistical as well as the knowledge-based approach - will benefit from a better model of the typist, as not all edit operations are equally likely CITATION.,,
se, we applied the Stanford NER CITATION.,,
For this purpose, we use WordNet CITATION for English and GermaNet CITATION for German.,,
show that the measure by CITATION yields the best results in their experiments on malapropism detection.,,
In addition, we test another path-based measure by CITATION, the gloss-based measure by CITATION, and the ESA measure CITATION based on concept vectors from Wikipedia, Wiktionary, and WordNet.,,
In contrast to the findings of CITATION, JiangConrath is not the best path-based measure, as Lin provides equal or better performance.,,
show that the measure by CITATION yields the best results in their experiments on malapropism detection.,,
In addition, we test another path-based measure by CITATION, the gloss-based measure by CITATION, and the ESA measure CITATION based on concept vectors from Wikipedia, Wiktionary, and WordNet.,,
In contrast to the findings of CITATION, JiangConrath is not the best path-based measure, as Lin provides equal or better performance.,,
CITATION used similar techniques to create a dataset of errors from the French Wikipedia.,,
Another possible source of real-word spelling errors are learner corpora CITATION, e.g.,,
Recently, the revision history of Wikipedia has been introduced as a valuable knowledge source for NLP (CITATION; CITATION).,,
Another possible source of real-word spelling errors are learner corpora CITATION, e.g.,,
the Cambridge Learner Corpus CITATION.,,
However, annotation of errors is difficult and costly CITATION, only a small fraction of observed errors will be real-word spelling errors, and learners are likely to make dif535 \x0cferent mistakes than proficient language users.,,
CITATION presented another statistical approach using the Google Web1T data CITATION to create the n-gram model.,,
Another possible source of real-word spelling errors are learner corpora CITATION, e.g.,,
the Cambridge Learner Corpus CITATION.,,
However, annotation of errors is difficult and costly CITATION, only a small fraction of observed errors will be real-word spelling errors, and learners are likely to make dif535 \x0cferent mistakes than proficient language users.,,
CITATION presented another statistical approach using the Google Web1T data CITATION to create the n-gram model.,,
006), the measure by CITATION yields the best results.,,
CITATION.,,
Some measures using a wider definition of semantic relatedness (CITATION; CITATIONb) instead of only using taxonomic relations in a knowledge source.,,
CITATION used a characteristic gap in the standard evaluation dataset by CITATION that separates unrelated from related word pairs.,,
5.1 Statistical Approach Table 1 summarizes the results obtained by the statistical approach using a trigram model based on the Google Web1T data CITATION.,,
 together with the JWPL Wikipedia API (CITATIONa).3 The API outputs plain text converted from Wiki-Markup, but the text still contains a small portion of leftover markup and other artifacts.,,
The remaining sentences are part-ofspeech tagged and lemmatized using TreeTagger CITATION.,,
ter recognition CITATION, co-reference resolution CITATION, or malapropism detection CITATION.,,
the quality of the optical character recognition module CITATION.,,
Besides typing mistakes, a major source of such errors is the failed attempt of automatic spelling correctors to correct a misspelled word CITATION.,,
1 Introduction Measuring the contextual fitness of a term in its context is a key component in different NLP applications like speech recognition CITATION, optical character recognition CITATION, co-reference resolution CITATION, or malapropism detection CITATION.,,
the quality of the optical character recognition module CITATION.,,
Besides typing mistakes, a major source of such errors is the failed attempt of automatic spelling correctors to correct a misspelled word CITATION.,,
Existing measures of contextual fitness can be categorized into knowledge-based CITATION and statistical methods (Mays et al., 1991; CITATION).,,
For that purpose, knowledge-based approaches employ the structural knowledge encoded in lexical-semantic networks like WordNet CITATION, while statistical approaches rely on co-occurrence counts collected from large corpora, e.g.,,
the Google Web1T corpus CITATION.,,
So far, evaluation of contextual fitness measures relied on artificial datasets (Mays et al., 1991; CITATION) which are created by taking a sentence that is known to be correct, and replacing a word with a similar word from the vocab,,
e Google Web1T data CITATION to create the n-gram model.,,
(1991), CITATION found that it outperformed the knowledge-based method by CITATION when evaluated on a corpus of artificial errors based on the WSJ corpus.,,
Recently, the revision history of Wikipedia has been introduced as a valuable knowledge source for NLP (CITATION; CITATION).,,
In the experiments by CITATION, the measure by CITATION yields the best results.,,
CITATION.,,
Some measures using a wider definition of semantic relatedness (CITATION; CITATIONb) instead of only using taxonomic relations in a knowledge source.,,
CITATION used a characteristic gap in the standard evaluation dataset by CITATION that separates unrelated from related word pairs.,,
2.1 Accessing the Revision Data We access the Wikipedia revision data using the freely available Wikipedia Revision Toolkit CITATION together with the JWPL Wikipedia API (CITATIONa).3 The API outputs plain text converted from Wiki-Markup, but the text still contains a small portion of leftover markup and other artifacts.,,
The remaining sentences are part-ofspeech tagged and lemmatized using TreeTagger CITATION.,,
In the experiments by CITATION, the measure by CITATION yields the best results.,,
CITATION.,,
Some measures using a wider definition of semantic relatedness (CITATION; CITATIONb) instead of only using taxonomic relations in a knowledge source.,,
CITATION used a characteristic gap in the standard evaluation dataset by CITATION that separates unrelated from related word pairs.,,
2.1 Accessing the Revision Data We access the Wikipedia revision data using the freely available Wikipedia Revision Toolkit CITATION together with the JWPL Wikipedia API (CITATIONa).3 The API outputs plain text converted from Wiki-Markup, but the text still contains a small portion of leftover markup and other artifacts.,,
The remaining sentences are part-ofspeech tagged and lemmatized using TreeTagger CITATION.,,
In the experiments by CITATION, the measure by CITATION yields the best results.,,
CITATION.,,
Some measures using a wider definition of semantic relatedness (CITATION; CITATIONb) instead of only using taxonomic relations in a knowledge source.,,
CITATION used a characteristic gap in the standard evaluation dataset by CITATION that separates unrelated from related word pairs.,,
