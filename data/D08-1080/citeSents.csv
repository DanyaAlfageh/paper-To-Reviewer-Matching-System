The most frequently used knowledge source in NLP in general, and also for summarization, is WordNet CITATION,,
CITATION use WordNet to model a texts content relative to a topic based on lexical chains,,
CITATION use the documents to be summarized themselves to cluster terms, and thus expanding the query internally,,
More advanced methods for query expansion use topic signatures words and grammatically related pairs of words that model the query and even the expected answer from sets of documents marked as relevant or not (CITATION; CITATION),,
Graph-based methods for text summarization work usually at the level of sentences (CITATION; CITATION),,
CITATION have shown that expanding the query within the set of documents leads to good results,,
4.1 Spreading Activation To find words/NEs related to the topic we spread an activation signal starting from the topic words and their expansions (in a manner similar to CITATION, and using an algorithm inspired by CITATION), which are given a node weight of 1,,
The body of research involving Wikipedia as a source of knowledge is growing fast, as the NLP community finds more and more applications of this useful resource: it is used to acquire knowledge (CITATION; CITATION); to induce taxonomies and compute semantic relatedness (Ponzetto & Strube, 2007b; 2007a); as a source of features for text classification CITATION and for answering questions (Ahn et al., 2004; CITATION),,
DUC (since 2008, Text Analysis Conference (TAC))1 events provide a forum for the comparison of a variety of approaches, ranging from knowledge poor CITATION rely exclusively on a parser, without any additional sources of information to knowledge rich and complex GISTexter CITATION combines question answering, textual entailment, topic signature modules and a va1 http://duc.nist.gov/, http://www.nist,,
The most frequently used knowledge source in NLP in general, and also for summarization, is WordNet CITATION,,
CITATION use WordNet to model a texts content relative to a topic based on lexical chains,,
CITATION use the documents to be summarized themselves to cluster terms, and thus expanding the query internally,,
After this initialization of the graph, we run a PageRank algorithm CITATION to determine more important nodes,,
Spreading activation was introduced in the 60s and 70s to model psychological processes of memory activation in humans (CITATION; CITATION),,
CITATION and CITATION have explored extractive summary formation, and have raised important evaluation issues for extractive summaries when compared to several human produced gold standards,,
The NIST organized competitions under the Document Understanding Conferences DUC (since 2008, Text Analysis Conference (TAC))1 events provide a forum for the comparison of a variety of approaches, ranging from knowledge poor CITATION rely exclusively on a parser, without any additional sources of in,,
CITATION use the documents to be summarized themselves to cluster terms, and thus expanding the query internally,,
More advanced methods for query expansion use topic signatures words and grammatically related pairs of words that model the query and even the expected answer from sets of documents marked as relevant or not (CITATION; CITATION),,
Graph-based methods for text summarization work usually at the level of sentences (CITATION; CITATION),,
At the word level, CITATION build a document graph using subject-verb-object triples, semantic normalization and coreference resolution,,
ding Conferences DUC (since 2008, Text Analysis Conference (TAC))1 events provide a forum for the comparison of a variety of approaches, ranging from knowledge poor CITATION rely exclusively on a parser, without any additional sources of information to knowledge rich and complex GISTexter CITATION combines question answering, textual entailment, topic signature modules and a va1 http://duc.nist.gov/, http://www.nist,,
The most frequently used knowledge source in NLP in general, and also for summarization, is WordNet CITATION,,
CITATION use WordNet to model a texts content relative to a topic based on lexical chains,,
CITATION use the documents to be summarized themselves to cluster terms, and thus expanding the query internally,,
The body of research involving Wikipedia as a source of knowledge is growing fast, as the NLP community finds more and more applications of this useful resource: it is used to acquire knowledge (CITATION; CITATION); to induce taxonomies and compute semantic relatedness (Ponzetto & Strube, 2007b; 2007a); as a source of features for text classification CITATION and for answering questions (Ahn et al., 2004; CITATION),,
CITATION and CITATION have explored extractive summary formation, and have raised important evaluation issues for extractive summaries when compared to several human produced gold standards,,
The NIST organized competitions under the Document Understanding Conferences DUC (since 2008, Text Analysis Conference (TAC))1 events provide a forum for the comparison of a variety of approaches, ranging from knowledge poor CITATION rely exclusively on a parser, without any additional sources of information to knowledge rich and complex GISTexter CITATION combines question answering, textual entailment, topic signature modules and a va1 http://duc.nist.gov/, http://www.nist,,
The most frequently used knowledge source in NLP in general, and also for summarization, is WordNet CITATION,,
CITATION use WordNet to model a texts content relative to a topic based on lexical chains,,
The PageRank algorithm is guaranteed to converge if the graph is aperiodic and irreducible CITATION,,
CITATION use the documents to be summarized themselves to cluster terms, and thus expanding the query internally,,
More advanced methods for query expansion use topic signatures words and grammatically related pairs of words that model the query and even the expected answer from sets of documents marked as relevant or not (CITATION; CITATION),,
Graph-based methods for text summarization work usually at the level of sentences (CITATION; CITATION),,
At the word level, CITATION build a document graph using subject-verb-object triples, semantic normalization and coreference resolution,,
The NIST organized competitions under the Document Understanding Conferences DUC (since 2008, Text Analysis Conference (TAC))1 events provide a forum for the comparison of a variety of approaches, ranging from knowledge poor CITATION rely exclusively on a parser, without any additional sources of information to knowledge rich and complex GISTexter CITATION combines question answering, textual entailment, topic signature modules and a va1 http://duc.nist.gov/, http://www.nist,,
The most frequently used knowledge source in NLP in general, and also for summarization, is WordNet CITATION,,
CITATION use WordNet to model a texts content relative to a topic based on lexical chains,,
The body of research involving Wikipedia as a source of knowledge is growing fast, as the NLP community finds more and more applications of this useful resource: it is used to acquire knowledge (CITATION; CITATION); to induce taxonomies and compute semantic relatedness (Ponzetto & Strube, 2007b; 2007a); as a source of features for text classification CITATION and for answering questions (Ahn et al., 2004; CITATION),,
We use a Lesk-like measure, and compute the overlap between the topic query and the set of hyperlinks in the first paragraph CITATION,,
 advanced methods for query expansion use topic signatures words and grammatically related pairs of words that model the query and even the expected answer from sets of documents marked as relevant or not (CITATION; CITATION),,
Graph-based methods for text summarization work usually at the level of sentences (CITATION; CITATION),,
At the word level, CITATION build a document graph using subject-verb-object triples, semantic normalization and coreference resolution,,
CITATION incrementally build a graph for a document collection by combining graph-representations of sentences,,
CITATION use the documents to be summarized themselves to cluster terms, and thus expanding the query internally,,
More advanced methods for query expansion use topic signatures words and grammatically related pairs of words that model the query and even the expected answer from sets of documents marked as relevant or not (CITATION; CITATION),,
Graph-based methods for text summarization work usually at the level of sentences (CITATION; CITATION),,
At the word level, CITATION build a document graph using subject-verb-object triples, semantic normalization and coreference resolution,,
CITATION build a chronological graph, in which sentence order is respected and each occurrence of a concept is a separate node,,
4.1 Spreading Activation To find words/NEs related to the topic we spread an activation signal starting from the topic words and their expansions (in a manner similar to CITATION, and using an algorithm inspired by CITATION), which are given a node weight of 1,,
CITATION use the documents to be summarized themselves to cluster terms, and thus expanding the query internally,,
More advanced methods for query expansion use topic signatures words and grammatically related pairs of words that model the query and even the expected answer from sets of documents marked as relevant or not (CITATION; CITATION),,
Graph-based methods for text summarization work usually at the level of sentences (CITATION; CITATION),,
At the word level, CITATION build a document graph using subject-verb-object triples, semantic normalization and coreference resolution,,
At the word level, CITATION build a document graph using subject-verb-object triples, semantic normalization and coreference resolution,,
CITATION incrementally build a graph for a document collection by combining graph-representations of sentences,,
CITATION build an extractive summary based on a concept lattice, which captures in a hierarchical structure co-occurrences of concepts among sentences,,
Spreading activation was introduced in the 60s and 70s to model psychological processes of memory activation in humans (CITATION; CITATION),,
CITATION and CITATION have explored extractive summary formation, and have raised important evaluation issues for extractive summaries when compared to several human produced gold standards,,
The NIST organized competitions under the Document Understanding Conferences DUC (since 2008, Text Analysis Conference (TAC))1 events provide a forum for the comparison of a variety of approaches, ranging from knowledge poor CITATION rely exclusively on a parser, without any add,,
The body of research involving Wikipedia as a source of knowledge is growing fast, as the NLP community finds more and more applications of this useful resource: it is used to acquire knowledge (CITATION; CITATION); to induce taxonomies and compute semantic relatedness (Ponzetto & Strube, 2007b; 2007a); as a source of features for text classification CITATION and for answering questions (Ahn et al., 2004; CITATION),,
CITATION incrementally build a graph for a document collection by combining graph-representations of sentences,,
CITATION build an extractive summary based on a concept lattice, which captures in a hierarchical structure co-occurrences of concepts among sentences,,
