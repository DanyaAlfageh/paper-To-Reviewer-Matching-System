For example, one could employ crowd workers to provide feedback on whether distant supervision examples are correct or not CITATION.,,
abilistic models; such models have recently been used to relax various assumptions of distant supervision (CITATION; CITATION; CITATION).,,
CITATION and CITATION study the quality-control issue for collecting training labels via crowdsourcing.,,
CITATION study how to acquire end-user feedback on relation-extraction results posted on an augmented Wikipedia site; it is interesting future work to integrate this source in our experiments.,,
We then solicit human labeling from Mechanical Turk (MTurk) while applying state-of-the-art quality control protocols following CITATION and those in the MTurk manual.10 These quality-control protocols are critical to ensure high quality: spamming is common on MTurk and some turkers may not be as proficient or careful as expected.,,
Entities are conceptual objects that exist in the world (e.g., Barack Obama), whereas authors use a variety of wordings to refer to (which we call mention) entities in text CITATION.,,
2 Related Work The idea of using entity-level structured data (e.g., facts in a database) to generate mention-level training data (e.g., in English text) is a classic one: researchers have used variants of this idea to extract entities of a certain type from webpages (CITATION; Brin, 1999).,,
Since CITATION coined the name distant supervision, there has been growing interest in this technique.,,
For example, distant supervision has been used for the TAC-KBP slot-filling tasks CITATION and other relation-extraction tasks (CITATION; Carlson et al., 2010; CITATIONa; CITATIONb).,,
CITATION and CITATION study the quality-control issue for collecting training labels via crowdsourcing.,,
CITATION study how to acquire end-user feedback on relation-extraction results posted on an augmented Wikipedia site; it is interesting future work to integrate this source in our experiments.,,
We tried several active-learning techniques as described by CITATION, but did not observe any notable advantage over uniform sampling-based example selection.3 3 Distant Supervision Methodology Relation extraction is the task of identifying relationships between mentions, in natural-language text, of entities.,,
data (e.g., in English text) is a classic one: researchers have used variants of this idea to extract entities of a certain type from webpages (CITATION; Brin, 1999).,,
Since CITATION coined the name distant supervision, there has been growing interest in this technique.,,
For example, distant supervision has been used for the TAC-KBP slot-filling tasks CITATION and other relation-extraction tasks (CITATION; Carlson et al., 2010; CITATIONa; CITATIONb).,,
While the largest corpus (Wikipedia and New York Times) employed by recent work on distant supervision (CITATION; CITATION; CITATION) contain about 2M documents, we run experiments on a 100M-document (50X more) corpus drawn from ClueWeb.1 While prior work CITATION on crowdsourcing for distant supervision used thousands of human feedback units, we acquire tens of thousands of human-provided labels.,,
abilistic models; such models have recently been used to relax various assumptions of distant supervision (CITATION; CITATION; CITATION).,,
CITATION and CITATION study the quality-control issue for collecting training labels via crowdsourcing.,,
 by generating what are known as silver-standard examples CITATION.,,
Following recent work (CITATION; CITATION; CITATION), we use Freebase5 as the knowledge base for seed facts.,,
We denote the relation that describes this mapping as the relation EL(e, m) where e E is an entity in the database D and m is a mention in the corpus C. For each relation Ri, we generate a set of (noisy) positive examples denoted R+ i defined as R+ i = {(m1, m2) |R(e1, e2) EL(e1, m1) EL(e2, m2)} As in previous work, we impose the constraint that both mentions (m1, m2) R+ i are contained in the same sentence (CITATION; CITATION; CITATION).,,
To generate negative examples for each relation, we follow the assumption in CITATION that relations are disjoint and sample from other relations, i.e., R i = j6=iR+ j .,,
Following recent work on distant supervision (CITATION; CITATION; CITATION), we use both lexical and syntactic features.,,
Interestingly, the Freebase held-out metric (CITATION; CITATION; CITATION) turns out to be heavily biased toward distantly labeled data (e.g., increasing human feedback hurts precision; see Section 4.6).,,
4.6 Freebase Held-out Metric In addition to the TAC-KBP benchmark, we also follow prior work (CITATION; CITATION; CITATION) and measure the quality using held-out data from Freebase.,,
Entities are conceptual objects that exist in the world (e.g., Barack Obama), whereas authors use a variety of wordings to refer to (which we call mention) entities in text CITATION.,,
2 Related Work The idea of using entity-level structured data (e.g., facts in a database) to generate mention-level training data (e.g., in English text) is a classic one: researchers have used variants of this idea to extract entities of a certain type from webpages (CITATION; Brin, 1999).,,
Since CITATION coined the name distant supervision, there has been growing interest in this technique.,,
To remedy these problems, recent years have seen interest in the distant supervision approach for relation extraction (CITATION; CITATION).,,
While the largest corpus (Wikipedia and New York Times) employed by recent work on distant supervision (CITATION; CITATION; CITATION) contain about 2M documents, we run experiments on a 100M-document (50X more) corpus drawn from ClueWeb.1 While prior work CITATION on crowdsourcing for distant supervision used thousands of human feedback units, we acquire tens of thousands of human-provided labels.,,
ack Obama), whereas authors use a variety of wordings to refer to (which we call mention) entities in text CITATION.,,
2 Related Work The idea of using entity-level structured data (e.g., facts in a database) to generate mention-level training data (e.g., in English text) is a classic one: researchers have used variants of this idea to extract entities of a certain type from webpages (CITATION; Brin, 1999).,,
Since CITATION coined the name distant supervision, there has been growing interest in this technique.,,
For example, distant supervision has been used for the TAC-KBP slot-filling tasks CITATION and other relation-extraction tasks (CITATION; Carlson et al., 2010; CITATIONa; CITATIONb).,,
technical report CITATION.,,
At each step of the distant supervision process, we closely follow the recent literature (CITATION; CITATION).,,
3.1 Distant Supervision Distant supervision compensates for a lack of training examples by generating what are known as silver-standard examples CITATION.,,
We denote the relation that describes this mapping as the relation EL(e, m) where e E is an entity in the database D and m is a mention in the corpus C. For each relation Ri, we generate a set of (noisy) positive examples denoted R+ i defined as R+ i = {(m1, m2) |R(e1, e2) EL(e1, m1) EL(e2, m2)} As in previous work, we impose the constraint that both mentions (m1, m2) R+ i are contained in the same sentence (CITATION; CITATION; CITATION).,,
To generate negative examples for each relation, we follow the assumption in CITATION that relations are disjoint and sample from other relations, i.e., R i = j6=iR+ j .,,
Following recent work on distant supervision (CITATION; CITATION; CITATION), we us,,
3.4 Statistical Modeling Issues Following CITATION, we use logistic regression classifiers to represent relation extractors.,,
Interestingly, the Freebase held-out metric (CITATION; CITATION; CITATION) turns out to be heavily biased toward distantly labeled data (e.g., increasing human feedback hurts precision; see Section 4.6).,,
4.6 Freebase Held-out Metric In addition to the TAC-KBP benchmark, we also follow prior work (CITATION; CITATION; CITATION) and measure the quality using held-out data from Freebase.,,
: researchers have used variants of this idea to extract entities of a certain type from webpages (CITATION; Brin, 1999).,,
Since CITATION coined the name distant supervision, there has been growing interest in this technique.,,
For example, distant supervision has been used for the TAC-KBP slot-filling tasks CITATION and other relation-extraction tasks (CITATION; Carlson et al., 2010; CITATIONa; CITATIONb).,,
: researchers have used variants of this idea to extract entities of a certain type from webpages (CITATION; Brin, 1999).,,
Since CITATION coined the name distant supervision, there has been growing interest in this technique.,,
For example, distant supervision has been used for the TAC-KBP slot-filling tasks CITATION and other relation-extraction tasks (CITATION; Carlson et al., 2010; CITATIONa; CITATIONb).,,
We use sparse logistic regression (`1 regularized) CITATION, which is used in previous studies.,,
Run dependency parsing on TAC with the Ensemble parser CITATION and on ClueWeb with MaltParser CITATION8; and 3.,,
abilistic models; such models have recently been used to relax various assumptions of distant supervision (CITATION; CITATION; CITATION).,,
CITATION and CITATION study the quality-control issue for collecting training labels via crowdsourcing.,,
CITATION study how to acquire end-user feedback on relation-extraction results posted on an augmented Wikipedia site; it is interesting future work to integrate this source in our experiments.,,
We tried several active-learning techniques as described by CITATION, but did not observe any notable advantage over uniform sampling-based example selection.3 3 Distant Supervision Methodology Relation extraction is the task of identifying relationships between mentions, in natural-language text, of entities.,,
Given a corpus C con3 More details in our technical report CITATION.,,
abilistic models; such models have recently been used to relax various assumptions of distant supervision (CITATION; CITATION; CITATION).,,
CITATION and CITATION study the quality-control issue for collecting training labels via crowdsourcing.,,
CITATION study how to acquire end-user feedback on relation-extraction results posted on an augmented Wikipedia site; it is interesting future work to integrate this source in our experiments.,,
distant supervision (CITATION; CITATION; CITATION), we use both lexical and syntactic features.,,
We use sparse logistic regression (`1 regularized) CITATION, which is used in previous studies.,,
Run dependency parsing on TAC with the Ensemble parser CITATION and on ClueWeb with MaltParser CITATION8; and 3.,,
g., facts in a database) to generate mention-level training data (e.g., in English text) is a classic one: researchers have used variants of this idea to extract entities of a certain type from webpages (CITATION; Brin, 1999).,,
Since CITATION coined the name distant supervision, there has been growing interest in this technique.,,
For example, distant supervision has been used for the TAC-KBP slot-filling tasks CITATION and other relation-extraction tasks (CITATION; Carlson et al., 2010; CITATIONa; CITATIONb).,,
Following recent work on distant supervision (CITATION; CITATION; CITATION), we use both lexical and syntactic features.,,
We use sparse logistic regression (`1 regularized) CITATION, which is used in previous studies.,,
Run dependency parsing on TAC with the Ensemble parser CITATION and on ClueWeb with MaltParser CITATION8; and 3.,,
To remedy these problems, recent years have seen interest in the distant supervision approach for relation extraction (CITATION; CITATION).,,
At each step of the distant supervision process, we closely follow the recent literature (CITATION; CITATION).,,
3.1 Distant Supervision Distant supervision compensates for a lack of training examples by generating what are known as silver-standard examples CITATION.,,
Following recent work (CITATION; CITATION; CITATION), we use Freebase5 as the knowledge base for seed facts,,
While the largest corpus (Wikipedia and New York Times) employed by recent work on distant supervision (CITATION; CITATION; CITATION) contain about 2M documents, we run experiments on a 100M-document (50X more) corpus drawn from ClueWeb.1 While prior work CITATION on crowdsourcing for distant supervision used thousands of human feedback units, we acquire tens of thousands of human-provided labels.,,
abilistic models; such models have recently been used to relax various assumptions of distant supervision (CITATION; CITATION; CITATION).,,
CITATION and CITATION study the quality-control issue for collecting training labels via crowdsourcing.,,
At each step of the distant supervision process, we closely follow the recent literature (CITATION; CITATION).,,
3.1 Distant Supervision Distant supervision compensates for a lack of training examples by generating what are known as silver-standard examples CITATION.,,
We denote the relation that describes this mapping as the relation EL(e, m) where e E is an entity in the database D and m is a mention in the corpus C. For each relation Ri, we generate a set of (noisy) positive examples denoted R+ i defined as R+ i = {(m1, m2) |R(e1, e2) EL(e1, m1) EL(e2, m2)} As in previous work, we impose the constraint that both mentions (m1, m2) R+ i are contained in the same sentence (CITATION; CITATION; CITATION).,,
To generate negative examples for each relation, we follow the assumption in CITATION that relations are disjoint and sample from other relations, i.e., R i = j6=iR+ j .,,
Following recent work on distant supervision (CITATION; CITATION; CITATION), we use both lexical and,,
Interestingly, the Freebase held-out metric (CITATION; CITATION; CITATION) turns out to be heavily biased toward distantly labeled data (e.g., increasing human feedback hurts precision; see Section 4.6).,,
4.6 Freebase Held-out Metric In addition to the TAC-KBP benchmark, we also follow prior work (CITATION; CITATION; CITATION) and measure the quality using held-out data from Freebase.,,
We tried several active-learning techniques as described by CITATION, but did not observe any notable advantage over uniform sampling-based example selection.3 3 Distant Supervision Methodology Relation extraction is the task of identifying relationships between mentions, in natural-language text, of entities.,,
Given a corpus C con3 More details in our technical report CITATION.,,
At each step of the distant supervision process, we closely follow the recent literature (CITATION; CITATION),,
12 More details in our technical report CITATION.,,
14 We report more details on per-relation quality in our technical report CITATION.,,
