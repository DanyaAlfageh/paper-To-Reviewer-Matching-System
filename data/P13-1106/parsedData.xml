<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.303698">
b&amp;quot;Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 10731082,
</note>
<address confidence="0.482612">
Sofia, Bulgaria, August 4-9 2013. c
</address>
<title confidence="0.652196333333333">
2013 Association for Computational Linguistics
Joint Word Alignment and Bilingual Named Entity Recognition
Using Dual Decomposition
</title>
<author confidence="0.952322">
Mengqiu Wang
</author>
<affiliation confidence="0.983549">
Stanford University
</affiliation>
<address confidence="0.964338">
Stanford, CA 94305
</address>
<email confidence="0.994177">
mengqiu@cs.stanford.edu
</email>
<author confidence="0.975888">
Wanxiang Che
</author>
<affiliation confidence="0.998022">
Harbin Institute of Technology
</affiliation>
<address confidence="0.996743">
Harbin, China, 150001
</address>
<email confidence="0.992251">
car@ir.hit.edu.cn
</email>
<author confidence="0.995348">
Christopher D. Manning
</author>
<affiliation confidence="0.995772">
Stanford University
</affiliation>
<address confidence="0.969435">
Stanford, CA 94305
</address>
<email confidence="0.996617">
manning@cs.stanford.edu
</email>
<sectionHeader confidence="0.990063" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.997044464285715">
Translated bi-texts contain complemen-
tary language cues, and previous work
on Named Entity Recognition (NER)
has demonstrated improvements in perfor-
mance over monolingual taggers by pro-
moting agreement of tagging decisions be-
tween the two languages. However, most
previous approaches to bilingual tagging
assume word alignments are given as fixed
input, which can cause cascading errors.
We observe that NER label information
can be used to correct alignment mis-
takes, and present a graphical model that
performs bilingual NER tagging jointly
with word alignment, by combining two
monolingual tagging models with two uni-
directional alignment models. We intro-
duce additional cross-lingual edge factors
that encourage agreements between tag-
ging and alignment decisions. We design
a dual decomposition inference algorithm
to perform joint decoding over the com-
bined alignment and NER output space.
Experiments on the OntoNotes dataset
demonstrate that our method yields signif-
icant improvements in both NER and word
alignment over state-of-the-art monolin-
gual baselines.
</bodyText>
<sectionHeader confidence="0.99809" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9995352">
We study the problem of Named Entity Recogni-
tion (NER) in a bilingual context, where the goal
is to annotate parallel bi-texts with named entity
tags. This is a particularly important problem for
machine translation (MT) since entities such as
person names, locations, organizations, etc. carry
much of the information expressed in the source
sentence. Recognizing them provides useful in-
formation for phrase detection and word sense dis-
ambiguation (e.g., melody as in a female name
has a different translation from the word melody
in a musical sense), and can be directly leveraged
to improve translation quality (Babych and Hart-
ley, 2003). We can also automatically construct a
named entity translation lexicon by annotating and
extracting entities from bi-texts, and use it to im-
prove MT performance (Huang and Vogel, 2002;
Al-Onaizan and Knight, 2002). Previous work
such as Burkett et al. (2010b), Li et al. (2012) and
Kim et al. (2012) have also demonstrated that bi-
texts annotated with NER tags can provide useful
additional training sources for improving the per-
formance of standalone monolingual taggers.
Because human translation in general preserves
semantic equivalence, bi-texts represent two per-
spectives on the same semantic content (Burkett et
al., 2010b). As a result, we can find complemen-
tary cues in the two languages that help to dis-
ambiguate named entity mentions (Brown et al.,
1991). For example, the English word Jordan
can be either a last name or a country. Without
sufficient context it can be difficult to distinguish
the two; however, in Chinese, these two senses are
disambiguated: as a last name, and
as a country name.
In this work, we first develop a bilingual NER
model (denoted as BI-NER) by embedding two
monolingual CRF-based NER models into a larger
undirected graphical model, and introduce addi-
tional edge factors based on word alignment (WA).
Because the new bilingual model contains many
cyclic cliques, exact inference is intractable. We
employ a dual decomposition (DD) inference al-
gorithm (Bertsekas, 1999; Rush et al., 2010) for
performing approximate inference. Unlike most
</bodyText>
<page confidence="0.964678">
1073
</page>
<table confidence="0.4166515">
\x0cf1 f2 f3 f4 f5 f6
e1 e2 e3 e4 e5 e6
Xinhua News Agency Beijing Feb 16
B-ORG I-ORG I-ORG [O] B-LOC O O
, ,
B-ORG O B-GPE O O O
</table>
<figureCaption confidence="0.999749">
Figure 1: Example of NER labels between two word-aligned bilingual parallel sentences. The [O] tag is
</figureCaption>
<bodyText confidence="0.99587975">
an example of a wrong tag assignment. The dashed alignment link between e3 and f2 is an example of
alignment error.
previous applications of the DD method in NLP,
where the model typically factors over two com-
ponents and agreement is to be sought between the
two (Rush et al., 2010; Koo et al., 2010; DeNero
and Macherey, 2011; Chieu and Teow, 2012), our
method decomposes the larger graphical model
into many overlapping components where each
alignment edge forms a separate factor. We design
clique potentials over the alignment-based edges
to encourage entity tag agreements. Our method
does not require any manual annotation of word
alignments or named entities over the bilingual
training data.
The aforementioned BI-NER model assumes
fixed alignment input given by an underlying word
aligner. But the entity span and type predictions
given by the NER models contain complementary
information for correcting alignment errors. To
capture this source of information, we present a
novel extension that combines the BI-NER model
with two uni-directional HMM-based alignment
models, and perform joint decoding of NER and
word alignments. The new model (denoted as
BI-NER-WA) factors over five components: one
NER model and one word alignment model for
each language, plus a joint NER-alignment model
which not only enforces NER label agreements but
also facilitates message passing among the other
four components. An extended DD decoding algo-
rithm is again employed to perform approximate
inference.
We give a formal definition of the Bi-NER
model in Section 2, and then move to present the
Bi-NER-WA model in Section 3.
</bodyText>
<sectionHeader confidence="0.895983" genericHeader="introduction">
2 Bilingual NER by Agreement
</sectionHeader>
<bodyText confidence="0.996035375">
The inputs to our models are parallel sentence
pairs (see Figure 1 for an example in English and
Chinese). We denote the sentences as e (for En-
glish) and f (for Chinese). We assume access
to two monolingual linear-chain CRF-based NER
models that are already trained. The English-side
CRF model assigns the following probability for a
tag sequence ye:
</bodyText>
<equation confidence="0.542246333333333">
PCRFe (ye
|e) =
Q
viVe
(vi)
Q
(vi,vj)De
(vi, vj)
Ze(e)
</equation>
<bodyText confidence="0.993929428571429">
where Ve is the set of vertices in the CRF and
De is the set of edges. (vi) and (vi, vj) are
the node and edge clique potentials, and Ze(e)
is the partition function for input sequence e un-
der the English CRF model. We let k(ye) be the
un-normalized log-probability of tag sequence ye,
defined as:
</bodyText>
<equation confidence="0.9518785">
k(ye
) = log
Y
viVe
(vi)
Y
(vi,vj)De
(vi, vj)
</equation>
<bodyText confidence="0.971656">
Similarly, we define model PCRFf
and un-
normalized log-probability l(yf) for Chinese.
We also assume that a set of word alignments
(A = {(i, j) : ei fj}) is given by a word
aligner and remain fixed in our model.
For clarity, we assume ye and yf are binary vari-
ables in the description of our algorithms. The ex-
tension to the multi-class case is straight-forward
and does not affect the core algorithms.
</bodyText>
<subsectionHeader confidence="0.985325">
2.1 Hard Agreement
</subsectionHeader>
<bodyText confidence="0.976170333333333">
We define a BI-NER model which imposes hard
agreement of entity labels over aligned word pairs.
At inference time, we solve the following opti-
</bodyText>
<page confidence="0.960638">
1074
</page>
<equation confidence="0.8630418">
\x0cmization problem:
max
ye,yf
log (PCRFe (ye
)) + log PCRFf
yf
\x01\x01
= max
ye,yf
k(ye
) + l(yf
) log Ze(e) log Zf (f)
&amp;apos; max
ye,yf
k(ye
) + l(yf
)
3 ye
i = yf
j (i, j) A
</equation>
<bodyText confidence="0.993325">
We dropped the Ze(e) and Zf(f) terms because
they remain constant at inference time.
The Lagrangian relaxation of this term is:
</bodyText>
<equation confidence="0.995552647058824">
L ye
, yf
, U
\x01
=
k (ye
) + l yf
\x01
+
X
(i,j)A
u(i, j)
\x10
ye
i yf
j
\x11
</equation>
<bodyText confidence="0.92681775">
where u(i, j) are the Lagrangian multipliers.
Instead of solving the Lagrangian directly, we
can form the dual of this problem and solve it us-
ing dual decomposition (Rush et al., 2010):
</bodyText>
<equation confidence="0.982881157894737">
min
U
max
ye
k (ye
) +
X
(i,j)A
u(i, j)ye
i
+ max
yf
l yf
\x01
X
(i,j)A
u(i, j)yf
j
!
</equation>
<bodyText confidence="0.998663133333333">
Similar to previous work, we solve this DD
problem by iteratively updating the sub-gradient
as depicted in Algorithm 1. T is the maximum
number of iterations before early stopping, and t
is the learning rate at time t. We adopt a learning
rate update rule from Koo et al. (2010) where t is
defined as 1
N , where N is the number of times we
observed a consecutive dual value increase from
iteration 1 to t.
A thorough introduction to the theoretical foun-
dations of dual decomposition algorithms is be-
yond the scope of this paper; we encourage un-
familiar readers to read Rush and Collins (2012)
for a full tutorial.
</bodyText>
<subsectionHeader confidence="0.998621">
2.2 Soft Agreement
</subsectionHeader>
<bodyText confidence="0.829062153846154">
The previously discussed hard agreement model
rests on the core assumption that aligned words
must have identical entity tags. In reality, however,
this assumption does not always hold. Firstly, as-
suming words are correctly aligned, their entity
tags may not agree due to inconsistency in anno-
tation standards. In Figure 1, for example, the
Algorithm 1 DD inference algorithm for hard
agreement model.
(i, j) A : u(i, j) = 0
for t 1 to T do
ye
argmax k (ye
</bodyText>
<equation confidence="0.99249040625">
) +
P
(i,j)A
u(i, j)ye
i
yf
argmax l yf
\x01
P
(i,j)A
u(i, j)yf
j
if (i, j) A: ye
i = yf
j then
return ye
, yf
\x01
end if
for all (i, j) A do
u(i, j) u(i, j) + t
\x10
yf
j ye
i
\x11
end for
end for
return ye
(T), yf
(T)
\x01
</equation>
<bodyText confidence="0.988015071428571">
word Beijing can be either a Geo-Political En-
tity (GPE) or a location. The Chinese annotation
standard may enforce that Beijing should always
be tagged as GPE when it is mentioned in isola-
tion, while the English standard may require the
annotator to judge based on word usage context.
The assumption in the hard agreement model can
also be violated if there are word alignment errors.
In order to model this uncertainty, we extend
the two previously independent CRF models into a
larger undirected graphical model, by introducing
a cross-lingual edge factor (i, j) for every pair of
word positions (i, j) A. We associate a clique
potential function h(i,j)(ye
</bodyText>
<equation confidence="0.9791318125">
i , yf
j) for (i, j):
h(i,j)
\x10
ye
i , yf
j
\x11
= pmi
\x10
ye
i , yf
j
\x11P(ei,fj)
where pmi(ye
i , yf
</equation>
<bodyText confidence="0.999069157894737">
j) is the point-wise mutual in-
formation (PMI) of the tag pair, and we raise it
to the power of a posterior alignment probability
P(ei, fj). For a pair of NEs that are aligned with
low probability, we cannot be too sure about the
association of the two NEs, therefore the model
should not impose too much influence from the
bilingual agreement model; instead, we will let the
monolingual NE models make their decisions, and
trust that those are the best estimates we can come
up with when we do not have much confidence in
their bilingual association. The use of the poste-
rior alignment probability facilitates this purpose.
Initially, each of the cross-lingual edge factors
will attempt to assign a pair of tags that has the
highest PMI score, but if the monolingual taggers
do not agree, a penalty will start accumulating
over this pair, until some other pair that agrees bet-
ter with the monolingual models takes the top spot.
</bodyText>
<page confidence="0.976873">
1075
</page>
<bodyText confidence="0.999566136363636">
\x0cSimultaneously, the monolingual models will also
be encouraged to agree with the cross-lingual edge
factors. This way, the various components effec-
tively trade penalties indirectly through the cross-
lingual edges, until a tag sequence that maximizes
the joint probability is achieved.
Since we assume no bilingually annotated NER
corpus is available, in order to get an estimate of
the PMI scores, we first tag a collection of unan-
notated bilingual sentence pairs using the mono-
lingual CRF taggers, and collect counts of aligned
entity pairs from this auto-generated tagged data.
Each of the (i, j) edge factors (e.g., the edge
between node f3 and e4 in Figure 1) overlaps with
each of the two CRF models over one vertex (e.g.,
f3 on Chinese side and e4 on English side), and
we seek agreement with the Chinese CRF model
over tag assignment of fj, and similarly for ei on
English side. In other words, no direct agreement
between the two CRF models is enforced, but they
both need to agree with the bilingual edge factors.
The updated optimization problem becomes:
</bodyText>
<equation confidence="0.994129636363636">
max
ye(k)
yf(l)
ye(h)
yf(h)
k
\x10
ye(k)
\x11
+ l
\x10
yf(l)
\x11
+
X
(i,j)A
h(i,j)
\x10
ye(h)
i , yf(h)
j
\x11
3 (i, j) A:
\x10
ye(k)
i = ye(h)
i
\x11
\x10
yf(l)
j = yf(h)
j
\x11
</equation>
<bodyText confidence="0.95790576">
where the notation ye(k)
i denotes tag assignment to
word ei by the English CRF and ye(h)
i denotes as-
signment to word ei by the bilingual factor; yf(l)
j
denotes the tag assignment to word fj by the Chi-
nese CRF and yf(h)
j denotes assignment to word
fj by the bilingual factor.
The updated DD algorithm is illustrated in Al-
gorithm 2 (case 2). We introduce two separate
sets of dual constraints we and wf, which range
over the set of vertices on their respective half
of the graph. Decoding the edge factor model
h(i,j)(ye
i , yf
j) simply involves finding the pair of
tag assignments that gives the highest PMI score,
subject to the dual constraints.
The way DD algorithms work in decomposing
undirected graphical models is analogous to other
message passing algorithms such as loopy belief
propagation, but DD gives a stronger optimality
guarantee upon convergence (Rush et al., 2010).
</bodyText>
<sectionHeader confidence="0.780937" genericHeader="method">
3 Joint Alignment and NER Decoding
</sectionHeader>
<bodyText confidence="0.99866322">
In this section we develop an extended model in
which NER information can in turn be used to
improve alignment accuracy. Although we have
seen more than a handful of recent papers that ap-
ply the dual decomposition method for joint in-
ference problems, all of the past work deals with
cases where the various model components have
the same inference output space (e.g., dependency
parsing (Koo et al., 2010), POS tagging (Rush et
al., 2012), etc.). In our case the output space is
the much more complex joint alignment and NER
tagging space. We propose a novel dual decom-
position variant for performing inference over this
joint space.
Most commonly used alignment models, such
as the IBM models and HMM-based aligner are
unsupervised learners, and can only capture sim-
ple distortion features and lexical translational fea-
tures due to the high complexity of the structure
prediction space. On the other hand, the CRF-
based NER models are trained on manually anno-
tated data, and admit richer sequence and lexical
features. The entity label predictions made by the
NER model can potentially be leveraged to correct
alignment mistakes. For example, in Figure 1, if
the tagger knows that the word Agency is tagged
I-ORG, and if it also knows that the first comma
in the Chinese sentence is not part of any entity,
then we can infer it is very unlikely that there ex-
ists an alignment link between Agency and the
comma.
To capture this intuition, we extend the BI-NER
model to jointly perform word alignment and NER
decoding, and call the resulting model BI-NER-
WA. As a first step, instead of taking the output
from an aligner as fixed input, we incorporate two
uni-directional aligners into our model. We name
the Chinese-to-English aligner model as m(Be)
and the reverse directional model n(Bf ). Be is
a matrix that holds the output of the Chinese-to-
English aligner. Each be(i, j) binary variable in
Be indicates whether fj is aligned to ei; similarly
we define output matrix Bf and bf (i, j) for Chi-
nese. In our experiments, we used two HMM-
based alignment models. But in principle we can
adopt any alignment model as long as we can per-
form efficient inference over it.
We introduce a cross-lingual edge factor (i, j)
in the undirected graphical model for every pair of
word indices (i, j), which predicts a binary vari-
</bodyText>
<page confidence="0.953579">
1076
</page>
<listItem confidence="0.70163">
\x0cAlgorithm 2 DD inference algorithm for joint
alignment and NER model. A line marked with (2)
means it applies to the BI-NER model; a line marked with
(3) means it applies to the BI-NER-WA model.
</listItem>
<equation confidence="0.997936125">
S A (2)
S {(i, j): i |e|, j |f|} (3)
i |e |: we
i = 0; j |f |: wf
j = 0 (2,3)
(i, j) S : de
(i, j) = 0, df
(i, j) = 0 (3)
</equation>
<bodyText confidence="0.577637">
for t 1 to T do
</bodyText>
<equation confidence="0.948088902777779">
ye(k)
argmax k
\x10
ye(k)
\x11
+
P
i|e|
we
i ye(k)
i (2,3)
yf(l)
argmax l
\x10
yf(l)
\x11
+
P
i|f|
wf
j yf(l)
j (2,3)
Be
argmax m (Be
) +
P
(i,j)
de
(i, j)be
(i, j) (3)
Bf
argmax n Bf
\x01
+
P
(i,j)
df
(i, j)bf
(i, j) (3)
for all (i, j) S do
(ye(h)
i yf(h)
j ) we
i ye(h)
i wf
j yf(h)
j
+ argmax h(i,j)(ye(q)
i yf(q)
j ) (2)
(ye(q)
i yf(q)
j a(i, j)
) we
i ye(q)
i wf
j yf(q)
j
+ argmax q(i,j)(ye(q)
i yf(q)
j a(i, j))
de
(i, j)a(i, j) df
(i, j)a(i, j) (3)
end for
Conv = (ye(k)
=ye(q)
yf(l)
=yf(q)
) (2)
Conv = (Be
=A=Bf
ye(k)
=ye(q)
yf(l)
=yf(q)
) (3)
if Conv = true , then
return
\x10
ye(k)
, yf(l)
\x11
(2)
return
\x10
ye(k)
, yf(l)
, A
\x11
(3)
else
for all i |e |do
we
i we
i + t
\x10
ye(q|h)
i ye(k)
i
\x11
(2,3)
end for
for all j |f |do
wf
j wf
j + t
\x10
yf(q|h)
j yf(l)
j
\x11
(2,3)
end for
for all (i, j) S do
de
(i, j) de
(i, j) + t (ae
(i, j) be
(i, j)) (3)
df
(i, j) df
(i, j) + t af
(i, j) bf
(i, j)
\x01
(3)
end for
end if
end for
return
\x10
ye(k)
(T) , yf(l)
(T)
\x11
(2)
return
\x10
ye(k)
(T) , yf(l)
(T) , A(T )
\x11
(3)
</equation>
<bodyText confidence="0.983208">
able a(i, j) for an alignment link between ei and
fj. The edge factor also predicts the entity tags for
ei and fj.
The new edge potential q is defined as:
</bodyText>
<equation confidence="0.997041157894737">
q(i,j)
\x10
ye
i , yf
j, a(i, j)
\x11
=
log(P(a(i, j) = 1)) + S(ye
i , yf
j|a(i, j))P(a(i,j)=1)
S(ye
i , yf
j|a(i, j))=
(
pmi(ye
i , yf
j), if a(i, j) = 1
0, else
P(a(i, j) = 1) is the alignment probability as-
</equation>
<bodyText confidence="0.855458">
signed by the bilingual edge factor between node
ei and fj. We initialize this value to P(ei, fj) =
</bodyText>
<equation confidence="0.9277115">
1
2(Pm(ei, fj) + Pn(ei, fj)), where Pm(ei, fj) and
</equation>
<bodyText confidence="0.806383666666667">
Pn(ei, fj) are the posterior probabilities assigned
by the HMM-aligners.
The joint optimization problem is defined as:
</bodyText>
<equation confidence="0.995966709677419">
max
ye(k)
yf(l)
ye(h)
yf(h)
BeBfA
k(ye(k)
) + l(yf(l)
)+
m(Be
) + n(Bf
) +
X
(i|e|,j|f|)
q(i,j)(yeh
i , yf(h)
j , a(i, j))
3 (i, j): be
(i, j)=a(i, j)
\x01
bf
(i, j)=a(i, j)
\x01
if a(i, j) = 1 then ye(k)
i =ye(h)
i
\x01
yf(l)
j =yf(h)
j
\x01
</equation>
<bodyText confidence="0.998708161290322">
We include two dual constraints de(i, j) and
df (i, j) over alignments for every bilingual edge
factor (i, j), which are applied to the English and
Chinese sides of the alignment space, respectively.
The DD algorithm used for this model is given
in Algorithm 2 (case 3). One special note is that
after each iteration when we consider updates to
the dual constraint for entity tags, we only check
tag agreements for cross-lingual edge factors that
have an alignment assignment value of 1. In other
words, cross-lingual edges that are not aligned do
not affect bilingual NER tagging.
Similar to (i, j), (i, j) factors do not provide
that much additional information other than some
selectional preferences via PMI score. But the
real power of these cross-language edge cliques
is that they act as a liaison between the NER
and alignment models on each language side, and
encourage these models to indirectly agree with
each other by having them all agree with the edge
cliques.
It is also worth noting that since we decode
the alignment models with Viterbi inference, ad-
ditional constraints such as the neighborhood con-
straint proposed by DeNero and Macherey (2011)
can be easily integrated into our model. The
neighborhood constraint enforces that if fj is
aligned to ei, then fj can only be aligned to ei+1
or ei1 (with a small penalty), but not any other
word position. We report results of adding neigh-
borhood constraints to our model in Section 6.
</bodyText>
<sectionHeader confidence="0.9965" genericHeader="method">
4 Experimental Setup
</sectionHeader>
<bodyText confidence="0.9967265">
We evaluate on the large OntoNotes (v4.0) cor-
pus (Hovy et al., 2006) which contains manually
</bodyText>
<page confidence="0.977413">
1077
</page>
<bodyText confidence="0.989700959183674">
\x0cannotated NER tags for both Chinese and En-
glish. Document pairs are sentence aligned us-
ing the Champollion Tool Kit (Ma, 2006). Af-
ter discarding sentences with no aligned counter-
part, a total of 402 documents and 8,249 paral-
lel sentence pairs were used for evaluation. We
will refer to this evaluation set as full-set. We use
odd-numbered documents as the dev set and even-
numbered documents as the blind test set. We
did not perform parameter tuning on the dev set
to optimize performance, instead we fix the ini-
tial learning rate to 0.5 and maximum iterations to
1,000 in all DD experiments. We only use the dev
set for model development.
The Stanford CRF-based NER tagger was used
as the monolingual component in our models
(Finkel et al., 2005). It also serves as a state-
of-the-art monolingual baseline for both English
and Chinese. For English, we use the default tag-
ger setting from Finkel et al. (2005). For Chi-
nese, we use an improved set of features over the
default tagger, which includes distributional sim-
ilarity features trained on large amounts of non-
overlapping data.1
We train the two CRF models on all portions
of the OntoNotes corpus that are annotated with
named entity tags, except the parallel-aligned por-
tion which we reserve for development and test
purposes. In total, there are about 660 train-
ing documents (16k sentences) for Chinese and
1,400 documents (39k sentences) for English.
Out of the 18 named entity types that are an-
notated in OntoNotes, which include person, lo-
cation, date, money, and so on, we select the four
most commonly seen named entity types for evalu-
ation. They are person, location, organization and
GPE. All entities of these four types are converted
to the standard BIO format, and background to-
kens and all other entity types are marked with
tag O. When we consider label agreements over
aligned word pairs in all bilingual agreement mod-
els, we ignore the distinction between B- and I-
tags.
We report standard NER measures (entity pre-
cision (P), recall (R) and F1 score) on the test
set. Statistical significance tests are done using the
paired bootstrap resampling method (Efron and
Tibshirani, 1993).
For alignment experiments, we train two uni-
</bodyText>
<page confidence="0.881823">
1
</page>
<bodyText confidence="0.996746283018868">
The exact feature set and the CRF implementation
can be found here: http://nlp.stanford.edu/
software/CRF-NER.shtml
directional HMM models as our baseline and
monolingual alignment models. The parameters
of the HMM were initialized by IBM Model 1 us-
ing the agreement-based EM training algorithms
from Liang et al. (2006). Each model is trained
for 2 iterations over a parallel corpus of 12 mil-
lion English words and Chinese words, almost
twice as much data as used in previous work that
yields state-of-the-art unsupervised alignment re-
sults (DeNero and Klein, 2008; Haghighi et al.,
2009; DeNero and Macherey, 2011).
Word alignment evaluation is done over the
sections of OntoNotes that have matching gold-
standard word alignment annotations from GALE
Y1Q4 dataset.2 This subset contains 288 docu-
ments and 3,391 sentence pairs. We will refer
to this subset as wa-subset. This evaluation set
is over 20 times larger than the 150 sentences
set used in most past evaluations (DeNero and
Klein, 2008; Haghighi et al., 2009; DeNero and
Macherey, 2011).
Alignments input to the BI-NER model are
produced by thresholding the averaged posterior
probability at 0.5. In joint NER and alignment ex-
periments, instead of posterior thresholding, we
take the direct intersection of the Viterbi-best
alignment of the two directional models. We re-
port the standard P, R, F1 and Alignment Error
Rate (AER) measures for alignment experiments.
An important past work to make comparisons
with is Burkett et al. (2010b). Their method
is similar to ours in that they also model bilin-
gual agreement in conjunction with two CRF-
based monolingual models. But instead of using
just the PMI scores of bilingual NE pairs, as in
our work, they employed a feature-rich log-linear
model to capture bilingual correlations. Parame-
ters in their log-linear model require training with
bilingually annotated data, which is not readily
available. To counter this problem, they proposed
an up-training method which simulates a super-
vised learning environment by pairing a weak clas-
sifier with strong classifiers, and train the bilin-
gual model to rank the output of the strong classi-
fier highly among the N-best outputs of the weak
classifier. In order to compare directly with their
method, we obtained the code behind Burkett et
al. (2010b) and reproduced their experimental set-
ting for the OntoNotes data. An extra set of 5,000
unannotated parallel sentence pairs are used for
</bodyText>
<page confidence="0.940135">
2
</page>
<table confidence="0.878762571428571">
LDC Catalog No. LDC2006E86.
1078
\x0cChinese English
P R F1 P R F1
Mono 76.89 61.64 68.42 81.98 74.59 78.11
Burkett 77.52 65.84 71.20 82.28 76.64 79.36
Bi-soft 79.14 71.55 75.15 82.58 77.96 80.20
</table>
<tableCaption confidence="0.999168">
Table 1: NER results on bilingual parallel test set.
</tableCaption>
<bodyText confidence="0.9876398">
Best numbers on each measure that are statistically
significantly better than the monolingual baseline
and Burkett et al. (2010b) are highlighted in bold.
training the reranker, and the reranker model se-
lection was performed on the development dataset.
</bodyText>
<sectionHeader confidence="0.985643" genericHeader="method">
5 Bilingual NER Results
</sectionHeader>
<bodyText confidence="0.999555037037037">
The main results on bilingual NER over the test
portion of full-set are shown in Table 1. We
initially experimented with the hard agreement
model, but it performs quite poorly for reasons we
discussed in Section 2.2. The BI-NER model with
soft agreement constraints, however, significantly
outperforms all baselines. In particular, it achieves
an absolute F1 improvement of 6.7% in Chinese
and 2.1% in English over the CRF monolingual
baselines.
A well-known issue with the DD method is
that when the model does not necessarily con-
verge, then the procedure could be very sensi-
tive to hyper-parameters such as initial step size
and early termination criteria. If a model only
gives good performance with well-tuned hyper-
parameters, then we must have manually anno-
tated data for tuning, which would significantly
reduce the applicability and portability of this
method to other language pairs and tasks. To eval-
uate the parameter sensitivity of our model, we
run the model from 50 to 3000 iterations before
early stopping, and with 6 different initial step
sizes from 0.01 to 1. The results are shown in Fig-
ure 2. The soft agreement model does not seem to
be sensitive to initial step size and almost always
converges to a superior solution than the baseline.
</bodyText>
<sectionHeader confidence="0.68002" genericHeader="method">
6 Joint NER and Alignment Results
</sectionHeader>
<bodyText confidence="0.999534875">
We present results for the BI-NER-WA model
in Table 2. By jointly decoding NER with word
alignment, our model not only maintains signifi-
cant improvements in NER performance, but also
yields significant improvements to alignment per-
formance. Overall, joint decoding with NER alone
yields a 10.8% error reduction in AER over the
baseline HMM-aligners, and also gives improve-
</bodyText>
<figure confidence="0.919535238095238">
0
0.01
0.05
0.1
0.2
0.5
1
2
3000
1000
800
500
300
100
50
73
74
75
76
77
78
</figure>
<page confidence="0.738633">
79
80
</page>
<bodyText confidence="0.791504">
initial step size
max no. of iterations
</bodyText>
<page confidence="0.823652">
F1
</page>
<figureCaption confidence="0.758990666666667">
score
Figure 2: Performance variance of the soft agree-
ment models on the Chinese dev dataset, as a func-
tion of step size (x-axis) and maximum number of
iterations before early stopping (y-axis).
ment over BI-NER in NER. Adding additional
</figureCaption>
<bodyText confidence="0.9994717">
neighborhood constraints gives a further 6% er-
ror reduction in AER, at the cost of a small loss
in Chinese NER. In terms of word alignment re-
sults, we see great increases in F1 and recall, but
precision goes down significantly. This is be-
cause the joint decoding algorithm promotes an ef-
fect of soft-union, by encouraging the two uni-
directional aligners to agree more often. Adding
the neighborhood constraints further enhances this
union effect.
</bodyText>
<sectionHeader confidence="0.991795" genericHeader="method">
7 Error Analysis and Discussion
</sectionHeader>
<bodyText confidence="0.999788904761905">
We can examine the example in Figure 3 to gain
an understanding of the models performance. In
this example, a snippet of a longer sentence pair is
shown with NER and word alignment results. The
monolingual Chinese tagger provides a strong cue
that word f6 is a person name because the unique
4-character word pattern is commonly associated
with foreign names in Chinese, and also the word
is immediately preceded by the word president.
The English monolingual tagger, however, con-
fuses the aligned word e0 with a GPE.
Our bilingual NER model is able to correct this
error as expected. Similarly, the bilingual model
corrects the error over e11. However, the model
also propagates labeling errors from the English
side over the entity Tibet Autonomous Region to
the Chinese side. Nevertheless, the resulting Chi-
nese tags are arguably more useful than the origi-
nal tags assigned by the baseline model.
In terms of word alignment, the HMM models
failed badly on this example because of the long
</bodyText>
<page confidence="0.976594">
1079
</page>
<table confidence="0.996928428571429">
\x0cNER-Chinese NER-English word alignment
P R F1 P R F1 P R F1 AER
HMM-WA - - - - - - 90.43 40.95 56.38 43.62
Mono-CRF 82.50 66.58 73.69 84.24 78.70 81.38 - - - -
Bi-NER 84.87 75.30 79.80 84.47 81.45 82.93 - - - -
Bi-NER-WA 84.42 76.34 80.18 84.25 82.20 83.21 77.45 50.43 61.09 38.91
Bi-NER-WA+NC 84.25 75.09 79.41 84.28 82.17 83.21 76.67 54.44 63.67 36.33
</table>
<tableCaption confidence="0.6883265">
Table 2: Joint alignment and NER test results. +NC means incorporating additional neighbor constraints
from DeNero and Macherey (2011) to the model. Best number in each column is highlighted in bold.
</tableCaption>
<table confidence="0.625708888888889">
f0 f1 f2 f3 f4 f5 f6
e0 e1 e2 e3 e4 e5 e6 e7 e8 e9 e10 e11
Suolangdaji , president of Tibet Auto. Region branch of Bank of China
B-PER O O O B-GPE I-GPE I-GPE O O B-ORG I-ORG I-ORG
B-PER O O O [B-LOC] [I-LOC] [I-LOC] O O B-ORG I-ORG I-ORG
[B-GPE] O O O [B-LOC] [I-LOC] [I-LOC] O O [O] [O] [B-GPE]
B-ORG I-ORG B-GPE O O O B-PER
B-ORG I-ORG [B-LOC] [I-LOC] O O B-PER
B-ORG I-ORG [O] O O O B-PER
</table>
<figureCaption confidence="0.801114">
Figure 3: An example output of our BI-NER-WA model. Dotted alignment links are the oracle, dashed
links are alignments from HMM baseline, and solid links are outputs of our model. Entity tags in the
</figureCaption>
<bodyText confidence="0.991519181818182">
gold line (closest to nodes ei and fj) are the gold-standard tags; in the green line (second closest to
nodes) are output from our model; and in the crimson line (furthest from nodes) are baseline output.
distance swapping phenomena. The two unidirec-
tional HMMs also have strong disagreements over
the alignments, and the resulting baseline aligner
output only recovers two links. If we were to take
this alignment as fixed input, most likely we would
not be able to recover the error over e11, but the
joint decoding method successfully recovered 4
more links, and indirectly resulted in the NER tag-
ging improvement discussed above.
</bodyText>
<sectionHeader confidence="0.999228" genericHeader="related work">
8 Related Work
</sectionHeader>
<bodyText confidence="0.999825463414634">
The idea of employing bilingual resources to im-
prove over monolingual systems has been ex-
plored by much previous work. For example,
Huang et al. (2009) improved parsing performance
using a bilingual parallel corpus. In the NER
domain, Li et al. (2012) presented a cyclic CRF
model very similar to our BI-NER model, and
performed approximate inference using loopy be-
lief propagation. The feature-rich CRF formula-
tion of bilingual edge potentials in their model is
much more powerful than our simple PMI-based
bilingual edge model. Adding a richer bilingual
edge model might well further improve our results,
and this is a possible direction for further experi-
mentation. However, a big drawback of this ap-
proach is that training such a feature-rich model
requires manually annotated bilingual NER data,
which can be prohibitively expensive to generate.
How and where to obtain training signals with-
out manual supervision is an interesting and open
question. One of the most interesting papers in this
regard is Burkett et al. (2010b), which explored
an up-training mechanism by using the outputs
from a strong monolingual model as ground-truth,
and simulated a learning environment where a
bilingual model is trained to help a weakened
monolingual model to recover the results of the
strong model. It is worth mentioning that since
our method does not require additional training
and can take pretty much any existing model as
black-box during decoding, the richer and more
accurate bilingual model learned from Burkett et
al. (2010b) can be directly plugged into our model.
A similar dual decomposition algorithm to ours
was proposed by Riedel and McCallum (2011)
for biomedical event detection. In their Model
3, the trigger and argument extraction models
are reminiscent of the two monolingual CRFs in
our model; additional binding agreements are en-
forced over every protein pair, similar to how we
enforce agreement between every aligned word
</bodyText>
<page confidence="0.924252">
1080
</page>
<bodyText confidence="0.999051228070175">
\x0cpair. Martins et al. (2011b) presented a new DD
method that combines the power of DD with the
augmented Lagrangian method. They showed
that their method can achieve faster convergence
than traditional sub-gradient methods in models
with many overlapping components (Martins et
al., 2011a). This method is directly applicable to
our work.
Another promising direction for improving
NER performance is in enforcing global label
consistency across documents, which is an idea
that has been greatly explored in the past (Sut-
ton and McCallum, 2004; Bunescu and Mooney,
2004; Finkel et al., 2005). More recently, Rush
et al. (2012) and Chieu and Teow (2012) have
shown that combining local prediction models
with global consistency models, and enforcing
agreement via DD is very effective. It is straight-
forward to incorporate an additional global consis-
tency model into our model for further improve-
ments.
Our joint alignment and NER decoding ap-
proach is inspired by prior work on improving
alignment quality through encouraging agreement
between bi-directional models (Liang et al., 2006;
DeNero and Macherey, 2011). Instead of enforc-
ing agreement in the alignment space based on
best sequences found by Viterbi, we could opt
to encourage agreement between posterior prob-
ability distributions, which is related to the pos-
terior regularization work by Graca et al. (2008).
Cromieres and Kurohashi (2009) proposed an ap-
proach that takes phrasal bracketing constraints
from parsing outputs, and uses them to enforce
phrasal alignments. This idea is similar to our joint
alignment and NER approach, but in our case the
phrasal constraints are indirectly imposed by en-
tity spans. We also differ in the implementation
details, where in their case belief propagation is
used in both training and Viterbi inference.
Burkett et al. (2010a) presented a supervised
learning method for performing joint parsing and
word alignment using log-linear models over parse
trees and an ITG model over alignment. The
model demonstrates performance improvements
in both parsing and alignment, but shares the com-
mon limitations of other supervised work in that it
requires manually annotated bilingual joint pars-
ing and word alignment data.
Chen et al. (2010) also tackled the problem of
joint alignment and NER. Their method employs a
set of heuristic rules to expand a candidate named
entity set generated by monolingual taggers, and
then rank those candidates using a bilingual named
entity dictionary. Our approach differs in that we
provide a probabilistic formulation of the problem
and do not require pre-existing NE dictionaries.
</bodyText>
<sectionHeader confidence="0.994665" genericHeader="conclusions">
9 Conclusion
</sectionHeader>
<bodyText confidence="0.999893272727273">
We introduced a graphical model that combines
two HMM word aligners and two CRF NER tag-
gers into a joint model, and presented a dual de-
composition inference method for performing ef-
ficient decoding over this model. Results from
NER and word alignment experiments suggest that
our method gives significant improvements in both
NER and word alignment. Our techniques make
minimal assumptions about the underlying mono-
lingual components, and can be adapted for many
other tasks such as parsing.
</bodyText>
<sectionHeader confidence="0.97839" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.81078825">
The authors would like to thank Rob Voigt and
the three anonymous reviewers for their valuable
comments and suggestions. We gratefully ac-
knowledge the support of the National Natural
</bodyText>
<reference confidence="0.920654230769231">
Science Foundation of China (NSFC) via grant
61133012, the National 863 Project via grant
2011AA01A207 and 2012AA011102, the Min-
istry of Education Research of Social Sciences
Youth funded projects via grant 12YJCZH304,
and the support of the U.S. Defense Advanced
Research Projects Agency (DARPA) Broad Op-
erational Language Translation (BOLT) program
through IBM.
Any opinions, findings, and conclusion or rec-
ommendations expressed in this material are those
of the authors and do not necessarily reflect the
view of DARPA, or the US government.
</reference>
<sectionHeader confidence="0.622005" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9988159">
Yaser Al-Onaizan and Kevin Knight. 2002. Translat-
ing named entities using monolingual and bilingual
resources. In Proceedings of ACL.
Bogdan Babych and Anthony Hartley. 2003. Im-
proving machine translation quality with automatic
named entity recognition. In Proceedings of the
7th International EAMT workshop on MT and other
Language Technology Tools, Improving MT through
other Language Technology Tools: Resources and
Tools for Building MT.
</reference>
<page confidence="0.569396">
1081
</page>
<reference confidence="0.999775821782178">
\x0cDimitri P. Bertsekas. 1999. Nonlinear Programming.
Athena Scientific, New York.
Peter F. Brown, Stephen A. Della Pietra, Vincent
J. Della Pietra, and Robert L. Mercer. 1991. Word-
sense disambiguation using statistical methods. In
Proceedings of ACL.
Razvan Bunescu and Raymond J. Mooney. 2004.
Collective information extraction with relational
Markov networks. In Proceedings of ACL.
David Burkett, John Blitzer, and Dan Klein. 2010a.
Joint parsing and alignment with weakly synchro-
nized grammars. In Proceedings of NAACL-HLT.
David Burkett, Slav Petrov, John Blitzer, and Dan
Klein. 2010b. Learning better monolingual mod-
els with unannotated bilingual text. In Proceedings
of CoNLL.
Yufeng Chen, Chengqing Zong, and Keh-Yih Su.
2010. On jointly recognizing and aligning bilingual
named entities. In Proceedings of ACL.
Hai Leong Chieu and Loo-Nin Teow. 2012. Com-
bining local and non-local information with dual de-
composition for named entity recognition from text.
In Proceedings of 15th International Conference on
Information Fusion (FUSION).
Fabien Cromieres and Sadao Kurohashi. 2009. An
alignment algorithm using belief propagation and a
structure-based distortion model. In Proceedings of
EACL/ IJCNLP.
John DeNero and Dan Klein. 2008. The complexity of
phrase alignment problems. In Proceedings of ACL.
John DeNero and Klaus Macherey. 2011. Model-
based aligner combination using dual decomposi-
tion. In Proceedings of ACL.
Brad Efron and Robert Tibshirani. 1993. An Introduc-
tion to the Bootstrap. Chapman &amp; Hall, New York.
Jenny Rose Finkel, Trond Grenager, and Christopher
Manning. 2005. Incorporating non-local informa-
tion into information extraction systems by Gibbs
sampling. In Proceedings of ACL.
Joao Graca, Kuzman Ganchev, and Ben Taskar. 2008.
Expectation maximization and posterior constraints.
In Proceedings of NIPS.
Aria Haghighi, John Blitzer, John DeNero, and Dan
Klein. 2009. Better word alignments with super-
vised ITG models. In Proceedings of ACL.
Eduard Hovy, Mitchell Marcus, Martha Palmer,
Lance Ramshaw, and Ralph Weischedel. 2006.
OntoNotes: the 90% solution. In Proceedings of
NAACL-HLT.
Fei Huang and Stephan Vogel. 2002. Improved named
entity translation and bilingual named entity extrac-
tion. In Proceedings of the 2002 International Con-
ference on Multimodal Interfaces (ICMI).
Liang Huang, Wenbin Jiang, and Qun Liu. 2009.
Bilingually-constrained (monolingual) shift-reduce
parsing. In Proceedings of EMNLP.
Sungchul Kim, Kristina Toutanova, and Hwanjo Yu.
2012. Multilingual named entity recognition using
parallel data and metadata from Wikipedia. In Pro-
ceedings of ACL.
Terry Koo, Alexander M. Rush, Michael Collins,
Tommi Jaakkola, and David Sontag. 2010. Dual
decomposition for parsing with non-projective head
automata. In Proceedings of EMNLP.
Qi Li, Haibo Li, Heng Ji, Wen Wang, Jing Zheng, and
Fei Huang. 2012. Joint bilingual name tagging for
parallel corpora. In Proceedings of CIKM.
Percy Liang, Ben Taskar, and Dan Klein. 2006. Align-
ment by agreement. In Proceedings of HLT-NAACL.
Xiaoyi Ma. 2006. Champollion: A robust parallel text
sentence aligner. In Proceedings of LREC.
Andre F. T. Martins, Noah A. Smith, Pedro M. Q.
Aguiar, and Mario A. T. Figueiredo. 2011a. Dual
decomposition with many overlapping components.
In Proceedings of EMNLP.
Andre F. T. Martins, Noah A. Smith, Eric P. Xing,
Pedro M. Q. Aguiar, and Mario A. T. Figueiredo.
2011b. Augmenting dual decomposition for map in-
ference. In Proceedings of the International Work-
shop on Optimization for Machine Learning (OPT
2010).
Sebastian Riedel and Andrew McCallum. 2011. Fast
and robust joint models for biomedical event extrac-
tion. In Proceedings of EMNLP.
Alexander M. Rush and Michael Collins. 2012. A tu-
torial on dual decomposition and Lagrangian relax-
ation for inference in natural language processing.
JAIR, 45:305362.
Alexander M. Rush, David Sontag, Michael Collins,
and Tommi Jaakkola. 2010. On dual decomposi-
tion and linear programming relaxations for natural
language processing. In Proceedings of EMNLP.
Alexander M. Rush, Roi Reichert, Michael Collins, and
Amir Globerson. 2012. Improved parsing and POS
tagging using inter-sentence consistency constraints.
In Proceedings of EMNLP.
Charles Sutton and Andrew McCallum. 2004. Col-
lective segmentation and labeling of distant entities
in information extraction. In Proceedings of ICML
Workshop on Statistical Relational Learning and Its
connections to Other Fields.
</reference>
<page confidence="0.874911">
1082
</page>
<figure confidence="0.247908">
\x0c&amp;quot;
</figure>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.365969">
<note confidence="0.886543">b&amp;quot;Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 10731082, Sofia, Bulgaria, August 4-9 2013. c 2013 Association for Computational Linguistics</note>
<title confidence="0.954809">Joint Word Alignment and Bilingual Named Entity Recognition Using Dual Decomposition</title>
<author confidence="0.990615">Mengqiu Wang</author>
<affiliation confidence="0.999982">Stanford University</affiliation>
<address confidence="0.999136">Stanford, CA 94305</address>
<email confidence="0.999632">mengqiu@cs.stanford.edu</email>
<author confidence="0.659267">Wanxiang Che</author>
<affiliation confidence="0.999977">Harbin Institute of Technology</affiliation>
<address confidence="0.999933">Harbin, China, 150001</address>
<email confidence="0.875102">car@ir.hit.edu.cn</email>
<author confidence="0.997098">Christopher D Manning</author>
<affiliation confidence="0.999987">Stanford University</affiliation>
<address confidence="0.999261">Stanford, CA 94305</address>
<email confidence="0.999624">manning@cs.stanford.edu</email>
<abstract confidence="0.99688824137931">Translated bi-texts contain complementary language cues, and previous work on Named Entity Recognition (NER) has demonstrated improvements in performance over monolingual taggers by promoting agreement of tagging decisions between the two languages. However, most previous approaches to bilingual tagging assume word alignments are given as fixed input, which can cause cascading errors. We observe that NER label information can be used to correct alignment mistakes, and present a graphical model that performs bilingual NER tagging jointly with word alignment, by combining two monolingual tagging models with two unidirectional alignment models. We introduce additional cross-lingual edge factors that encourage agreements between tagging and alignment decisions. We design a dual decomposition inference algorithm to perform joint decoding over the combined alignment and NER output space. Experiments on the OntoNotes dataset demonstrate that our method yields significant improvements in both NER and word alignment over state-of-the-art monolingual baselines.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Yaser Al-Onaizan</author>
<author>Kevin Knight</author>
</authors>
<title>Translating named entities using monolingual and bilingual resources.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="2468" citStr="Al-Onaizan and Knight, 2002" startWordPosition="353" endWordPosition="356">entities such as person names, locations, organizations, etc. carry much of the information expressed in the source sentence. Recognizing them provides useful information for phrase detection and word sense disambiguation (e.g., melody as in a female name has a different translation from the word melody in a musical sense), and can be directly leveraged to improve translation quality (Babych and Hartley, 2003). We can also automatically construct a named entity translation lexicon by annotating and extracting entities from bi-texts, and use it to improve MT performance (Huang and Vogel, 2002; Al-Onaizan and Knight, 2002). Previous work such as Burkett et al. (2010b), Li et al. (2012) and Kim et al. (2012) have also demonstrated that bitexts annotated with NER tags can provide useful additional training sources for improving the performance of standalone monolingual taggers. Because human translation in general preserves semantic equivalence, bi-texts represent two perspectives on the same semantic content (Burkett et al., 2010b). As a result, we can find complementary cues in the two languages that help to disambiguate named entity mentions (Brown et al., 1991). For example, the English word Jordan can be eit</context>
</contexts>
<marker>Al-Onaizan, Knight, 2002</marker>
<rawString>Yaser Al-Onaizan and Kevin Knight. 2002. Translating named entities using monolingual and bilingual resources. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bogdan Babych</author>
<author>Anthony Hartley</author>
</authors>
<title>Improving machine translation quality with automatic named entity recognition.</title>
<date>2003</date>
<booktitle>In Proceedings of the 7th International EAMT workshop on MT and other Language Technology Tools, Improving MT through other Language Technology Tools: Resources and Tools for Building MT.</booktitle>
<contexts>
<context position="2253" citStr="Babych and Hartley, 2003" startWordPosition="319" endWordPosition="323">oblem of Named Entity Recognition (NER) in a bilingual context, where the goal is to annotate parallel bi-texts with named entity tags. This is a particularly important problem for machine translation (MT) since entities such as person names, locations, organizations, etc. carry much of the information expressed in the source sentence. Recognizing them provides useful information for phrase detection and word sense disambiguation (e.g., melody as in a female name has a different translation from the word melody in a musical sense), and can be directly leveraged to improve translation quality (Babych and Hartley, 2003). We can also automatically construct a named entity translation lexicon by annotating and extracting entities from bi-texts, and use it to improve MT performance (Huang and Vogel, 2002; Al-Onaizan and Knight, 2002). Previous work such as Burkett et al. (2010b), Li et al. (2012) and Kim et al. (2012) have also demonstrated that bitexts annotated with NER tags can provide useful additional training sources for improving the performance of standalone monolingual taggers. Because human translation in general preserves semantic equivalence, bi-texts represent two perspectives on the same semantic </context>
</contexts>
<marker>Babych, Hartley, 2003</marker>
<rawString>Bogdan Babych and Anthony Hartley. 2003. Improving machine translation quality with automatic named entity recognition. In Proceedings of the 7th International EAMT workshop on MT and other Language Technology Tools, Improving MT through other Language Technology Tools: Resources and Tools for Building MT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>\x0cDimitri P Bertsekas</author>
</authors>
<title>Nonlinear Programming. Athena Scientific,</title>
<date>1999</date>
<location>New York.</location>
<contexts>
<context position="3664" citStr="Bertsekas, 1999" startWordPosition="548" endWordPosition="549">d Jordan can be either a last name or a country. Without sufficient context it can be difficult to distinguish the two; however, in Chinese, these two senses are disambiguated: as a last name, and as a country name. In this work, we first develop a bilingual NER model (denoted as BI-NER) by embedding two monolingual CRF-based NER models into a larger undirected graphical model, and introduce additional edge factors based on word alignment (WA). Because the new bilingual model contains many cyclic cliques, exact inference is intractable. We employ a dual decomposition (DD) inference algorithm (Bertsekas, 1999; Rush et al., 2010) for performing approximate inference. Unlike most 1073 \x0cf1 f2 f3 f4 f5 f6 e1 e2 e3 e4 e5 e6 Xinhua News Agency Beijing Feb 16 B-ORG I-ORG I-ORG [O] B-LOC O O , , B-ORG O B-GPE O O O Figure 1: Example of NER labels between two word-aligned bilingual parallel sentences. The [O] tag is an example of a wrong tag assignment. The dashed alignment link between e3 and f2 is an example of alignment error. previous applications of the DD method in NLP, where the model typically factors over two components and agreement is to be sought between the two (Rush et al., 2010; Koo et al</context>
</contexts>
<marker>Bertsekas, 1999</marker>
<rawString>\x0cDimitri P. Bertsekas. 1999. Nonlinear Programming. Athena Scientific, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>Wordsense disambiguation using statistical methods.</title>
<date>1991</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="3019" citStr="Brown et al., 1991" startWordPosition="442" endWordPosition="445"> MT performance (Huang and Vogel, 2002; Al-Onaizan and Knight, 2002). Previous work such as Burkett et al. (2010b), Li et al. (2012) and Kim et al. (2012) have also demonstrated that bitexts annotated with NER tags can provide useful additional training sources for improving the performance of standalone monolingual taggers. Because human translation in general preserves semantic equivalence, bi-texts represent two perspectives on the same semantic content (Burkett et al., 2010b). As a result, we can find complementary cues in the two languages that help to disambiguate named entity mentions (Brown et al., 1991). For example, the English word Jordan can be either a last name or a country. Without sufficient context it can be difficult to distinguish the two; however, in Chinese, these two senses are disambiguated: as a last name, and as a country name. In this work, we first develop a bilingual NER model (denoted as BI-NER) by embedding two monolingual CRF-based NER models into a larger undirected graphical model, and introduce additional edge factors based on word alignment (WA). Because the new bilingual model contains many cyclic cliques, exact inference is intractable. We employ a dual decomposit</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1991</marker>
<rawString>Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and Robert L. Mercer. 1991. Wordsense disambiguation using statistical methods. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Razvan Bunescu</author>
<author>Raymond J Mooney</author>
</authors>
<title>Collective information extraction with relational Markov networks.</title>
<date>2004</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="31915" citStr="Bunescu and Mooney, 2004" startWordPosition="5567" endWordPosition="5570">we enforce agreement between every aligned word 1080 \x0cpair. Martins et al. (2011b) presented a new DD method that combines the power of DD with the augmented Lagrangian method. They showed that their method can achieve faster convergence than traditional sub-gradient methods in models with many overlapping components (Martins et al., 2011a). This method is directly applicable to our work. Another promising direction for improving NER performance is in enforcing global label consistency across documents, which is an idea that has been greatly explored in the past (Sutton and McCallum, 2004; Bunescu and Mooney, 2004; Finkel et al., 2005). More recently, Rush et al. (2012) and Chieu and Teow (2012) have shown that combining local prediction models with global consistency models, and enforcing agreement via DD is very effective. It is straightforward to incorporate an additional global consistency model into our model for further improvements. Our joint alignment and NER decoding approach is inspired by prior work on improving alignment quality through encouraging agreement between bi-directional models (Liang et al., 2006; DeNero and Macherey, 2011). Instead of enforcing agreement in the alignment space b</context>
</contexts>
<marker>Bunescu, Mooney, 2004</marker>
<rawString>Razvan Bunescu and Raymond J. Mooney. 2004. Collective information extraction with relational Markov networks. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Burkett</author>
<author>John Blitzer</author>
<author>Dan Klein</author>
</authors>
<title>Joint parsing and alignment with weakly synchronized grammars.</title>
<date>2010</date>
<booktitle>In Proceedings of NAACL-HLT.</booktitle>
<contexts>
<context position="2512" citStr="Burkett et al. (2010" startWordPosition="361" endWordPosition="364">ons, etc. carry much of the information expressed in the source sentence. Recognizing them provides useful information for phrase detection and word sense disambiguation (e.g., melody as in a female name has a different translation from the word melody in a musical sense), and can be directly leveraged to improve translation quality (Babych and Hartley, 2003). We can also automatically construct a named entity translation lexicon by annotating and extracting entities from bi-texts, and use it to improve MT performance (Huang and Vogel, 2002; Al-Onaizan and Knight, 2002). Previous work such as Burkett et al. (2010b), Li et al. (2012) and Kim et al. (2012) have also demonstrated that bitexts annotated with NER tags can provide useful additional training sources for improving the performance of standalone monolingual taggers. Because human translation in general preserves semantic equivalence, bi-texts represent two perspectives on the same semantic content (Burkett et al., 2010b). As a result, we can find complementary cues in the two languages that help to disambiguate named entity mentions (Brown et al., 1991). For example, the English word Jordan can be either a last name or a country. Without suffic</context>
<context position="22621" citStr="Burkett et al. (2010" startWordPosition="4007" endWordPosition="4010"> evaluation set is over 20 times larger than the 150 sentences set used in most past evaluations (DeNero and Klein, 2008; Haghighi et al., 2009; DeNero and Macherey, 2011). Alignments input to the BI-NER model are produced by thresholding the averaged posterior probability at 0.5. In joint NER and alignment experiments, instead of posterior thresholding, we take the direct intersection of the Viterbi-best alignment of the two directional models. We report the standard P, R, F1 and Alignment Error Rate (AER) measures for alignment experiments. An important past work to make comparisons with is Burkett et al. (2010b). Their method is similar to ours in that they also model bilingual agreement in conjunction with two CRFbased monolingual models. But instead of using just the PMI scores of bilingual NE pairs, as in our work, they employed a feature-rich log-linear model to capture bilingual correlations. Parameters in their log-linear model require training with bilingually annotated data, which is not readily available. To counter this problem, they proposed an up-training method which simulates a supervised learning environment by pairing a weak classifier with strong classifiers, and train the bilingua</context>
<context position="23943" citStr="Burkett et al. (2010" startWordPosition="4223" endWordPosition="4226">fier. In order to compare directly with their method, we obtained the code behind Burkett et al. (2010b) and reproduced their experimental setting for the OntoNotes data. An extra set of 5,000 unannotated parallel sentence pairs are used for 2 LDC Catalog No. LDC2006E86. 1078 \x0cChinese English P R F1 P R F1 Mono 76.89 61.64 68.42 81.98 74.59 78.11 Burkett 77.52 65.84 71.20 82.28 76.64 79.36 Bi-soft 79.14 71.55 75.15 82.58 77.96 80.20 Table 1: NER results on bilingual parallel test set. Best numbers on each measure that are statistically significantly better than the monolingual baseline and Burkett et al. (2010b) are highlighted in bold. training the reranker, and the reranker model selection was performed on the development dataset. 5 Bilingual NER Results The main results on bilingual NER over the test portion of full-set are shown in Table 1. We initially experimented with the hard agreement model, but it performs quite poorly for reasons we discussed in Section 2.2. The BI-NER model with soft agreement constraints, however, significantly outperforms all baselines. In particular, it achieves an absolute F1 improvement of 6.7% in Chinese and 2.1% in English over the CRF monolingual baselines. A we</context>
<context position="30423" citStr="Burkett et al. (2010" startWordPosition="5334" endWordPosition="5337">lation of bilingual edge potentials in their model is much more powerful than our simple PMI-based bilingual edge model. Adding a richer bilingual edge model might well further improve our results, and this is a possible direction for further experimentation. However, a big drawback of this approach is that training such a feature-rich model requires manually annotated bilingual NER data, which can be prohibitively expensive to generate. How and where to obtain training signals without manual supervision is an interesting and open question. One of the most interesting papers in this regard is Burkett et al. (2010b), which explored an up-training mechanism by using the outputs from a strong monolingual model as ground-truth, and simulated a learning environment where a bilingual model is trained to help a weakened monolingual model to recover the results of the strong model. It is worth mentioning that since our method does not require additional training and can take pretty much any existing model as black-box during decoding, the richer and more accurate bilingual model learned from Burkett et al. (2010b) can be directly plugged into our model. A similar dual decomposition algorithm to ours was propo</context>
<context position="33171" citStr="Burkett et al. (2010" startWordPosition="5765" endWordPosition="5768">rbi, we could opt to encourage agreement between posterior probability distributions, which is related to the posterior regularization work by Graca et al. (2008). Cromieres and Kurohashi (2009) proposed an approach that takes phrasal bracketing constraints from parsing outputs, and uses them to enforce phrasal alignments. This idea is similar to our joint alignment and NER approach, but in our case the phrasal constraints are indirectly imposed by entity spans. We also differ in the implementation details, where in their case belief propagation is used in both training and Viterbi inference. Burkett et al. (2010a) presented a supervised learning method for performing joint parsing and word alignment using log-linear models over parse trees and an ITG model over alignment. The model demonstrates performance improvements in both parsing and alignment, but shares the common limitations of other supervised work in that it requires manually annotated bilingual joint parsing and word alignment data. Chen et al. (2010) also tackled the problem of joint alignment and NER. Their method employs a set of heuristic rules to expand a candidate named entity set generated by monolingual taggers, and then rank those</context>
</contexts>
<marker>Burkett, Blitzer, Klein, 2010</marker>
<rawString>David Burkett, John Blitzer, and Dan Klein. 2010a. Joint parsing and alignment with weakly synchronized grammars. In Proceedings of NAACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Burkett</author>
<author>Slav Petrov</author>
<author>John Blitzer</author>
<author>Dan Klein</author>
</authors>
<title>Learning better monolingual models with unannotated bilingual text.</title>
<date>2010</date>
<booktitle>In Proceedings of CoNLL.</booktitle>
<contexts>
<context position="2512" citStr="Burkett et al. (2010" startWordPosition="361" endWordPosition="364">ons, etc. carry much of the information expressed in the source sentence. Recognizing them provides useful information for phrase detection and word sense disambiguation (e.g., melody as in a female name has a different translation from the word melody in a musical sense), and can be directly leveraged to improve translation quality (Babych and Hartley, 2003). We can also automatically construct a named entity translation lexicon by annotating and extracting entities from bi-texts, and use it to improve MT performance (Huang and Vogel, 2002; Al-Onaizan and Knight, 2002). Previous work such as Burkett et al. (2010b), Li et al. (2012) and Kim et al. (2012) have also demonstrated that bitexts annotated with NER tags can provide useful additional training sources for improving the performance of standalone monolingual taggers. Because human translation in general preserves semantic equivalence, bi-texts represent two perspectives on the same semantic content (Burkett et al., 2010b). As a result, we can find complementary cues in the two languages that help to disambiguate named entity mentions (Brown et al., 1991). For example, the English word Jordan can be either a last name or a country. Without suffic</context>
<context position="22621" citStr="Burkett et al. (2010" startWordPosition="4007" endWordPosition="4010"> evaluation set is over 20 times larger than the 150 sentences set used in most past evaluations (DeNero and Klein, 2008; Haghighi et al., 2009; DeNero and Macherey, 2011). Alignments input to the BI-NER model are produced by thresholding the averaged posterior probability at 0.5. In joint NER and alignment experiments, instead of posterior thresholding, we take the direct intersection of the Viterbi-best alignment of the two directional models. We report the standard P, R, F1 and Alignment Error Rate (AER) measures for alignment experiments. An important past work to make comparisons with is Burkett et al. (2010b). Their method is similar to ours in that they also model bilingual agreement in conjunction with two CRFbased monolingual models. But instead of using just the PMI scores of bilingual NE pairs, as in our work, they employed a feature-rich log-linear model to capture bilingual correlations. Parameters in their log-linear model require training with bilingually annotated data, which is not readily available. To counter this problem, they proposed an up-training method which simulates a supervised learning environment by pairing a weak classifier with strong classifiers, and train the bilingua</context>
<context position="23943" citStr="Burkett et al. (2010" startWordPosition="4223" endWordPosition="4226">fier. In order to compare directly with their method, we obtained the code behind Burkett et al. (2010b) and reproduced their experimental setting for the OntoNotes data. An extra set of 5,000 unannotated parallel sentence pairs are used for 2 LDC Catalog No. LDC2006E86. 1078 \x0cChinese English P R F1 P R F1 Mono 76.89 61.64 68.42 81.98 74.59 78.11 Burkett 77.52 65.84 71.20 82.28 76.64 79.36 Bi-soft 79.14 71.55 75.15 82.58 77.96 80.20 Table 1: NER results on bilingual parallel test set. Best numbers on each measure that are statistically significantly better than the monolingual baseline and Burkett et al. (2010b) are highlighted in bold. training the reranker, and the reranker model selection was performed on the development dataset. 5 Bilingual NER Results The main results on bilingual NER over the test portion of full-set are shown in Table 1. We initially experimented with the hard agreement model, but it performs quite poorly for reasons we discussed in Section 2.2. The BI-NER model with soft agreement constraints, however, significantly outperforms all baselines. In particular, it achieves an absolute F1 improvement of 6.7% in Chinese and 2.1% in English over the CRF monolingual baselines. A we</context>
<context position="30423" citStr="Burkett et al. (2010" startWordPosition="5334" endWordPosition="5337">lation of bilingual edge potentials in their model is much more powerful than our simple PMI-based bilingual edge model. Adding a richer bilingual edge model might well further improve our results, and this is a possible direction for further experimentation. However, a big drawback of this approach is that training such a feature-rich model requires manually annotated bilingual NER data, which can be prohibitively expensive to generate. How and where to obtain training signals without manual supervision is an interesting and open question. One of the most interesting papers in this regard is Burkett et al. (2010b), which explored an up-training mechanism by using the outputs from a strong monolingual model as ground-truth, and simulated a learning environment where a bilingual model is trained to help a weakened monolingual model to recover the results of the strong model. It is worth mentioning that since our method does not require additional training and can take pretty much any existing model as black-box during decoding, the richer and more accurate bilingual model learned from Burkett et al. (2010b) can be directly plugged into our model. A similar dual decomposition algorithm to ours was propo</context>
<context position="33171" citStr="Burkett et al. (2010" startWordPosition="5765" endWordPosition="5768">rbi, we could opt to encourage agreement between posterior probability distributions, which is related to the posterior regularization work by Graca et al. (2008). Cromieres and Kurohashi (2009) proposed an approach that takes phrasal bracketing constraints from parsing outputs, and uses them to enforce phrasal alignments. This idea is similar to our joint alignment and NER approach, but in our case the phrasal constraints are indirectly imposed by entity spans. We also differ in the implementation details, where in their case belief propagation is used in both training and Viterbi inference. Burkett et al. (2010a) presented a supervised learning method for performing joint parsing and word alignment using log-linear models over parse trees and an ITG model over alignment. The model demonstrates performance improvements in both parsing and alignment, but shares the common limitations of other supervised work in that it requires manually annotated bilingual joint parsing and word alignment data. Chen et al. (2010) also tackled the problem of joint alignment and NER. Their method employs a set of heuristic rules to expand a candidate named entity set generated by monolingual taggers, and then rank those</context>
</contexts>
<marker>Burkett, Petrov, Blitzer, Klein, 2010</marker>
<rawString>David Burkett, Slav Petrov, John Blitzer, and Dan Klein. 2010b. Learning better monolingual models with unannotated bilingual text. In Proceedings of CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yufeng Chen</author>
<author>Chengqing Zong</author>
<author>Keh-Yih Su</author>
</authors>
<title>On jointly recognizing and aligning bilingual named entities.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="33579" citStr="Chen et al. (2010)" startWordPosition="5827" endWordPosition="5830">asal constraints are indirectly imposed by entity spans. We also differ in the implementation details, where in their case belief propagation is used in both training and Viterbi inference. Burkett et al. (2010a) presented a supervised learning method for performing joint parsing and word alignment using log-linear models over parse trees and an ITG model over alignment. The model demonstrates performance improvements in both parsing and alignment, but shares the common limitations of other supervised work in that it requires manually annotated bilingual joint parsing and word alignment data. Chen et al. (2010) also tackled the problem of joint alignment and NER. Their method employs a set of heuristic rules to expand a candidate named entity set generated by monolingual taggers, and then rank those candidates using a bilingual named entity dictionary. Our approach differs in that we provide a probabilistic formulation of the problem and do not require pre-existing NE dictionaries. 9 Conclusion We introduced a graphical model that combines two HMM word aligners and two CRF NER taggers into a joint model, and presented a dual decomposition inference method for performing efficient decoding over this </context>
</contexts>
<marker>Chen, Zong, Su, 2010</marker>
<rawString>Yufeng Chen, Chengqing Zong, and Keh-Yih Su. 2010. On jointly recognizing and aligning bilingual named entities. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hai Leong Chieu</author>
<author>Loo-Nin Teow</author>
</authors>
<title>Combining local and non-local information with dual decomposition for named entity recognition from text.</title>
<date>2012</date>
<booktitle>In Proceedings of 15th International Conference on Information Fusion (FUSION).</booktitle>
<contexts>
<context position="4321" citStr="Chieu and Teow, 2012" startWordPosition="669" endWordPosition="672">approximate inference. Unlike most 1073 \x0cf1 f2 f3 f4 f5 f6 e1 e2 e3 e4 e5 e6 Xinhua News Agency Beijing Feb 16 B-ORG I-ORG I-ORG [O] B-LOC O O , , B-ORG O B-GPE O O O Figure 1: Example of NER labels between two word-aligned bilingual parallel sentences. The [O] tag is an example of a wrong tag assignment. The dashed alignment link between e3 and f2 is an example of alignment error. previous applications of the DD method in NLP, where the model typically factors over two components and agreement is to be sought between the two (Rush et al., 2010; Koo et al., 2010; DeNero and Macherey, 2011; Chieu and Teow, 2012), our method decomposes the larger graphical model into many overlapping components where each alignment edge forms a separate factor. We design clique potentials over the alignment-based edges to encourage entity tag agreements. Our method does not require any manual annotation of word alignments or named entities over the bilingual training data. The aforementioned BI-NER model assumes fixed alignment input given by an underlying word aligner. But the entity span and type predictions given by the NER models contain complementary information for correcting alignment errors. To capture this so</context>
<context position="31998" citStr="Chieu and Teow (2012)" startWordPosition="5582" endWordPosition="5585">presented a new DD method that combines the power of DD with the augmented Lagrangian method. They showed that their method can achieve faster convergence than traditional sub-gradient methods in models with many overlapping components (Martins et al., 2011a). This method is directly applicable to our work. Another promising direction for improving NER performance is in enforcing global label consistency across documents, which is an idea that has been greatly explored in the past (Sutton and McCallum, 2004; Bunescu and Mooney, 2004; Finkel et al., 2005). More recently, Rush et al. (2012) and Chieu and Teow (2012) have shown that combining local prediction models with global consistency models, and enforcing agreement via DD is very effective. It is straightforward to incorporate an additional global consistency model into our model for further improvements. Our joint alignment and NER decoding approach is inspired by prior work on improving alignment quality through encouraging agreement between bi-directional models (Liang et al., 2006; DeNero and Macherey, 2011). Instead of enforcing agreement in the alignment space based on best sequences found by Viterbi, we could opt to encourage agreement betwee</context>
</contexts>
<marker>Chieu, Teow, 2012</marker>
<rawString>Hai Leong Chieu and Loo-Nin Teow. 2012. Combining local and non-local information with dual decomposition for named entity recognition from text. In Proceedings of 15th International Conference on Information Fusion (FUSION).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabien Cromieres</author>
<author>Sadao Kurohashi</author>
</authors>
<title>An alignment algorithm using belief propagation and a structure-based distortion model.</title>
<date>2009</date>
<booktitle>In Proceedings of EACL/ IJCNLP.</booktitle>
<contexts>
<context position="32745" citStr="Cromieres and Kurohashi (2009)" startWordPosition="5696" endWordPosition="5699">very effective. It is straightforward to incorporate an additional global consistency model into our model for further improvements. Our joint alignment and NER decoding approach is inspired by prior work on improving alignment quality through encouraging agreement between bi-directional models (Liang et al., 2006; DeNero and Macherey, 2011). Instead of enforcing agreement in the alignment space based on best sequences found by Viterbi, we could opt to encourage agreement between posterior probability distributions, which is related to the posterior regularization work by Graca et al. (2008). Cromieres and Kurohashi (2009) proposed an approach that takes phrasal bracketing constraints from parsing outputs, and uses them to enforce phrasal alignments. This idea is similar to our joint alignment and NER approach, but in our case the phrasal constraints are indirectly imposed by entity spans. We also differ in the implementation details, where in their case belief propagation is used in both training and Viterbi inference. Burkett et al. (2010a) presented a supervised learning method for performing joint parsing and word alignment using log-linear models over parse trees and an ITG model over alignment. The model </context>
</contexts>
<marker>Cromieres, Kurohashi, 2009</marker>
<rawString>Fabien Cromieres and Sadao Kurohashi. 2009. An alignment algorithm using belief propagation and a structure-based distortion model. In Proceedings of EACL/ IJCNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John DeNero</author>
<author>Dan Klein</author>
</authors>
<title>The complexity of phrase alignment problems.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="21691" citStr="DeNero and Klein, 2008" startWordPosition="3858" endWordPosition="3861">ani, 1993). For alignment experiments, we train two uni1 The exact feature set and the CRF implementation can be found here: http://nlp.stanford.edu/ software/CRF-NER.shtml directional HMM models as our baseline and monolingual alignment models. The parameters of the HMM were initialized by IBM Model 1 using the agreement-based EM training algorithms from Liang et al. (2006). Each model is trained for 2 iterations over a parallel corpus of 12 million English words and Chinese words, almost twice as much data as used in previous work that yields state-of-the-art unsupervised alignment results (DeNero and Klein, 2008; Haghighi et al., 2009; DeNero and Macherey, 2011). Word alignment evaluation is done over the sections of OntoNotes that have matching goldstandard word alignment annotations from GALE Y1Q4 dataset.2 This subset contains 288 documents and 3,391 sentence pairs. We will refer to this subset as wa-subset. This evaluation set is over 20 times larger than the 150 sentences set used in most past evaluations (DeNero and Klein, 2008; Haghighi et al., 2009; DeNero and Macherey, 2011). Alignments input to the BI-NER model are produced by thresholding the averaged posterior probability at 0.5. In joint</context>
</contexts>
<marker>DeNero, Klein, 2008</marker>
<rawString>John DeNero and Dan Klein. 2008. The complexity of phrase alignment problems. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John DeNero</author>
<author>Klaus Macherey</author>
</authors>
<title>Modelbased aligner combination using dual decomposition.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="4298" citStr="DeNero and Macherey, 2011" startWordPosition="665" endWordPosition="668"> al., 2010) for performing approximate inference. Unlike most 1073 \x0cf1 f2 f3 f4 f5 f6 e1 e2 e3 e4 e5 e6 Xinhua News Agency Beijing Feb 16 B-ORG I-ORG I-ORG [O] B-LOC O O , , B-ORG O B-GPE O O O Figure 1: Example of NER labels between two word-aligned bilingual parallel sentences. The [O] tag is an example of a wrong tag assignment. The dashed alignment link between e3 and f2 is an example of alignment error. previous applications of the DD method in NLP, where the model typically factors over two components and agreement is to be sought between the two (Rush et al., 2010; Koo et al., 2010; DeNero and Macherey, 2011; Chieu and Teow, 2012), our method decomposes the larger graphical model into many overlapping components where each alignment edge forms a separate factor. We design clique potentials over the alignment-based edges to encourage entity tag agreements. Our method does not require any manual annotation of word alignments or named entities over the bilingual training data. The aforementioned BI-NER model assumes fixed alignment input given by an underlying word aligner. But the entity span and type predictions given by the NER models contain complementary information for correcting alignment err</context>
<context position="18518" citStr="DeNero and Macherey (2011)" startWordPosition="3323" endWordPosition="3326">aligned do not affect bilingual NER tagging. Similar to (i, j), (i, j) factors do not provide that much additional information other than some selectional preferences via PMI score. But the real power of these cross-language edge cliques is that they act as a liaison between the NER and alignment models on each language side, and encourage these models to indirectly agree with each other by having them all agree with the edge cliques. It is also worth noting that since we decode the alignment models with Viterbi inference, additional constraints such as the neighborhood constraint proposed by DeNero and Macherey (2011) can be easily integrated into our model. The neighborhood constraint enforces that if fj is aligned to ei, then fj can only be aligned to ei+1 or ei1 (with a small penalty), but not any other word position. We report results of adding neighborhood constraints to our model in Section 6. 4 Experimental Setup We evaluate on the large OntoNotes (v4.0) corpus (Hovy et al., 2006) which contains manually 1077 \x0cannotated NER tags for both Chinese and English. Document pairs are sentence aligned using the Champollion Tool Kit (Ma, 2006). After discarding sentences with no aligned counterpart, a tot</context>
<context position="21742" citStr="DeNero and Macherey, 2011" startWordPosition="3866" endWordPosition="3869"> two uni1 The exact feature set and the CRF implementation can be found here: http://nlp.stanford.edu/ software/CRF-NER.shtml directional HMM models as our baseline and monolingual alignment models. The parameters of the HMM were initialized by IBM Model 1 using the agreement-based EM training algorithms from Liang et al. (2006). Each model is trained for 2 iterations over a parallel corpus of 12 million English words and Chinese words, almost twice as much data as used in previous work that yields state-of-the-art unsupervised alignment results (DeNero and Klein, 2008; Haghighi et al., 2009; DeNero and Macherey, 2011). Word alignment evaluation is done over the sections of OntoNotes that have matching goldstandard word alignment annotations from GALE Y1Q4 dataset.2 This subset contains 288 documents and 3,391 sentence pairs. We will refer to this subset as wa-subset. This evaluation set is over 20 times larger than the 150 sentences set used in most past evaluations (DeNero and Klein, 2008; Haghighi et al., 2009; DeNero and Macherey, 2011). Alignments input to the BI-NER model are produced by thresholding the averaged posterior probability at 0.5. In joint NER and alignment experiments, instead of posterio</context>
<context position="28087" citStr="DeNero and Macherey (2011)" startWordPosition="4926" endWordPosition="4929">tags assigned by the baseline model. In terms of word alignment, the HMM models failed badly on this example because of the long 1079 \x0cNER-Chinese NER-English word alignment P R F1 P R F1 P R F1 AER HMM-WA - - - - - - 90.43 40.95 56.38 43.62 Mono-CRF 82.50 66.58 73.69 84.24 78.70 81.38 - - - - Bi-NER 84.87 75.30 79.80 84.47 81.45 82.93 - - - - Bi-NER-WA 84.42 76.34 80.18 84.25 82.20 83.21 77.45 50.43 61.09 38.91 Bi-NER-WA+NC 84.25 75.09 79.41 84.28 82.17 83.21 76.67 54.44 63.67 36.33 Table 2: Joint alignment and NER test results. +NC means incorporating additional neighbor constraints from DeNero and Macherey (2011) to the model. Best number in each column is highlighted in bold. f0 f1 f2 f3 f4 f5 f6 e0 e1 e2 e3 e4 e5 e6 e7 e8 e9 e10 e11 Suolangdaji , president of Tibet Auto. Region branch of Bank of China B-PER O O O B-GPE I-GPE I-GPE O O B-ORG I-ORG I-ORG B-PER O O O [B-LOC] [I-LOC] [I-LOC] O O B-ORG I-ORG I-ORG [B-GPE] O O O [B-LOC] [I-LOC] [I-LOC] O O [O] [O] [B-GPE] B-ORG I-ORG B-GPE O O O B-PER B-ORG I-ORG [B-LOC] [I-LOC] O O B-PER B-ORG I-ORG [O] O O O B-PER Figure 3: An example output of our BI-NER-WA model. Dotted alignment links are the oracle, dashed links are alignments from HMM baseline, and</context>
<context position="32458" citStr="DeNero and Macherey, 2011" startWordPosition="5651" endWordPosition="5654">n greatly explored in the past (Sutton and McCallum, 2004; Bunescu and Mooney, 2004; Finkel et al., 2005). More recently, Rush et al. (2012) and Chieu and Teow (2012) have shown that combining local prediction models with global consistency models, and enforcing agreement via DD is very effective. It is straightforward to incorporate an additional global consistency model into our model for further improvements. Our joint alignment and NER decoding approach is inspired by prior work on improving alignment quality through encouraging agreement between bi-directional models (Liang et al., 2006; DeNero and Macherey, 2011). Instead of enforcing agreement in the alignment space based on best sequences found by Viterbi, we could opt to encourage agreement between posterior probability distributions, which is related to the posterior regularization work by Graca et al. (2008). Cromieres and Kurohashi (2009) proposed an approach that takes phrasal bracketing constraints from parsing outputs, and uses them to enforce phrasal alignments. This idea is similar to our joint alignment and NER approach, but in our case the phrasal constraints are indirectly imposed by entity spans. We also differ in the implementation det</context>
</contexts>
<marker>DeNero, Macherey, 2011</marker>
<rawString>John DeNero and Klaus Macherey. 2011. Modelbased aligner combination using dual decomposition. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brad Efron</author>
<author>Robert Tibshirani</author>
</authors>
<title>An Introduction to the Bootstrap.</title>
<date>1993</date>
<publisher>Chapman &amp; Hall,</publisher>
<location>New York.</location>
<contexts>
<context position="21079" citStr="Efron and Tibshirani, 1993" startWordPosition="3762" endWordPosition="3765">so on, we select the four most commonly seen named entity types for evaluation. They are person, location, organization and GPE. All entities of these four types are converted to the standard BIO format, and background tokens and all other entity types are marked with tag O. When we consider label agreements over aligned word pairs in all bilingual agreement models, we ignore the distinction between B- and Itags. We report standard NER measures (entity precision (P), recall (R) and F1 score) on the test set. Statistical significance tests are done using the paired bootstrap resampling method (Efron and Tibshirani, 1993). For alignment experiments, we train two uni1 The exact feature set and the CRF implementation can be found here: http://nlp.stanford.edu/ software/CRF-NER.shtml directional HMM models as our baseline and monolingual alignment models. The parameters of the HMM were initialized by IBM Model 1 using the agreement-based EM training algorithms from Liang et al. (2006). Each model is trained for 2 iterations over a parallel corpus of 12 million English words and Chinese words, almost twice as much data as used in previous work that yields state-of-the-art unsupervised alignment results (DeNero and</context>
</contexts>
<marker>Efron, Tibshirani, 1993</marker>
<rawString>Brad Efron and Robert Tibshirani. 1993. An Introduction to the Bootstrap. Chapman &amp; Hall, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Trond Grenager</author>
<author>Christopher Manning</author>
</authors>
<title>Incorporating non-local information into information extraction systems by Gibbs sampling.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="19676" citStr="Finkel et al., 2005" startWordPosition="3526" endWordPosition="3529"> After discarding sentences with no aligned counterpart, a total of 402 documents and 8,249 parallel sentence pairs were used for evaluation. We will refer to this evaluation set as full-set. We use odd-numbered documents as the dev set and evennumbered documents as the blind test set. We did not perform parameter tuning on the dev set to optimize performance, instead we fix the initial learning rate to 0.5 and maximum iterations to 1,000 in all DD experiments. We only use the dev set for model development. The Stanford CRF-based NER tagger was used as the monolingual component in our models (Finkel et al., 2005). It also serves as a stateof-the-art monolingual baseline for both English and Chinese. For English, we use the default tagger setting from Finkel et al. (2005). For Chinese, we use an improved set of features over the default tagger, which includes distributional similarity features trained on large amounts of nonoverlapping data.1 We train the two CRF models on all portions of the OntoNotes corpus that are annotated with named entity tags, except the parallel-aligned portion which we reserve for development and test purposes. In total, there are about 660 training documents (16k sentences) </context>
<context position="31937" citStr="Finkel et al., 2005" startWordPosition="5571" endWordPosition="5574">en every aligned word 1080 \x0cpair. Martins et al. (2011b) presented a new DD method that combines the power of DD with the augmented Lagrangian method. They showed that their method can achieve faster convergence than traditional sub-gradient methods in models with many overlapping components (Martins et al., 2011a). This method is directly applicable to our work. Another promising direction for improving NER performance is in enforcing global label consistency across documents, which is an idea that has been greatly explored in the past (Sutton and McCallum, 2004; Bunescu and Mooney, 2004; Finkel et al., 2005). More recently, Rush et al. (2012) and Chieu and Teow (2012) have shown that combining local prediction models with global consistency models, and enforcing agreement via DD is very effective. It is straightforward to incorporate an additional global consistency model into our model for further improvements. Our joint alignment and NER decoding approach is inspired by prior work on improving alignment quality through encouraging agreement between bi-directional models (Liang et al., 2006; DeNero and Macherey, 2011). Instead of enforcing agreement in the alignment space based on best sequences</context>
</contexts>
<marker>Finkel, Grenager, Manning, 2005</marker>
<rawString>Jenny Rose Finkel, Trond Grenager, and Christopher Manning. 2005. Incorporating non-local information into information extraction systems by Gibbs sampling. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joao Graca</author>
<author>Kuzman Ganchev</author>
<author>Ben Taskar</author>
</authors>
<title>Expectation maximization and posterior constraints.</title>
<date>2008</date>
<booktitle>In Proceedings of NIPS.</booktitle>
<contexts>
<context position="32713" citStr="Graca et al. (2008)" startWordPosition="5692" endWordPosition="5695"> agreement via DD is very effective. It is straightforward to incorporate an additional global consistency model into our model for further improvements. Our joint alignment and NER decoding approach is inspired by prior work on improving alignment quality through encouraging agreement between bi-directional models (Liang et al., 2006; DeNero and Macherey, 2011). Instead of enforcing agreement in the alignment space based on best sequences found by Viterbi, we could opt to encourage agreement between posterior probability distributions, which is related to the posterior regularization work by Graca et al. (2008). Cromieres and Kurohashi (2009) proposed an approach that takes phrasal bracketing constraints from parsing outputs, and uses them to enforce phrasal alignments. This idea is similar to our joint alignment and NER approach, but in our case the phrasal constraints are indirectly imposed by entity spans. We also differ in the implementation details, where in their case belief propagation is used in both training and Viterbi inference. Burkett et al. (2010a) presented a supervised learning method for performing joint parsing and word alignment using log-linear models over parse trees and an ITG </context>
</contexts>
<marker>Graca, Ganchev, Taskar, 2008</marker>
<rawString>Joao Graca, Kuzman Ganchev, and Ben Taskar. 2008. Expectation maximization and posterior constraints. In Proceedings of NIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>John Blitzer</author>
<author>John DeNero</author>
<author>Dan Klein</author>
</authors>
<title>Better word alignments with supervised ITG models.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="21714" citStr="Haghighi et al., 2009" startWordPosition="3862" endWordPosition="3865">t experiments, we train two uni1 The exact feature set and the CRF implementation can be found here: http://nlp.stanford.edu/ software/CRF-NER.shtml directional HMM models as our baseline and monolingual alignment models. The parameters of the HMM were initialized by IBM Model 1 using the agreement-based EM training algorithms from Liang et al. (2006). Each model is trained for 2 iterations over a parallel corpus of 12 million English words and Chinese words, almost twice as much data as used in previous work that yields state-of-the-art unsupervised alignment results (DeNero and Klein, 2008; Haghighi et al., 2009; DeNero and Macherey, 2011). Word alignment evaluation is done over the sections of OntoNotes that have matching goldstandard word alignment annotations from GALE Y1Q4 dataset.2 This subset contains 288 documents and 3,391 sentence pairs. We will refer to this subset as wa-subset. This evaluation set is over 20 times larger than the 150 sentences set used in most past evaluations (DeNero and Klein, 2008; Haghighi et al., 2009; DeNero and Macherey, 2011). Alignments input to the BI-NER model are produced by thresholding the averaged posterior probability at 0.5. In joint NER and alignment expe</context>
</contexts>
<marker>Haghighi, Blitzer, DeNero, Klein, 2009</marker>
<rawString>Aria Haghighi, John Blitzer, John DeNero, and Dan Klein. 2009. Better word alignments with supervised ITG models. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eduard Hovy</author>
<author>Mitchell Marcus</author>
<author>Martha Palmer</author>
<author>Lance Ramshaw</author>
<author>Ralph Weischedel</author>
</authors>
<title>OntoNotes: the 90% solution.</title>
<date>2006</date>
<booktitle>In Proceedings of NAACL-HLT.</booktitle>
<contexts>
<context position="18895" citStr="Hovy et al., 2006" startWordPosition="3391" endWordPosition="3394">other by having them all agree with the edge cliques. It is also worth noting that since we decode the alignment models with Viterbi inference, additional constraints such as the neighborhood constraint proposed by DeNero and Macherey (2011) can be easily integrated into our model. The neighborhood constraint enforces that if fj is aligned to ei, then fj can only be aligned to ei+1 or ei1 (with a small penalty), but not any other word position. We report results of adding neighborhood constraints to our model in Section 6. 4 Experimental Setup We evaluate on the large OntoNotes (v4.0) corpus (Hovy et al., 2006) which contains manually 1077 \x0cannotated NER tags for both Chinese and English. Document pairs are sentence aligned using the Champollion Tool Kit (Ma, 2006). After discarding sentences with no aligned counterpart, a total of 402 documents and 8,249 parallel sentence pairs were used for evaluation. We will refer to this evaluation set as full-set. We use odd-numbered documents as the dev set and evennumbered documents as the blind test set. We did not perform parameter tuning on the dev set to optimize performance, instead we fix the initial learning rate to 0.5 and maximum iterations to 1,</context>
</contexts>
<marker>Hovy, Marcus, Palmer, Ramshaw, Weischedel, 2006</marker>
<rawString>Eduard Hovy, Mitchell Marcus, Martha Palmer, Lance Ramshaw, and Ralph Weischedel. 2006. OntoNotes: the 90% solution. In Proceedings of NAACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Huang</author>
<author>Stephan Vogel</author>
</authors>
<title>Improved named entity translation and bilingual named entity extraction.</title>
<date>2002</date>
<booktitle>In Proceedings of the 2002 International Conference on Multimodal Interfaces (ICMI).</booktitle>
<contexts>
<context position="2438" citStr="Huang and Vogel, 2002" startWordPosition="349" endWordPosition="352">translation (MT) since entities such as person names, locations, organizations, etc. carry much of the information expressed in the source sentence. Recognizing them provides useful information for phrase detection and word sense disambiguation (e.g., melody as in a female name has a different translation from the word melody in a musical sense), and can be directly leveraged to improve translation quality (Babych and Hartley, 2003). We can also automatically construct a named entity translation lexicon by annotating and extracting entities from bi-texts, and use it to improve MT performance (Huang and Vogel, 2002; Al-Onaizan and Knight, 2002). Previous work such as Burkett et al. (2010b), Li et al. (2012) and Kim et al. (2012) have also demonstrated that bitexts annotated with NER tags can provide useful additional training sources for improving the performance of standalone monolingual taggers. Because human translation in general preserves semantic equivalence, bi-texts represent two perspectives on the same semantic content (Burkett et al., 2010b). As a result, we can find complementary cues in the two languages that help to disambiguate named entity mentions (Brown et al., 1991). For example, the </context>
</contexts>
<marker>Huang, Vogel, 2002</marker>
<rawString>Fei Huang and Stephan Vogel. 2002. Improved named entity translation and bilingual named entity extraction. In Proceedings of the 2002 International Conference on Multimodal Interfaces (ICMI).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>Wenbin Jiang</author>
<author>Qun Liu</author>
</authors>
<title>Bilingually-constrained (monolingual) shift-reduce parsing.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="29545" citStr="Huang et al. (2009)" startWordPosition="5194" endWordPosition="5197">s) are baseline output. distance swapping phenomena. The two unidirectional HMMs also have strong disagreements over the alignments, and the resulting baseline aligner output only recovers two links. If we were to take this alignment as fixed input, most likely we would not be able to recover the error over e11, but the joint decoding method successfully recovered 4 more links, and indirectly resulted in the NER tagging improvement discussed above. 8 Related Work The idea of employing bilingual resources to improve over monolingual systems has been explored by much previous work. For example, Huang et al. (2009) improved parsing performance using a bilingual parallel corpus. In the NER domain, Li et al. (2012) presented a cyclic CRF model very similar to our BI-NER model, and performed approximate inference using loopy belief propagation. The feature-rich CRF formulation of bilingual edge potentials in their model is much more powerful than our simple PMI-based bilingual edge model. Adding a richer bilingual edge model might well further improve our results, and this is a possible direction for further experimentation. However, a big drawback of this approach is that training such a feature-rich mode</context>
</contexts>
<marker>Huang, Jiang, Liu, 2009</marker>
<rawString>Liang Huang, Wenbin Jiang, and Qun Liu. 2009. Bilingually-constrained (monolingual) shift-reduce parsing. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sungchul Kim</author>
<author>Kristina Toutanova</author>
<author>Hwanjo Yu</author>
</authors>
<title>Multilingual named entity recognition using parallel data and metadata from Wikipedia.</title>
<date>2012</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="2554" citStr="Kim et al. (2012)" startWordPosition="370" endWordPosition="373">ssed in the source sentence. Recognizing them provides useful information for phrase detection and word sense disambiguation (e.g., melody as in a female name has a different translation from the word melody in a musical sense), and can be directly leveraged to improve translation quality (Babych and Hartley, 2003). We can also automatically construct a named entity translation lexicon by annotating and extracting entities from bi-texts, and use it to improve MT performance (Huang and Vogel, 2002; Al-Onaizan and Knight, 2002). Previous work such as Burkett et al. (2010b), Li et al. (2012) and Kim et al. (2012) have also demonstrated that bitexts annotated with NER tags can provide useful additional training sources for improving the performance of standalone monolingual taggers. Because human translation in general preserves semantic equivalence, bi-texts represent two perspectives on the same semantic content (Burkett et al., 2010b). As a result, we can find complementary cues in the two languages that help to disambiguate named entity mentions (Brown et al., 1991). For example, the English word Jordan can be either a last name or a country. Without sufficient context it can be difficult to distin</context>
</contexts>
<marker>Kim, Toutanova, Yu, 2012</marker>
<rawString>Sungchul Kim, Kristina Toutanova, and Hwanjo Yu. 2012. Multilingual named entity recognition using parallel data and metadata from Wikipedia. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terry Koo</author>
<author>Alexander M Rush</author>
<author>Michael Collins</author>
<author>Tommi Jaakkola</author>
<author>David Sontag</author>
</authors>
<title>Dual decomposition for parsing with non-projective head automata.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="4271" citStr="Koo et al., 2010" startWordPosition="661" endWordPosition="664">kas, 1999; Rush et al., 2010) for performing approximate inference. Unlike most 1073 \x0cf1 f2 f3 f4 f5 f6 e1 e2 e3 e4 e5 e6 Xinhua News Agency Beijing Feb 16 B-ORG I-ORG I-ORG [O] B-LOC O O , , B-ORG O B-GPE O O O Figure 1: Example of NER labels between two word-aligned bilingual parallel sentences. The [O] tag is an example of a wrong tag assignment. The dashed alignment link between e3 and f2 is an example of alignment error. previous applications of the DD method in NLP, where the model typically factors over two components and agreement is to be sought between the two (Rush et al., 2010; Koo et al., 2010; DeNero and Macherey, 2011; Chieu and Teow, 2012), our method decomposes the larger graphical model into many overlapping components where each alignment edge forms a separate factor. We design clique potentials over the alignment-based edges to encourage entity tag agreements. Our method does not require any manual annotation of word alignments or named entities over the bilingual training data. The aforementioned BI-NER model assumes fixed alignment input given by an underlying word aligner. But the entity span and type predictions given by the NER models contain complementary information f</context>
<context position="7873" citStr="Koo et al. (2010)" startWordPosition="1305" endWordPosition="1308"> \x01 = k (ye ) + l yf \x01 + X (i,j)A u(i, j) \x10 ye i yf j \x11 where u(i, j) are the Lagrangian multipliers. Instead of solving the Lagrangian directly, we can form the dual of this problem and solve it using dual decomposition (Rush et al., 2010): min U max ye k (ye ) + X (i,j)A u(i, j)ye i + max yf l yf \x01 X (i,j)A u(i, j)yf j ! Similar to previous work, we solve this DD problem by iteratively updating the sub-gradient as depicted in Algorithm 1. T is the maximum number of iterations before early stopping, and t is the learning rate at time t. We adopt a learning rate update rule from Koo et al. (2010) where t is defined as 1 N , where N is the number of times we observed a consecutive dual value increase from iteration 1 to t. A thorough introduction to the theoretical foundations of dual decomposition algorithms is beyond the scope of this paper; we encourage unfamiliar readers to read Rush and Collins (2012) for a full tutorial. 2.2 Soft Agreement The previously discussed hard agreement model rests on the core assumption that aligned words must have identical entity tags. In reality, however, this assumption does not always hold. Firstly, assuming words are correctly aligned, their entit</context>
<context position="13187" citStr="Koo et al., 2010" startWordPosition="2268" endWordPosition="2271">cal models is analogous to other message passing algorithms such as loopy belief propagation, but DD gives a stronger optimality guarantee upon convergence (Rush et al., 2010). 3 Joint Alignment and NER Decoding In this section we develop an extended model in which NER information can in turn be used to improve alignment accuracy. Although we have seen more than a handful of recent papers that apply the dual decomposition method for joint inference problems, all of the past work deals with cases where the various model components have the same inference output space (e.g., dependency parsing (Koo et al., 2010), POS tagging (Rush et al., 2012), etc.). In our case the output space is the much more complex joint alignment and NER tagging space. We propose a novel dual decomposition variant for performing inference over this joint space. Most commonly used alignment models, such as the IBM models and HMM-based aligner are unsupervised learners, and can only capture simple distortion features and lexical translational features due to the high complexity of the structure prediction space. On the other hand, the CRFbased NER models are trained on manually annotated data, and admit richer sequence and lexi</context>
</contexts>
<marker>Koo, Rush, Collins, Jaakkola, Sontag, 2010</marker>
<rawString>Terry Koo, Alexander M. Rush, Michael Collins, Tommi Jaakkola, and David Sontag. 2010. Dual decomposition for parsing with non-projective head automata. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qi Li</author>
<author>Haibo Li</author>
<author>Heng Ji</author>
<author>Wen Wang</author>
<author>Jing Zheng</author>
<author>Fei Huang</author>
</authors>
<title>Joint bilingual name tagging for parallel corpora.</title>
<date>2012</date>
<booktitle>In Proceedings of CIKM.</booktitle>
<contexts>
<context position="2532" citStr="Li et al. (2012)" startWordPosition="365" endWordPosition="368">the information expressed in the source sentence. Recognizing them provides useful information for phrase detection and word sense disambiguation (e.g., melody as in a female name has a different translation from the word melody in a musical sense), and can be directly leveraged to improve translation quality (Babych and Hartley, 2003). We can also automatically construct a named entity translation lexicon by annotating and extracting entities from bi-texts, and use it to improve MT performance (Huang and Vogel, 2002; Al-Onaizan and Knight, 2002). Previous work such as Burkett et al. (2010b), Li et al. (2012) and Kim et al. (2012) have also demonstrated that bitexts annotated with NER tags can provide useful additional training sources for improving the performance of standalone monolingual taggers. Because human translation in general preserves semantic equivalence, bi-texts represent two perspectives on the same semantic content (Burkett et al., 2010b). As a result, we can find complementary cues in the two languages that help to disambiguate named entity mentions (Brown et al., 1991). For example, the English word Jordan can be either a last name or a country. Without sufficient context it can </context>
<context position="29645" citStr="Li et al. (2012)" startWordPosition="5210" endWordPosition="5213">reements over the alignments, and the resulting baseline aligner output only recovers two links. If we were to take this alignment as fixed input, most likely we would not be able to recover the error over e11, but the joint decoding method successfully recovered 4 more links, and indirectly resulted in the NER tagging improvement discussed above. 8 Related Work The idea of employing bilingual resources to improve over monolingual systems has been explored by much previous work. For example, Huang et al. (2009) improved parsing performance using a bilingual parallel corpus. In the NER domain, Li et al. (2012) presented a cyclic CRF model very similar to our BI-NER model, and performed approximate inference using loopy belief propagation. The feature-rich CRF formulation of bilingual edge potentials in their model is much more powerful than our simple PMI-based bilingual edge model. Adding a richer bilingual edge model might well further improve our results, and this is a possible direction for further experimentation. However, a big drawback of this approach is that training such a feature-rich model requires manually annotated bilingual NER data, which can be prohibitively expensive to generate. </context>
</contexts>
<marker>Li, Li, Ji, Wang, Zheng, Huang, 2012</marker>
<rawString>Qi Li, Haibo Li, Heng Ji, Wen Wang, Jing Zheng, and Fei Huang. 2012. Joint bilingual name tagging for parallel corpora. In Proceedings of CIKM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Percy Liang</author>
<author>Ben Taskar</author>
<author>Dan Klein</author>
</authors>
<title>Alignment by agreement.</title>
<date>2006</date>
<booktitle>In Proceedings of HLT-NAACL.</booktitle>
<contexts>
<context position="21446" citStr="Liang et al. (2006)" startWordPosition="3817" endWordPosition="3820">ore the distinction between B- and Itags. We report standard NER measures (entity precision (P), recall (R) and F1 score) on the test set. Statistical significance tests are done using the paired bootstrap resampling method (Efron and Tibshirani, 1993). For alignment experiments, we train two uni1 The exact feature set and the CRF implementation can be found here: http://nlp.stanford.edu/ software/CRF-NER.shtml directional HMM models as our baseline and monolingual alignment models. The parameters of the HMM were initialized by IBM Model 1 using the agreement-based EM training algorithms from Liang et al. (2006). Each model is trained for 2 iterations over a parallel corpus of 12 million English words and Chinese words, almost twice as much data as used in previous work that yields state-of-the-art unsupervised alignment results (DeNero and Klein, 2008; Haghighi et al., 2009; DeNero and Macherey, 2011). Word alignment evaluation is done over the sections of OntoNotes that have matching goldstandard word alignment annotations from GALE Y1Q4 dataset.2 This subset contains 288 documents and 3,391 sentence pairs. We will refer to this subset as wa-subset. This evaluation set is over 20 times larger than </context>
<context position="32430" citStr="Liang et al., 2006" startWordPosition="5647" endWordPosition="5650">an idea that has been greatly explored in the past (Sutton and McCallum, 2004; Bunescu and Mooney, 2004; Finkel et al., 2005). More recently, Rush et al. (2012) and Chieu and Teow (2012) have shown that combining local prediction models with global consistency models, and enforcing agreement via DD is very effective. It is straightforward to incorporate an additional global consistency model into our model for further improvements. Our joint alignment and NER decoding approach is inspired by prior work on improving alignment quality through encouraging agreement between bi-directional models (Liang et al., 2006; DeNero and Macherey, 2011). Instead of enforcing agreement in the alignment space based on best sequences found by Viterbi, we could opt to encourage agreement between posterior probability distributions, which is related to the posterior regularization work by Graca et al. (2008). Cromieres and Kurohashi (2009) proposed an approach that takes phrasal bracketing constraints from parsing outputs, and uses them to enforce phrasal alignments. This idea is similar to our joint alignment and NER approach, but in our case the phrasal constraints are indirectly imposed by entity spans. We also diff</context>
</contexts>
<marker>Liang, Taskar, Klein, 2006</marker>
<rawString>Percy Liang, Ben Taskar, and Dan Klein. 2006. Alignment by agreement. In Proceedings of HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaoyi Ma</author>
</authors>
<title>Champollion: A robust parallel text sentence aligner.</title>
<date>2006</date>
<booktitle>In Proceedings of LREC. Andre</booktitle>
<contexts>
<context position="19055" citStr="Ma, 2006" startWordPosition="3419" endWordPosition="3420">ch as the neighborhood constraint proposed by DeNero and Macherey (2011) can be easily integrated into our model. The neighborhood constraint enforces that if fj is aligned to ei, then fj can only be aligned to ei+1 or ei1 (with a small penalty), but not any other word position. We report results of adding neighborhood constraints to our model in Section 6. 4 Experimental Setup We evaluate on the large OntoNotes (v4.0) corpus (Hovy et al., 2006) which contains manually 1077 \x0cannotated NER tags for both Chinese and English. Document pairs are sentence aligned using the Champollion Tool Kit (Ma, 2006). After discarding sentences with no aligned counterpart, a total of 402 documents and 8,249 parallel sentence pairs were used for evaluation. We will refer to this evaluation set as full-set. We use odd-numbered documents as the dev set and evennumbered documents as the blind test set. We did not perform parameter tuning on the dev set to optimize performance, instead we fix the initial learning rate to 0.5 and maximum iterations to 1,000 in all DD experiments. We only use the dev set for model development. The Stanford CRF-based NER tagger was used as the monolingual component in our models </context>
</contexts>
<marker>Ma, 2006</marker>
<rawString>Xiaoyi Ma. 2006. Champollion: A robust parallel text sentence aligner. In Proceedings of LREC. Andre F. T. Martins, Noah A. Smith, Pedro M. Q.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aguiar</author>
<author>Mario A T Figueiredo</author>
</authors>
<title>Dual decomposition with many overlapping components.</title>
<date>2011</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<marker>Aguiar, Figueiredo, 2011</marker>
<rawString>Aguiar, and Mario A. T. Figueiredo. 2011a. Dual decomposition with many overlapping components. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andre F T Martins</author>
<author>Noah A Smith</author>
<author>Eric P Xing</author>
<author>Pedro M Q Aguiar</author>
<author>Mario A T Figueiredo</author>
</authors>
<title>Augmenting dual decomposition for map inference.</title>
<date>2011</date>
<booktitle>In Proceedings of the International Workshop on Optimization for Machine Learning (OPT</booktitle>
<contexts>
<context position="31374" citStr="Martins et al. (2011" startWordPosition="5484" endWordPosition="5487">ditional training and can take pretty much any existing model as black-box during decoding, the richer and more accurate bilingual model learned from Burkett et al. (2010b) can be directly plugged into our model. A similar dual decomposition algorithm to ours was proposed by Riedel and McCallum (2011) for biomedical event detection. In their Model 3, the trigger and argument extraction models are reminiscent of the two monolingual CRFs in our model; additional binding agreements are enforced over every protein pair, similar to how we enforce agreement between every aligned word 1080 \x0cpair. Martins et al. (2011b) presented a new DD method that combines the power of DD with the augmented Lagrangian method. They showed that their method can achieve faster convergence than traditional sub-gradient methods in models with many overlapping components (Martins et al., 2011a). This method is directly applicable to our work. Another promising direction for improving NER performance is in enforcing global label consistency across documents, which is an idea that has been greatly explored in the past (Sutton and McCallum, 2004; Bunescu and Mooney, 2004; Finkel et al., 2005). More recently, Rush et al. (2012) a</context>
</contexts>
<marker>Martins, Smith, Xing, Aguiar, Figueiredo, 2011</marker>
<rawString>Andre F. T. Martins, Noah A. Smith, Eric P. Xing, Pedro M. Q. Aguiar, and Mario A. T. Figueiredo. 2011b. Augmenting dual decomposition for map inference. In Proceedings of the International Workshop on Optimization for Machine Learning (OPT 2010).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Riedel</author>
<author>Andrew McCallum</author>
</authors>
<title>Fast and robust joint models for biomedical event extraction.</title>
<date>2011</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="31056" citStr="Riedel and McCallum (2011)" startWordPosition="5434" endWordPosition="5437">ch explored an up-training mechanism by using the outputs from a strong monolingual model as ground-truth, and simulated a learning environment where a bilingual model is trained to help a weakened monolingual model to recover the results of the strong model. It is worth mentioning that since our method does not require additional training and can take pretty much any existing model as black-box during decoding, the richer and more accurate bilingual model learned from Burkett et al. (2010b) can be directly plugged into our model. A similar dual decomposition algorithm to ours was proposed by Riedel and McCallum (2011) for biomedical event detection. In their Model 3, the trigger and argument extraction models are reminiscent of the two monolingual CRFs in our model; additional binding agreements are enforced over every protein pair, similar to how we enforce agreement between every aligned word 1080 \x0cpair. Martins et al. (2011b) presented a new DD method that combines the power of DD with the augmented Lagrangian method. They showed that their method can achieve faster convergence than traditional sub-gradient methods in models with many overlapping components (Martins et al., 2011a). This method is dir</context>
</contexts>
<marker>Riedel, McCallum, 2011</marker>
<rawString>Sebastian Riedel and Andrew McCallum. 2011. Fast and robust joint models for biomedical event extraction. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander M Rush</author>
<author>Michael Collins</author>
</authors>
<title>A tutorial on dual decomposition and Lagrangian relaxation for inference in natural language processing.</title>
<date>2012</date>
<journal>JAIR,</journal>
<pages>45--305362</pages>
<contexts>
<context position="8188" citStr="Rush and Collins (2012)" startWordPosition="1363" endWordPosition="1366">f \x01 X (i,j)A u(i, j)yf j ! Similar to previous work, we solve this DD problem by iteratively updating the sub-gradient as depicted in Algorithm 1. T is the maximum number of iterations before early stopping, and t is the learning rate at time t. We adopt a learning rate update rule from Koo et al. (2010) where t is defined as 1 N , where N is the number of times we observed a consecutive dual value increase from iteration 1 to t. A thorough introduction to the theoretical foundations of dual decomposition algorithms is beyond the scope of this paper; we encourage unfamiliar readers to read Rush and Collins (2012) for a full tutorial. 2.2 Soft Agreement The previously discussed hard agreement model rests on the core assumption that aligned words must have identical entity tags. In reality, however, this assumption does not always hold. Firstly, assuming words are correctly aligned, their entity tags may not agree due to inconsistency in annotation standards. In Figure 1, for example, the Algorithm 1 DD inference algorithm for hard agreement model. (i, j) A : u(i, j) = 0 for t 1 to T do ye argmax k (ye ) + P (i,j)A u(i, j)ye i yf argmax l yf \x01 P (i,j)A u(i, j)yf j if (i, j) A: ye i = yf j then return</context>
</contexts>
<marker>Rush, Collins, 2012</marker>
<rawString>Alexander M. Rush and Michael Collins. 2012. A tutorial on dual decomposition and Lagrangian relaxation for inference in natural language processing. JAIR, 45:305362.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander M Rush</author>
<author>David Sontag</author>
<author>Michael Collins</author>
<author>Tommi Jaakkola</author>
</authors>
<title>On dual decomposition and linear programming relaxations for natural language processing.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="3684" citStr="Rush et al., 2010" startWordPosition="550" endWordPosition="553">ither a last name or a country. Without sufficient context it can be difficult to distinguish the two; however, in Chinese, these two senses are disambiguated: as a last name, and as a country name. In this work, we first develop a bilingual NER model (denoted as BI-NER) by embedding two monolingual CRF-based NER models into a larger undirected graphical model, and introduce additional edge factors based on word alignment (WA). Because the new bilingual model contains many cyclic cliques, exact inference is intractable. We employ a dual decomposition (DD) inference algorithm (Bertsekas, 1999; Rush et al., 2010) for performing approximate inference. Unlike most 1073 \x0cf1 f2 f3 f4 f5 f6 e1 e2 e3 e4 e5 e6 Xinhua News Agency Beijing Feb 16 B-ORG I-ORG I-ORG [O] B-LOC O O , , B-ORG O B-GPE O O O Figure 1: Example of NER labels between two word-aligned bilingual parallel sentences. The [O] tag is an example of a wrong tag assignment. The dashed alignment link between e3 and f2 is an example of alignment error. previous applications of the DD method in NLP, where the model typically factors over two components and agreement is to be sought between the two (Rush et al., 2010; Koo et al., 2010; DeNero and </context>
<context position="7507" citStr="Rush et al., 2010" startWordPosition="1230" endWordPosition="1233"> At inference time, we solve the following opti1074 \x0cmization problem: max ye,yf log (PCRFe (ye )) + log PCRFf yf \x01\x01 = max ye,yf k(ye ) + l(yf ) log Ze(e) log Zf (f) &amp;apos; max ye,yf k(ye ) + l(yf ) 3 ye i = yf j (i, j) A We dropped the Ze(e) and Zf(f) terms because they remain constant at inference time. The Lagrangian relaxation of this term is: L ye , yf , U \x01 = k (ye ) + l yf \x01 + X (i,j)A u(i, j) \x10 ye i yf j \x11 where u(i, j) are the Lagrangian multipliers. Instead of solving the Lagrangian directly, we can form the dual of this problem and solve it using dual decomposition (Rush et al., 2010): min U max ye k (ye ) + X (i,j)A u(i, j)ye i + max yf l yf \x01 X (i,j)A u(i, j)yf j ! Similar to previous work, we solve this DD problem by iteratively updating the sub-gradient as depicted in Algorithm 1. T is the maximum number of iterations before early stopping, and t is the learning rate at time t. We adopt a learning rate update rule from Koo et al. (2010) where t is defined as 1 N , where N is the number of times we observed a consecutive dual value increase from iteration 1 to t. A thorough introduction to the theoretical foundations of dual decomposition algorithms is beyond the sco</context>
<context position="12745" citStr="Rush et al., 2010" startWordPosition="2192" endWordPosition="2195">al factor. The updated DD algorithm is illustrated in Algorithm 2 (case 2). We introduce two separate sets of dual constraints we and wf, which range over the set of vertices on their respective half of the graph. Decoding the edge factor model h(i,j)(ye i , yf j) simply involves finding the pair of tag assignments that gives the highest PMI score, subject to the dual constraints. The way DD algorithms work in decomposing undirected graphical models is analogous to other message passing algorithms such as loopy belief propagation, but DD gives a stronger optimality guarantee upon convergence (Rush et al., 2010). 3 Joint Alignment and NER Decoding In this section we develop an extended model in which NER information can in turn be used to improve alignment accuracy. Although we have seen more than a handful of recent papers that apply the dual decomposition method for joint inference problems, all of the past work deals with cases where the various model components have the same inference output space (e.g., dependency parsing (Koo et al., 2010), POS tagging (Rush et al., 2012), etc.). In our case the output space is the much more complex joint alignment and NER tagging space. We propose a novel dual</context>
</contexts>
<marker>Rush, Sontag, Collins, Jaakkola, 2010</marker>
<rawString>Alexander M. Rush, David Sontag, Michael Collins, and Tommi Jaakkola. 2010. On dual decomposition and linear programming relaxations for natural language processing. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander M Rush</author>
<author>Roi Reichert</author>
<author>Michael Collins</author>
<author>Amir Globerson</author>
</authors>
<title>Improved parsing and POS tagging using inter-sentence consistency constraints.</title>
<date>2012</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="13220" citStr="Rush et al., 2012" startWordPosition="2274" endWordPosition="2277"> message passing algorithms such as loopy belief propagation, but DD gives a stronger optimality guarantee upon convergence (Rush et al., 2010). 3 Joint Alignment and NER Decoding In this section we develop an extended model in which NER information can in turn be used to improve alignment accuracy. Although we have seen more than a handful of recent papers that apply the dual decomposition method for joint inference problems, all of the past work deals with cases where the various model components have the same inference output space (e.g., dependency parsing (Koo et al., 2010), POS tagging (Rush et al., 2012), etc.). In our case the output space is the much more complex joint alignment and NER tagging space. We propose a novel dual decomposition variant for performing inference over this joint space. Most commonly used alignment models, such as the IBM models and HMM-based aligner are unsupervised learners, and can only capture simple distortion features and lexical translational features due to the high complexity of the structure prediction space. On the other hand, the CRFbased NER models are trained on manually annotated data, and admit richer sequence and lexical features. The entity label pr</context>
<context position="31972" citStr="Rush et al. (2012)" startWordPosition="5577" endWordPosition="5580">Martins et al. (2011b) presented a new DD method that combines the power of DD with the augmented Lagrangian method. They showed that their method can achieve faster convergence than traditional sub-gradient methods in models with many overlapping components (Martins et al., 2011a). This method is directly applicable to our work. Another promising direction for improving NER performance is in enforcing global label consistency across documents, which is an idea that has been greatly explored in the past (Sutton and McCallum, 2004; Bunescu and Mooney, 2004; Finkel et al., 2005). More recently, Rush et al. (2012) and Chieu and Teow (2012) have shown that combining local prediction models with global consistency models, and enforcing agreement via DD is very effective. It is straightforward to incorporate an additional global consistency model into our model for further improvements. Our joint alignment and NER decoding approach is inspired by prior work on improving alignment quality through encouraging agreement between bi-directional models (Liang et al., 2006; DeNero and Macherey, 2011). Instead of enforcing agreement in the alignment space based on best sequences found by Viterbi, we could opt to </context>
</contexts>
<marker>Rush, Reichert, Collins, Globerson, 2012</marker>
<rawString>Alexander M. Rush, Roi Reichert, Michael Collins, and Amir Globerson. 2012. Improved parsing and POS tagging using inter-sentence consistency constraints. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles Sutton</author>
<author>Andrew McCallum</author>
</authors>
<title>Collective segmentation and labeling of distant entities in information extraction.</title>
<date>2004</date>
<booktitle>In Proceedings of ICML Workshop on Statistical Relational Learning and Its connections to Other</booktitle>
<location>Fields.</location>
<contexts>
<context position="31889" citStr="Sutton and McCallum, 2004" startWordPosition="5562" endWordPosition="5566">otein pair, similar to how we enforce agreement between every aligned word 1080 \x0cpair. Martins et al. (2011b) presented a new DD method that combines the power of DD with the augmented Lagrangian method. They showed that their method can achieve faster convergence than traditional sub-gradient methods in models with many overlapping components (Martins et al., 2011a). This method is directly applicable to our work. Another promising direction for improving NER performance is in enforcing global label consistency across documents, which is an idea that has been greatly explored in the past (Sutton and McCallum, 2004; Bunescu and Mooney, 2004; Finkel et al., 2005). More recently, Rush et al. (2012) and Chieu and Teow (2012) have shown that combining local prediction models with global consistency models, and enforcing agreement via DD is very effective. It is straightforward to incorporate an additional global consistency model into our model for further improvements. Our joint alignment and NER decoding approach is inspired by prior work on improving alignment quality through encouraging agreement between bi-directional models (Liang et al., 2006; DeNero and Macherey, 2011). Instead of enforcing agreemen</context>
</contexts>
<marker>Sutton, McCallum, 2004</marker>
<rawString>Charles Sutton and Andrew McCallum. 2004. Collective segmentation and labeling of distant entities in information extraction. In Proceedings of ICML Workshop on Statistical Relational Learning and Its connections to Other Fields.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>