previous applications of the DD method in NLP, where the model typically factors over two components and agreement is to be sought between the two (CITATION; CITATION; CITATION; CITATION), our method decomposes the larger graphical model into many overlapping components where each alignment edge forms a separate factor,,
Each model is trained for 2 iterations over a parallel corpus of 12 million English words and Chinese words, almost twice as much data as used in previous work that yields state-of-the-art unsupervised alignment results (CITATION; CITATION; CITATION),,
Although we have seen more than a handful of recent papers that apply the dual decomposition method for joint inference problems, all of the past work deals with cases where the various model components have the same inference output space (e.g., dependency parsing CITATION, POS tagging CITATION, etc.),,
an idea that has been greatly explored in the past (CITATION; CITATION; CITATION),,
For example, CITATION improved parsing performance using a bilingual parallel corpus,,
 MT performance (CITATION; CITATION),,
In order to compare directly with their method, we obtained the code behind CITATIONb) and reproduced their experimental setting for the OntoNotes data,,
kas, 1999; CITATION) for performing approximate inference,,
CITATION also tackled the problem of joint alignment and NER,,
 message passing algorithms such as loopy belief propagation, but DD gives a stronger optimality guarantee upon convergence CITATION,,
ch as the neighborhood constraint proposed by CITATION can be easily integrated into our model,,
In the NER domain, CITATION presented a cyclic CRF model very similar to our BI-NER model, and performed approximate inference using loopy belief propagation,,
The parameters of the HMM were initialized by IBM Model 1 using the agreement-based EM training algorithms from CITATION,,
n greatly explored in the past (CITATION; CITATION; CITATION),,
+NC means incorporating additional neighbor constraints from CITATION to the model,,
rbi, we could opt to encourage agreement between posterior probability distributions, which is related to the posterior regularization work by CITATION,,
Document pairs are sentence aligned using the Champollion Tool Kit CITATION,,
We employ a dual decomposition (DD) inference algorithm (CITATION; CITATION) for performing approximate inference,,
This evaluation set is over 20 times larger than the 150 sentences set used in most past evaluations (CITATION; CITATION; CITATION),,
A similar dual decomposition algorithm to ours was proposed by CITATION for biomedical event detection,,
More recently, CITATION and CITATION have shown that combining local prediction models with global consistency models, and enforcing agreement via DD is very effective,,
4 Experimental Setup We evaluate on the large OntoNotes (v4.0) corpus CITATION which contains manually 1077 \x0cannotated NER tags for both Chinese and English,,
It is also worth noting that since we decode the alignment models with Viterbi inference, additional constraints such as the neighborhood constraint proposed by CITATION can be easily integrated into our model,,
More recently, CITATION a,,
It is worth mentioning that since our method does not require additional training and can take pretty much any existing model as black-box during decoding, the richer and more accurate bilingual model learned from CITATIONb) can be directly plugged into our model,,
We adopt a learning rate update rule from CITATION where t is defined as 1 N , where N is the number of times we observed a consecutive dual value increase from iteration 1 to t,,
previous applications of the DD method in NLP, where the model typically factors over two components and agreement is to be sought between the two (CITATION; Koo et al,,
ditional training and can take pretty much any existing model as black-box during decoding, the richer and more accurate bilingual model learned from CITATIONb) can be directly plugged into our model,,
Previous work such as CITATIONb), CITATION and CITATION have also demonstrated that bitexts annotated with NER tags can provide useful additional training sources for improving the performance of standalone monolingual taggers,,
One of the most interesting papers in this regard is CITATIONb), which explored an up-training mechanism by using the outputs from a strong monolingual model as ground-truth, and simulated a learning environment where a bilingual model is trained to help a weakened monolingual model to recover the results of the strong model,,
CITATIONa) presented a supervised learning method for performing joint parsing and word alignment using log-linear models over parse trees and an ITG model over alignment,,
Recognizing them provides useful information for phrase detection and word sense disambiguation (e.g., melody as in a female name has a different translation from the word melody in a musical sense), and can be directly leveraged to improve translation quality CITATION,,
Instead of enforcing agreement in the alignment space based on best sequences found by Viterbi, we could opt to encourage agreement between posterior probability distributions, which is related to the posterior regularization work by CITATION,,
 evaluation set is over 20 times larger than the 150 sentences set used in most past evaluations (CITATION; CITATION; CITATION),,
An important past work to make comparisons with is CITATIONb),,
A thorough introduction to the theoretical foundations of dual decomposition algorithms is beyond the scope of this paper; we encourage unfamiliar readers to read CITATION for a full tutorial,,
previous applications of the DD method in NLP, where the model typically factors over two components and agreement is to be sought between the two (CITATION; CITATION; DeNero and ,,
We can also automatically construct a named entity translation lexicon by annotating and extracting entities from bi-texts, and use it to improve MT performance (CITATION; CITATION),,
CITATIONa) presented a supervised learning method for performing joint parsing and word alignment using log-linear models over parse trees and an ITG ,,
CITATIONb) presented a new DD method that combines the power of DD with the augmented Lagrangian method,,
Best numbers on each measure that are statistically significantly better than the monolingual baseline and CITATIONb) are highlighted in bold,,
The way DD algorithms work in decomposing undirected graphical models is analogous to other message passing algorithms such as loopy belief propagation, but DD gives a stronger optimality guarantee upon convergence CITATION,,
Statistical significance tests are done using the paired bootstrap resampling method CITATION,,
The Stanford CRF-based NER tagger was used as the monolingual component in our models CITATION,,
CITATION proposed an approach that takes phrasal bracketing constraints from parsing outputs, and uses them to enforce phrasal alignments,,
cal models is analogous to other message passing algorithms such as loopy belief propagation, but DD gives a stronger optimality guarantee upon convergence CITATION,,
Another promising direction for improving NER performance is in enforcing global label consistency across documents, which is an idea that has been greatly explored in the past (CITATION; CITATION; CITATION),,
Instead of solving the Lagrangian directly, we can form the dual of this problem and solve it using dual decomposition CITATION: min U max ye k (ye ) + X (i,j)A u(i, j)ye i + max yf l yf \x01 X (i,j)A u(i, j)yf j ! Similar to previous work, we solve this DD problem by iteratively updating the sub-gradient as depicted in Algorithm 1,,
As a result, we can find complementary cues in the two languages that help to disambiguate named entity mentions CITATION,,
Our joint alignment and NER decoding approach is inspired by prior work on improving alignment quality through encouraging agreement between bi-directional models (CITATION; CITATION),,
