Our D&B-STYLE baseline used the same test time method as CITATION, however at training time we created data for all mention pairs,,
Ng and Cardie (2002a) and CITATION highlight the problem of determining whether or not common noun phrases are anaphoric,,
More recently, CITATION utilized an integer linear programming (ILP) solver to better combine the decisions made by these two complementary classifiers, by finding the globally optimal solution according to both classifiers,,
The COREF-ILP model of CITATION took a different approach at test time: for each mention they would work backwards and add a link for all previous mentions which the classifier deemed coreferent,,
1 Introduction Much recent work on coreference resolution, which is the task of deciding which noun phrases, or mentions, in a document refer to the same real world entity, builds on CITATION,,
e tagger of CITATION, and used the tags to decide if mentions were plural or singular,,
3.1 Evaluation Metrics The MUC scorer CITATION is a popular coreference evaluation metric, but we found it to be fatally flawed,,
45 \x0copposed to pairwise models) has included: CITATION who used a Bell tree whose leaves represent possible partitionings of the mentions into entities and then trained a model for searching the tree; CITATION who defined several conditional random field-based models; CITATION who took a reranking approach; and CITATION who use a probabilistic first-order logic model,,
(2004) who used a Bell tree whose leaves represent possible partitionings of the mentions into entities and then trained a model for searching the tree; CITATION who defined several conditional random field-based models; CITATION who took a reranking approach; and CITATION who use a probabilistic first-order logic model,,
For comparison, we also give the results of the COREFILP system of CITATION, which was also based on a nave pair,,
This approach made sense for CITATION because testing proceeded in a similar manner: for each mention, work backwards until you find a previous mention which the classifier thinks is coreferent, add a link, and terminate the search,,
mentions; the Rand index CITATION, which is pairwise accuracy of the clustering; and variation of information CITATION, which utilizes the entropy of the clusterings and their mutual information (and for which lower values are better),,
Much work that followed improved upon this strategy, by improving the features (CITATIONb), the type of classifier CITATION, and changing mention links to be to the most likely antecedent rather than the most recent positively labeled antecedent (CITATIONb),,
Our feature set was simple, and included many features from CITATION, including the pronoun, string match, definite and demonstrative NP, number an,,
As observed by CITATION, if all mentions in each document are placed into a single entity, the results on the MUC-6 formal test set are 100% recall, 78.9% precision, and 88.2% F1 score significantly higher than any published system,,
Our SOON-STYLE baseline used the same training and testing regimen as CITATION,,
This corpus had a third portion, NPAPER, but we found that several documents where too long for lp solve to find a solution.4 We added named entity (NE) tags to the data using the tagger of CITATION,,
In addition to the MUC and b3 scorers, we also evaluate using cluster f-measure CITATION, which is the standard f-measure computed over true/false coreference decisions for pairs of 3 Fro,,
a solution.4 We added named entity (NE) tags to the data using the tagger of CITATION,,
Our feature set was simple, and included many features from CITATION, including the pronoun, string match, definite and demonstrative NP, number and gender agreement, proper name and appositive features,,
For comparison, we also give the results of the COREFILP system of CITATION, which was also based on a nave pairwise classifier,,
mentions; the Rand index CITATION, which is pairwise accuracy of the clustering; and variation of information CITATION, which utilizes the entropy of th,,
Prior work (CITATION; CITATION) has generated training data for pairwise classifiers in the following manner,,
When describing our model, we build upon the notation used by CITATION,,
We also added part of speech (POS) tags to the data using the tagger of CITATION, and used the tags to decide if mentions were plural or singular,,
3.1 Evaluation Metrics The MUC scorer CITATION is a popular c,,
As observed by CITATION, if all mentions in each document are placed into a single entity, the results on the MUC-6 formal test set are 100% recall, 78.9% precision, and 88.2% F1 score significantly higher than any published syste,,
The b3 scorer CITATION was proposed to overcome several shortcomings of the MUC scorer,,
In addition to the MUC and b3 scorers, we also evaluate using cluster f-measure CITATION, which is the standard f-measure computed over true/false coreference decisions for pairs of 3 From http://lpsolve.sourceforge.net/ 4 Integer linear programming is, after all, NP-hard,,
