1 Evaluation Metrics The MUC scorer CITATION is a popular coreference evaluation metric, but we found it to be fatally flawed,,
 As observed by CITATION, if all mentions in each document are placed into a single entity, the results on the MUC-6 formal test set are 100% recall, 78,,
 The b3 scorer CITATION was proposed to overcome several shortcomings of the MUC scorer,,
 In addition to the MUC and b3 scorers, we also evaluate using cluster f-measure CITATION, which is the standard f-measure computed over true/false coreference decisions for pairs of 3 From http://lpsolve,,
 mentions; the Rand index CITATION, which is pairwise accuracy of the clustering; and variation of information CITATION, which utilizes the entropy of th,,
 45 \x0copposed to pairwise models) has included: CITATION who used a Bell tree whose leaves represent possible partitionings of the mentions into entities and then trained a model for searching the tree; CITATION who defined several conditional random field-based models; CITATION who took a reranking approach; and CITATION who use a probabilistic first-order logic model,,
 When describing our model, we build upon the notation used by CITATION,,
 Much work that followed improved upon this strategy, by improving the features (CITATIONb), the type of classifier CITATION, and changing mention links to be to the most likely antecedent rather than the most recent positively labeled antecedent (CITATIONb),,
 Ng and Cardie (2002a) and CITATION highlight the problem of determining whether or not common noun phrases are anaphoric,,
 (2004) who used a Bell tree whose leaves represent possible partitionings of the mentions into entities and then trained a model for searching the tree; CITATION who defined several conditional random field-based models; CITATION who took a reranking approach; and CITATION who use a probabilistic first-order logic model,,
 When describing our model, we build upon the notation used by CITATION,,
 This approach made sense for CITATION because testing proceeded in a similar manner: for each mention, work backwards until you find a previous mention which the classifier thinks is coreferent, add a link, and terminate the search,,
 The COREF-ILP model of CITATION took a different approach at test time: for each mention they would work backwards and add a link for all previous mentions which the classifier deemed coreferent,,
 mentions; the Rand index CITATION, which is pairwise accuracy of the clustering; and variation of information CITATION, which utilizes the entropy of the clusterings and their mutual information (and for which lower values are better),,
 For comparison, we also give the results of the COREFILP system of CITATION, which was also based on a nave pairwise classifier,,
4 We added named entity (NE) tags to the data using the tagger of CITATION,,
 We also added part of speech (POS) tags to the data using the tagger of CITATION, and used the tags to decide if mentions were plural or singular,,
 Our feature set was simple, and included many features from CITATION, including the pronoun, string match, definite and demonstrative NP, number an,,
 As observed by CITATION, if all mentions in each document are placed into a single entity, the results on the MUC-6 formal test set are 100% recall, 78,,
 The b3 scorer CITATION was proposed to overcome several shortcomings of the MUC scorer,,
 In addition to the MUC and b3 scorers, we also evaluate using cluster f-measure CITATION, which is the standard f-measure computed over true/false coreference decisions for pairs of 3 From http://lpsolve,,
 mentions; the Rand index CITATION, which is pairwise accuracy of the clustering; and variation of information CITATION, which utilizes the entropy of the clusterings and their mutual information (and for which lower values are better),,
 45 \x0copposed to pairwise models) has included: CITATION who used a Bell tree whose leaves represent possible partitionings of the mentions into entities and then trained a model for searching the tree; CITATION who defined several conditional random field-based models; CITATION who took a reranking approach; and CITATION who use a probabilistic first-order logic model,,
 Our feature set was simple, and included many features from CITATION, including the pronoun, string match, definite and demonstrative NP, number and gender agreement, proper name and appositive features,,
1 Evaluation Metrics The MUC scorer CITATION is a popular coreference evaluation metric, but we found it to be fatally flawed,,
 As observed by CITATION, if all mentions in each document are placed into a single entity, the results on the MUC-6 formal test set are 100% recall, 78,,
 The b3 scorer CITATION was proposed to overcome several shortcomings of the MUC scorer,,
 In addition to the MUC and b3 scorers, we also evaluate using cluster f-measure CITATION, which is the standard f-measure computed over true/false coreference decisions for pairs of 3 Fro,,
 45 \x0copposed to pairwise models) has included: CITATION who used a Bell tree whose leaves represent possible partitionings of the mentions into entities and then trained a model for searching the tree; CITATION who defined several conditional random field-based models; CITATION who took a reranking approach; and CITATION who use a probabilistic first-order logic model,,
 When describing our model, we build upon the notation used by CITATION,,
 The b3 scorer CITATION was proposed to overcome several shortcomings of the MUC scorer,,
 In addition to the MUC and b3 scorers, we also evaluate using cluster f-measure CITATION, which is the standard f-measure computed over true/false coreference decisions for pairs of 3 From http://lpsolve,,
 mentions; the Rand index CITATION, which is pairwise accuracy of the clustering; and variation of information CITATION, which utilizes the entropy of the clusterings and their mutual information (and for which lower values are better),,
 For comparison, we also give the results of the COREFILP system of CITATION, which was also based on a nave pairwise classifier,,
 Much work that followed improved upon this strategy, by improving the features (CITATIONb), the type of classifier CITATION, and changing mention links to be to the most likely antecedent rather than the most recent positively labeled antecedent (CITATIONb),,
 Ng and Cardie (2002a) and CITATION highlight the problem of determining whether or not common noun phrases are anaphoric,,
 Much work that followed improved upon this strategy, by improving the features (CITATIONb), the type of classifier CITATION, and changing mention links to be to the most likely antecedent rather than the most recent positively labeled antecedent (CITATIONb),,
 Ng and Cardie (2002a) and CITATION highlight the problem of determining whether or not common noun phrases are anaphoric,,
 Much work that followed improved upon this strategy, by improving the features (CITATIONb), the type of classifier CITATION, and changing mention links to be to the most likely antecedent rather than the most recent positively labeled antecedent (CITATIONb),,
 Ng and Cardie (2002a) and CITATION highlight the problem of determining whether or not common noun phrases are anaphoric,,
 More recently, CITATION utilized an integer linear programming (ILP) solver to better combine the decisions made by these two complementary classifiers, by finding the globally optimal solution according to both classifiers,,
 45 \x0copposed to pairwise models) has included: CITATION who used a Bell tree whose leaves represent possible partitionings of the mentions into entities and then trained a model for searching the tree; CITATION who defined several conditional random field-based models; CITATION who took a reranking approach; and CITATION who use a probabilistic first-order logic model,,
 When describing our model, we build upon the notation used by CITATION,,
 The b3 scorer CITATION was proposed to overcome several shortcomings of the MUC scorer,,
 In addition to the MUC and b3 scorers, we also evaluate using cluster f-measure CITATION, which is the standard f-measure computed over true/false coreference decisions for pairs of 3 From http://lpsolve,,
 mentions; the Rand index CITATION, which is pairwise accuracy of the clustering; and variation of information CITATION, which utilizes the entropy of the clusterings and their mutual information (and for which lower values are better),,
 For comparison, we also give the results of the COREFILP system of CITATION, which was also based on a nave pair,,
 1 Introduction Much recent work on coreference resolution, which is the task of deciding which noun phrases, or mentions, in a document refer to the same real world entity, builds on CITATION,,
 Prior work (CITATION; CITATION) has generated training data for pairwise classifiers in the following manner,,
 This approach made sense for CITATION because testing proceeded in a similar manner: for each mention, work backwards until you find a previous mention which the classifier thinks is coreferent, add a link, and terminate the search,,
 Our SOON-STYLE baseline used the same training and testing regimen as CITATION,,
 Our D&B-STYLE baseline used the same test time method as CITATION, however at training time we created data for all mention pairs,,
4 We added named entity (NE) tags to the data using the tagger of CITATION,,
 We also added part of speech (POS) tags to the data using the tagger of CITATION, and used the tags to decide if mentions were plural or singular,,
 Our feature set was simple, and included many features from CITATION, including the pronoun, string match, definite and demonstrative NP, number and gender agreement, proper name and appositive features,,
1 Evaluation Metrics The MUC scorer CITATION is a popular coreference evaluation metric, but we found it to be fatally flawed,,
 As observed by CITATION, if all mentions in each document are placed into a single entity, the results on the MUC-6 formal test set are 100% recall, 78,,
4 We added named entity (NE) tags to the data using the tagger of CITATION,,
 We also added part of speech (POS) tags to the data using the tagger of CITATION, and used the tags to decide if mentions were plural or singular,,
 Our feature set was simple, and included many features from CITATION, including the pronoun, string match, definite and demonstrative NP, number and gender agreement, proper name and appositive features,,
1 Evaluation Metrics The MUC scorer CITATION is a popular c,,
e tagger of CITATION, and used the tags to decide if mentions were plural or singular,,
 Our feature set was simple, and included many features from CITATION, including the pronoun, string match, definite and demonstrative NP, number and gender agreement, proper name and appositive features,,
1 Evaluation Metrics The MUC scorer CITATION is a popular coreference evaluation metric, but we found it to be fatally flawed,,
 As observed by CITATION, if all mentions in each document are placed into a single entity, the results on the MUC-6 formal test set are 100% recall, 78,,
 The b3 scorer CITATION was proposed to overcome several shortcomings of the MUC scorer,,
