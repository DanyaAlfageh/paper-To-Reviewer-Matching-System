CITATION),,
 Ando & ZhangCITATION for a derivation of the decision rule from Equation 3 under these assumptions,,
(CITATION; CITATION) and information retrieval CITATION,,
 We cast this problem in the multiple-view (multiview) learning framework (CITATION; CITATION; CITATION; CITATION),,
5 Supervised Trained Bilingual Models CITATION 86,,
 the Penn Chinese treebank CITATION (articles 400-1151), excluding the bilingual portion,,
 The bilingual data consists of the parallel part of the Chinese treebank (articles 1-270), which also includes manually parsed English translations of each Chinese sentence CITATION,,
 For comparison, we also show results for the supervised bilingual model of CITATION,,
ks, such as cross-lingual named entity recognition (CITATION; CITATION) and information retrieval CITATION,,
 We cast this problem in the multiple-view (multiview) learning framework (CITATION; CITATION; CITATION; CITATION),,
 Two recent, successful unsupervised induction methods are those of CITATION and CITATION,,
 Projection methods, on the other hand, were among the first applications of parallel text (after machine translation) (CITATION; CITATION; CITATION; CITATION),,
 For this problem, our method automatically learns (a variation on) earlier hand-designed rule-based bilingual NER predictors (CITATION; CITATION), resulting in absolute performance gains of up to 16,,
 For this task, we follow the setup of CITATION, who improved Chinese and English monolingual parsers using parallel, hand-parsed text,,
 These results carry over to machine translation, where we can achieve slightly better BLEU improvements than the supervised model of CITATION since we are able to train our model directly on the parallel data where we perform rule extraction,,
, 2001; CITATION; CITATION; CITATION),,
 Our work falls into the final category: We wish to use bilingual data to improve monolingual models which are already trained on large amounts of data and effective on their own (CITATION; CITATION; CITATION; CITATION),,
 Procedurally, our work is most closely related to that of CITATION,,
 We parameterize the bilingual view using at most one-to-one matchings between nodes of structured labels in each language CITATION,,
 First, we use the word alignment density features from CITATION, which measure how well the aligned entity pair matches up with alignments from an independent 48 \x0cInput: full and weakened monolingual models: p1(y1|x1), p2(y2|x2), pw 1 (y1|x1), pw 2 (y2|x2) unannotated bilingual data: U Output: bilingual parameters: , 1, 2 1,,
 In our parsing experiments, we use the Berkeley parser (CITATION; CITATION), a split-merge latent variable parser, for our monolingual models,,
 For the bilingual model, we use the same bilingual feature set as CITATION,,
 5 Training Bilingual Models Previous work in multiview learning has focused on the case of agreement regularization (CITATION; CITATION),,
 This maxlikelihood optimization can be solved by an EMlike procedure CITATION,,
5 Supervised Trained Bilingual Models CITATION 86,,
 the Penn Chinese treebank CITATION (articles 400-1151), excluding the bilingual portion,,
 The bilingual data consists of the parallel part of the Chinese treebank (articles 1-270), which also includes manually parsed English translations of each Chinese sentence CITATION,,
oring matching CITATION: A(; x) = log X y max a \x12 exp h &gt; (y1, a, y2) i\x13 ,,
 We further simplify inference in our model by working in a reranking setting (CITATION; CITATION), where we only consider the top k outputs from monolingual models in both languages, for a total of k2 labels y,,
1 Including Weakened Models Now that we have defined our bilingual model, we could train it to agree with the output of the monolingual model (CITATION; CITATION),,
 named entity recognition (CITATION; CITATION) and information retrieval CITATION,,
 We cast this problem in the multiple-view (multiview) learning framework (CITATION; CITATION; CITATION; CITATION),,
 We further simplify inference in our model by working in a reranking setting (CITATION; CITATION), where we only consider the top k outputs from monolingual models in both languages, for a total of k2 labels y,,
1 Including Weakened Models Now that we have defined our bilingual model, we could train it to agree with the output of the monolingual model (CITATION; CITATION),,
 In our parsing experiments, we use the Berkeley parser (CITATION; CITATION), a split-merge latent variable parser, for our monolingual models,,
 For the bilingual model, we use the same bilingual feature set as CITATION,,
 5 Training Bilingual Models Previous work in multiview learning has focused on the case of agreement regularization (CITATION; CITATION),,
 One obvious choice is to choose the labeling that maximizes the agreement distribution (CITATION; CITATION),,
 the maximum-scoring matching CITATION: A(; x) = log X y max a \x12 exp h &gt; (y1, a, y2) i\x13 ,,
 We further simplify inference in our model by working in a reranking setting (CITATION; CITATION), where we only consider the top k outputs from monolingual models in both languages, for a total of k2 labels y,,
1 Including Weakened Models Now that we have defined our bilingual model, we could train it to agree with the output of the monolingual model (CITATION; CITATION),,
 We used the Stanford NER tagger CITATION with its default configuration as our full monolingual model for each language,,
 Our experimental setup is as follows: first, we used the first 100,000 sentences of the EnglishChinese bitext from CITATION to train Moses CITATION, a phrase-based MT system that we use as a baseline,,
 We then used the same sentences to extract tree-to-string transducer rules from target-side (English) trees CITATION,,
 CITATION) and information retrieval CITATION,,
 We cast this problem in the multiple-view (multiview) learning framework (CITATION; CITATION; CITATION; CITATION),,
 We further simplify inference in our model by working in a reranking setting (CITATION; CITATION), where we only consider the top k outputs from monolingual models in both languages, for a total of k2 labels y,,
1 Including Weakened Models Now that we have defined our bilingual model, we could train it to agree with the output of the monolingual model (CITATION; CITATION),,
In our parsing experiments, we use the Berkeley parser (CITATION; CITATION), a split-merge latent variable parser, for our monolingual models,,
 For the bilingual model, we use the same bilingual feature set as CITATION,,
 5 Training Bilingual Models Previous work in multiview learning has focused on the case of agreement regularization (CITATION; CITATION),,
 One obvious choice is to choose the labeling that maximizes the agreement distribution (CITATION; CITATION),,
 Ando & ZhangCITATION,,
 This observation has formed the basis for important work on syntax projection across languages (CITATION; CITATION; CITATION) and unsupervised syntax induction in multiple languages CITATION, as well as other tasks, such as cross-lingual named entity recognition (CITATION; CITATION) and information retrieval CITATION,,
 Two recent, successful unsupervised induction methods are those of CITATION and CITATION,,
 Projection methods, on the other hand, were among the first applications of parallel text (after machine translation) (CITATION; CITATION; CITATION; CITATION),,
 Our work falls into the final category: We wish to use bilingual data to improve monolingual models which are already trained on large amounts of data and effective on their own (CITATION; CITATION; CITATION; CITATION),,
 This observation has formed the basis for important work on syntax projection across languages (CITATION; CITATION; CITATION) and unsupervised syntax induction in multiple languages CITATION, as well as other tasks, such as cross-lingual named entity recognition (CITATION; CITATION) and information retrieval CITATION,,
 We cast this problem in the multiple-view (multiview) learning framework (CITATION; CITATION; CITATION;,,
 For this problem, our method automatically learns (a variation on) earlier hand-designed rule-based bilingual NER predictors (CITATION; CITATION), resulting in absolute performance gains of up to 16,,
 For this task, we follow the setup of CITATION, who improved Chinese and English monolingual parsers using parallel, hand-parsed text,,
 These results carry over to machine translation, where we can achieve slightly better BLEU improvements than the supervised model of CITATION since we are able to train our model directly on the parallel data where we perform rule e,,
st applications of parallel text (after machine translation) (CITATION; CITATION; CITATION; CITATION),,
 Our work falls into the final category: We wish to use bilingual data to improve monolingual models which are already trained on large amounts of data and effective on their own (CITATION; CITATION; CITATION; CITATION),,
 Procedurally, our work is most closely related to that of CITATION,,
 This observation has formed the basis for important work on syntax projection across languages (CITATION; CITATION; CITATION) and unsupervised syntax induction in multiple languages CITATION, as well as other tasks, such as cross-lingual named entity recognition (CITATION; CITATION) and information retrieval CITATION,,
 Two recent, successful unsupervised induction methods are those of CITATION and CITATION,,
 Projection methods, on the other hand, were among the first applications of parallel text (after machine translation) (CITATION; CITATION; CITATION; CITATION),,
 Our work falls into the final category: We wish to use bilingual data to improve monolingual models which are already trained on large amounts of data and effective on their own (CITATION; CITATION; CITATION; CITATION),,
 Our experimental setup is as follows: first, we used the first 100,000 sentences of the EnglishChinese bitext from CITATION to train Moses CITATION, a phrase-based MT system that we use as a baseline,,
 We then used the same sentences to extract tree-to-string transducer rules from target-side (English) trees CITATION,,
 We trained both our full and weakened monolingual English models on the Penn Wall Street Journal corpus CITATION, as described in Section 4,,
 This observation has formed the basis for important work on syntax projection across languages (CITATION; CITATION; CITATION) and unsupervised syntax induction in multiple languages CITATION, as well as other tasks, such as cross-lingual named entity recognition (CITATION; CITATION) and information retrieval CITATION,,
 We cast this problem in the multiple-view (multiview) learning framework (CITATION; CITATION; CITATION; Ganchev et al,,
 For this problem, our method automatically learns (a variation on) earlier hand-designed rule-based bilingual NER predictors (CITATION; CITATION), resulting in absolute performance gains of up to 16,,
 For this task, we follow the setup of CITATION, who improved Chinese and English monolingual parsers using parallel, hand-parsed text,,
 These results carry over to machine translation, where we can achieve slightly better BLEU improvements than the supervised model of CITATION since we are able to train our model directly on the parallel data where we perform rule extraction,,
 In our parsing experiments, we use the Berkeley parser (CITATION; CITATION), a split-merge latent variable parser, for our monolingual models,,
 For the bilingual model, we use the same bilingual feature set as CITATION,,
 5 Training Bilingual Models Previous work in multiview learning has focused on the case of agreement regularization (CITATION; CITATION),,
 In our parsing experiments, we use the Berkeley parser (CITATION; CITATION), a split-merge latent variable parser, for our monolingual models,,
 For the bilingual model, we use the same bilingual feature set as CITATION,,
 5 Training Bilingual Models Previous work in multiview learning has focused on the case of agreement regularization (CITATION; CITATION),,
 This observation has formed the basis for important work on syntax projection across languages (CITATION; CITATION; CITATION) and unsupervised syntax induction in multiple languages CITATION, as well as other tasks, such as cross-lingual named entity recognition (CITATION; CITATION) and information retrieval CITATION,,
 We cast this problem in the multiple-view (multiview) learning framework (CITATION; CITATION; CITATION; CITATION),,
llel text (after machine translation) (CITATION; CITATION; CITATION; CITATION),,
 Our work falls into the final category: We wish to use bilingual data to improve monolingual models which are already trained on large amounts of data and effective on their own (CITATION; CITATION; CITATION; CITATION),,
 Procedurally, our work is most closely related to that of CITATION,,
e translation) (CITATION; CITATION; CITATION; CITATION),,
 Our work falls into the final category: We wish to use bilingual data to improve monolingual models which are already trained on large amounts of data and effective on their own (CITATION; CITATION; CITATION; CITATION),,
 Procedurally, our work is most closely related to that of CITATION,,
 This observation has formed the basis for important work on syntax projection across languages (CITATION; CITATION; CITATION) and unsupervised syntax induction in multiple languages CITATION, as well as other tasks, such as cross-lingual named entity recognition (CITATION; CITATION) and information retrieval CITATION,,
 Two recent, successful unsupervised induction methods are those of CITATION and CITATION,,
 Projection methods, on the other hand, were among the first applications of parallel text (after machine translation) (CITATION; CITATION; CITATION; CITATION),,
 Our experimental setup is as follows: first, we used the first 100,000 sentences of the EnglishChinese bitext from CITATION to train Moses CITATION, a phrase-based MT system that we use as a baseline,,
 We then used the same sentences to extract tree-to-string transducer rules from target-side (English) trees CITATION,,
5 Supervised Trained Bilingual Models CITATION 86,,
 the Penn Chinese treebank CITATION (articles 400-1151), excluding the bilingual portion,,
 The bilingual data consists of the parallel part of the Chinese treebank (articles 1-270), which also includes manually parsed English translations of each Chinese sentence CITATION,,
 Two recent, successful unsupervised induction methods are those of CITATION and CITATION,,
 Projection methods, on the other hand, were among the first applications of parallel text (after machine translation) (CITATION; CITATION; CITATION; CITATION),,
 Our work falls into the final category: We wish to use bilingual data to improve monolingual models which are already trained on large amounts of data and effective on their own (CITATION; CITATION; CITATION; CITATION),,
 This observation has formed the basis for important work on syntax projection across languages (CITATION; CITATION; CITATION) and unsupervised syntax induction in multiple languages CITATION, as well as other tasks, such as cross-lingual named entity recognition (CITATION; CITATION) and information retrieval CITATION,,
 Two recent, successful unsupervised induction methods are those of CITATION and CITATION,,
 Projection methods, on the other hand, were among the first applications of parallel text (after machine translation) (CITATION; CITATION; CITATION; CITATION),,
 Our work falls into the final category: We wish to use bilingual data to improve monolingual models which are already trained on large amounts of data and effective on their own (CITATION; CITATION; CITATION; Burkett an,,
