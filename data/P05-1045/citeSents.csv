We can, however, borrow a technique from the study of non-convex optimization and use simulated annealing CITATION,,
Gibbs sampling provides a clever solution CITATION,,
One such algorithm is Gibbs sampling, a simple Monte Carlo algorithm that is appropriate for inference in any factored probabilistic model, including sequence models and probabilistic context free grammars CITATION,,
CITATION and CITATION incorporate label consistency information by using adhoc multi-stage labeling procedures that are effective but special-purpose,,
We also provide the results from CITATION for comparison,,
4.2 The CMU Seminar Announcements Task This dataset was developed as part of Dayne Freitags dissertation research CITATION.5 It consists of 485 emails containing seminar announcements at Carnegie Mellon University,,
algorithm that is appropriate for inference in any factored probabilistic model, including sequence models and probabilistic context free grammars CITATION,,
way that is consistent with the Markov Network literature (see CITATION): we create a linear chain of cliques, where each clique, c, represents the probabilistic relationship between an adjacent pair of states2 using a clique potential c, which is just a table containing a value for each possible state assignment,,
 such algorithm is Gibbs sampling, a simple Monte Carlo algorithm that is appropriate for inference in any factored probabilistic model, including sequence models and probabilistic context free grammars CITATION,,
1 Prior uses in NLP of which we are aware include: CITATION, Della CITATION and CITATION,,
CITATION propose a solution to this problem: for each token, they define additional features taken from other occurrences of the same token in the document,,
The most relevant prior works are CITATION, who use a Relational Markov Network (RMN) CITATION to explicitly models long-distance dependencies, and Sutton ,,
CITATION and CITATION condition the label of a token at a particular position on the label of the most recent previous instance of that same token in a prior sentence of the same document,,
CITATION used 5-fold cross validation when evaluating on this dataset, so we obtained and used their data splits, so that results can be properly compared,,
Statistical hidden state sequence models, such as Hidden Markov Models (HMMs) (CITATION; CITATION), Conditional Markov Models (CMMs) CITATION, and Conditional Random Fields (CRFs) CITATION are a prominent recent approach to information extraction tasks,,
3 A Conditional Random Field Model Our basic CRF model follows that of CITATION,,
2 Gibbs Sampling for Inference in Sequence Models In hidden state sequence models such as HMMs, CMMs, and CRFs, it is standard to use the Viterbi algorithm, a dynamic programming algorithm, to infer the most likely hidden state sequence given the input and the model (see, e.g., CITATION),,
The most relevant prior works are CITATION, who use a Relational Markov Network (RMN) CITATION to explicitly models long-distance dependencies, and CITATION, who introduce skip-chain CRFs, which maintain the underlying CRF sequence model (which (Bunescu and Mooney, 2004) lack) while adding skip edges between distant nodes,,
CITATION show that it is easy to modify a Gibbs Markov chain to do annealing; at time t we replace the distribution in (1) with PA(s(t) |s(t1) ) = PM (s (t) i |s (t1) i , o)1/ct P j PM (s (t) j |s (t1) j , o)1/ct (2) where c = {c0, ,,
