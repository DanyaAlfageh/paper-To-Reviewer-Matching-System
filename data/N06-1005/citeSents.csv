 We then incorporate paraphrase similarity within the lexical similarity model by allowing, for some unaligned node h Ph, where t Pt: sim(h, t) = max(MN(h, t), score(Ph, Pt)) 38 \x0cOur approach to paraphrase detection is most similar to the TE/ASE algorithm CITATION, and bears similarity to both DIRT CITATION and KnowItAll CITATION,,
 The chief difference in our algorithm is that we generate the surface text search strings from the parsed logical forms using the generation capabilities of NLPWIN CITATION, and we verify that the syntactic relations in each discovered web snippet are isomorphic to those in the original candidate paraphrase template,,
 For example, two high-accuracy systems are those described in CITATION, achieving 60,,
4% accuracy with no task-specific information, and CITATION, which achieves 61,,
 Many previous approaches have used a logical form representation of the text and hypothesis sentences, focusing on deriving a proof by which one can infer the hypothesis logical form from the text logical form (CITATION; CITATION; CITATION; CITATION),,
 Attempts have been made to remedy this deficit through various techniques, including modelbuilding CITATION and the addition of semantic axioms CITATION,,
1% in one independent labeling CITATION), but an extremely challenging task for automated systems,,
 For example, two high-accuracy systems are those described in CITATION, achieving 60,,
4% accuracy with no task-specific information, and CITATION, which achieves 61,,
 We would expect a higher CWS to result from learning a more appropriate confidence function; nonetheless our overall 6 As in CITATION we compute the confidenceweighted score (or average precision) over n examples {c1, c2, ,,
 We then incorporate paraphrase similarity within the lexical similarity model by allowing, for some unaligned node h Ph, where t Pt: sim(h, t) = max(MN(h, t), score(Ph, Pt)) 38 \x0cOur approach to paraphrase detection is most similar to the TE/ASE algorithm CITATION, and bears similarity to both DIRT CITATION and KnowItAll CITATION,,
 The chief difference in our algorithm is that we generate the surface text search strings from the parsed logical forms using the generation capabilities of NLPWIN CITATION, and we verify that the syntactic relations in each discovered web snippet are isomorphic to those in the original candidate paraphrase template,,
1 Lexical similarity using MindNet In case none of the preceding heuristics for rejection are applicable, we back off to a lexical similarity model similar to that described in CITATION,,
 For every content node h H 37 \x0cnot already aligned by one of the heuristics in Section 3, we obtain a similarity score MN(h, t) from a similarity database that is constructed automatically from the data contained in MindNet5 as described in CITATION,,
 These logical forms are generated using NLPWIN3, a robust system for natural language parsing and generation CITATION,,
1 WordNet synonym match As in CITATION and others, we align a node h H to any node t T that has both the same part of speech and belongs to the same synset in WordNet,,
6 Other heuristics for alignment In addition to these heuristics, we implemented a hyponym match heuristic similar to that discussed in CITATION, and a heuristic based on the string-edit distance of two lemmas; however, these heuristics yielded a decrease in our systems accuracy on the development set and were thus left out of our final system,,
 We then incorporate paraphrase similarity within the lexical similarity model by allowing, for some unaligned node h Ph, where t Pt: sim(h, t) = max(MN(h, t), score(Ph, Pt)) 38 \x0cOur approach to paraphrase detection is most similar to the TE/ASE algorithm CITATION, and bears similarity to both DIRT CITATION and KnowItAll CITATION,,
 The chief difference in our algorithm is that we generate the surface text search strings from the parsed logical forms using the generation capabilities of NLPWIN CITATION, and we verify that the syntactic relations in each discovered web snippet are isomorphic to those in the original candidate paraphrase template,,
xample, two high-accuracy systems are those described in CITATION, achieving 60,,
4% accuracy with no task-specific information, and CITATION, which achieves 61,,
 Many previous approaches have used a logical form representation of the text and hypothesis sentences, focusing on deriving a proof by which one can infer the hypothesis logical form from the text logical form (CITATION; CITATION; CITATION; CITATION),,
 Attempts have been made to remedy this deficit through various techniques, including modelbuilding CITATION and the addition of semantic axioms CITATION,,
6534 is higher than previouslyreported task-independent systems (however, the task-dependent system reported in CITATION achieves a CWS of 0,,
1 Lexical similarity using MindNet In case none of the preceding heuristics for rejection are applicable, we back off to a lexical similarity model similar to that described in CITATION,,
 For every content node h H 37 \x0cnot already aligned by one of the heuristics in Section 3, we obtain a similarity score MN(h, t) from a similarity database that is constructed automatically from the data contained in MindNet5 as described in CITATION,,
 We then compute the entailment score: score(H, T) = 1 |H| Y hH max tT sim(h, t) This approach is identical to that used in CITATION, except that we use alignment heuristics and MindNet similarity scores in place of their web-based estimation of lexical entailment probabilities, and we take as our score the geometric mean of the component entailm,,
 We then incorporate paraphrase similarity within the lexical similarity model by allowing, for some unaligned node h Ph, where t Pt: sim(h, t) = max(MN(h, t), score(Ph, Pt)) 38 \x0cOur approach to paraphrase detection is most similar to the TE/ASE algorithm CITATION, and bears similarity to both DIRT CITATION and KnowItAll CITATION,,
 The chief difference in our algorithm is that we generate the surface text search strings from the parsed logical forms using the generation capabilities of NLPWIN CITATION, and we verify that the syntactic relations in each discovered web snippet are isomorphic to those in the original candidate paraphrase template,,
1% in one independent labeling CITATION), but an extremely challenging task for automated systems,,
 For example, two high-accuracy systems are those described in CITATION, achieving 60,,
4% accuracy with no task-specific information, and CITATION, which achieves 61,,
 Many previous approaches have used a logical form representation of the text and hypothesis sentences, focusing on deriving a proof by which one can infer the hypothesis logical form from the text logical form (CITATION; CITATION; CITATION; CITATION),,
1% absolute improvement over the task-independent system described in CITATION, and a 20,,
 Our approach is inspired by an analysis of the RTE dataset that suggested a syntax-based approach should be approximately twice as effective at predicting false entailment as true entailment CITATION,,
 2 CITATION suggest that the truth or falsehood of 48% of the entailment examples in the RTE test set could be correctly identified via syntax and a thesaurus alone; thus by random guessing on the rest of the examples one might hope for an accuracy level of 0,,
