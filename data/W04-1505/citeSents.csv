 4 Evaluation (CITATION; CITATION) suggest evaluating on the linguistically meaningful level of dependency relations,,
 First, a general-purpose evaluation using a hand-compiled gold standard corpus CITATION, which contains the grammatical relation data of 500 random sentences from the Susanne corpus,,
 The performance (table 3), according to CITATION, is similar to a large selection of statistical parsers and a grammatical relation \x0cnder,,
 A number of robust statistical parsers that o\x0ber solutions to these problems have become available (CITATION; CITATION; CITATION),,
 If one were to assume a constantly full \x0cxed beam, or uses an oracle CITATION it is linear in practice3,,
 Also worst-case complexity for exhaustive parsing is low, as these parsers are CFGbased CITATION4,,
 This grammar is also a Bare Phrase Structure grammar known from Minimalism CITATION,,
 for the Verb-PP attachment relation pobj (following CITATION,,
 \x0cWhether the combination (CITATION merge) of two binary constituents directly projects to a \\real&quot; CFG rule LHS or an implicit intermediate constituent does not matter,,
 P (RHSjLHS) \x18 = l(h) \x01 n+m Y i=0 Pl;r(t(Hi ); l(Hi)jt(Hi ); t(H 0 i ); l(H 0 i); d(i)) P (t(Hi)jt(Hi); t(H 0 i )) is a projection or attachment grammar model modeling the unlexicalized probability of t(H) and t(H\&apos;) participating in a binary rule with t(H) as head { the merge probability in Bare Phrase Structure CITATION; an unlabeled version of (4),,
 \x0f The second reason for not using tag information is because Pro3Gres backs o\x0b to semantic WordNet classes (Fellbaum, 1998) for nouns and to Levin classes CITATION for verbs instead of to tags, which has the advantage of being more \x0cne-grained,,
 CITATION made similar observations for Korean,,
2 Relation to Collins Model 2 CITATION Model 2 extends the parser to include a complement/adjunct distinction for NPs and subordinate,,
inimalism CITATION,,
 for the Verb-PP attachment relation pobj (following CITATION including the description noun7) p(pobjjright; verb; prep; desc:noun) \x18 = #(pobj; right; verb; prep; desc:noun) #(right; verb; prep; desc:noun) The distance (measured in chunks) between a head and a dependent is a limiting factor for the probability of a dependency between them,,
 Robust, successful parsers (Abney, 1995; CITATION) have shown that this division of labour is particularly attractive for DG,,
 Few handcrafted, deep linguistic grammars achieve the coverage and robustness needed to parse large corpora (see CITATION, (Burke et al,,
, 2004) and CITATION for exceptions), and speed remains a serious challenge,,
 A number of robust statistical parsers that o\x0ber solutions to these problems have become available (CITATION; CITATION; CITATION),,
 If one were to assume a constantly full \x0cxed beam, or uses an oracle CITATION it is linear in practice3,,
 Also worst-case complexity for exhaustive parsing is low, as these parsers are CFGbased CITATION4,,
 2 The Bene\x0ct of DG Characteristics In addition to some obvious bene\x0cts, such as the integration of chunking and parsing (Abney, 1995), where a chunk largely corresponds to a nucleus (Tesni\x12 CITATION), or that in an endocentric theory projection can never fail, we present eight characteristics in more detail, which in their combination allow us to treat the majority of English long-distance dependencies (LDD) in our DG parser Pro3Gres in a context-fee way,,
 5CITATION Model 2 uses some of the functional labels, and Model 3 some long-distance dependencies The ten most frequent types of empty nodes cover more than 60,000 of the approximately 64,000 empty nodes of sections 2-21 of the Penn Treebank,,
 Table 1, reproduced from CITATION [line numbers and counts from the whole Treebank added], gives an overview,,
 By application of the chain rule and assuming that distance is independent of the lexical heads we get: p(R; distja; b) \x18 = #(R; a; b) #(a; b) \x01 #(R; dist) #R (8) We now explore Pro3Gres\&apos; main probability model by comparing it to CITATION, and an adaptation of it, CITATION,,
1 Relation of Pro3Gres to Collins Model 1 We will \x0crst consider the non-generative Model 1 CITATION,,
 Both CITATION Model 1 and Pro3Gres are mainly dependency-based statistical parsers over heads of chunks, a close relation can thus be expected,,
 The CITATION Model 1 MLE estimation is: P (Rjha; atagi; hb; btagi; dist) \x18 = #(R; ha; atagi; hb; btagi; dist) #(ha; atagi; hb; btagi; dist) (9) Di\x0berences in comparison to (8) are: \x0f Pro3Gres does not use tag information,,
 CITATION made similar observations for Korean,,
2 Relation to Collins Model 2 CITATION Model 2 extends the parser to include a complement/adjunct distinction for NPs and subordinated clauses, and it includes a subcategorisation frame model,,
 German is considerably more in ectional which means that discarding functional information is more harmful, and which explains why the NEGRA annotation has been conceived to be quite at CITATION,,
 CITATION observe that models such as Collins when applied directly perform worse than an unlexicalized PCFG baseline,,
 The CITATION Model 2 rule generation model for P ! Lm:::L1HR1:::Rn, is P (RHSjLHS) = Ph(HjP; t(P ); l(P )) \x01 m Y i=0 Pl(Li; t(Li); l(Li)jP; H; t(H); l(H); d(i)) \x01 n Y i=0 Pr(Ri; t(Ri ); l(Ri)jP; H; t(H); l(H); d(i)) Ph P of head t(H) tag of H head word LHS left-hand side RHS right-hand side Pl:1::m P(words left of head) Pr:1::n P(words right of head) H LHS Head Category P RHS Mother Category L left Constit,,
inguistic Dependency Parsers (CITATION; Tapanainen and J\x7f arvinen, 1997) do not have a statistical base,,
 When converting DG structures to CFG, the order of application of these rules is not necessarily known, but in a labeled DG, the set of rules can specify the order CITATION,,
 By application of the chain rule and assuming that distance is independent of the lexical heads we get: p(R; distja; b) \x18 = #(R; a; b) #(a; b) \x01 #(R; dist) #R (8) We now explore Pro3Gres\&apos; main probability model by comparing it to CITATION, and an adaptation of it, CITATION,,
1 Relation of Pro3Gres to Collins Model 1 We will \x0crst consider the non-generative Model 1 CITATION,,
 Both CITATION Model 1 and Pro3Gres are mainly dependency-based statistical parsers over heads of chunks, a close relation can thus be expected,,
 The CITATION Model 1 MLE estimation is: P (Rjha; atagi; hb; btagi; dist) \x18 = #(R; ha; atagi; hb; btagi; dist) #(ha; atagi; hb; btagi; dist) (9) Di\x0berences in comparison to (8) are: \x0f Pro3Gres does not use tag information,,
3 Relation to Dubey & Keller 03 CITATION address the question whether models such as Collins also improve performance on freer word order languages, in their case German,,
 German is considerably more in ectional which means that discarding functional information is more harmful, and which explains why the NEGRA annotation has been conceived to be quite at CITATION,,
 CITATION observe that models such as Collins when applied directly perform worse than an unlexicalized PCFG baseline,,
 With these observations in mind, we can compare Pro3Gres to CITATION,,
x0ber solutions to these problems have become available (CITATION; CITATION; CITATION),,
 If one were to assume a constantly full \x0cxed beam, or uses an oracle CITATION it is linear in practice3,,
 Also worst-case complexity for exhaustive parsing is low, as these parsers are CFGbased CITATION4,,
 Although grammatical function and empty 2For Tree-Adjoining Grammars (TAG) it is O(n7) or O(n8) depending on the implementation CITATION,,
 CITATION state that the theoretical bound of worst time complexity for Head-Driven Phrase Structure Grammar (HPSG) parsing is exponential,,
 A number of robust statistical parsers that o\x0ber solutions to these problems have become available (CITATION; CITATION; CITATION),,
 If one were to assume a constantly full \x0cxed beam, or uses an oracle CITATION it is linear in practice3,,
 Also worst-case complexity for exhaustive parsing is low, as these parsers are CFGbased CITATION4,,
 Robust, successful parsers (Abney, 1995; CITATION) have shown that this division of labour is particularly attractive for DG,,
 Few handcrafted, deep linguistic grammars achieve the coverage and robustness needed to parse large corpora (see CITATION, (Burke et al,,
, 2004) and CITATION for exceptions), and speed remains a serious challenge,,
6 Graphs DG theory often conceives of DG structures as graphs instead of trees CITATION,,
7 Transformation to Semantic Layer Pro3Gres is currently being applied in a Question Answering system speci\x0ccally targeted at technical domains (CITATIONb),,
 One of the main advantages of a DG parser such as Pro3Gres over other parsing approaches is that a mapping from the syntactic layer to a semantic layer (meaning representation) is partly simpli\x0ced (Moll\x13 CITATION),,
p is nice 3 WHNP NP *T* 10,659 WH trace the woman who you saw *T* (4) *U* 9,202 Empty units $ 25 *U* (5) 0 7,057 Empty complementizers Sam said 0 Sasha snores (6) S S *T* 5,035 Moved clauses Sam had to go, Sasha said *T* 7 WHADVP ADVP *T* 3,181 WH-trace Sam explained how to leave *T* (8) SBAR 2,513 Empty clauses Sam had to go, said Sasha (SBAR) (9) WHNP 0 2,139 Empty relative pronouns the woman 0 we saw (10) WHADVP 0 726 Empty relative pronouns the reason 0 to leave Table 1: The distribution of the 10 most frequent types of empty nodes and their antecedents in the Penn Treebank (adapted from CITATION),,
 Bracketed line numbers only involve LDDs as grammar artifact nodes annotation expressing long-distance dependencies are provided in Treebanks such as the Penn Treebank CITATION, most statistical Treebank trained parsers fully or largely ignore them5, which entails two problems: \x0crst, the training cannot pro\x0ct from valuable annotation data,,
 a chunk largely corresponds to a nucleus (Tesni\x12 CITATION), or that in an endocentric theory projection can never fail, we present eight characteristics in more detail, which in their combination allow us to treat the majority of English long-distance dependencies (LDD) in our DG parser Pro3Gres in a context-fee way,,
 5CITATION Model 2 uses some of the functional labels, and Model 3 some long-distance dependencies The ten most frequent types of empty nodes cover more than 60,000 of the approximately 64,000 empty nodes of sections 2-21 of the Penn Treebank,,
 Table 1, reproduced from CITATION [line numbers and counts from the whole Treebank added], gives an overview,,
 relations and a selection of 5 LDD relations, and on the terminology-annotated GENIA corpus Secondly, to answer how the parser performs over domains markedly di\x0berent to the training corpus, to test whether terminology is the key to a successful parsing system, and to assess the impact of chunking errors, the parser has been applied to the GENIA corpus CITATION, 2000 MEDLINE abstracts of more than 400,000 words describing the results of Biomedical research, which is annotated for multi-word terms and thus contains near-perfect chunking,,
 100 random sentences from the GENIA corpus have been manually annotated and compared to the parser output (CITATIONa),,
 The CITATION Model 1 MLE estimation is: P (Rjha; atagi; hb; btagi; dist) \x18 = #(R; ha; atagi; hb; btagi; dist) #(ha; atagi; hb; btagi; dist) (9) Di\x0berences in comparison to (8) are: \x0f Pro3Gres does not use tag information,,
 \x0f The second reason for not using tag information is because Pro3Gres backs o\x0b to semantic WordNet classes (Fellbaum, 1998) for nouns and to Levin classes CITATION for verbs instead of to tags, which has the advantage of being more \x0cne-grained,,
 CITATION made similar observations for Korean,,
 4 Evaluation (CITATION; CITATION) suggest evaluating on the linguistically meaningful level of dependency relations,,
 First, a general-purpose evaluation using a hand-compiled gold standard corpus CITATION, which contains the grammatical relation data of 500 random sentences from the Susanne corpus,,
 The performance (table 3), according to CITATION, is similar to a large selection of statistical parsers and a grammatical relation \x0cnder,,
hanges of a word called translations (Tesni\x12 CITATION) are an exception to endocentricity,,
 3 The Statistical Dependency Model Most successful deep-linguistic Dependency Parsers (CITATION; Tapanainen and J\x7f arvinen, 1997) do not have a statistical base,,
 When converting DG structures to CFG, the order of application of these rules is not necessarily known, but in a labeled DG, the set of rules can specify the order CITATION,,
uses Sam had to go, Sasha said *T* 7 WHADVP ADVP *T* 3,181 WH-trace Sam explained how to leave *T* (8) SBAR 2,513 Empty clauses Sam had to go, said Sasha (SBAR) (9) WHNP 0 2,139 Empty relative pronouns the woman 0 we saw (10) WHADVP 0 726 Empty relative pronouns the reason 0 to leave Table 1: The distribution of the 10 most frequent types of empty nodes and their antecedents in the Penn Treebank (adapted from CITATION),,
 Bracketed line numbers only involve LDDs as grammar artifact nodes annotation expressing long-distance dependencies are provided in Treebanks such as the Penn Treebank CITATION, most statistical Treebank trained parsers fully or largely ignore them5, which entails two problems: \x0crst, the training cannot pro\x0ct from valuable annotation data,,
 For these reasons, CITATION refers to them as \\half-grammars,,
ry nestedness): ?hhhh h ( ( ( ( ( NP-SBJ-X@ noun VP@ hh h ( ( ( V passive verb NP -NONE*-X ? hhhh h ( ( ( ( ( NP-SBJ-X@ noun VP@ hh h ( ( ( V control-verb S NP-SBJ -NONE*-X Our approach employs \x0cnite-state approximations of long-distance dependencies, described in CITATION for DG and (Cahill et al,,
5 Monostratalism and Functionalism While multistratal DGs exist and several dependency levels can be distinguished (Mel\&apos;\x14 CITATION) we follow a conservative view close to the original (Tesni\x12 CITATION), which basically parses directly for a simple LFG f-structure without needing a c-structure detour,,
ry often conceives of DG structures as graphs instead of trees CITATION,,
7 Transformation to Semantic Layer Pro3Gres is currently being applied in a Question Answering system speci\x0ccally targeted at technical domains (CITATIONb),,
 One of the main advantages of a DG parser such as Pro3Gres over other parsing approaches is that a mapping from the syntactic layer to a semantic layer (meaning representation) is partly simpli\x0ced (Moll\x13 CITATION),,
8 Tesni\x12 ere\&apos;s Translations The possible functional changes of a word called translations (Tesni\x12 CITATION) are an exception to endocentricity,,
 A number of robust statistical parsers that o\x0ber solutions to these problems have become available (CITATION; CITATION; CITATION),,
 If one were to assume a constantly full \x0cxed beam, or uses an oracle CITATION it is linear in practice3,,
 Also worst-case complexity for exhaustive parsing is low, as these parsers are CFGbased CITATION4,,
 Although grammatical function and empty 2For Tree-Adjoining Grammars (TAG) it is O(n7) or O(n8) depending on the implementation CITATION,,
 CITATION state that the theoretical bound of worst time complexity for Head-Driven Phrase Structure Grammar (HPSG) parsing is exponential,,
 4 Evaluation (CITATION; CITATION) suggest evaluating on the linguistically meaningful level of dependency relations,,
 First, a general-purpose evaluation using a hand-compiled gold standard corpus CITATION, which contains the grammatical relation data of 500 random sentences from the Susanne corpus,,
 The performance (table 3), according to CITATION, is similar to a large selection of statistical parsers and a grammatical relation \x0cnder,,
 Robust, successful parsers (Abney, 1995; CITATION) have shown that this division of labour is particularly attractive for DG,,
 Few handcrafted, deep linguistic grammars achieve the coverage and robustness needed to parse large corpora (see CITATION, (Burke et al,,
, 2004) and CITATION for exceptions), and speed remains a serious challenge,,
6 Graphs DG theory often conceives of DG structures as graphs instead of trees CITATION,,
7 Transformation to Semantic Layer Pro3Gres is currently being applied in a Question Answering system speci\x0ccally targeted at technical domains (CITATIONb),,
 One of the main advantages of a DG parser such as Pro3Gres over other parsing approaches is that a mapping from the syntactic layer to a semantic layer (meaning representation) is partly simpli\x0ced (Moll\x13 CITATION),,
8 Tesni\x12 ere\&apos;s Translations The possible functional changes of a word called translations (Tesni\x12 CITATION) are an exception to endocentricity,,
ology-annotated GENIA corpus Secondly, to answer how the parser performs over domains markedly di\x0berent to the training corpus, to test whether terminology is the key to a successful parsing system, and to assess the impact of chunking errors, the parser has been applied to the GENIA corpus CITATION, 2000 MEDLINE abstracts of more than 400,000 words describing the results of Biomedical research, which is annotated for multi-word terms and thus contains near-perfect chunking,,
 100 random sentences from the GENIA corpus have been manually annotated and compared to the parser output (CITATIONa),,
 If one were to assume a constantly full \x0cxed beam, or uses an oracle CITATION it is linear in practice3,,
 Also worst-case complexity for exhaustive parsing is low, as these parsers are CFGbased CITATION4,,
 Although grammatical function and empty 2For Tree-Adjoining Grammars (TAG) it is O(n7) or O(n8) depending on the implementation CITATION,,
 CITATION state that the theoretical bound of worst time complexity for Head-Driven Phrase Structure Grammar (HPSG) parsing is exponential,,
 (@ stands for arbitrary nestedness): ?hhhh h ( ( ( ( ( NP-SBJ-X@ noun VP@ hh h ( ( ( V passive verb NP -NONE*-X ? hhhh h ( ( ( ( ( NP-SBJ-X@ noun VP@ hh h ( ( ( V control-verb S NP-SBJ -NONE*-X Our approach employs \x0cnite-state approximations of long-distance dependencies, described in CITATION for DG and (Cahill et al,,
5 Monostratalism and Functionalism While multistratal DGs exist and several dependency levels can be distinguished (Mel\&apos;\x14 CITATION) we follow a conservative view close to the original (Tesni\x12 CITATION), which basically parses directly for a simple LFG f-structure without needing a c-structure detour,,
3 Relation to Dubey & Keller 03 CITATION address the question whether models such as Collins also improve performance on freer word order languages, in their case German,,
 German is considerably more in ectional which means that discarding functional information is more harmful, and which explains why the NEGRA annotation has been conceived to be quite at CITATION,,
 CITATION observe that models such as Collins when applied directly perform worse than an unlexicalized PCFG baseline,,
 The CITATION Model 2 rule generation model for P ! Lm:::L1HR1:::Rn, is P (RHSjLHS) = Ph(HjP; t(P ); l(P )) \x01 m Y i=0 Pl(Li; t(Li); l(Li)jP; H; t(H); l(H); d(i)) \x01 n Y i=0 Pr(Ri; t(Ri ); l(Ri)jP; H; t(H); l(H); d(i)) Ph P of head t(H) tag of H head word LHS ,,
 2 The Bene\x0ct of DG Characteristics In addition to some obvious bene\x0cts, such as the integration of chunking and parsing (Abney, 1995), where a chunk largely corresponds to a nucleus (Tesni\x12 CITATION), or that in an endocentric theory projection can never fail, we present eight characteristics in more detail, which in their combination allow us to treat the majority of English long-distance dependencies (LDD) in our DG parser Pro3Gres in a context-fee way,,
 5CITATION Model 2 uses some of the functional labels, and Model 3 some long-distance dependencies The ten most frequent types of empty nodes cover more than 60,000 of the approximately 64,000 empty nodes of sections 2-21 of the Penn Treebank,,
 Table 1, reproduced from CITATION [line numbers and counts from the whole Treebank,,
verb NP -NONE*-X ? hhhh h ( ( ( ( ( NP-SBJ-X@ noun VP@ hh h ( ( ( V control-verb S NP-SBJ -NONE*-X Our approach employs \x0cnite-state approximations of long-distance dependencies, described in CITATION for DG and (Cahill et al,,
5 Monostratalism and Functionalism While multistratal DGs exist and several dependency levels can be distinguished (Mel\&apos;\x14 CITATION) we follow a conservative view close to the original (Tesni\x12 CITATION), which basically parses directly for a simple LFG f-structure without needing a c-structure detour,,
7 Transformation to Semantic Layer Pro3Gres is currently being applied in a Question Answering system speci\x0ccally targeted at technical domains (CITATIONb),,
 One of the main advantages of a DG parser such as Pro3Gres over other parsing approaches is that a mapping from the syntactic layer to a semantic layer (meaning representation) is partly simpli\x0ced (Moll\x13 CITATION),,
8 Tesni\x12 ere\&apos;s Translations The possible functional changes of a word called translations (Tesni\x12 CITATION) are an exception to endocentricity,,
 3 The Statistical Dependency Model Most successful deep-linguistic Dependency Parsers (CITATION; Tapanainen and J\x7f arvinen, 1997) do not have,,
