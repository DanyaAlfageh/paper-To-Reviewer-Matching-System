<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000447">
<bodyText confidence="0.6035265">
b&amp;apos;Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 233236,
Columbus, Ohio, USA, June 2008. c
</bodyText>
<sectionHeader confidence="0.483842" genericHeader="abstract">
2008 Association for Computational Linguistics
</sectionHeader>
<title confidence="0.774208">
Active Learning with Confidence
</title>
<author confidence="0.903209">
Mark Dredze and Koby Crammer
</author>
<affiliation confidence="0.9949035">
Department of Computer and Information Science
University of Pennsylvania
</affiliation>
<address confidence="0.968285">
Philadelphia, PA 19104
</address>
<email confidence="0.998675">
{mdredze,crammer}@cis.upenn.edu
</email>
<sectionHeader confidence="0.990378" genericHeader="keywords">
Abstract
</sectionHeader>
<bodyText confidence="0.997856909090909">
Active learning is a machine learning ap-
proach to achieving high-accuracy with a
small amount of labels by letting the learn-
ing algorithm choose instances to be labeled.
Most of previous approaches based on dis-
criminative learning use the margin for choos-
ing instances. We present a method for in-
corporating confidence into the margin by us-
ing a newly introduced online learning algo-
rithm and show empirically that confidence
improves active learning.
</bodyText>
<sectionHeader confidence="0.99831" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999117571428571">
Successful applications of supervised machine
learning to natural language rely on quality labeled
training data, but annotation can be costly, slow and
difficult. One popular solution is Active Learning,
which maximizes learning accuracy while minimiz-
ing labeling efforts. In active learning, the learning
algorithm itself selects unlabeled examples for anno-
tation. A variety of techniques have been proposed
for selecting examples that maximize system perfor-
mance as compared to selecting instances randomly.
Two learning methodologies dominate NLP ap-
plications: probabilistic methods naive Bayes,
logistic regression and margin methods sup-
port vector machines and passive-aggressive. Active
learning for probabilistic methods often uses uncer-
tainty sampling: label the example with the lowest
probability prediction (the most uncertain) (Lewis
and Gale, 1994). The equivalent technique for mar-
gin learning associates the margin with prediction
certainty: label the example with the lowest margin
(Tong and Koller, 2001). Common intuition equates
large margins with high prediction confidence.
However, confidence and margin are two distinct
properties. For example, an instance may receive
a large margin based on a single feature which has
been updated only a small number of times. Another
example may receive a small margin, but its features
have been learned from a large number of examples.
While the first example has a larger margin it has
low confidence compared to the second. Both the
margin value and confidence should be considered
in choosing which example to label.
We present active learning with confidence us-
ing a recently introduced online learning algo-
rithm called Confidence-Weighted linear classifica-
tion. The classifier assigns labels according to a
Gaussian distribution over margin values instead of
a single value, which arises from parameter confi-
dence (variance). The variance of this distribution
represents the confidence in the mean (margin). We
then employ this distribution for a new active learn-
ing criteria, which in turn could improve other mar-
gin based active learning techniques. Additionally,
we favor the use of an online method since online
methods have achieved good NLP performance and
are fast to train an important property for inter-
active learning. Experimental validation on a num-
ber of datasets shows that active learning with con-
fidence can improve standard methods.
</bodyText>
<sectionHeader confidence="0.96411" genericHeader="method">
2 Confidence-Weighted Linear Classifiers
</sectionHeader>
<bodyText confidence="0.988656">
Common online learning algorithms, popular in
many NLP tasks, are not designed to deal with
the particularities of natural language data. Fea-
</bodyText>
<page confidence="0.997209">
233
</page>
<bodyText confidence="0.998888393939394">
\x0cture representations have very high dimension and
most features are observed on a small fraction of in-
stances. Confidence-weighted (CW) linear classifi-
cation (Dredze et al., 2008), a new online algorithm,
maintains a probabilistic measure of parameter con-
fidence leading to a measure of prediction confi-
dence, potentially useful for active learning. We
summarize CW learning to familiarize the reader.
Parameter confidence is formalized with a distri-
bution over weight vectors, specifically a Gaussian
distribution with mean RN and diagonal co-
variance RNN . The values j and j,j repre-
sent knowledge of and confidence in the parameter
for feature j. The smaller j,j, the more confidence
we have in the mean parameter value j.
A model predicts the label with the highest prob-
ability, maxy{1} PrwN(,) [y(w x) 0] .
The Gaussian distribution over parameter vectors w
induces a univariate Gaussian distribution over the
unsigned-margin M = w x parameterized by ,
and the instance x: M N (M, V ), where the
mean is M = x and the variance V = x&amp;gt;x.
CW is an online algorithm inspired by the Passive
Aggressive (PA) update (Crammer et al., 2006)
which ensures a positive margin while minimizing
parameter change. CW replaces the Euclidean dis-
tance used in the PA update with the KL divergence
over Gaussian distributions. It also replaces the min-
imal margin constraint with a minimal probability
constraint: with some given probability (0.5, 1]
a drawn classifier will assign the correct label. This
strategy yields the following objective solved on
each round of learning:
</bodyText>
<equation confidence="0.8444956">
(i+1, i+1) = min DKL (N (, ) k N (i, i))
s.t. Pr [yi ( xi) 0] ,
where (i, i) are the parameters on round i and
i+1, i+1
\x01
</equation>
<bodyText confidence="0.999926875">
are the new parameters after update.
The constraint ensures that the resulting parameters
will correctly classify xi with probability at least .
For convenience we write = 1 (), where is
the cumulative function of the normal distribution.
The optimization problem above is not convex, but
a closed form approximation of its solution has the
following additive form: i+1 = i +iyiixi and
</bodyText>
<equation confidence="0.982917">
1
i+1 = 1
i + 2ixix&amp;gt;
i for,
i =
(1+2Mi)+
q
(1+2Mi)2
8 (MiVi)
4Vi
.
</equation>
<bodyText confidence="0.9961915">
Each update changes the feature weights , and in-
creases confidence (variance always decreases).
</bodyText>
<sectionHeader confidence="0.991752" genericHeader="method">
3 Active Learning with Confidence
</sectionHeader>
<bodyText confidence="0.979883075">
We consider pool based active learning. An active
learning algorithm is given a pool of unlabeled in-
stances U = {xi}n
i=1, a learning algorithm A and a
set of labeled examples initially set to be L = . On
each round the active learner uses its selection crite-
ria to return a single instance xi to be labeled by an
annotator with yi {1, +1} (for binary classifica-
tion). The instance and label are added to the labeled
set L L {(xi, yi)} and passed to the learning
algorithm A, which in turn generates a new model.
At the end of labeling the algorithm returns a classi-
fier trained on the final labeled set. Effective active
learning minimizes prediction error and the number
of labeled examples.
Most active learners for margin based algorithms
rely on the magnitude of the margin. Tong and
Koller (2001) motivate this approach by consider-
ing the half-space representation of the hypothesis
space for learning. They suggest three margin based
active learning methods: Simple margin, MaxMin
margin, and Ratio margin. In Simple margin, the al-
gorithm predicts an unsigned margin M for each in-
stance in U and returns for labeling the instance with
the smallest margin. The intuition is that instances
for which the classifier is uncertain (small margin)
provide the most information for learning. Active
learning based on PA algorithms runs in a similar
fashion but full SVM retraining on every round is
replaced with a single PA update using the new la-
beled example, greatly increasing learning speed.
Maintaining a distribution over prediction func-
tions makes the CW algorithm attractive for ac-
tive learning. Instead of using a geometrical
quantity (margin), it use a probabilistic quan-
tity and picks the example whose label is pre-
dicted with the lowest probability. Formally,
the margin criteria, x = arg minzU (w z),
is replaced with a probabilistic criteria x =
arg minzU  |PrwN(i,i) [sign(w z) = 1]
</bodyText>
<figure confidence="0.703160666666667">
\x01
1
2  |.
</figure>
<page confidence="0.994899">
234
</page>
<bodyText confidence="0.9980795">
\x0cThe selection criteria naturally captures the notion
that we should label the example with the highest
uncertainty. Interestingly, we can show (omitted due
to lack of space) that the probabilistic criteria can be
translated into a corrected geometrical criteria. In
practice, we can compute this normalized margin as
</bodyText>
<equation confidence="0.8134915">
M = M/
V . We call this selection criteria Active
</equation>
<sectionHeader confidence="0.6636515" genericHeader="method">
Confident Learning (ACL).
4 Evaluation
</sectionHeader>
<bodyText confidence="0.992151206896552">
To evaluate our active learning methods we used
a similar experimental setup to Tong and Koller
(2001). Each active learning algorithm was given
two labeled examples, one from each class, for ini-
tial training of a classifier, and remaining data as un-
labeled examples. On each round the algorithm se-
lected a single instance for which it was then given
the correct label. The algorithm updated the online
classifier and evaluated it on held out test data to
measure learning progress.
We selected four binary NLP datasets for evalu-
ation: 20 Newsgroups1 and Reuters (Lewis et al.,
2004) (used by Tong and Koller) and sentiment clas-
sification (Blitzer et al., 2007) and spam (Bickel,
2006). For each dataset we extracted binary uni-
gram features and sentiment was prepared accord-
ing to Blitzer et al. (2007). From 20 Newsgroups
we created 3 binary decision tasks to differentiate
between two similar labels from computers, sci-
ence and talk. We created 3 similar problems from
Reuters from insurance, business services and re-
tail distribution. Sentiment used 4 Amazon domains
(book, dvd, electronics, kitchen). Spam used the
three users from task A data. Each problem had
2000 instances except for 20 Newsgroups, which
used between 1850 and 1971 instances. This created
13 classification problems across four tasks.
Each active learning algorithm was evaluated us-
ing a PA (with slack variable c = 1) or CW classifier
</bodyText>
<equation confidence="0.73069">
( = 1) using 10-fold cross validation. We eval-
</equation>
<bodyText confidence="0.992530666666667">
uated several methods in the Simple margin frame-
work: PA Margin and CW Margin, which select ex-
amples with the smallest margin, and ACL. As a
baseline we included selecting a random instance.
We also evaluated CW and a PA classifier trained on
all training instances. Each method was evaluated by
</bodyText>
<equation confidence="0.806337">
1
http://people.csail.mit.edu/jrennie/20Newsgroups/
</equation>
<bodyText confidence="0.997615722222222">
labeling up to 500 labels, about 25% of the training
data. The 10 runs on each dataset for each problem
appear in the left and middle panel of Fig. 1, which
show the test accuracy after each round of active
learning. Horizontal lines indicate CW (solid) and
PA (dashed) training on all instances. Legend num-
bers are accuracy after 500 labels. The left panel av-
erages results over 20 Newsgroups, and the middle
panel averages results over all 13 datasets.
To achieve 80% of the accuracy of training on all
data, a realistic goal for less than 100 labels, PA
Margin required 93% the number of labels of PA
Random, while CW Margin needed only 73% of
the labels of CW Random. By using fewer labels
compared to random selection baselines, CW Mar-
gin learns faster in the active learning setting as com-
pared with PA. Furthermore, adding confidence re-
duced labeling cost compared to margin alone. ACL
improved over CW Margin on every task and after
almost every round; it required 63% of the labels of
CW Random to reach the 80% mark.
We computed the fraction of labels CW Margin
and ACL required (compared to CW Random) to
achieve the 80% accuracy mark of training with all
data. The results are summarized in the right panel
of Fig. 1, where we plot one point per dataset. Points
above the diagonal-line demonstrate the superiority
of ACL over CW Margin. ACL required fewer la-
bels than CW margin twice as often as the opposite
occurred (8 vs 4). Note that CW Margin used more
labels than CW Random in three cases, while ACL
only once, and this one time only about a dozen la-
bels were needed. To conclude, not only does CW
Margin outperforms PA Margin for active-learning,
CW maintains additional valuable information (con-
fidence), which further improves performance.
</bodyText>
<sectionHeader confidence="0.999358" genericHeader="related work">
5 Related Work
</sectionHeader>
<bodyText confidence="0.996868555555556">
Active learning has been widely used for NLP tasks
such as part of speech tagging (Ringger et al., 2007),
parsing (Tang et al., 2002) and word sense disam-
biguation (Chan and Ng, 2007). Many methods rely
on entropy-based scores such as uncertainty sam-
pling (Lewis and Gale, 1994). Others use margin
based methods, such as Kim et al. (2006), who com-
bined margin scores with corpus diversity, and Sas-
sano (2002), who considered SVM active learning
</bodyText>
<page confidence="0.978972">
235
</page>
<figure confidence="0.996398468085106">
\x0c100 150 200 250 300 350 400 450 500
Labels
0.65
0.70
0.75
0.80
0.85
0.90
0.95
Test
Accuracy
20 Newsgroups
PA Random (82.53)
CW Random (92.92)
PA Margin (88.06)
CW Margin (95.39)
ACL (95.51)
100 150 200 250 300 350 400 450 500
Labels
0.75
0.80
0.85
0.90
Test
Accuracy
All
PA Random (81.30)
CW Random (86.67)
PA Margin (83.99)
CW Margin (88.61)
ACL (88.79)
0.2 0.4 0.6 0.8 1.0 1.2 1.4
ACL Labels
0.2
0.4
0.6
0.8
1.0
1.2
1.4
CW
Margin
Labels
Reuters
20 Newsgroups
Sentiment
Spam
</figure>
<figureCaption confidence="0.8418085">
Figure 1: Results averaged over 20 Newsgroups (left) and all datasets (center) showing test accuracy over active
learning rounds. The right panel shows the amount of labels needed by CW Margin and ACL to achieve 80% of the
</figureCaption>
<bodyText confidence="0.9980875">
accuracy of training on all data - each points refers to a different dataset.
for Japanese word segmentation. Our confidence
based approach can be used to improve these tasks.
Furthermore, margin methods can outperform prob-
abilistic methods; CW beats maximum entropy on
many NLP tasks (Dredze et al., 2008).
A theoretical analysis of margin based methods
selected labels that maximize the reduction of the
version space, the hypothesis set consistent with the
training data (Tong and Koller, 2001). Another ap-
proach selects instances that minimize the future er-
ror in probabilistic algorithms (Roy and McCallum,
2001). Since we consider an online learning algo-
rithm our techniques can be easily extended to on-
line active learning (Cesa-Bianchi et al., 2005; Das-
gupta et al., 2005; Sculley, 2007).
</bodyText>
<sectionHeader confidence="0.9978" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.998313666666667">
We have presented techniques for incorporating con-
fidence into the margin for active learning and have
shown that CW selects better examples than PA, a
popular online algorithm. This approach creates op-
portunities for new active learning frameworks that
depend on margin confidence.
</bodyText>
<sectionHeader confidence="0.989193" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.991651822222223">
S. Bickel. 2006. Ecml-pkdd discovery challenge
overview. In The Discovery Challenge Workshop.
J. Blitzer, M. Dredze, and F. Pereira. 2007. Biographies,
bollywood, boom-boxes and blenders: Domain adap-
tation for sentiment classification. In ACL.
Nicolo Cesa-Bianchi, Gabor Lugosi, and Gilles Stolt.
2005. Minimizing regret with label efficient predic-
tion. IEEE Tran. on Inf. Theory, 51(6), June.
Y. S. Chan and H. T. Ng. 2007. Domain adaptation with
active learning for word sense disambiguation. In As-
sociation for Computational Linguistics (ACL).
K. Crammer, O. Dekel, J. Keshet, S. Shalev-Shwartz,
and Y. Singer. 2006. Online passive-aggressive al-
gorithms. JMLR, 7:551585.
S. Dasgupta, A.T. Kalai, and C. Monteleoni. 2005. Anal-
ysis of perceptron-based active learning. In COLT.
Mark Dredze, Koby Crammer, and Fernando Pereira.
2008. Confidence-weighted linear classification. In
ICML.
S. Kim, Yu S., K. Kim, J-W Cha, and G.G. Lee. 2006.
Mmr-based active machine learning for bio named en-
tity recognition. In NAACL/HLT.
D. D. Lewis and W. A. Gale. 1994. A sequential algo-
rithm for training text classifiers. In SIGIR.
D. D. Lewis, Y. Yand, T. Rose, and F. Li. 2004. Rcv1:
A new benchmark collection for text categorization re-
search. JMLR, 5:361397.
E. Ringger, P. McClanahan, R. Haertel, G. Busby,
M. Carmen, J. Carroll, K. Seppi, and D. Lonsdale.
2007. Active learning for part-of-speech tagging: Ac-
celerating corpus annotation. In ACL Linguistic Anno-
tation Workshop.
N. Roy and A. McCallum. 2001. Toward optimal active
learning through sampling estimation of error reduc-
tion. In ICML.
Manabu Sassano. 2002. An empirical study of active
learning with support vector machines for japanese
word segmentation. In ACL.
D. Sculley. 2007. Online active learning methods for fast
label-efficient spam filtering. In CEAS.
M. Tang, X. Luo, and S. Roukos. 2002. Active learning
for statistical natural language parsing. In ACL.
S. Tong and D. Koller. 2001. Supprt vector machine
active learning with applications to text classification.
JMLR.
</reference>
<page confidence="0.978288">
236
</page>
<figure confidence="0.254938">
\x0c&amp;apos;
</figure>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.604586">
<note confidence="0.858932666666667">b&amp;apos;Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 233236, Columbus, Ohio, USA, June 2008. c 2008 Association for Computational Linguistics</note>
<title confidence="0.834748">Active Learning with Confidence</title>
<author confidence="0.998928">Mark Dredze</author>
<author confidence="0.998928">Koby Crammer</author>
<affiliation confidence="0.9999035">Department of Computer and Information Science University of Pennsylvania</affiliation>
<address confidence="0.999339">Philadelphia, PA 19104</address>
<email confidence="0.999484">mdredze@cis.upenn.edu</email>
<email confidence="0.999484">crammer@cis.upenn.edu</email>
<abstract confidence="0.99909725">Active learning is a machine learning approach to achieving high-accuracy with a small amount of labels by letting the learning algorithm choose instances to be labeled. Most of previous approaches based on discriminative learning use the margin for choosing instances. We present a method for incorporating confidence into the margin by using a newly introduced online learning algorithm and show empirically that confidence improves active learning.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Bickel</author>
</authors>
<title>Ecml-pkdd discovery challenge overview.</title>
<date>2006</date>
<booktitle>In The Discovery Challenge Workshop.</booktitle>
<contexts>
<context position="8713" citStr="Bickel, 2006" startWordPosition="1402" endWordPosition="1403">etup to Tong and Koller (2001). Each active learning algorithm was given two labeled examples, one from each class, for initial training of a classifier, and remaining data as unlabeled examples. On each round the algorithm selected a single instance for which it was then given the correct label. The algorithm updated the online classifier and evaluated it on held out test data to measure learning progress. We selected four binary NLP datasets for evaluation: 20 Newsgroups1 and Reuters (Lewis et al., 2004) (used by Tong and Koller) and sentiment classification (Blitzer et al., 2007) and spam (Bickel, 2006). For each dataset we extracted binary unigram features and sentiment was prepared according to Blitzer et al. (2007). From 20 Newsgroups we created 3 binary decision tasks to differentiate between two similar labels from computers, science and talk. We created 3 similar problems from Reuters from insurance, business services and retail distribution. Sentiment used 4 Amazon domains (book, dvd, electronics, kitchen). Spam used the three users from task A data. Each problem had 2000 instances except for 20 Newsgroups, which used between 1850 and 1971 instances. This created 13 classification pro</context>
</contexts>
<marker>Bickel, 2006</marker>
<rawString>S. Bickel. 2006. Ecml-pkdd discovery challenge overview. In The Discovery Challenge Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Blitzer</author>
<author>M Dredze</author>
<author>F Pereira</author>
</authors>
<title>Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification.</title>
<date>2007</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="8689" citStr="Blitzer et al., 2007" startWordPosition="1396" endWordPosition="1399">we used a similar experimental setup to Tong and Koller (2001). Each active learning algorithm was given two labeled examples, one from each class, for initial training of a classifier, and remaining data as unlabeled examples. On each round the algorithm selected a single instance for which it was then given the correct label. The algorithm updated the online classifier and evaluated it on held out test data to measure learning progress. We selected four binary NLP datasets for evaluation: 20 Newsgroups1 and Reuters (Lewis et al., 2004) (used by Tong and Koller) and sentiment classification (Blitzer et al., 2007) and spam (Bickel, 2006). For each dataset we extracted binary unigram features and sentiment was prepared according to Blitzer et al. (2007). From 20 Newsgroups we created 3 binary decision tasks to differentiate between two similar labels from computers, science and talk. We created 3 similar problems from Reuters from insurance, business services and retail distribution. Sentiment used 4 Amazon domains (book, dvd, electronics, kitchen). Spam used the three users from task A data. Each problem had 2000 instances except for 20 Newsgroups, which used between 1850 and 1971 instances. This creat</context>
</contexts>
<marker>Blitzer, Dredze, Pereira, 2007</marker>
<rawString>J. Blitzer, M. Dredze, and F. Pereira. 2007. Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicolo Cesa-Bianchi</author>
<author>Gabor Lugosi</author>
<author>Gilles Stolt</author>
</authors>
<title>Minimizing regret with label efficient prediction.</title>
<date>2005</date>
<journal>IEEE Tran. on Inf. Theory,</journal>
<volume>51</volume>
<issue>6</issue>
<marker>Cesa-Bianchi, Lugosi, Stolt, 2005</marker>
<rawString>Nicolo Cesa-Bianchi, Gabor Lugosi, and Gilles Stolt. 2005. Minimizing regret with label efficient prediction. IEEE Tran. on Inf. Theory, 51(6), June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y S Chan</author>
<author>H T Ng</author>
</authors>
<title>Domain adaptation with active learning for word sense disambiguation.</title>
<date>2007</date>
<booktitle>In Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="11792" citStr="Chan and Ng, 2007" startWordPosition="1925" endWordPosition="1928">Margin. ACL required fewer labels than CW margin twice as often as the opposite occurred (8 vs 4). Note that CW Margin used more labels than CW Random in three cases, while ACL only once, and this one time only about a dozen labels were needed. To conclude, not only does CW Margin outperforms PA Margin for active-learning, CW maintains additional valuable information (confidence), which further improves performance. 5 Related Work Active learning has been widely used for NLP tasks such as part of speech tagging (Ringger et al., 2007), parsing (Tang et al., 2002) and word sense disambiguation (Chan and Ng, 2007). Many methods rely on entropy-based scores such as uncertainty sampling (Lewis and Gale, 1994). Others use margin based methods, such as Kim et al. (2006), who combined margin scores with corpus diversity, and Sassano (2002), who considered SVM active learning 235 \x0c100 150 200 250 300 350 400 450 500 Labels 0.65 0.70 0.75 0.80 0.85 0.90 0.95 Test Accuracy 20 Newsgroups PA Random (82.53) CW Random (92.92) PA Margin (88.06) CW Margin (95.39) ACL (95.51) 100 150 200 250 300 350 400 450 500 Labels 0.75 0.80 0.85 0.90 Test Accuracy All PA Random (81.30) CW Random (86.67) PA Margin (83.99) CW Ma</context>
</contexts>
<marker>Chan, Ng, 2007</marker>
<rawString>Y. S. Chan and H. T. Ng. 2007. Domain adaptation with active learning for word sense disambiguation. In Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Crammer</author>
<author>O Dekel</author>
<author>J Keshet</author>
<author>S Shalev-Shwartz</author>
<author>Y Singer</author>
</authors>
<title>Online passive-aggressive algorithms.</title>
<date>2006</date>
<journal>JMLR,</journal>
<pages>7--551585</pages>
<contexts>
<context position="4567" citStr="Crammer et al., 2006" startWordPosition="695" endWordPosition="698"> with mean RN and diagonal covariance RNN . The values j and j,j represent knowledge of and confidence in the parameter for feature j. The smaller j,j, the more confidence we have in the mean parameter value j. A model predicts the label with the highest probability, maxy{1} PrwN(,) [y(w x) 0] . The Gaussian distribution over parameter vectors w induces a univariate Gaussian distribution over the unsigned-margin M = w x parameterized by , and the instance x: M N (M, V ), where the mean is M = x and the variance V = x&amp;gt;x. CW is an online algorithm inspired by the Passive Aggressive (PA) update (Crammer et al., 2006) which ensures a positive margin while minimizing parameter change. CW replaces the Euclidean distance used in the PA update with the KL divergence over Gaussian distributions. It also replaces the minimal margin constraint with a minimal probability constraint: with some given probability (0.5, 1] a drawn classifier will assign the correct label. This strategy yields the following objective solved on each round of learning: (i+1, i+1) = min DKL (N (, ) k N (i, i)) s.t. Pr [yi ( xi) 0] , where (i, i) are the parameters on round i and i+1, i+1 \x01 are the new parameters after update. The const</context>
</contexts>
<marker>Crammer, Dekel, Keshet, Shalev-Shwartz, Singer, 2006</marker>
<rawString>K. Crammer, O. Dekel, J. Keshet, S. Shalev-Shwartz, and Y. Singer. 2006. Online passive-aggressive algorithms. JMLR, 7:551585.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Dasgupta</author>
<author>A T Kalai</author>
<author>C Monteleoni</author>
</authors>
<title>Analysis of perceptron-based active learning.</title>
<date>2005</date>
<booktitle>In COLT.</booktitle>
<marker>Dasgupta, Kalai, Monteleoni, 2005</marker>
<rawString>S. Dasgupta, A.T. Kalai, and C. Monteleoni. 2005. Analysis of perceptron-based active learning. In COLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Dredze</author>
<author>Koby Crammer</author>
<author>Fernando Pereira</author>
</authors>
<title>Confidence-weighted linear classification.</title>
<date>2008</date>
<booktitle>In ICML.</booktitle>
<contexts>
<context position="3611" citStr="Dredze et al., 2008" startWordPosition="531" endWordPosition="534">hod since online methods have achieved good NLP performance and are fast to train an important property for interactive learning. Experimental validation on a number of datasets shows that active learning with confidence can improve standard methods. 2 Confidence-Weighted Linear Classifiers Common online learning algorithms, popular in many NLP tasks, are not designed to deal with the particularities of natural language data. Fea233 \x0cture representations have very high dimension and most features are observed on a small fraction of instances. Confidence-weighted (CW) linear classification (Dredze et al., 2008), a new online algorithm, maintains a probabilistic measure of parameter confidence leading to a measure of prediction confidence, potentially useful for active learning. We summarize CW learning to familiarize the reader. Parameter confidence is formalized with a distribution over weight vectors, specifically a Gaussian distribution with mean RN and diagonal covariance RNN . The values j and j,j represent knowledge of and confidence in the parameter for feature j. The smaller j,j, the more confidence we have in the mean parameter value j. A model predicts the label with the highest probabilit</context>
<context position="13067" citStr="Dredze et al., 2008" startWordPosition="2146" endWordPosition="2149">L Labels 0.2 0.4 0.6 0.8 1.0 1.2 1.4 CW Margin Labels Reuters 20 Newsgroups Sentiment Spam Figure 1: Results averaged over 20 Newsgroups (left) and all datasets (center) showing test accuracy over active learning rounds. The right panel shows the amount of labels needed by CW Margin and ACL to achieve 80% of the accuracy of training on all data - each points refers to a different dataset. for Japanese word segmentation. Our confidence based approach can be used to improve these tasks. Furthermore, margin methods can outperform probabilistic methods; CW beats maximum entropy on many NLP tasks (Dredze et al., 2008). A theoretical analysis of margin based methods selected labels that maximize the reduction of the version space, the hypothesis set consistent with the training data (Tong and Koller, 2001). Another approach selects instances that minimize the future error in probabilistic algorithms (Roy and McCallum, 2001). Since we consider an online learning algorithm our techniques can be easily extended to online active learning (Cesa-Bianchi et al., 2005; Dasgupta et al., 2005; Sculley, 2007). 6 Conclusion We have presented techniques for incorporating confidence into the margin for active learning an</context>
</contexts>
<marker>Dredze, Crammer, Pereira, 2008</marker>
<rawString>Mark Dredze, Koby Crammer, and Fernando Pereira. 2008. Confidence-weighted linear classification. In ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kim</author>
<author>S Yu</author>
<author>K Kim</author>
<author>J-W Cha</author>
<author>G G Lee</author>
</authors>
<title>Mmr-based active machine learning for bio named entity recognition.</title>
<date>2006</date>
<booktitle>In NAACL/HLT.</booktitle>
<contexts>
<context position="11947" citStr="Kim et al. (2006)" startWordPosition="1951" endWordPosition="1954">ree cases, while ACL only once, and this one time only about a dozen labels were needed. To conclude, not only does CW Margin outperforms PA Margin for active-learning, CW maintains additional valuable information (confidence), which further improves performance. 5 Related Work Active learning has been widely used for NLP tasks such as part of speech tagging (Ringger et al., 2007), parsing (Tang et al., 2002) and word sense disambiguation (Chan and Ng, 2007). Many methods rely on entropy-based scores such as uncertainty sampling (Lewis and Gale, 1994). Others use margin based methods, such as Kim et al. (2006), who combined margin scores with corpus diversity, and Sassano (2002), who considered SVM active learning 235 \x0c100 150 200 250 300 350 400 450 500 Labels 0.65 0.70 0.75 0.80 0.85 0.90 0.95 Test Accuracy 20 Newsgroups PA Random (82.53) CW Random (92.92) PA Margin (88.06) CW Margin (95.39) ACL (95.51) 100 150 200 250 300 350 400 450 500 Labels 0.75 0.80 0.85 0.90 Test Accuracy All PA Random (81.30) CW Random (86.67) PA Margin (83.99) CW Margin (88.61) ACL (88.79) 0.2 0.4 0.6 0.8 1.0 1.2 1.4 ACL Labels 0.2 0.4 0.6 0.8 1.0 1.2 1.4 CW Margin Labels Reuters 20 Newsgroups Sentiment Spam Figure 1:</context>
</contexts>
<marker>Kim, Yu, Kim, Cha, Lee, 2006</marker>
<rawString>S. Kim, Yu S., K. Kim, J-W Cha, and G.G. Lee. 2006. Mmr-based active machine learning for bio named entity recognition. In NAACL/HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D D Lewis</author>
<author>W A Gale</author>
</authors>
<title>A sequential algorithm for training text classifiers.</title>
<date>1994</date>
<booktitle>In SIGIR.</booktitle>
<contexts>
<context position="1686" citStr="Lewis and Gale, 1994" startWordPosition="234" endWordPosition="237">ile minimizing labeling efforts. In active learning, the learning algorithm itself selects unlabeled examples for annotation. A variety of techniques have been proposed for selecting examples that maximize system performance as compared to selecting instances randomly. Two learning methodologies dominate NLP applications: probabilistic methods naive Bayes, logistic regression and margin methods support vector machines and passive-aggressive. Active learning for probabilistic methods often uses uncertainty sampling: label the example with the lowest probability prediction (the most uncertain) (Lewis and Gale, 1994). The equivalent technique for margin learning associates the margin with prediction certainty: label the example with the lowest margin (Tong and Koller, 2001). Common intuition equates large margins with high prediction confidence. However, confidence and margin are two distinct properties. For example, an instance may receive a large margin based on a single feature which has been updated only a small number of times. Another example may receive a small margin, but its features have been learned from a large number of examples. While the first example has a larger margin it has low confiden</context>
<context position="11887" citStr="Lewis and Gale, 1994" startWordPosition="1940" endWordPosition="1943">vs 4). Note that CW Margin used more labels than CW Random in three cases, while ACL only once, and this one time only about a dozen labels were needed. To conclude, not only does CW Margin outperforms PA Margin for active-learning, CW maintains additional valuable information (confidence), which further improves performance. 5 Related Work Active learning has been widely used for NLP tasks such as part of speech tagging (Ringger et al., 2007), parsing (Tang et al., 2002) and word sense disambiguation (Chan and Ng, 2007). Many methods rely on entropy-based scores such as uncertainty sampling (Lewis and Gale, 1994). Others use margin based methods, such as Kim et al. (2006), who combined margin scores with corpus diversity, and Sassano (2002), who considered SVM active learning 235 \x0c100 150 200 250 300 350 400 450 500 Labels 0.65 0.70 0.75 0.80 0.85 0.90 0.95 Test Accuracy 20 Newsgroups PA Random (82.53) CW Random (92.92) PA Margin (88.06) CW Margin (95.39) ACL (95.51) 100 150 200 250 300 350 400 450 500 Labels 0.75 0.80 0.85 0.90 Test Accuracy All PA Random (81.30) CW Random (86.67) PA Margin (83.99) CW Margin (88.61) ACL (88.79) 0.2 0.4 0.6 0.8 1.0 1.2 1.4 ACL Labels 0.2 0.4 0.6 0.8 1.0 1.2 1.4 CW </context>
</contexts>
<marker>Lewis, Gale, 1994</marker>
<rawString>D. D. Lewis and W. A. Gale. 1994. A sequential algorithm for training text classifiers. In SIGIR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D D Lewis</author>
<author>Y Yand</author>
<author>T Rose</author>
<author>F Li</author>
</authors>
<title>Rcv1: A new benchmark collection for text categorization research.</title>
<date>2004</date>
<journal>JMLR,</journal>
<pages>5--361397</pages>
<contexts>
<context position="8611" citStr="Lewis et al., 2004" startWordPosition="1383" endWordPosition="1386">fident Learning (ACL). 4 Evaluation To evaluate our active learning methods we used a similar experimental setup to Tong and Koller (2001). Each active learning algorithm was given two labeled examples, one from each class, for initial training of a classifier, and remaining data as unlabeled examples. On each round the algorithm selected a single instance for which it was then given the correct label. The algorithm updated the online classifier and evaluated it on held out test data to measure learning progress. We selected four binary NLP datasets for evaluation: 20 Newsgroups1 and Reuters (Lewis et al., 2004) (used by Tong and Koller) and sentiment classification (Blitzer et al., 2007) and spam (Bickel, 2006). For each dataset we extracted binary unigram features and sentiment was prepared according to Blitzer et al. (2007). From 20 Newsgroups we created 3 binary decision tasks to differentiate between two similar labels from computers, science and talk. We created 3 similar problems from Reuters from insurance, business services and retail distribution. Sentiment used 4 Amazon domains (book, dvd, electronics, kitchen). Spam used the three users from task A data. Each problem had 2000 instances ex</context>
</contexts>
<marker>Lewis, Yand, Rose, Li, 2004</marker>
<rawString>D. D. Lewis, Y. Yand, T. Rose, and F. Li. 2004. Rcv1: A new benchmark collection for text categorization research. JMLR, 5:361397.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Ringger</author>
<author>P McClanahan</author>
<author>R Haertel</author>
<author>G Busby</author>
<author>M Carmen</author>
<author>J Carroll</author>
<author>K Seppi</author>
<author>D Lonsdale</author>
</authors>
<title>Active learning for part-of-speech tagging: Accelerating corpus annotation.</title>
<date>2007</date>
<booktitle>In ACL Linguistic Annotation Workshop.</booktitle>
<contexts>
<context position="11713" citStr="Ringger et al., 2007" startWordPosition="1911" endWordPosition="1914">ataset. Points above the diagonal-line demonstrate the superiority of ACL over CW Margin. ACL required fewer labels than CW margin twice as often as the opposite occurred (8 vs 4). Note that CW Margin used more labels than CW Random in three cases, while ACL only once, and this one time only about a dozen labels were needed. To conclude, not only does CW Margin outperforms PA Margin for active-learning, CW maintains additional valuable information (confidence), which further improves performance. 5 Related Work Active learning has been widely used for NLP tasks such as part of speech tagging (Ringger et al., 2007), parsing (Tang et al., 2002) and word sense disambiguation (Chan and Ng, 2007). Many methods rely on entropy-based scores such as uncertainty sampling (Lewis and Gale, 1994). Others use margin based methods, such as Kim et al. (2006), who combined margin scores with corpus diversity, and Sassano (2002), who considered SVM active learning 235 \x0c100 150 200 250 300 350 400 450 500 Labels 0.65 0.70 0.75 0.80 0.85 0.90 0.95 Test Accuracy 20 Newsgroups PA Random (82.53) CW Random (92.92) PA Margin (88.06) CW Margin (95.39) ACL (95.51) 100 150 200 250 300 350 400 450 500 Labels 0.75 0.80 0.85 0.9</context>
</contexts>
<marker>Ringger, McClanahan, Haertel, Busby, Carmen, Carroll, Seppi, Lonsdale, 2007</marker>
<rawString>E. Ringger, P. McClanahan, R. Haertel, G. Busby, M. Carmen, J. Carroll, K. Seppi, and D. Lonsdale. 2007. Active learning for part-of-speech tagging: Accelerating corpus annotation. In ACL Linguistic Annotation Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Roy</author>
<author>A McCallum</author>
</authors>
<title>Toward optimal active learning through sampling estimation of error reduction.</title>
<date>2001</date>
<booktitle>In ICML.</booktitle>
<marker>Roy, McCallum, 2001</marker>
<rawString>N. Roy and A. McCallum. 2001. Toward optimal active learning through sampling estimation of error reduction. In ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manabu Sassano</author>
</authors>
<title>An empirical study of active learning with support vector machines for japanese word segmentation.</title>
<date>2002</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="12017" citStr="Sassano (2002)" startWordPosition="1964" endWordPosition="1966">ls were needed. To conclude, not only does CW Margin outperforms PA Margin for active-learning, CW maintains additional valuable information (confidence), which further improves performance. 5 Related Work Active learning has been widely used for NLP tasks such as part of speech tagging (Ringger et al., 2007), parsing (Tang et al., 2002) and word sense disambiguation (Chan and Ng, 2007). Many methods rely on entropy-based scores such as uncertainty sampling (Lewis and Gale, 1994). Others use margin based methods, such as Kim et al. (2006), who combined margin scores with corpus diversity, and Sassano (2002), who considered SVM active learning 235 \x0c100 150 200 250 300 350 400 450 500 Labels 0.65 0.70 0.75 0.80 0.85 0.90 0.95 Test Accuracy 20 Newsgroups PA Random (82.53) CW Random (92.92) PA Margin (88.06) CW Margin (95.39) ACL (95.51) 100 150 200 250 300 350 400 450 500 Labels 0.75 0.80 0.85 0.90 Test Accuracy All PA Random (81.30) CW Random (86.67) PA Margin (83.99) CW Margin (88.61) ACL (88.79) 0.2 0.4 0.6 0.8 1.0 1.2 1.4 ACL Labels 0.2 0.4 0.6 0.8 1.0 1.2 1.4 CW Margin Labels Reuters 20 Newsgroups Sentiment Spam Figure 1: Results averaged over 20 Newsgroups (left) and all datasets (center) </context>
</contexts>
<marker>Sassano, 2002</marker>
<rawString>Manabu Sassano. 2002. An empirical study of active learning with support vector machines for japanese word segmentation. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Sculley</author>
</authors>
<title>Online active learning methods for fast label-efficient spam filtering.</title>
<date>2007</date>
<booktitle>In CEAS.</booktitle>
<marker>Sculley, 2007</marker>
<rawString>D. Sculley. 2007. Online active learning methods for fast label-efficient spam filtering. In CEAS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Tang</author>
<author>X Luo</author>
<author>S Roukos</author>
</authors>
<title>Active learning for statistical natural language parsing.</title>
<date>2002</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="11742" citStr="Tang et al., 2002" startWordPosition="1916" endWordPosition="1919">l-line demonstrate the superiority of ACL over CW Margin. ACL required fewer labels than CW margin twice as often as the opposite occurred (8 vs 4). Note that CW Margin used more labels than CW Random in three cases, while ACL only once, and this one time only about a dozen labels were needed. To conclude, not only does CW Margin outperforms PA Margin for active-learning, CW maintains additional valuable information (confidence), which further improves performance. 5 Related Work Active learning has been widely used for NLP tasks such as part of speech tagging (Ringger et al., 2007), parsing (Tang et al., 2002) and word sense disambiguation (Chan and Ng, 2007). Many methods rely on entropy-based scores such as uncertainty sampling (Lewis and Gale, 1994). Others use margin based methods, such as Kim et al. (2006), who combined margin scores with corpus diversity, and Sassano (2002), who considered SVM active learning 235 \x0c100 150 200 250 300 350 400 450 500 Labels 0.65 0.70 0.75 0.80 0.85 0.90 0.95 Test Accuracy 20 Newsgroups PA Random (82.53) CW Random (92.92) PA Margin (88.06) CW Margin (95.39) ACL (95.51) 100 150 200 250 300 350 400 450 500 Labels 0.75 0.80 0.85 0.90 Test Accuracy All PA Random</context>
</contexts>
<marker>Tang, Luo, Roukos, 2002</marker>
<rawString>M. Tang, X. Luo, and S. Roukos. 2002. Active learning for statistical natural language parsing. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Tong</author>
<author>D Koller</author>
</authors>
<title>Supprt vector machine active learning with applications to text classification.</title>
<date>2001</date>
<publisher>JMLR.</publisher>
<contexts>
<context position="1846" citStr="Tong and Koller, 2001" startWordPosition="258" endWordPosition="261"> proposed for selecting examples that maximize system performance as compared to selecting instances randomly. Two learning methodologies dominate NLP applications: probabilistic methods naive Bayes, logistic regression and margin methods support vector machines and passive-aggressive. Active learning for probabilistic methods often uses uncertainty sampling: label the example with the lowest probability prediction (the most uncertain) (Lewis and Gale, 1994). The equivalent technique for margin learning associates the margin with prediction certainty: label the example with the lowest margin (Tong and Koller, 2001). Common intuition equates large margins with high prediction confidence. However, confidence and margin are two distinct properties. For example, an instance may receive a large margin based on a single feature which has been updated only a small number of times. Another example may receive a small margin, but its features have been learned from a large number of examples. While the first example has a larger margin it has low confidence compared to the second. Both the margin value and confidence should be considered in choosing which example to label. We present active learning with confide</context>
<context position="6506" citStr="Tong and Koller (2001)" startWordPosition="1038" endWordPosition="1041">ially set to be L = . On each round the active learner uses its selection criteria to return a single instance xi to be labeled by an annotator with yi {1, +1} (for binary classification). The instance and label are added to the labeled set L L {(xi, yi)} and passed to the learning algorithm A, which in turn generates a new model. At the end of labeling the algorithm returns a classifier trained on the final labeled set. Effective active learning minimizes prediction error and the number of labeled examples. Most active learners for margin based algorithms rely on the magnitude of the margin. Tong and Koller (2001) motivate this approach by considering the half-space representation of the hypothesis space for learning. They suggest three margin based active learning methods: Simple margin, MaxMin margin, and Ratio margin. In Simple margin, the algorithm predicts an unsigned margin M for each instance in U and returns for labeling the instance with the smallest margin. The intuition is that instances for which the classifier is uncertain (small margin) provide the most information for learning. Active learning based on PA algorithms runs in a similar fashion but full SVM retraining on every round is repl</context>
<context position="8130" citStr="Tong and Koller (2001)" startWordPosition="1302" endWordPosition="1305">nzU (w z), is replaced with a probabilistic criteria x = arg minzU |PrwN(i,i) [sign(w z) = 1] \x01 1 2 |. 234 \x0cThe selection criteria naturally captures the notion that we should label the example with the highest uncertainty. Interestingly, we can show (omitted due to lack of space) that the probabilistic criteria can be translated into a corrected geometrical criteria. In practice, we can compute this normalized margin as M = M/ V . We call this selection criteria Active Confident Learning (ACL). 4 Evaluation To evaluate our active learning methods we used a similar experimental setup to Tong and Koller (2001). Each active learning algorithm was given two labeled examples, one from each class, for initial training of a classifier, and remaining data as unlabeled examples. On each round the algorithm selected a single instance for which it was then given the correct label. The algorithm updated the online classifier and evaluated it on held out test data to measure learning progress. We selected four binary NLP datasets for evaluation: 20 Newsgroups1 and Reuters (Lewis et al., 2004) (used by Tong and Koller) and sentiment classification (Blitzer et al., 2007) and spam (Bickel, 2006). For each datase</context>
<context position="13258" citStr="Tong and Koller, 2001" startWordPosition="2175" endWordPosition="2178">cy over active learning rounds. The right panel shows the amount of labels needed by CW Margin and ACL to achieve 80% of the accuracy of training on all data - each points refers to a different dataset. for Japanese word segmentation. Our confidence based approach can be used to improve these tasks. Furthermore, margin methods can outperform probabilistic methods; CW beats maximum entropy on many NLP tasks (Dredze et al., 2008). A theoretical analysis of margin based methods selected labels that maximize the reduction of the version space, the hypothesis set consistent with the training data (Tong and Koller, 2001). Another approach selects instances that minimize the future error in probabilistic algorithms (Roy and McCallum, 2001). Since we consider an online learning algorithm our techniques can be easily extended to online active learning (Cesa-Bianchi et al., 2005; Dasgupta et al., 2005; Sculley, 2007). 6 Conclusion We have presented techniques for incorporating confidence into the margin for active learning and have shown that CW selects better examples than PA, a popular online algorithm. This approach creates opportunities for new active learning frameworks that depend on margin confidence. Refe</context>
</contexts>
<marker>Tong, Koller, 2001</marker>
<rawString>S. Tong and D. Koller. 2001. Supprt vector machine active learning with applications to text classification. JMLR.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>