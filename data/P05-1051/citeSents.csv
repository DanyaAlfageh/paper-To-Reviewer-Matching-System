 2 Prior Work A wide variety of trainable models have been applied to the name tagging task, including HMMs CITATION, maximum entropy models (Borthwick, 1999), support vector machines (SVMs), and conditional random fields,,
 (Borthwick, 1999) made a second tagging pass which uses information on token sequences tagged in the first pass; CITATION used as features information about features assigned to other instances of the same toke,,
 The HMM tagger generally follows the Nymble model CITATION, but with multiple hypotheses as output and a larger number of states (12) to handle name prefixes and suffixes, and transliterated foreign names separately,,
 variety of trainable models have been applied to the name tagging task, including HMMs CITATION, maximum entropy models (Borthwick, 1999), support vector machines (SVMs), and conditional random fields,,
 (Borthwick, 1999) made a second tagging pass which uses information on token sequences tagged in the first pass; CITATION used as features information about features assigned to other instances of the same token,,
 BBN proposed the N-Best algorithm for speech recognition in CITATION,,
 Since then NBest methods have been widely used by other researchers (Collins, 2002; CITATION),,
 3 Similar methods based on HMM margins were used by CITATION,,
 To address these limitations, some recent systems have used more parallel designs, in which a single classifier (incorporating a wide range of features) encompasses what were previously several separate stages (Kambhatla, 2004; CITATION),,
 BBN proposed the N-Best algorithm for speech recognition in CITATION,,
 Since then NBest methods have been widely used by other researchers (Collins, 2002; CITATION),,
 In addition, we apply the mechanism of weighted voting among hypotheses CITATION as an additional feature in this second-stage re-ranking,,
