In a language understanding task, the head word dependencies or parse tree path are successfully applied to learn and predict semantic roles, especially those with ambiguous labels CITATION.,,
In a semantic role labeling task, the syntax and semantics are correlated with each other CITATION, that is, the global structure of the sentence is useful for identifying ambiguous semantic roles.,,
The second group includes governing category and parse tree paths introduced by semantic role labeling CITATION.,,
The parse tree path and governing category show a small improvement of performance over local features, but it is rather insignificant (word vs. word+path, McNemars test CITATION; p = 0.022).,,
<s> i wanna go from denver to new york on november eighteenth </s> FROMLOC.CITY NAME = denver TOLOC.CITY NAME = new york MONTH NAME = november DAY NUMBER = eighteenth This example from air travel data (CUCommunicator corpus) was automatically generated by a Phoenix parser and manually corrected (CITATION; CITATION).,,
Following CITATION, the slot labels are drawn from a set of classes constructed by extending each label by three additional symbols, Beginning/Inside/Outside (B/I/O).,,
5 Related Work and Discussion The most relevant previous work is CITATION who describes an generative approach hidden vector state (HVS) model.,,
To extract semantic frames from utterance inputs, we use a linearchain CRF model; a model that assigns a joint probability distribution over labels which is conditional on the input sequences, where the distribution respects the independent relations encoded in a graph CITATION.,,
Our approach is based on an automatic feature induction algorithm, which is a novel method to select a feature in an exponential model (CITATION; CITATION).,,
Following (CITATION; CITATION), the mean field approximation and agglomerated features allows us to treat the above calculation as the independent inference problem rather than sequential inference.,,
Rather than summing over all training instances, we only need to use the mislabeled N tokens by the current parameter (i) CITATION.,,
CITATION demonstrated that the trigger word pairs improve the perplexity in ME-based language models.,,
Our method is based on two works of feature induction on an exponential model, CITATION and CITATION.,,
CITATION suggested using only the mislabeled events rather than the whole training events.,,
<s> i wanna go from denver to new york on november eighteenth </s> FROMLOC.CITY NAME = denver TOLOC.CITY NAME = new york MONTH NAME = november DAY NUMBER = eighteenth This example from air travel data (CUCommunicator corpus) was automatically generated by a Phoenix parser and manually corrected (CITATION; CITATION).,,
Following CITATION, the slot labels are drawn from a set of classes constructed by extending each label by three additional symbols, Beginning/Inside/Outside (B/I/O).,,
The framework for inducing trigger features is based on the Kullback-Leibler divergence criterion which measures the improvement of loglikelihood on the current parameters by adding a new feature CITATION.,,
Our approach is based on an automatic feature induction algorithm, which is a novel method to select a feature in an exponential model (CITATION; CITATION).,,
Following (CITATION; CITATION), the mean field approximation and agglomerated features allows us to treat the above calculation as the independent inference problem rather than sequential inference.,,
CITATION demonstrated that the trigger word pairs improve the perplexity in ME-based language models.,,
Our method is based on two works of feature induction on an exponential model, CITATION and CITATION.,,
CITATION suggested using only the mislabeled events rather than the whole training events.,,
Y NAME = new york MONTH NAME = november DAY NUMBER = eighteenth This example from air travel data (CUCommunicator corpus) was automatically generated by a Phoenix parser and manually corrected (CITATION; CITATION).,,
Following CITATION, the slot labels are drawn from a set of classes constructed by extending each label by three additional symbols, Beginning/Inside/Outside (B/I/O).,,
The trigger word pairs are introduced by CITATION.,,
To select reasonable pairs from arbitrary word pairs, CITATION used averaged mutual information (MI).,,
The trigger pairs introduced by CITATION are just word pairs.,,
CITATION demonstrated that the trigger word pairs improve the perplexity in ME-based language models.,,
Our method is based on two works of feature induction on an exponential model, CITATION and CITATION.,,
CITATION suggested using only the mi,,
The L-BFGS method converges super-linearly to the solution, so it can be an efficient optimization technique on large-scale NLP problems CITATION.,,
An additional consistent edge of a linear-chain conditional random field (CRF) explicitly models the dependencies between distant occurrences of similar words (CITATION; Finkel et al., 2005).,,
