<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000003">
<tableCaption confidence="0.173742">
b&amp;quot;Coling 2008: Companion volume Posters and Demonstrations, pages 4750
</tableCaption>
<address confidence="0.728353">
Manchester, August 2008
</address>
<title confidence="0.924216">
ILP-based Conceptual Analysis for Chinese NPs
</title>
<author confidence="0.993338">
Paul D. Ji
</author>
<affiliation confidence="0.981295">
Center for Language and Philology
Oxford University
</affiliation>
<email confidence="0.961557">
Paul_dji@yahoo.com.uk
</email>
<author confidence="0.975551">
Stephen Pulman
</author>
<affiliation confidence="0.966558">
Computing Laboratory
Oxford University
</affiliation>
<email confidence="0.994626">
sgp@clg.ox.ac.uk
</email>
<sectionHeader confidence="0.929183" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.996931375">
In this paper, we explore a conceptual re-
source for Chinese nominal phrases,
which allows multi-dependency and dis-
tinction between dependency and the cor-
responding exact relation. We also pro-
vide an ILP-based method to learn map-
ping rules from training data, and use the
rules to analyze new nominal phrases.
</bodyText>
<sectionHeader confidence="0.997819" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.991171305555556">
Nominal phrases have long been a concern in
linguistic research and language processing (e.g.,
Copestake and Briscoe, 2005; Giegerich, 2004).
Generally, nominal phrases can be classified into
two categories according to whether they contain
attributive clauses or not. We focus on nominal
phrases without attributive clauses.
Closely related with nominal phrases, nominal
compounds or base NPs have also attracted a
great attention in language processing. Gener-
ally, nominal compounds refer to nominal
phrases consisting of a series of nouns, while
base NPs refer to non-recursive nominal phrases.
However, such compounds or base NPs usually
co-occur with other non-nominal words in run-
ning texts, and it is impossible to separate them
during analysis. Furthermore, there exist syntac-
tic makers for attributive clauses, e.g., which or
who in English and (of) in Chinese, nomi-
nal phrases without attributive clauses tend to be
a better linguistic category for theoretical and
practical investigation.
To analyze NPs, we need first to determine
what kinds of information are to be recognized.
In this work, we focus on conceptual relatedness
between words. For example, in linguistics and
2008. Licensed under the Creative Commons Attri-
bution-Noncommercial-Share Alike 3.0 Unported
license (http://creativecommons.org/licenses/by-nc-
sa/3.0/). Some rights reserved.
law books, linguistic and law are both conceptu-
ally related with books, although linguistics
doesnt have a superficial syntactic relation with
books. Then, we need to fulfill two sub-tasks.
One is about representation, i.e., what schemes
are to be used. The other is about analysis, i.e.,
how to derive the formal representation.
Regarding representation scheme, one possible
strategy would be using syntactic structures, as
are usually used in analysis for sentences. How-
ever, syntactic components for NPs, unlike those
for sentences (e.g., V, VP, A, AP, and S, etc.),
are difficult to differentiate, and rules governing
nominal phrases are especially difficult to deter-
mine. As an example, consider (bank
loan interest), which is a nominal compound
consisting of three serial nouns. For such a NP, if
a rule with binary combination is used, it would
produce two structures for the unambiguous NP.
If a rule with triple combination is used, as in
Chinese Treebank (Xue et al., 2005), it would be
difficult to disclose the lexical relation between
(bank) and (loan).
Another possible representation strategy
would be using dependency structures (Melcuk,
1988). Under this strategy, a NP could be repre-
sented as a dependency tree, which captures
various lexical control or dependency in the
phrase. However, traditional framework only
focuses on syntactic dependency, while concep-
tual relatedness may exist without syntactic rela-
tions. For example, for (eco-
nomic development and law construction in Shang-
hai), in traditional dependency analysis,
(Shanghai) would depend on the conjunction
word (and), since conjunction words are usu-
ally regarded as heads in coordinate structures.
Although the relatedness may go downward from
the head, it would be difficult to derive the relat-
edness between (Shanghai) and
(economic) or (law), since the two words are
even not heads of the conjuncts (eco-
</bodyText>
<page confidence="0.998521">
47
</page>
<bodyText confidence="0.995816344827586">
\x0cnomic development) and (law develop-
ment).
As to analysis of NPs, there have been a lot of
work on statistical techniques for lexical depend-
ency parsing of sentences (Collins and Roark,
2004; McDonald et al., 2005), and these tech-
niques potentially can be used for analysis of
NPs if appropriate resources for NPs are avail-
able. However, these techniques are all meant to
building a dependency tree, while the conceptual
relatedness in NPs may form a graph, with multi-
dependency allowed. Additionally, these meth-
ods generally suffer from the difficulty of local
estimation from limited contexts and the struc-
tural information is difficult to be exploited
(Califf and Mooney, 2003).
Recently, relational learning methods in gen-
eral and inductive logic programming (ILP) in
particular have attracted a great of attention due
to their capability of going beyond finite feature
vectors and exploiting unbounded structural in-
formation from data (Califf and Mooney, 2003;
Page et al., 2003; Srinivasan et al., 2003).
In this work, we try to extend syntactic de-
pendency to conceptual dependency to capture
the embedded lexical relatedness, and use ILP to
analyze nominal phrases, making use of the
structural information provided by the resources
based on conceptual dependency.
</bodyText>
<sectionHeader confidence="0.945888" genericHeader="method">
2 Conceptual dependency
</sectionHeader>
<bodyText confidence="0.8699205">
In comparison with syntactic dependency, con-
ceptual dependency may allow a word to be de-
pendent on multiple words at the same time. For
example, in (Economic devel-
opment and law construction in Shanghai),
(Shanghai) conceptually relates with both
(economic) and (law), while in
(activity of blood donation for university student
volunteers), (university student) relates on
both (volunteer) and (blood donation).
In addition, syntactic dependency doesnt
exactly specify what kind of relatedness held
between words, although the words denoting the
relatedness may occur within NPs. For example,
</bodyText>
<listItem confidence="0.9099426">
1) is an ambiguous compound with two possible
interpretations listed in 2).
1) (student discussion)
2) i) discussion by students
ii) discussion about students
</listItem>
<bodyText confidence="0.993199382352941">
However, the dependency trees corresponding
with the two interpretations remain the same:
(student) depends on (discussion) in both
cases. In fact, their difference lies in the exact
semantic relations held between the words:
(student) is agent and patient of (discussion)
in 2i) and 2ii) respectively. This suggests that
only syntactic dependency is not enough to re-
flect conceptual difference.
Notice that in (2), the relations between the
two words (student) and (discussion) are
denoted by two proper nouns, agent and patient,
which may never co-occur with them in running
texts. However, in some cases, some word co-
occurring with two conceptually related words
do denote the relatedness exactly. Consider
(car in read color), where (color) relates with
both (car) and (red). In the conceptual view,
(color) can be seen as a feature of (car), and
(red) can be seen as a kind of value for the fea-
ture, as was also adopted in dealing with adjec-
tives in WordNet (Fellbaum, 1988). In this set-
ting, (red) directly depends on (car), and
(color) represents the relation between them.
In building the resource for Chinese NPs,
the conceptual relatedness is based on semantic
reference, while the dependency is based on syn-
tactic or potential syntactic relations. The feature
words we adopt are mostly listed in a medium
class, coded as Dn, in a Chinese thesaurus,
Tongyici Cilin (henceafter Cilin, Mei et al.,
1982). Function words (e.g., (from)), Part
words (e.g., (leg)) and Number words (e.g.,
(count)) are also regarded as feature words.
</bodyText>
<sectionHeader confidence="0.998409" genericHeader="method">
3 ILP-based Analysis
</sectionHeader>
<bodyText confidence="0.910712">
Fig. 1 gives the overall structure of the analysis
procedure.
</bodyText>
<sectionHeader confidence="0.476447" genericHeader="method">
END
</sectionHeader>
<bodyText confidence="0.995184222222222">
Fig. 1 Overall structure of analysis procedure
The analysis consists of two phases, training and
parsing. During the training phase, rules are
learned for mapping from conceptual depend-
ency graphs to word strings based on training
examples. During the parsing phase, there are
three steps. Search is to find candidate depend-
ency graphs, Generation is to generate word
strings from candidate dependency graphs using
</bodyText>
<figure confidence="0.515538833333333">
Rule Learning
Search
Generation
Evaluation
Parsing
Training
</figure>
<page confidence="0.955636">
48
</page>
<bodyText confidence="0.5745705">
\x0cthe learned rules, and Evaluation is to compare
the generated word strings with the original NPs.
</bodyText>
<subsectionHeader confidence="0.974769">
3.1 Training: learning rules
</subsectionHeader>
<bodyText confidence="0.99499105">
For each training sample, we have a nominal
phrase and its corresponding conceptual depend-
ency graph. To learn the rules mapping from de-
pendency graphs to word strings, we need to tag
the words with their sense labels, which denote
the synsets in the thesaurus (Mei et al., 1982).
For the sense tagging, we used the same method
as in (Yarowsky, 1992) and used the minor cate-
gories in the thesaurus as the synsets.
Generally, a rule consists of two parts, Gr and
Sr. Gr is a dependency sub-graph and Sr is a
sense label string. Intuitively, conceptual con-
figuration in Gr is represented by the label string
of Sr.
To capture more structural information, we
need to find the maximal sub-graph in the train-
ing data, whose corresponding labels form a con-
tinuous substring in the training data. But the
problem is NP hard, and we thus use heuristics to
find am optimally maximal sub-graphs. How-
ever, the search has a bias to larger sub-graphs,
and to avoid the bias, we set the coverage of a
sub-graph as the penalty. Here, the coverage of
the sub-graph refers to the percentage of the
nodes in the sub-graphs among all the nodes in
the training data. The overall algorithm is:
i) to find the most common edge in the training data,
whose corresponding label strings are continuous;
ii) to add another edge to the sub-graph, if the label
strings corresponding with the new sub-graph are
still continuous until the coverage of the sub-graph
doesnt increase.
After finding such a sub-graph, we merge all
the nodes into one, and merge the sense label
strings into one, and repeat the process until all
the nodes in the training data are covered The
result of the learning is a set of rules, and each
rule specifies a sub-graph and a label string.
For example, w got a rule which includes the
sub-graph in Fig. 2 and sense label string in 3).
</bodyText>
<figureCaption confidence="0.916293">
Fig. 2. Sub-graph in a rule.
</figureCaption>
<equation confidence="0.377871">
3) SL( )SL( )SL( )
</equation>
<bodyText confidence="0.9928935">
For rule generalization, we dont try to com-
press the rule set, and simply use the sense hier-
archy in the thesaurus, including the minor, me-
dium and major classes.
</bodyText>
<subsectionHeader confidence="0.999789">
3.2 Parsing
</subsectionHeader>
<bodyText confidence="0.999284">
After training phase, we get a set of learned
rules. During parsing, the task is to find a con-
ceptual dependency graph for a new input data,
which would generate the NP using the learned
rules.
The optimal parsing can be implemented in a
greedy manner. First, one dependency with two
words is selected. Then, another word is added if
the resulted conceptual dependency graph gener-
ates a word string which best matches the input
nominal phrase. This process can be repeated
until the graph includes all the words in the data.
To compare the generated word string with the
original input, we use edit distance between
them, which is based on the times of operations
(including adjacent move, deletion, insertion)
needed to convert one word string to another.
</bodyText>
<sectionHeader confidence="0.997225" genericHeader="evaluation">
4 Experiments and Evaluation
</sectionHeader>
<bodyText confidence="0.9910925">
There are 10,000 nominal phrases annotated in
the resource, and they were selected from 1,221
articles form the corpora of China daily, 1992.
Table 1 gives the statistics of the resource.
</bodyText>
<figure confidence="0.911284727272727">
num de
structure
Nominal
compound
Depend-
ency with
feature
Multi-
depend-
ency
10K 4,234 5,766 1,235 976
</figure>
<tableCaption confidence="0.993716">
Table 1. Statistics of NP resource
</tableCaption>
<bodyText confidence="0.9792792">
Here, de structure refer to the phrase with
word (of). Nominal compounds refer to the
nominal phrases with no occurrence of (of).
Dependency with features refers to those tagged
with features, which also occur in the same NPs.
Multi-dependency refers to the number of mono-
dependencies occurring in the multi-dependency.
We randomly selected 10% of the training
data as closed test data, and the other 90% or less
as training data. To evaluate the performance of
the dependency analysis, we used F-scores as
evaluation measure as usual. Fig. 4 shows the
results for overall dependency, multi-dependency
and dependency with features. The results are
averaged over 10 random runs.
</bodyText>
<figure confidence="0.958025">
(and)
(boys)
(some)
49
\x0c0
0. 2
0. 4
0. 6
0. 8
1
10% 30% 50% 70% 90%
Tr ai ni ng dat a
F-
S
cor
e
over al dependency
m
ul t i - dependency
dependency w
i t h f eat ures
</figure>
<bodyText confidence="0.967377333333333">
Fig. 3 Performance with varying training data
Fig. 3 demonstrates that with more training
data, the performance generally improved. The
performance for dependency with features
seemed better than that for overall dependency or
multi-dependency. To check the reason, we
found that we treated the Amount words in
Number-Amount structures as features, and these
words are generally easier to be identified, since
they tend to be unambiguous. Once they were
recognized as Amount words, the relevant de-
pendency would be correctly identified.
For an open test, we selected another 1,000
nominal phrases from the same corpus, but from
different time period (1994). Such phrases were
annotated with the same standard as those train-
ing data. Fig. 4 shows the results with varying
training data.
</bodyText>
<figure confidence="0.940665769230769">
0
0. 2
0. 4
0. 6
0. 8
1
10% 30% 50% 70% 90%
Tr ai ni ng dat a
F-
Scor
e
cl osed t est ( 1000)
open t est (1000)
</figure>
<figureCaption confidence="0.9091905">
Fig. 4 Comparison: Closed test and open test
Fig. 4 shows that the open test performance is
</figureCaption>
<bodyText confidence="0.9844272">
generally worse than that of the closed test. No-
tice that although the test data was selected from
the same resource, but with a different period,
which may account for the different perform-
ance.
</bodyText>
<sectionHeader confidence="0.998278" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.9996016">
In this paper, we described a resource for lexical
conceptual dependency of Chinese nominal
phrases. Compared with other ones, it allows
multi-dependency and distinguishes dependency
and relation, which exactly denotes what kinds of
dependency held. We also provided an ILP-
based analysis method, in which some rules
mapping from conceptual dependency to word
strings are learned from the training data, and
then the rules are used to find the conceptual de-
pendency graph for a new data. Compared with
other search strategies, this method makes use of
the structural information and allows construc-
tion of a dependency graph, not just a depend-
ency tree.
</bodyText>
<sectionHeader confidence="0.99164" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999794421052631">
Califf, M.R. and Mooney, R.J. 2003. Bottom-Up Re-
lational Learning of Pattern Matching Rules for In-
formation Extraction, JMLR: 4:177-210.
Collins M. and Roark, B. 2004. Incremental parsing
with the perceptron algorithm. In Proc. of the 42rd
Annual Meeting of the ACL.
Copestake, A. and Briscoe, T. 2005. Noun com-
pounds revisited. In John I. Tait, editor, Charting a
New Course: Natural Language Processing and
Information Retrieval. Springer, Berlin, 2005.
Fellbaum, editor. 1998. WordNet: An Electronic
Lexical Database. The MIT Press.
Giegerich, H.J. Compound or phrase? English noun-
plus-noun constructions and the stress criterion.
English Language and Linguistics, 8(1):1-24,
2004.
McDonald, R., Pereira, F., Ribarov, K. and Hajic, J.
2005. Non-projective dependency parsing using
spanning tree algorithms. In Proc. of HLT/EMNLP.
Mei, J., Zhu, Y., Gao, Y., and Yin, H. 1982. Tongyici Cilin.
Shanghai Dictionary Press.
Mel&apos;cuk, I., 1988. Dependency Syntax: Theory and
Practice. Albany. State Univ. of New York Press.
Page, D. Srinivasan A. 2003. ILP: A Short Look Back
and a Longer Look Forward. Journal of Machine
Learning Research 4: 415-430
Srinivasan, A. Ross D. K., Michael B. 2003. An Em-
pirical Study of the Use of Relevance Information
in Inductive Logic Programming. Journal of Ma-
chine Learning Research 4: 369-383.
Xue, N.W., Xia, F., Chiou, F.D.and Palmer, M. The
Penn Chinese TreeBank: Phrase Structure Annota-
tion of a Large Corpus. Natural Language Engi-
neering, 11(2): 207-238.
Yarowsky, D. 1982. Word-Sense Disambiguation
Using Statistical Models of Roget&apos;s Categories
Trained on Large Corpora. In Proceedings, COL-
ING-92. pp. 454-460, 1992.
</reference>
<figure confidence="0.3999695">
50
\x0c&amp;quot;
</figure>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.391275">
<note confidence="0.8076195">b&amp;quot;Coling 2008: Companion volume Posters and Demonstrations, pages 4750 Manchester, August 2008</note>
<title confidence="0.970732">ILP-based Conceptual Analysis for Chinese NPs</title>
<author confidence="0.999957">Paul D Ji</author>
<affiliation confidence="0.9992895">Center for Language and Philology Oxford University</affiliation>
<title confidence="0.628668">Paul_dji@yahoo.com.uk</title>
<author confidence="0.999527">Stephen Pulman</author>
<affiliation confidence="0.9999845">Computing Laboratory Oxford University</affiliation>
<email confidence="0.987949">sgp@clg.ox.ac.uk</email>
<abstract confidence="0.996661444444444">In this paper, we explore a conceptual resource for Chinese nominal phrases, which allows multi-dependency and distinction between dependency and the corresponding exact relation. We also provide an ILP-based method to learn mapping rules from training data, and use the rules to analyze new nominal phrases.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M R Califf</author>
<author>R J Mooney</author>
</authors>
<date>2003</date>
<booktitle>Bottom-Up Relational Learning of Pattern Matching Rules for Information Extraction, JMLR:</booktitle>
<pages>4--177</pages>
<contexts>
<context position="4566" citStr="Califf and Mooney, 2003" startWordPosition="689" endWordPosition="692">s of NPs, there have been a lot of work on statistical techniques for lexical dependency parsing of sentences (Collins and Roark, 2004; McDonald et al., 2005), and these techniques potentially can be used for analysis of NPs if appropriate resources for NPs are available. However, these techniques are all meant to building a dependency tree, while the conceptual relatedness in NPs may form a graph, with multidependency allowed. Additionally, these methods generally suffer from the difficulty of local estimation from limited contexts and the structural information is difficult to be exploited (Califf and Mooney, 2003). Recently, relational learning methods in general and inductive logic programming (ILP) in particular have attracted a great of attention due to their capability of going beyond finite feature vectors and exploiting unbounded structural information from data (Califf and Mooney, 2003; Page et al., 2003; Srinivasan et al., 2003). In this work, we try to extend syntactic dependency to conceptual dependency to capture the embedded lexical relatedness, and use ILP to analyze nominal phrases, making use of the structural information provided by the resources based on conceptual dependency. 2 Concep</context>
</contexts>
<marker>Califf, Mooney, 2003</marker>
<rawString>Califf, M.R. and Mooney, R.J. 2003. Bottom-Up Relational Learning of Pattern Matching Rules for Information Extraction, JMLR: 4:177-210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
<author>B Roark</author>
</authors>
<title>Incremental parsing with the perceptron algorithm.</title>
<date>2004</date>
<booktitle>In Proc. of the 42rd Annual Meeting of the ACL.</booktitle>
<contexts>
<context position="4076" citStr="Collins and Roark, 2004" startWordPosition="611" endWordPosition="614"> development and law construction in Shanghai), in traditional dependency analysis, (Shanghai) would depend on the conjunction word (and), since conjunction words are usually regarded as heads in coordinate structures. Although the relatedness may go downward from the head, it would be difficult to derive the relatedness between (Shanghai) and (economic) or (law), since the two words are even not heads of the conjuncts (eco47 \x0cnomic development) and (law development). As to analysis of NPs, there have been a lot of work on statistical techniques for lexical dependency parsing of sentences (Collins and Roark, 2004; McDonald et al., 2005), and these techniques potentially can be used for analysis of NPs if appropriate resources for NPs are available. However, these techniques are all meant to building a dependency tree, while the conceptual relatedness in NPs may form a graph, with multidependency allowed. Additionally, these methods generally suffer from the difficulty of local estimation from limited contexts and the structural information is difficult to be exploited (Califf and Mooney, 2003). Recently, relational learning methods in general and inductive logic programming (ILP) in particular have at</context>
</contexts>
<marker>Collins, Roark, 2004</marker>
<rawString>Collins M. and Roark, B. 2004. Incremental parsing with the perceptron algorithm. In Proc. of the 42rd Annual Meeting of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Copestake</author>
<author>T Briscoe</author>
</authors>
<title>Noun compounds revisited. In</title>
<date>2005</date>
<booktitle>Charting a New Course: Natural Language Processing and Information Retrieval.</booktitle>
<editor>John I. Tait, editor,</editor>
<publisher>Springer,</publisher>
<location>Berlin,</location>
<contexts>
<context position="752" citStr="Copestake and Briscoe, 2005" startWordPosition="104" endWordPosition="107">for Chinese NPs Paul D. Ji Center for Language and Philology Oxford University Paul_dji@yahoo.com.uk Stephen Pulman Computing Laboratory Oxford University sgp@clg.ox.ac.uk ABSTRACT In this paper, we explore a conceptual resource for Chinese nominal phrases, which allows multi-dependency and distinction between dependency and the corresponding exact relation. We also provide an ILP-based method to learn mapping rules from training data, and use the rules to analyze new nominal phrases. 1 Introduction Nominal phrases have long been a concern in linguistic research and language processing (e.g., Copestake and Briscoe, 2005; Giegerich, 2004). Generally, nominal phrases can be classified into two categories according to whether they contain attributive clauses or not. We focus on nominal phrases without attributive clauses. Closely related with nominal phrases, nominal compounds or base NPs have also attracted a great attention in language processing. Generally, nominal compounds refer to nominal phrases consisting of a series of nouns, while base NPs refer to non-recursive nominal phrases. However, such compounds or base NPs usually co-occur with other non-nominal words in running texts, and it is impossible to </context>
</contexts>
<marker>Copestake, Briscoe, 2005</marker>
<rawString>Copestake, A. and Briscoe, T. 2005. Noun compounds revisited. In John I. Tait, editor, Charting a New Course: Natural Language Processing and Information Retrieval. Springer, Berlin, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>editor Fellbaum</author>
</authors>
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<booktitle>Compound or phrase? English nounplus-noun constructions and the stress criterion.</booktitle>
<editor>Giegerich, H.J.</editor>
<publisher>The MIT Press.</publisher>
<marker>Fellbaum, 1998</marker>
<rawString>Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database. The MIT Press. Giegerich, H.J. Compound or phrase? English nounplus-noun constructions and the stress criterion.</rawString>
</citation>
<citation valid="true">
<authors>
<author>English Language</author>
<author>Linguistics</author>
</authors>
<date>2004</date>
<pages>8--1</pages>
<marker>Language, Linguistics, 2004</marker>
<rawString>English Language and Linguistics, 8(1):1-24, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>F Pereira</author>
<author>K Ribarov</author>
<author>J Hajic</author>
</authors>
<title>Non-projective dependency parsing using spanning tree algorithms.</title>
<date>2005</date>
<booktitle>In Proc. of HLT/EMNLP.</booktitle>
<contexts>
<context position="4100" citStr="McDonald et al., 2005" startWordPosition="615" endWordPosition="618">truction in Shanghai), in traditional dependency analysis, (Shanghai) would depend on the conjunction word (and), since conjunction words are usually regarded as heads in coordinate structures. Although the relatedness may go downward from the head, it would be difficult to derive the relatedness between (Shanghai) and (economic) or (law), since the two words are even not heads of the conjuncts (eco47 \x0cnomic development) and (law development). As to analysis of NPs, there have been a lot of work on statistical techniques for lexical dependency parsing of sentences (Collins and Roark, 2004; McDonald et al., 2005), and these techniques potentially can be used for analysis of NPs if appropriate resources for NPs are available. However, these techniques are all meant to building a dependency tree, while the conceptual relatedness in NPs may form a graph, with multidependency allowed. Additionally, these methods generally suffer from the difficulty of local estimation from limited contexts and the structural information is difficult to be exploited (Califf and Mooney, 2003). Recently, relational learning methods in general and inductive logic programming (ILP) in particular have attracted a great of atten</context>
</contexts>
<marker>McDonald, Pereira, Ribarov, Hajic, 2005</marker>
<rawString>McDonald, R., Pereira, F., Ribarov, K. and Hajic, J. 2005. Non-projective dependency parsing using spanning tree algorithms. In Proc. of HLT/EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Mei</author>
<author>Y Zhu</author>
<author>Y Gao</author>
<author>H Yin</author>
</authors>
<title>Tongyici Cilin.</title>
<date>1982</date>
<publisher>Shanghai Dictionary Press.</publisher>
<contexts>
<context position="7346" citStr="Mei et al., 1982" startWordPosition="1124" endWordPosition="1127">ual view, (color) can be seen as a feature of (car), and (red) can be seen as a kind of value for the feature, as was also adopted in dealing with adjectives in WordNet (Fellbaum, 1988). In this setting, (red) directly depends on (car), and (color) represents the relation between them. In building the resource for Chinese NPs, the conceptual relatedness is based on semantic reference, while the dependency is based on syntactic or potential syntactic relations. The feature words we adopt are mostly listed in a medium class, coded as Dn, in a Chinese thesaurus, Tongyici Cilin (henceafter Cilin, Mei et al., 1982). Function words (e.g., (from)), Part words (e.g., (leg)) and Number words (e.g., (count)) are also regarded as feature words. 3 ILP-based Analysis Fig. 1 gives the overall structure of the analysis procedure. END Fig. 1 Overall structure of analysis procedure The analysis consists of two phases, training and parsing. During the training phase, rules are learned for mapping from conceptual dependency graphs to word strings based on training examples. During the parsing phase, there are three steps. Search is to find candidate dependency graphs, Generation is to generate word strings from candi</context>
</contexts>
<marker>Mei, Zhu, Gao, Yin, 1982</marker>
<rawString>Mei, J., Zhu, Y., Gao, Y., and Yin, H. 1982. Tongyici Cilin. Shanghai Dictionary Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Mel&apos;cuk</author>
</authors>
<title>Dependency Syntax: Theory and Practice.</title>
<date>1988</date>
<publisher>Press.</publisher>
<location>Albany. State Univ. of New York</location>
<marker>Mel&apos;cuk, 1988</marker>
<rawString>Mel&apos;cuk, I., 1988. Dependency Syntax: Theory and Practice. Albany. State Univ. of New York Press.</rawString>
</citation>
<citation valid="false">
<authors>
<author>D Srinivasan A Page</author>
</authors>
<title>ILP: A Short Look Back and a Longer Look Forward.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research</journal>
<volume>4</volume>
<pages>415--430</pages>
<marker>Page, 2003</marker>
<rawString>Page, D. Srinivasan A. 2003. ILP: A Short Look Back and a Longer Look Forward. Journal of Machine Learning Research 4: 415-430 Srinivasan, A. Ross D. K., Michael B. 2003. An Empirical Study of the Use of Relevance Information in Inductive Logic Programming. Journal of Machine Learning Research 4: 369-383. Xue, N.W., Xia, F., Chiou, F.D.and Palmer, M. The Penn Chinese TreeBank: Phrase Structure Annotation of a Large Corpus. Natural Language Engineering, 11(2): 207-238.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
</authors>
<title>Word-Sense Disambiguation Using Statistical Models of Roget&apos;s Categories Trained on Large Corpora.</title>
<date>1982</date>
<booktitle>In Proceedings, COLING-92.</booktitle>
<pages>454--460</pages>
<marker>Yarowsky, 1982</marker>
<rawString>Yarowsky, D. 1982. Word-Sense Disambiguation Using Statistical Models of Roget&apos;s Categories Trained on Large Corpora. In Proceedings, COLING-92. pp. 454-460, 1992.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>