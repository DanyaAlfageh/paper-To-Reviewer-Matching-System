Structural disambiguation of morpho-syntactic categorial parsing
for Korean 
Jeongwon Cha and Geunbae Lee
Department of Computer Science & Engineering
Pohang University of Science & Technology
Pohang, Korea
fhimen, gbleeg@postech.ac.kr
Abstract
The Korean Combinatory Categorial Grammar
(KCCG) formalism can uniformly handle word
order variation among arguments and adjuncts
within a clause as well as in complex clauses
and across clause boundaries, i.e., long distance
scrambling. In this paper, incremental pars-
ing technique of a morpheme graph is devel-
oped using the KCCG. We present techniques
for choosing the most plausible parse tree us-
ing lexical information such as category merge
probability, head-head co-occurrence heuristic,
and the heuristic based on the coverage of sub-
trees. The performance results for various mod-
els for choosing the most plausibleparse tree are
compared.
1 Introduction
Korean is a non-congurational, postpositional,
agglutinative language. Postpositions, such as
noun-endings, verb-endings, and prenal verb-
endings, are morphemes that determine the
functional role of NPs (noun phrases) and VPs
(verb phrases) in sentences and also transform
VPs into NPs or APs (adjective phrases). Since
a sequence of prenal verb-endings, auxiliary
verbs and verb-endings can generate hundreds
of dierent usages of the same verb, morpheme-
based grammar modeling is considered as a nat-
ural consequence for Korean.
There have been various researches to dis-
ambiguate the structural ambiguities in pars-
ing. Lexical and contextual information has
been shown to be most crucial for many pars-
ing decisions, such as prepositional-phrase at-
tachment (Hindleand Rooth, 1993). (Charniak,
1995; Collins, 1996) use the lexical information
 This research was partially supported by KOSEF spe-
cial basic research program (1997.9  2000.8).
and (Magerman and Marcus, 1991; Magerman
and Weir, 1992) use the contextual information
for structural disambiguation. But, there have
been few researches that used probability infor-
mation for reducing the spurious ambiguities in
choosing the most plausible parse tree of CCG
formalism, especiallyfor morpho-syntactic pars-
ing of agglutinative language.
In this paper, we describe the probabilistic
method (e.g., category merge probability, head-
head co-occurrence, coverage heuristics) to re-
duce the spurious ambiguities and choose the
most plausible parse tree for agglutinative lan-
guages such as Korean.
2 Overview of KCCG
This section briey reviews the basic KCCG for-
malism.
Following (Steedman, 1985), order-preserving
type-raising rules are used to convert nouns in
grammar into the functors over a verb. The
following rules are obligatorily activated during
parsing when case-marking morphemes attach
to noun stems.
 Type Raising Rules:
np + case-marker =) v=(vnnp[case-
feature])
This rule indicates that a noun in the pres-
ence of a case morpheme becomes a functor
looking for a verb on its right; this verb is also
a functor looking for the original noun with the
appropriate case on its left. After the noun
functor combines with the appropriate verb, the
result is a functor, which is looking for the re-
maining arguments of the verb. `v' is a vari-
able for a verb phrase at any level, e.g., the
verb of a matrix clause or the verb of an em-
bedded clause. And `v' is matched to all of
the \v[X]nArgs" patterns of the verb categories.
Since all case-marked nouns in Korean occur in
front of the verb, we don't need to employ the
directionalrules introducedby (Homan, 1995).
We extend the combinatory rules for uncur-
ried functions as follows. The sets indicated by
braces in these rules are order-free.
 Forward Application (A>):
X=(Args [ fYg) Y =) X=Args
 Backward Application (A<):
Y Xn(Args [ fYg) =) XnArgs
Using these rules, a verb can apply to its
arguments in any order, or as in most cases,
the case-marked noun phrases, which are type-
raised functors, can apply to the appropriate
verbs.
Coordination constructions are modied to
allow two type-raised noun phrases that are
looking for the same verb to combine together.
Since noun phrases, or a noun phrase and ad-
verb phrase, are functors, the following compo-
sition rules combine two functions with a set
value arguments.
 Forward Composition (B>):
X=(XnArgsX ) Y=(YnArgsY ) =)
X=(Xn(ArgsX [ArgsY )),
Y = XnArgsX
 Backward Composition (B<):
YnArgsY Xn(ArgsX [ fYg) =)
Xn(ArgsX [ArgsY )
 Coordination ():
X CONJ X =) X
3 Basic morph-syntactic chart
parsing
Korean chart parser has been developed based
on our KCCG modeling with a 100,000 mor-
pheme dictionary. Each morpheme entry in
the dictionary has morphological category, mor-
photactics connectivity and KCCG syntax cat-
egories for the morpheme.
In the morphological analysis stage, a un-
known word treatment method based on a mor-
pheme pattern dictionary and syllable bigrams
is used after (Cha et al., 1998). POS(part-of-
speech) tagger which is tightly coupled with
the morphological analyzer removes the irrele-
vant morpheme candidates from the morpheme
graph. The morpheme graph is a compact
representation method of Korean morphologi-
cal structure. KCCG parser analyzes the mor-
pheme graph at once through the morpheme
graph embedding technique (Lee et al., 1996).
The KCCG parser incrementally analyzes the
sentence, eojeol by eojeol 1. Whenever an eo-
jeol is newly processed by the morphological an-
alyzer, the morphemes resulted in a new mor-
pheme graph are embedded in a chart and an-
alyzed and combined with the previous parsing
results.
4 Statistical structured
disambiguation for KCCG parsing
The statistics which have been used in the ex-
periments have been collected from the KCCG
parsed corpora. The data required for train-
ing have been collected by parsing the stan-
dard Korean sentence types2, example sentences
of grammar book, and colloquial sentences in
trade interview domain3 and hotel reservation
domain4. We use about 1500 sentences for
training and 591 independent sentences for eval-
uation.
The evaluation is based on parseval
method (Black et al., 1991). In the evalu-
ation, \No-crossing" is the number of sentences
which have no crossing brackets between the
result and the corresponding correct trees of
the sentences. \Ave. crossing" is the average
number of crossings per sentence.
4.1 Basic statistical model
A basic method of choosing the most plausible
parse tree is to order the probabilitiesby the lex-
ical preferences5 and the syntactic merge prob-
ability. In general, a statistical parsing model
denes the conditional probability, P(jS), for
each candidate tree  for a sentence S. A gener-
ative model uses the observation that maximis-
ing P(;S) is equivalent to maximisingP(jS)6.
1
Eojeol is a spacing unit in Korean and is similar to
an English word.
2
Sentences of length  11.
3
Sentences of length  25.
4
Sentences of length  13.
5
The frequency with which a certain category is as-
sociated with a morpheme tagged for part-of-speech.
6
P(S) is constant.
Thus, when S is a sentence consisted of a se-
quence of morphemes tagged for part-of-speech,
(w1;t1);(w2;t2);:::;(wn;tn), where wi is a ith
morpheme, ti is the part-of-speech tag of the
morpheme wi, and cij is a category with rela-
tive position i, j, the basic statistical model will
be given by:
 = argmax

P(jS) (1)
= argmax

P(;S)
P(S) (2)
 argmax

P(;S): (3)
The  is the probabilities of the optimal parse
tree.
P(;S) is then estimated by attaching proba-
bilities to a bottom-up composition of the tree.
P(;S) =
Y
cij 2
P(cij) (4)
=
Y
cij 2
(P(cijjcik;ck+1j)
P(cik)P(ck+1j)); (5)
i  k  j;
if cij is a terminal;
then P(cij) = P(cijjwi;ti);
and
P(cijjti;wi)  frequency(cij;ti;wi)
frequency(ti;wi) ; (6)
P(cijjcik;ck+1j)  frequency(cij;cik;ck+1j)
frequency(cik;ck+1j) : (7)
The basic statistical model has been applied
to morpheme/part-of-speech/category 3-tuple.
Due to the sparseness of the data, we have
used part-of-speech/category pairs7 together,
i.e., collected the frequencies of the categories
associated with the part-of-speeches assigned to
the morpheme. Table 1 illustrates the sample
entries of the category probability database. In
table, 'nal (y)' has two categories with 0.6375
and 0.3625 probability respectively. Table 2 il-
lustrates the sample entries of the merge prob-
ability database using equation 7.
7
We dene this as P(cij jti)  f requency(cij;ti)
f requency(ti)
.
Table 3: Results from the Basic Statistical
Model
Total sentences 591
No-crossing 74.62%
Ave. crossing 1.00
Labeled Recall 77.02
Labeled Precision 79.15
Ch
Bh
r
Ch
Bh
r
Figure 1: Sub-constituents for head-head co-
occurrence heuristics
Table 3 summarizes the results on an open
test set of 591 sentences.
4.2 Head-head co-occurrence heuristics
In the basic statistical model, lexical depen-
dencies between morphemes that take part in
merging process cannot be incorporated into the
model. When there is a dierent morpheme
with the same syntactic category, it can be a
miss match on merging process. This limita-
tion can be overcome through the co-occurrence
between the head morphemes of left and right
sub-constituent.
When Bh
is a head morpheme of left sub-
constituent, r is a case relation, Ch
is a head
morpheme of right sub-constituent as shown in
gure 1, head-head co-occurrence heuristics are
dened by:
P(Bh
jr;Ch
)  frequency(Bh
;r;Ch
)
frequency(r;Ch) :(8)
The head-head co-occurrence heuristics have
been augmented to equation 5 to model the lex-
ical co-occurrence preference in category merg-
ing process. Table 4 illustrates the sample en-
tries of the co-occurrence probability database.
In Table 4, a morpheme `sae (means `bird')',
which has a \MCK (common noun)" as POS
tag, has been used a nominative of verb `nal
(means `y')' with 0.8925 probability.
Table 1: Sample entries of the category probability database (`DIl' means an `l' irregular verb.)
POS, morpheme category probability
DIl, nal v[D]nfnp[nom]g 0.6375
DIl, nal v[D]nfnp[nom],np[acc]g 0.3625
DIl v[D]nfnp[nom]g 0.3079
DIl v[D]nfnp[nom],np[acc]g 0.2020
Table 2: Sample entries of syntactic merge probability database
left category right category merged category probability
v=(vnnp[nom]) v[D]nfnp[nom],np[acc]g v[D]nfnp[acc]g 0.0473
v=(vnnp[acc]) v[D]nfnp[nom],np[acc]g v[D]nfnp[nom]g 0.6250
np (v=(vnnom))nnp v=(vnnp[nom]) 0.2197
The modied model has been tested on the
same set of the open sentences as in the basic
model experiment. Table 5 summarizes the re-
sult of these experiments.
 Experiment: (linear combination of the ba-
sic model and the head-head co-occurrence
heuristics).
P(;S) =
Y
cij 2
((P(cijjcik;ck+1j)
+ P(Bh
jr;Ch
))
P(cik)P(ck+1j)); (9)
i  k  j;
if cij is a terminal;
then P(cij) = P(cijjwi;ti):
Table 5: Results from the Basic Statistical
Model plus head-head co-occurrence heuristics
Total sentences 591
No-crossing 81.05%
Ave. crossing 0.70
Labeled Recall 84.02
Labeled Precision 85.30
4.3 The coverage heuristics
If there is a case relation or a modication re-
lation in two constituents, coverage heuristics
designate it is easier to add the smaller tree to
the larger one than to merge the two medium
sized trees. On the contrary, in the coordination
relation, it is easier to merge two medium sized
trees. We implemented these heuristics using
the following coverage score:
Case relation, modication relation:
COV score =
left subtree coverage + right subtree coverage
4
peft subtree coverage  right subtree coverage
(10)
Coordination:
COV score =
2
pleft subtree coverage  right subtree coverage
left subtree coverage + right subtree coverage
(11)
A coverage heuristics are added to the basic
model to model the structural preferences. Ta-
ble 6 shows the results of the experiments on
the same set of the open sentences.
 Experiment: (the basic model to the
COV score heuristics). We have used the
COV score as the exponent weight feature
for this experiment since the two numbers
are in the dierent nature of statistics.
P(;S) =
Y
cij 2
(P(cijjcik;ck+1j)1,COV score
P(cik)P(ck+1j)); (12)
i  k  j;
if cij is a terminal;
then P(cij) = P(cijjwi;ti):
Table 4: Sample entries of co-occurrence probability database.
head-head co-occurrence probability
(MCC<ganeungseong>,np[nom],HR<nob>) 0.8932
(MCK<sae>,np[nom],DIl<nal>) 0.8925
(MCK<galeuchim>,np[acc],DIeu<ddaleu>) 0.8743
Table 6: Results from the Basic Statistical
model plus Coverage heuristics
Total sentences 591
No-crossing 80.13%
Ave. crossing 0.81
Labeled Recall 82.59
Labeled Precision 83.75
5 Summary
We developed a morpho-syntactic categorial
parser of Korean and devised a morpheme-
based statistical structural disambiguation
schemes.
Through the KCCG model, we successfully
handled dicult Korean modeling problems, in-
cluding relative free-word ordering, coordina-
tion, and case-marking, during the parsing.
To extract the most plausibleparse trees from
the parse forest, we have presented basic statis-
tical techniques using the lexical and contextual
information such as morpheme-category proba-
bility and category merge probability.
Two dierent nature of heuristics, head-head
co-occurrence and coverage scores, are also de-
veloped and tested to augment the basic statis-
tical model. Each of them demonstrates reason-
able performance increase.
The next step willbeto devisemore heuristics
and good combination strategies for the dier-
ent nature of heuristics.
References
E. Black, S. Abney, D. Flickenger, C. Gdaniec,
R. Grishman, P. Harrison, D. Hindle, R. In-
gria, F. Jelinek, J. Klavans, M. Liberman,
M. Marcus, S. Roukos, B. Santorini, and
T. Strzalkowski. 1991. A Procedure for
Quantitatively Comparing the Syntactic Cov-
erage of English Grammars. In Proc. of
Fourth DARPA Speech and Natural Lan-
guage Workshop.
Jeongwon Cha, Geunbae Lee, and Jong-Hyeok
Lee. 1998. Generalized unknown morpheme
guessing for hybrid pos tagging of korean.
In Proceedings of Sixth Workshop on Very
Large Corpora in Coling-ACL 98, Montreal,
Canada.
E. Charniak. 1995. Prsing with Context-Free
Grammars and Word Statistics. Technical
Report CS-95-28, Brown University.
M. Collins. 1996. A New Statistical Parser
Based on Bigram Lexical Dependencies. In
Proceedings of the 34th Annual Meeting of the
ACL, Santa Cruz.
D. Hindle and M. Rooth. 1993. Structural am-
biguity and lexical relations. Computational
Linguistics, 19(1):103{120.
B. Homan. 1995. The Computational Analy-
sis of the Syntax and Interpretation of \Free"
Word Order in Turkish. Ph.D. thesis, Univer-
sity of Pennsylvania. IRCS Report 95-17.
Wonil Lee, Geunbae Lee, and Jong-Hyeok Lee.
1996. Chart-driven connectionist categorial
parsing of spoken korean. Computer process-
ing of oriental languages, Vol 10, No 2:147{
159.
D. M. Magerman and M. P. Marcus. 1991.
Parsing the voyager domain using pearl. In
In Proc. Of the DARPA Speech and Natural
Language Workshop, pages 231{236.
D. M. Magerman and C. Weir. 1992. Ef-
ciency, robustness and accuracy in picky
chart parsing. In In Proc. Of the 30th An-
nual Meeting of the Assoc. For Computa-
tional Linguistics(ACL-92), pages 40{47.
Mark Steedman. 1985. Dependency and Coor-
dination in the Grammar of Dutch and En-
glish. Language, 61:523{568.
