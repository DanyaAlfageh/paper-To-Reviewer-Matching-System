A Class-based Probabilistic approach to Structural
Disambiguation
Stephen Clark and David Weir
School of Cognitive and Computing Sciences
University of Sussex
Brighton, BN1 9HQ, UK
fstephecl,davidwg@cogs.susx.ac.uk
Abstract
Knowledge of which words are able to ll partic-
ular argument slots of a predicate can be used
for structural disambiguation. This paper de-
scribes a proposal for acquiring such knowledge,
and in line with much of the recent work in this
area, a probabilistic approach is taken. We de-
velop a novel way of using a semantic hierar-
chy to estimate the probabilities, and demon-
strate the general approach using a preposi-
tional phrase attachment experiment.
1 Introduction
Knowledge of which words are able to ll
particular argument slots of a predicate can
be used for structural disambiguation. In
the following example (Charniak, 1993), the
fact that dog, rather than prize, is often
the subject of run, can be used to decide
on the attachment site of the relative clause:
Fred awarded a prize for the dog that ran the fastest
We describe a proposal for acquiring such
knowledge, and as in other recent work in this
area (Resnik, 1993; Li and Abe, 1998), a prob-
abilistic approach is taken. Using probabilities
accords with the intuition that there are no ab-
solute constraints on the arguments of predi-
cates, but rather that constraints are satised
to a certain degree (Resnik, 1993). Unfortu-
nately, dening probabilities in terms of words
leads to a model with a vast number of param-
eters, resulting in a sparse data problem. To
overcome this, we propose to dene a probabil-
ity model in terms of senses from a semantic hi-
erarchy, exploiting the fact that senses of nouns
can be grouped together into semantically sim-
ilar classes.
We use the semantic hierarchy of noun senses
in WordNet (Fellbaum, 1998), which consists of
`lexicalised concepts' related by the `is-a-kind-
of' relation. If c0 is a kind of c, then c is a hy-
pernym of c0, and c0 a hyponym of c. Counts are
passed up the hierarchy from the senses of nouns
appearing in the data. Thus if eat chicken ap-
pears in the data, the count for this item passes
up to hmeati, hfoodi, and all the other hyper-
nyms of that sense of chicken.1
In order to es-
timate the probability that a sense of chicken
appears as the object of the verb eat, we repre-
sent hchickeni using a suitable hypernym, such
as hfoodi, and base our probability estimate on
that instead. The level at which hchickeni is
represented is crucial: it should be high enough
for adequate counts to have accumulated, but
not too high so that the hypernym is no longer
representative of hchickeni. An example of a
hypernym which would be too high is hentityi,
as not all entities are semantically similar with
respect to the object position of eat.
The problem of choosing an appropriate level
in the hierarchy at which to represent a par-
ticular noun sense (given a predicate and argu-
ment position) has been investigated by Resnik
(1993), Li and Abe (1998) and Ribas (1995).
The learning mechanism presented here is a
novel approach based on nding semantically
similar sets of concepts in a hierarchy. We
demonstrate the eectiveness of our approach
using a PP-attachment experiment.
2 The Input Data and Semantic
Hierarchy
The data used to estimate the probabilities is
a multiset of `co-occurrence triples': a noun
1
We use italics when referring to words, and angled
brackets for concepts. This notation does not always
pick out a concept uniquely, but the context should make
clear the concept being referred to.
lemma, verb lemma, and argument position.2
Let the universe of verbs, argument posi-
tions and nouns that can appear in the in-
put data be denoted V = fv1;::: ;vkV
g, R =
fr1;::: ;rkR
g and N = fn1;::: ;nkN
g, respec-
tively. Such data can be obtained from a tree-
bank, or from a shallow parser. Note that we
do not distinguish between alternative senses of
verbs, and assume that each instance of a noun
in the data refers to exactly one concept.
The semantic hierarchy used is the noun hy-
pernym taxonomy of WordNet (version 1.6).3
Let C = fc1;::: ;ckC
g be the set of concepts
in WordNet (kC  66;000). A concept is repre-
sented in WordNet by a synset: a set of synony-
mous words which can be used to denote that
concept. For example, the concept `cocaine',
as in the drug, is represented by the following
synset: fcocaine, cocain, coke, snow, Cg. Let
syn(c)  N be the synset for the concept c,
and let cn(n) = fc jn 2 syn(c) g be the set of
concepts that can be denoted by the noun n.
The hierarchy has the structure of a directed
acyclic graph, although the number of nodes in
the graph with more than one parent is only
around one percent of the total. The edges in
the graph form what we call the direct-isa rela-
tion (direct-isa  C  C). Let isa = direct-isa
be the transitive, reexive closure of direct-isa,
so that (c0;c) 2 isa ) c is a hypernym of c0; and
let c = fc0 j(c0;c) 2 isa g be the set consisting
of the concept c and all of its hyponyms. Thus,
the set hfoodi contains all the concepts which
are kinds of food, including hfoodi.
Note that words in the data can appear in
synsets anywhere in the hierarchy. Even con-
cepts such as hentityi, which appear near the
root of the hierarchy, have synsets containing
words which may appear in the data. The
synset for hentityi is fentity, somethingg, and
the words entity and something can appear in
the argument positions of verbs in the data.
3 Probability Estimation
The problem being addressed in this section is
to estimate p(cjv;r), for c 2 C, v 2 V, and
2
Only verbs are considered here, but this work applies
to other predicates which take arguments that can be
organised into a semantic hierarchy.
3
When we refer to concepts in WordNet, we mean
concepts in WordNet's noun taxonomy.
r 2 R. The probability p(cjv;r) is the prob-
ability that some noun in syn(c), when denot-
ing concept c, appears in position r of verb v
(given r and v). Using the relative clause ex-
ample from the introduction, the probabilities
p(hdogijrun;subj) and p(hprizeijrun;subj) can
be compared to decide on the attachment site
in Fred awarded a prize for the dog that ran
the fastest. We expect p(hdogijrun;subj) to be
greater than p(hprizeijrun;subj). Although the
focus is on p(cjv;r), the techniques described
here can be used to estimate other probabilities,
such as p(c;rjv). (In fact, the latter probabil-
ity is used in the PP-attachment experiments
described in Section 5.)
Using maximum likelihood to estimate
p(cjv;r) is not viable because of the huge num-
ber of parameters involved. Many combinations
of c, v and r will not occur in the data. To re-
duce the number of parameters which need to
be estimated, we utilise the fact that concepts
can be grouped into classes, and represent c us-
ing a class c0, for some hypernym c0 of c. How-
ever, p(c0jv;r) cannot be used as an estimate of
p(cjv;r), as p(c0jv;r) is given by the following:
p(c0jv;r) =
X
c00
2c0
p(c00
jv;r)
The probability p(c0jv;r) increases as c0
moves up the hierarchy. For example,
p(hfoodijeat;obj) is not a good estimate of
p(hchickenijeat;obj). What can be done
though, is to condition on sets of concepts, and
use the probability p(vjc0;r). If it can be shown
that p(vjc0;r), for some hypernym c0 of c, is a
reasonable estimate of p(vjc;r), then we have a
way of estimating p(cjv;r). To get p(vjc;r)from
p(cjv;r) Bayes rule is used:
p(cjv;r)= p(vjc;r)p(cjr)
p(vjr)
The probabilities p(cjr) and p(vjr) can be esti-
mated using maximum likelihood estimates, as
the conditioning event is likely to occur often
enough for sparse data not to be a problem.
(Alternatively one could back-o to p(c) and
p(v) respectively, or use a linear combination
of p(cjr) and p(c), and p(vjr) and p(v), respec-
tively.) The formulae for these estimates will
be given shortly. This only leaves p(vjc;r). The
proposal is to estimate p(eatjhchickeni;obj) us-
ing p(eatjhfoodi;obj), or something similar. The
following proposition shows that if p(vjc00;r) is
the same for each c00 in c0, where c0 is some
hypernym of c, then p(vjc0;r) will be equal to
p(vjc;r):
p(vjc00
;r) = k for all c00
2 c0 ) p(vjc0;r) = k
The proof is as follows:
p(vjc0;r) = p(c0jv;r)p(vjr)
p(c0jr)
= p(vjr)
p(c0jr)
X
c00
2c0
p(c00jv;r)
= p(vjr)
p(c0jr)
X
c00
2c0
p(vjc00
;r)p(c00jr)
p(vjr)
= 1
p(c0jr)
k
X
c
00
2c0
p(c00
jr)
= k
So in order to estimate p(vjc;r), we need a
way of searching for a set c0, where c0 is a hy-
pernym of c, which consists of concepts c00 which
have similar p(vjc00;r). Of course we cannot ex-
pect to nd a set consisting of concepts which
have identical p(vjc00;r), which the proposition
strictly requires, but if the p(vjc00;r) are similar,
then we can expect p(vjc0;r) to be a reasonable
estimate of p(vjc;r). We refer to the set c0 as
the `similarity-class' of c, and the suitable hy-
pernym, c0, as top(c;v;r). The next section ex-
plains how we determine similarity classes. The
maximum likelihood estimates for the relevant
probabilities are given in Table 1.4
4 Finding Similarity-classes
First we explain how we determine if a set of
concepts has similar p(vjc00;r) for each concept
c00 in the set. Then we explain howwe determine
top(c;v;r).
4
Since we are assuming the data is not sense dis-
ambiguated, freq(c;v;r) cannot be obtained by sim-
ply counting senses. The standard approach, which is
adopted here, is to estimate freq(c;v;r) by distributing
the count for each noun n in syn(c) evenly among all
senses of the noun. Yarowsky (1992) and Resnik (1993)
explain how the noise introduced by this technique tends
to dissipate as counts are passed up the hierarchy.
Table 1: Maximum Likelihood Estimates {
freq(c;v;r) is the number of (n;v;r) triples in
the data in which n is being used to denote c.
^
p(cjr) = freq(c;r)
freq(r)
=
P
v02V
freq(c;v
0
;r)
Pv02V
Pc02C
freq(c0
;v0
;r)
^
p(vjr) = freq(v;r)
freq(r)
=
Pc02C
freq(c
0
;v;r)
Pv02V
Pc02C
freq(c
0
;v
0
;r)
^
p(vjc0;r) = freq(c0
;v;r)
freq(c
0
;r)
=
P
c00 2c0
freq(c
00
;v;r)
Pv02V
P
c002c0
freq(c00
;v0
;r)
The method used for comparing the p(vjc00;r)
for c00 in some set c0, is based on the technique
in Clark and Weir (1999) used for nding homo-
geneous sets of concepts in the WordNet noun
hierarchy. Rather than directly compare esti-
mates of p(vjc00;r), which are likely to be unreli-
able, we consider the children of c0, and use esti-
mates based on counts which have accumulated
at the children. If c0 has children c0
1;c0
2;::: ;c0
n
,
we compare p(vjc0
i
;r) for each i. This is an
approximation, but if the p(vjc0
i
;r) are similar,
then we assume that the p(vjc00;r) for c00 in c0
are similar too.
To determine whether the children of some
hypernym c0 have similar p(vjc0
i
), where c0
i
is the
ith child, we apply a 2
test to a contingency
table of frequency counts. Table 2 shows some
example frequencies for c0 equal to hnutrimenti,
in the object position of eat. The gures in
brackets are the expected values, based on the
marginal totals in the table. The null hypoth-
esis of the test is that p(vjc0
i
;r) is the same for
each i. For Table 2 the null hypothesis is that
for every child, c0
i
, of hnutrimenti, the probabil-
ity p(eatjc0
i
;obj) is the same.
The log-likelihood 2
statistic corresponding
to Table 2 is 4:8. The log-likelihood 2
statistic
is used rather than the Pearson's 2
statistic
because it is thought to be more appropriate
when the counts in the contingency table are
low (Dunning, 1993). This tends to occur when
the test is being applied to a set of concepts
near the foot of the hierarchy.5
We compared
5
Fisher's exact test could be used for tables with low
counts, but we do not do so because tables dominated
by low counts are likely to have a high percentage of
noise, due to the way counts for a noun are split among
Table 2: Contingency table for children of hnutrimenti
ci
^
freq(ci;eat;obj) ^
freq(ci;obj), ^
freq(ci;obj) =
^
freq(ci;eat;obj)
Pv2V
^
freq(ci;v;obj)
hmilki 0.0 (0.6) 9.0 (8.4) 9.0
hmeali 8.5 (5.6) 78.0 (80.9) 86.5
hcoursei 1.3 (1.7) 24.7 (24.3) 26.0
hdishi 5.3 (5.7) 82.3 (81.9) 87.6
hdelicacyi 0.3 (1.8) 27.4 (25.9) 27.7
15.4 221.4 236.8
the performance of log-likelihood 2
and Pear-
son's 2
using the PP-attachment experiment
described in Section 5. It was found that the
log-likelihood 2
test did perform slightly bet-
ter. For a signicance level of 0:05 (which is the
level used in the experiments), with 4 degrees
of freedom, the critical value is 14.86 (Howell,
1997). Thus in this case, the null hypothesis
would not be rejected.
In order to determine top(c;v;r),we compare
p(vjci;r) for the children of the hypernyms of
c. Initially top(c;v;r) is assigned to be the con-
cept c itself. Then, by working up the hierarchy,
top(c;v;r) is reassigned to be successive hyper-
nyms of c until the siblings of top(c;v;r) have
signicantly dierent probabilities. In cases
where a concept has more than one parent, the
parent is chosen which results in the lowest 2
value as this indicates the p(vjci;r) are more
similar. The set top(c;v;r) is the similarity-
class of c for verb v and position r.
The next section provides evidence that the
technique for choosing top(c;v;r),which we call
the `similarity-class' technique, does select an
appropriate level of generalisation.
5 Experiments using PP-attachment
ambiguity
The PP-attachment problem we address con-
siders 4-tuples of the form v;n1;pr;n2, and
the problem is to decide whether the prepo-
sitional phrase pr n2 attaches to the verb v
or the noun n1. For example, in the fol-
lowing case the problem is to decide whether
alternative senses. We rely on the log-likelihood 2
test
returning a non-signicant result in these cases.
from minister attaches to await or approval:
await approval from minister
We chose the PP-attachment problem because
PP-attachmentis a pervasive form of ambiguity,
and there exist standard training and test data,
which makes for easy comparisons with other
approaches. This problem has been tackled by a
number of researchers. Brill and Resnik (1994),
Ratnaparkhi et al. (1994), Collins (1995), Za-
vrel and Daelemans (1997) all report results be-
tween 81% and 85%, with Stetina and Nagao
(1997) reporting a result of 88%, which matches
the human performance on this task reported by
Ratnaparkhi et al. (1994).
Although the PP-attachment problem has
characteristics that make it suitable for evalua-
tion, it presents a much bigger sparse data prob-
lem than would be expected in other problems
such as relative clause attachment. The reason
for this is that we need to consider how a con-
cept is associated with combinations of predi-
cates and prepositions. The approach described
here uses probabilities of the form p(c;prjv)
and p(c;prjn1), where c 2 cn(n2). This means
that for many predicate/preposition combina-
tions which occur infrequently in the data, there
are few examples of n2 which can be used for
populating WordNet in these cases. Despite
this, we were still able to carry out an evalu-
ation by considering subsets of the test data for
which the relevant predicate/preposition com-
binations did occur frequently in the training
data.
We decide on the attachment site by compar-
ing p(cv;prjv) and p(cn1;prjn1), where
cv = arg max
c2cn(n2)
p(c;prjv)
cn1 = arg max
c2cn(n2)
p(c;prjn1)
The sense of n2 is chosen which maximises
the relevant probability in each potential at-
tachment case. If p(cv;prjv) is greater than
p(cn1;prjn1), the attachment is made to v, oth-
erwise to n1. If n2 is not in WordNet we com-
pare p(prjv) and p(prjn1). Probabilities of the
form p(c;prjv) and p(c;prjn1) are used rather
than p(cjv;pr) and p(cjn1;pr), because the as-
sociation between the preposition and v and n1
contains useful information. In fact, for a lot
of cases this information alone can be used to
decide on the correct attachment site. The orig-
inal corpus-based method of Hindle and Rooth
(1993) used exactly this information. Thus the
method described here can be thoughtof as Hin-
dle and Rooth's method with additional class-
based information about n2.
In order to estimate p(cv;prjv) (and
p(cn1;prjn1)) we apply the same procedure
as described in Section 3, rst rewriting the
probability using Bayes' rule:
p(cv ;prjv) = p(vjcv;pr)p(cv;pr)
p(v)
= p(vjcv;pr)p(prjcv)p(cv )
p(v)
The probabilities p(cv) and p(v) can be es-
timated using maximum likelihood estimates,
and p(vjcv;pr) and p(prjcv) can be esti-
mated using maximum likelihood estimates of
p(vjtop(cv;v;pr);pr) and p(prjtop(cv;pr)) re-
spectively.6
We used the training and test data described
in Ratnaparkhi et al. (1994), which was taken
from the Penn Treebank and has now become
the standard data set for this task. The data
set consists of tuples of the form (v, n1, pr, n2),
together with the attachment site for each tu-
ple. There is also a development set to prevent
implicit training on the test set during develop-
ment. We extracted (v, pr, n2) and (n1, pr, n2)
6
In Section 4 we only gave the procedure for deter-
mining top(cv;v;pr), but top(cv;pr) can be determined
in an analogous fashion.
triples from the training set, and in order to in-
crease the number of training triples, we also
extracted triples from unambiguous cases of at-
tachment in the Penn Treebank. We prepro-
cessed the training and test databy lemmatising
the words, replacing numerical amounts with
the words `denite quantity', replacing mone-
tary amounts with the words `sum of money'
etc. We then ignored those triples in the re-
sulting training set (but not test set) for which
n2 was not in WordNet, which left a total of
66;881 triples of training data. The test set
contains 3;097 examples.
Table 3 gives some examples of the ex-
tent to which the similarity-class technique
is generalising, using the training data just
described, and a signicance level of 0:05.
The chosen hypernym is shown in upper
case. Note that the WordNet hierarchy con-
sists of nine separate sub-hierarchies, headed
by such concepts as hentityi, habstractioni,
hpsychological featurei, but we assume the ex-
istence of a single root which dominates each
of the sub-hierarchies, which is referred to as
hrooti. In cases where WordNet is very sparsely
populated, it is preferable to go to hrooti,
rather than stay at the root of one of the sub-
hierarchies where the data may be noisy or too
sparse to be of any use. The table shows that
with the amount ofdata available fromthe Tree-
bank, the similarity-class technique is selecting
a level at or close to hrooti in many cases.
We compared the similarity-class technique
with xing the level of generalisation. Two xed
levels were used: the root of the entire hierar-
chy (hrooti), and the set consisting of the roots
of each of the 9 sub-hierarchies. The procedure
which always selects hrootiignores any informa-
tion about n2, and is equivalent to comparing
p(prjv) and p(prjn1), which is the Hindle and
Rooth approach. The results on the 3;097 test
cases are shown in Table 4. We used a signi-
cance level  of 0:05 for the 2
test.7
As the table shows, the disambiguation ac-
curacy is below the state of the art. However,
the results are comparable with those of Li and
7
Similar results were obtained using alternative levels
of signicance. Rather than simply selecting a value for
 such as 0:05,  can be treated as a parameter of the
model, whose optimum value can be obtained by running
the disambiguation method on some held-out supervised
data.
Table 3: How the similarity-class technique chooses top(c;v;pr) and top(c;n1;pr)
(n1;pr;c) Hypernyms of c
(bid,for,hcompanyi) hcompanyihestablishmentihorganisationihsocial groupihGROUPihrooti
(concern,about,hriski) hriskihventureihtaskihworkihactivityihactihROOTi
(billion,in,hcashi) hcashihcurrencyihmonetary systemihassetihPOSSESSIONihrooti
(v;pr;c)
(notify,of,htransactioni) htransactionihgroup actionihactihROOTi
(close,at,hdefinite quantityi) hDEFINITE QUANTITYihmeasureihabstractionihrooti
(meet,with,hofficiali) hofficialihadjudicatorihpersonihlife formihCAUSAL AGENTihentityihrooti
Table 4: Complete test set {3097 test cases
Generalisation technique % correct
Similarity-class 80:3
Select root of sub-hierarchy 77:9
Always select hrooti 79:0
Abe (1998) who adopt a similar approach us-
ing WordNet, but with a dierent training and
test set. Li and Abe improved on the Hin-
dle and Rooth technique by 1:5%, which is in
line with our results. As an evaluation of the
similarity-class technique, the result is incon-
clusive. The reason for this is that when the
technique was being used to estimate p(vjcv;pr)
and p(n1jcn1;pr), in many cases the root of the
hierarchy was being chosen as the appropriate
level of generalisation, due to a sparsely popu-
lated WordNet in that instance. Recall that this
is largely due to the fact that we are attempt-
ing to populate WordNet for combinations of
predicates and prepositions. In such cases the
similarity-class technique is not helping because
there is very little or no information about n2.8
8
In an eort to obtain more data we applied the ex-
traction heuristic of Ratnaparkhi (1998) to Wall Street
Journal text, which increased the number of training
triples by a factor of 10. This only achieved comparable
results, however, presumably because the high volume
of noise in the data outweighs the benet of the increase
in data size. Ratnaparkhi reports only 69% accuracy for
Table 5: hrooti being selected for both attach-
ment points { 113 test cases
Generalisation technique % correct
Similarity-class 90:3
Select root of sub-hierarchy 81:4
Always select hrooti 79:6
Table 6: hrooti being selected for at most one
of the attachment points { 1032 test cases
Generalisation technique % correct
Similarity-class 88:1
Select root of sub-hierarchy 85:5
Always select hrooti 85:5
In order to evaluate the similarity-class tech-
nique further, we took those test cases for which
the root was not being selected when estimating
both p(vjcv;pr) and p(n1jcn1;pr). This applied
to 113 cases. The results are given in Table 5.
We also took those test cases for which the root
was being selected when estimating at most one
of p(vjcv;pr) and p(n1jcn1;pr). This applied to
1032 test cases. The results are shown in Ta-
ble 6.
the extraction heuristic when applied to the Penn Tree-
bank (excluding cases where the preposition is of).
6 Conclusions
We have shown that when instances of Word-
Net are well populated with examples of
n2, the method described here for solving
PP-attachment ambiguities is highly accurate.
When WordNet is sparsely populated, the
method automatically resorts to comparing just
the preposition and each of the potential attach-
ment sites, as the similarity-class technique will
select hrooti as the appropriate level of general-
isation for n2 in such cases. We have also shown
the similarity-class technique to be superior to
using a xed level of generalisation in WordNet.
Further work will look at how to integrate
probabilities such as p(cjv;r) into a model of
dependency structure, similar to that of Collins
(1996) and Collins (1997), which can be used
for parse selection. However, knowledge of se-
lectional preferences cannot by itself solve the
problem of structural disambiguation, and this
further work will also look at using additional
knowledge, such as subcategorisation informa-
tion.
References
Eric Brill and Philip Resnik. 1994. A rule-based
approach to prepositional phrase attachment
disambiguation. In Proceedings of the f-
teenth International Conference on Compu-
tational Linguistics.
Eugene Charniak. 1993. Statistical Language
Learning. The MIT Press.
Stephen Clark and David Weir. 1999. An it-
erative approach to estimating frequencies
over a semantic hierarchy. In Proceedings of
the Joint SIGDAT Conference on Empirical
Methods in Natural Language Processing and
Very Large Corpora, pages 258{265.
Michael Collins. 1995. Prepositional phrase
attachment through a backed-o model. In
Proceedings of the Third Workshop on Very
Large Corpora, pages 27{38, Cambridge,
Massachusetts.
Michael Collins. 1996. A new statistical parser
based on bigram lexical dependencies. In
Proceedings of the 34th Annual Meeting of the
ACL, pages 184{191.
Michael Collins. 1997. Three generative, lexi-
calised models for statistical parsing. In Pro-
ceedings of the 35th Annual Meeting of the
Association for Computational Linguistics,
pages 16{23.
Ted Dunning. 1993. Accurate methods for the
statistics of surprise and coincidence. Com-
putational Linguistics, 19(1):61{74.
Christiane Fellbaum, editor. 1998. WordNet
An Electronic Lexical Database. The MIT
Press.
Donald Hindle and Mats Rooth. 1993. Struc-
tural ambiguity and lexical relations. Com-
putational Linguistics, 19(1):103{120.
David Howell. 1997. Statistical Methods for
Psychology: 4th ed. Duxbury Press.
Hang Li and Naoki Abe. 1998. Generaliz-
ing case frames using a thesaurus and the
MDL principle. Computational Linguistics,
24(2):217{244.
Adwait Ratnaparkhi, Je Reynar, and Salim
Roukos. 1994. A maximum entropy model
for prepositional phrase attachment. In Pro-
ceedings of the ARPA Human Language Tech-
nology Workshop, pages 250{255.
Adwait Ratnaparkhi. 1998. Unsupervised sta-
tistical models for prepositional phrase at-
tachment. In Proceedings of the Seventeenth
International Conference on Computational
Linguistics, Montreal, Canada, Aug.
Philip Resnik. 1993. Selection and Informa-
tion: A Class-Based Approach to Lexical Re-
lationships. Ph.D. thesis, University of Penn-
sylvania.
Francesc Ribas. 1995. On learning more appro-
priate selectional restrictions. In Proceedings
of the Seventh Conference of the European
Chapter of the Association for Computational
Linguistics, Dublin, Ireland.
Jiri Stetina and Makoto Nagao. 1997. Corpus
based PP attachment ambiguity resolution
with a semantic dictionary. In Proceedings of
the Fifth Workshop on Very Large Corpora,
pages 66{80, Beijing and Hong Kong.
David Yarowsky. 1992. Word-sense disam-
biguation using statistical models of Roget's
categories trained on large corpora. In Pro-
ceedings of COLING-92, pages 454{460.
Jakub Zavrel and Walter Daelemans. 1997.
Memory-based learning: Using similarity for
smoothing. In Proceedings of ACL/EACL-
97, Madrid, Spain.
