<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<figure confidence="0.25629675">
b&amp;apos;Coling 2010: Poster Volume, pages 13731381,
Beijing, August 2010
Syntax-Driven Machine Translation as a Model of ESL
Revision
</figure>
<author confidence="0.804709">
Huichao Xue and Rebecca Hwa
</author>
<affiliation confidence="0.994427">
Department of Computer Science
University of Pittsburgh
</affiliation>
<email confidence="0.996381">
{hux10,hwa}@cs.pitt.edu
</email>
<sectionHeader confidence="0.990753" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.991114230769231">
In this work, we model the writing re-
vision process of English as a Second
Language (ESL) students with syntax-
driven machine translation methods.
We compare two approaches: tree-to-
string transformations (Yamada and
Knight, 2001) and tree-to-tree trans-
formations (Smith and Eisner, 2006).
Results suggest that while the tree-to-
tree model provides a greater cover-
age, the tree-to-string approach offers
a more plausible model of ESL learn-
ers revision writing process.
</bodyText>
<sectionHeader confidence="0.998117" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9968526875">
When learning a second language, students
make mistakes along the way. While some
mistakes are idiosyncratic and individual,
many are systematic and common to people
who share the same primary language. There
has been extensive research on grammar error
detection. Most previous efforts focus on iden-
tifying specific types of problems commonly
encountered by English as a Second Language
(ESL) learners. Some examples include the
proper usage of determiners (Yi et al., 2008;
Gamon et al., 2008), prepositions (Chodorow
et al., 2007; Gamon et al., 2008; Hermet et al.,
2008), and mass versus count nouns (Nagata
et al., 2006). However, previous work suggests
that grammar error correction is considerably
more challenging than detection (Han et al.,
2010). Furthermore, an ESL learners writing
may contain multiple interacting errors that
are difficult to detect and correct in isolation.
A promising research direction is to tackle
automatic grammar error correction as a ma-
chine translation (MT) problem. The dis-
fluent sentences produced by an ESL learner
can be seen as the input source language,
and the corrected revision is the result of the
translation. Brockett et al. (2006) showed
that phrase-based statistical MT can help to
correct mistakes made on mass nouns. To
our knowledge, phrase-based MT techniques
have not been applied for rewriting entire sen-
tences. One major challenge is the lack of ap-
propriate training data such as a sizable par-
allel corpus. Another concern is that phrase-
based MT may not be similar enough to the
problem of correcting ESL learner mistakes.
While MT rewrites an entire source sentence
into the target language, not every word writ-
ten by an ESL learner needs to be modified.
Another alternative that may afford a more
general model of ESL error corrections is to
consider syntax-driven MT approaches. We
argue that syntax-based approaches can over-
come the expected challenges in applying MT
to this domain. First, it can be less data-
intensive because the mapping is formed at a
structural level rather than the surface word
level. While it does require a robust parser,
a syntax-driven MT model may not need to
train on a very large parallel corpus. Second,
syntactic transformations provide an intuitive
description of how second language learners
revise their writings: they are transforming
structures in their primary language to those
in the new language.
In this paper, we conduct a first inquiry into
the applicability of syntax-driven MT meth-
ods to automatic grammar error correction.
In particular, we investigate whether a syntax-
driven model can capture ESL students pro-
cess of writing revisions. We compare two ap-
proaches: a tree-to-string mapping proposed
by Yamada &amp; Knight (2001) and a tree-to-
tree mapping using the Quasi-Synchronous
</bodyText>
<page confidence="0.88033">
1373
</page>
<bodyText confidence="0.982264272727273">
\x0cGrammar (QG) formalism (Smith and Eisner,
2006). We train both models on a parallel cor-
pus consisting of multiple drafts of essays by
ESL students. The approaches are evaluated
on how well they model the revision pairs in an
unseen test corpus. Experimental results sug-
gest that 1) the QG model has more flexibility
and is able to describe more types of transfor-
mations; but 2) the YK model is better at cap-
turing the incremental improvements in the
ESL learners revision writing process.
</bodyText>
<sectionHeader confidence="0.982314" genericHeader="method">
2 Problem Description
</sectionHeader>
<bodyText confidence="0.999739266666667">
This paper explores the research question: can
ESL learners process of revising their writ-
ings be described by a computational model?
A successful model of the revision process has
several potential applications. In addition to
automatic grammar error detection and cor-
rection, it may also be useful as an auto-
matic metric in an intelligent tutoring system
to evaluate how well the students are learning
to make their own revisions.
Revising an ESL students writing bears
some resemblance to translating. The stu-
dents first draft is likely to contain disfluent
expressions that arose from translation diver-
gences between English and the students pri-
mary language. In the revised draft, the diver-
gences should be resolved so that the text be-
comes fluent English. We investigate to what
extent are formalisms used for machine trans-
lation applicable to model writing revision.
We hypothesize that ESL students typically
modify sentences to make them sound more
fluent rather than to drastically change the
meanings of what they are trying to convey.
Thus, our work focuses on syntax-driven MT
models.
One challenge of applying MT methods to
model grammar error correction is the lack of
appropriate training data. The equivalence
to the bilingual parallel corpus used for de-
veloping MT systems would be a corpus in
which each student sentence is paired with a
fluent version re-written by an instructor. Un-
like bilingual text, however, there is not much
data of this type in practice because there
are typically too many students for the teach-
ers to provide detailed manual inspection and
correction at a large scale. More commonly,
students are asked to revise their previously
written essays as they learn more about the
English language. Here is an example of a
student sentence from a first-draft essay:
The problem here is that they come
to the US like illegal.
In a later draft, it has been revised into:
The problem here is that they come
to the US illegally.
Although the students are not able to cre-
ate gold standard revisions due to their still
imperfect understanding of English, a corpus
that pairs the students earlier and later drafts
still offers us an opportunity to model how
ESL speakers make mistakes.
More formally, the corpus C consists of a
set of sentence pairs (O, R), where O repre-
sents the students original draft and R rep-
resents the revised draft. Note that while R
is assumed to be an improvement upon O,
its quality may fall short of the gold stan-
dard revision, G. To train the syntax-driven
MT models, we optimize the joint probabil-
ity of observing the sentence pair, Pr(O, R),
through some form of mapping between their
parse trees, O and R.
An added wrinkle to our problem is that it
might not always be possible to assign a sen-
sible syntactic structure to an ungrammati-
cal sentence. It is well-known that an English
parser trained on the Penn Treebank is bad
at handling disfluent sentences (Charniak et
al., 2003; Foster et al., 2008). In our domain,
since O (and perhaps also R) might be disflu-
ent, an important question that a translation
model must address is: how should the map-
ping between the trees O and R be handled?
</bodyText>
<sectionHeader confidence="0.7180115" genericHeader="method">
3 Syntax-Driven Models for Essay
Revisions
</sectionHeader>
<bodyText confidence="0.991217">
There is extensive literature on syntax-driven
approaches to MT (cf. a recent survey by
</bodyText>
<page confidence="0.960032">
1374
</page>
<bodyText confidence="0.997458">
\x0cLopez (2008)); we focus on two particular for-
malisms that reflects different perspectives on
the role of syntax. Our goal is to assess which
formalism is a better fit with the domain of
essay revision modeling, in which the data
largely consist of imperfect sentences that may
not support a plausible syntactic interpreta-
tion.
</bodyText>
<subsectionHeader confidence="0.960652">
3.1 Tree-to-String Model
</subsectionHeader>
<bodyText confidence="0.985568708333333">
The Yamada &amp; Knight (henceforth, YK) tree-
to-string model is an instance of noisy channel
translation systems, which assumes that the
observed source sentence is the result of trans-
formation performed on the parse tree of the
intended target sentence due to a noisy com-
munication channel. Given a parallel corpus,
and a parser for the the target side, the pa-
rameters of this model can be estimated using
EM(Expectation Maximization). The trained
models job is to recover the target sentence
(and tree) through decoding.
While the noisy channel generation story
may sound somewhat counter-intuitive for
translation, it gives a plausible account of ESL
learners writing process. The student really
wants to convey a fluent English sentence with
a well-formed structure, but due to an im-
perfect understanding of the language, writes
down an ungrammatical sentence, O, as a first
draft. The student serves as the noisy channel.
The YK model describes this as a stochastic
process that performs three operations on G,
the parse of the intended sentence, G:
</bodyText>
<listItem confidence="0.817192285714286">
1. Each node in G may have its children
reordered with some probability.
2. Each node in G may have a child node
inserted to its left or right with some
probability.
3. Each leaf node (i.e., surface word) in G
is replaced by some (possibly empty)
</listItem>
<bodyText confidence="0.9947938">
string according to its lexical translation
distribution.
The resulting sentence, O, is the concatena-
tion of the leaf nodes of the transformed G.
Common mistakes made by ESL learners,
such as misuses of determiners and preposi-
tions, word choice errors, and incorrect con-
stituency orderings, can be modeled by a com-
bination of the insert, replace, and reorder
operators. The YK model allows us to per-
form transformations on a higher syntactic
level. Another potential benefit is that the
model does not attempt to assign syntactic
interpretations over the source sentences (i.e.,
the less fluent original draft).
</bodyText>
<subsectionHeader confidence="0.867976">
3.2 Tree-to-Tree Model
</subsectionHeader>
<bodyText confidence="0.997476866666667">
The Quasi-Synchronous Grammar formalism
(Smith and Eisner, 2006) is a generative model
that aims to produce the most likely target
tree for a given source tree. It differs from the
more strict synchronous grammar formalisms
(Wu, 1995; Melamed et al., 2004) because it
does not try to perform simultaneous pars-
ing on parallel grammars; instead, the model
learns an augmented target-language gram-
mar whose rules make soft alignments with
a given source tree.
QG has been applied to some NLP tasks
other than MT, including answer selection for
question-answering (Wang et al., 2007), para-
phrase identification (Das and Smith, 2009),
and parser adaptation and projection (Smith
and Eisner, 2009). In this work we use
an instantiation of QG that largely follows
the model described by Smith and Eisner
(2006). The model is trained on a parallel
corpus in which both the first-draft and re-
vised sentences have been parsed. Using EM
to estimate its parameters, it learns an aug-
mented target PCFG grammar1 whose pro-
duction rules form associations with the given
source trees.
Consider the scenario in Figure 1. Given a
source tree O, the trained model generates a
target tree by expanding the production rules
in the augmented target PCFG. To apply a
</bodyText>
<page confidence="0.885345">
1
</page>
<bodyText confidence="0.96113975">
For expository purposes, we illustrate the model
using a PCFG production rule. In the experiment, a
statistical English dependency parser (Klein and Man-
ning, 2004) was used.
</bodyText>
<page confidence="0.95748">
1375
</page>
<figureCaption confidence="0.585019">
\x0cFigure 1: An example of QGs soft alignments
</figureCaption>
<bodyText confidence="0.925408928571429">
between a given source tree and a possible tar-
get rule expansion.
target-side production rule such as
A BC,
the model considers which source tree nodes
might be associated with each target-side non-
terminals:
(, A) (, B)(, C)
where , , are nodes in O. Thus, as-
suming that the target symbol A has already
been aligned to source node from an ear-
lier derivation step, the likelihood of expand-
ing (, A) with the above production rule de-
pends on three factors:
</bodyText>
<listItem confidence="0.994938625">
1. the likelihood of the monolingual tar-
get rule, Pr(A BC)
2. the likelihood of alignments between B
and as well as C and .
3. the likelihood that the source nodes form
some expected configuration (i.e., be-
tween and as well as between and
). In this work, we distinguish between
</listItem>
<bodyText confidence="0.919589">
two configuration types: parent-child and
other. This restriction doesnt reduce the
explanatory power of the resulting QG
model, though it may not be as fine-tuned
as some models in (Smith and Eisner,
2006).
Under QG, the ESL students first drafts
are seen as text in a different language that
has its own syntactic constructions. QG ex-
plains the grammar rules that govern the re-
vised text in terms of how different compo-
nents map to structures in the original draft.
It makes explicit the representation of diver-
gences between the students original mental
model and the expected structure.
</bodyText>
<subsectionHeader confidence="0.999445">
3.3 Method of Model Comparison
</subsectionHeader>
<bodyText confidence="0.969944421052632">
Cross entropy can be used as a metric that
measures the distance between the learned
probabilistic model and the real data. It can
be interpreted as measuring the amount of in-
formation that is needed in addition to the
model to accurately recover the observed data.
In language modeling, cross entropy is widely
used in showing a given models prediction
power.
To determine how well the two syntax-
driven MT models capture the ESL student
revision generation process, we measure the
cross entropy of each trained model on an un-
seen test corpus. This quantity measures how
surprised a model is about relating an initial
sentence, O, to its corresponding revision, R.
Specifically, the cross entropy for some model
M on a test corpus C of original and revised
sentence pairs (O, R) is:
</bodyText>
<equation confidence="0.525656714285714">
1
|C|
X
(O,R)C
log Pr
M
(O, R)
</equation>
<bodyText confidence="0.978128222222222">
Because neither model computes the joint
probability of the sentence pair, we need to
make additional computations so that the
models can be compared directly.
The YK model computes the likelihood
of the first-draft sentence O given an as-
sumed gold parse R of the revised sentence:
PrY K(O  |R). To determine the joint proba-
bility, we would need to compute:
</bodyText>
<equation confidence="0.998716214285714">
Pr
Y K
(O, R) =
X
RR
Pr
Y K
(O, R)
=
X
RR
Pr
Y K
(O  |R) Pr(R)
</equation>
<bodyText confidence="0.9918922">
where R represents the set of possible parse
trees for sentence R. Practically, perform-
ing tree-to-string mapping over the entire set
of trees in R is computationally intractable.
Moreover, the motivation behind the YK
</bodyText>
<page confidence="0.918267">
1376
</page>
<table confidence="0.9875062">
\x0cmean stdev
percentage of O = R 54.11% N/A
Os length 12.95 4.87
Rs length 12.74 4.20
edit distance 1.88 3.58
</table>
<tableCaption confidence="0.995808">
Table 1: This table summarizes some statis-
</tableCaption>
<bodyText confidence="0.723724666666667">
tics of the dataset.
model is to trust the given R. Thus, we made
a Viterbi approximation:
</bodyText>
<equation confidence="0.970575571428571">
Pr
Y K
(O, R) =
X
RR
Pr
Y K
(O  |R) Pr(R)
Pr
Y K
(O |
R) Pr(
R)
where Pr(
</equation>
<bodyText confidence="0.99255025">
R) is the probability of the single
best parse tree according to a standard En-
glish parser.
Similarly, to compute the joint sentence pair
probability under the QG model would require
summing over both sets of trees because the
model computes PrQG(R  |O). Here, we
make the Viterbi approximation on both trees.
</bodyText>
<equation confidence="0.990627730769231">
Pr
QG
(O, R) =
X
RR
X
OO
Pr
QG
(O, R)
=
X
RR
X
OO
Pr
QG
(R  |O) Pr(O)
Pr
QG
(
R |
O) Pr(
O)
where
O and
</equation>
<bodyText confidence="0.927596333333333">
R are the best parses for sen-
tences O and R according to the underlying
English dependency parser, respectively.
</bodyText>
<sectionHeader confidence="0.997176" genericHeader="method">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.96782">
4.1 Data
</subsectionHeader>
<bodyText confidence="0.954337571428571">
Our experiments are conducted using a collec-
tion of ESL students writing samples2. These
are short essays of approximately 30 sentences
on topics such as a letter to your parents.
The students are asked to revise their essays
at least once. From the dataset, we extracted
358 article pairs.
</bodyText>
<page confidence="0.912915">
2
</page>
<bodyText confidence="0.967860608695652">
The dataset is made available by the Pittsburgh
Science of Learning Center English as a Second Lan-
guage Course Committee, supported by NSF Award
SBE-0354420.
Typically, the changes between the drafts
are incremental. Approximately half of the
sentences are not changed at all. These sen-
tences are considered useful because this phe-
nomenon strongly implies that the original
version is good enough to the best of the au-
thors knowledge. In a few rare cases, stu-
dents may write an entirely different essay.
We applied TF-IDF to automatically align the
sentences between essay drafts. Any sentence
pair with a cosine similarity score of less than
0.3 is filtered. This resulted in a parallel cor-
pus of 7580 sentence pairs.
Because both models are computational in-
tensive, we further restricted our experiments
to sentence pairs for which the revised sen-
tence has no more than 20 words. This re-
duces our corpus to 4666 sentence pairs. Some
statistics of the sentence pairs are shown in
</bodyText>
<tableCaption confidence="0.977795">
Table 1.
</tableCaption>
<subsectionHeader confidence="0.987419">
4.2 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.98244762962963">
We randomly split the resulting dataset into
a training corpus of 4566 sentence pairs and a
test corpus of 100 pairs.
The training of both models involve an EM
algorithm. We initialize the model parameters
with some reasonable values. Then, in each it-
eration of training, the model parameters are
re-estimated by collecting the expected counts
across possible alignments between each sen-
tence pair in the training corpus. In out ex-
periments, both models had two iterations of
training. Below, we highlight our initializa-
tion procedure for each model.
In the YK model, the initial reordering
probability distribution is set to prefer no
change 50% of the time. The remaining prob-
ability mass is distributed evenly over all of
the other permutations. For the insertion
operation, for each node, the YK model first
chooses whether to insert a new string to its
left, to its right, or not at all, conditioned on
the nodes label and its parents label. These
distributions are initialized uniformly (1
3). If
a new string should be inserted, the model
then makes that choice with some probability.
The insertion probability of each string in the
</bodyText>
<page confidence="0.936982">
1377
</page>
<bodyText confidence="0.9862162">
\x0cdictionary is assigned evenly with 1
N , where
N is the number of words in the dictionary.
Finally, the replace probability distribution
is initialized uniformly with the same value
</bodyText>
<equation confidence="0.5275995">
( 1
N+1) across all words in the dictionary, in-
</equation>
<bodyText confidence="0.99763175">
cluding the empty string.
For the QG model, the initial parameters
are determined as follows: For the monolin-
gual target parsing model parameters,
we first parse the target side of the corpus
(i.e., the revised sentences) with the Stanford
parser; we then use the maximum likelihood
estimates based on these parse trees to ini-
tialize the parameters of the target parser,
Dependency Model with Valence (DMV). We
uniformly initialized the configuration pa-
rameters; the parent-child configuration and
other configuration each has 0.5 probability.
For the alignment parameters, we ran the
GIZA++ implementation of the IBM word
alignment model (Och and Ney, 2003) on the
sentence pairs, and used the resulting transla-
tion table as our initial estimation. There may
be better initialization setups, but the differ-
ence between those setups will become small
after a few rounds of EM.
Once trained, the two models compute the
joint probability of every sentence pair in the
test corpus as described in Section 3.3.
</bodyText>
<subsectionHeader confidence="0.997818">
4.3 Experiment I
</subsectionHeader>
<bodyText confidence="0.999605873015873">
To evaluate how well the models describe the
ESL revision domain, we want to see which
model is less surprised by the test data. We
expected that the better model should be able
to transform more sentence pair in the test
corpus; we also expect that the better model
should have a lower cross entropy with respect
to the test corpus.
Applying both YK and QG to the test cor-
pus, we find that neither model is able to
transform all the test sentence pairs. Of the
two, QG had the better coverage; it success-
fully modeled 59 pairs out of 100 (we denote
this subset as DQG). In contrast, YK modeled
36 pairs (this subset is denoted as DY K).
To determine whether there were some
characteristics of the data that made one
model better at performing transformations
for certain sentence pairs, we compare corpus
statistics for different test subsets. Based on
the results summarized in Table 2, we make a
few observations.
First, the sentence pairs that neither model
could transform seem, as a whole, more diffi-
cult. Their average lengths are longer, and the
average per word Levenshtein edit distance is
bigger. The differences between Neither and
the other subsets are statistically significant
with 90% confidence. For the length differ-
ence, we applied standard two-sample t-test.
For the edit distance difference, we applied hy-
pothesis testing with the null-hypothesis that
longer sentence pairs are as likely to be cov-
ered by our model as shorter ones.
Second, both models sometimes have trou-
ble with sentence pairs that require no change.
This may be due to out-of-vocabulary words
in the test corpus. A more aggressive smooth-
ing strategy could improve the coverage for
both models.
Third, comparing the subset of sentence
pairs that only QG could transform (DQG
DY K) against the subset of sentences that
both models could transform (DQG DY K),
the former has slightly higher average edit dis-
tance and length, but the difference is not
statistically significant. Although QG could
transform more sentence pairs, the cross en-
tropy of DQG DY K is higher than QGs es-
timate for the DQG DY K subset. QGs soft
alignment property allows it to model more
complex transformations with greater flexibil-
ity.
Finally, while the YK model has a more lim-
ited coverage, it models those transformations
with a greater certainty. For the common sub-
set of sentence pairs that both models could
transform, YK has a much lower cross entropy
than QG. Table 3 further breaks down the
common subset. It is not surprising that both
models have low entropy for identical sentence
pairs. For modeling sentence pairs that con-
tain revisions, YK is more efficient than QG.
</bodyText>
<page confidence="0.967">
1378
</page>
<table confidence="0.973707875">
\x0cNeither DQG DY K DQG DY K DY K DQG
number of instances 38 33 26 3
average edit distance 2.42 1.88 2.08 1
% of identical pairs 53% 48% 58% 67%
average O length 14.63 12.36 12.58 6.67
average R length 13.87 12.06 12.62 6.67
QG cross entropy N/A 127.95 138.9 N/A
YK cross entropy N/A 78.76 N/A 43.84
</table>
<tableCaption confidence="0.816916">
Table 2: A comparison of the two models based on their coverage of the test corpus. Some
relevant statistics on the sentence subsets are also summarized in the table.
</tableCaption>
<table confidence="0.947939">
YK QG
overall entropy 78.76 127.95
on identical pairs 52.59 85.40
on non-identical pairs 103.99 168.00
</table>
<tableCaption confidence="0.829422">
Table 3: A further comparison of the two mod-
els on DQG DY K, the sentence pairs in the
test corpus that both could transform.
</tableCaption>
<subsectionHeader confidence="0.989217">
4.4 Experiment II
</subsectionHeader>
<bodyText confidence="0.999828804878049">
The results of the previous experiment raises
the possibility that QG might have a greater
coverage because it is too flexible. However,
an appropriate model should not only assign
large probability mass to positive examples,
but it should also have a low chance of choos-
ing negative examples. In this next experi-
ment, we construct a negative test corpus
to see how it affects the models.
To construct a negative scenario, we still
use the same test corpus as before, but we re-
verse the sentence pairs. That is, we use the
revised sentences as originals and the origi-
nal sentences as revisions. We would expect
a good model to have a raised cross entropy
values along with a drop in coverage on the
new dataset because the revisions should be
more disfluent than the original sentences.
Table 4 summarizes the results. We ob-
serve that the number of instances that can
be transformed has dropped for both models:
from 59 to 49 pairs for QG, and from 36 to
20 pairs for YK; also, the proportion of iden-
tical instances in each set has raised. This
means that both models are more surprised
by the reverse test corpus, suggesting that
both models have, to some extent, succeeded
in modeling the ESL revision domain. How-
ever, QG still allows for many more transfor-
mations. Moreover, 16 out of the 49 instances
are non-identical pairs. In contrast, YK mod-
eled only 1 non-identical sentence pair. The
results from these two experiments suggest
that YK is more suited for modeling the ESL
revision domain than QG. One possible expla-
nation is that QG allows more flexibility and
would require more training. Another possi-
ble explanation is that because YK assumes
well-formed syntax structure for only the tar-
get side, the philosophy behind its design is a
better fit with the ESL revision problem.
</bodyText>
<sectionHeader confidence="0.999702" genericHeader="method">
5 Related Work
</sectionHeader>
<bodyText confidence="0.997620315789474">
There are many research directions in the field
of ESL error correction. A great deal of the
work focuses on the lexical or shallow syn-
tactic level. Typically, local features such
as word identity and POS tagging informa-
tion are combined to deal with some specific
kind of error. Among them, (Burstein et al.,
2004) developed a tool called Critique that
detects collocation errors and word choice er-
rors. Nagata et al. (2006) uses a rule-based
approach in distinguishing mass and count
nouns. Knight and Chander (1994) and Han
et al. (2006) both addressed the misuse of ar-
ticles. Chodorow et al. (2007), Gamon et al.
(2008), Hermet et al. (2008) proposed several
techniques in detecting and correcting propo-
sition errors. In detecting errors and giving
suggestions, Liu et al. (2000), Gamon et al.
(2008) and Hermet et al. (2008) make use of
</bodyText>
<page confidence="0.876485">
1379
</page>
<table confidence="0.8550235">
\x0cNeither DQG DY K DQG DY K DY K DQG
number of instances 50 19 30 1
average edit distance 2.88 0.05 2.17 1
percentage of identical pairs 0.40 0.95 0.5 0
average O length 14.18 9.00 12.53 17
average R length 14.98 9.05 12.47 16
QG cross entropy N/A 81.85 139.36 N/A
YK cross entropy N/A 51.2 N/A 103.75
</table>
<tableCaption confidence="0.99793">
Table 4: This table compares the two models on a trick test corpus in which the earlier and
</tableCaption>
<bodyText confidence="0.991338470588235">
later drafts are reversed. If a model is trained to prefer more fluent English sentences are the
revision, it should be perplexed on this corpus.
information retrieval techniques. Chodorow
et al. (2007) instead treat it as a classification
problem and employed a maximum entropy
classifier. Similar to our approach, Brockett
et al. (2006) view error correction as a Ma-
chine Translation problem. But their transla-
tion system is built on phrase level, with the
purpose of correcting local errors such as mass
noun errors.
The problem of error correction at a syn-
tactic level is less explored. Lee and Seneff
(2008) examined the task of correcting verb
form misuse by applying tree template match-
ing rules. The parse tree transformation rules
are learned from synthesized training data.
</bodyText>
<sectionHeader confidence="0.997868" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.998888190476191">
This paper investigates the suitability of
syntax-driven MT approaches for modeling
the revision writing process of ESL learn-
ers. We have considered both the Yamada &amp;
Knight tree-to-string model, which only con-
siders syntactic information from the typically
more fluent revised text, as well as Quasi-
Synchronous Grammar, a tree-to-tree model
that attempts to learn syntactic transforma-
tion patterns between the students original
and revised texts. Our results suggests that
while QG offers a greater degree of freedom,
thus allowing for a better coverage of the
transformations, YK has a lower entropy on
the test corpus. Moreover, when presented
with an alternative trick corpus in which the
revision is in fact the earlier draft, YK was
more perplexed than QG. These results sug-
gest that the YK model may be a promising
approach for automatic grammar error correc-
tion.
</bodyText>
<sectionHeader confidence="0.967147" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99596775">
This work has been supported by NSF Grant
IIS-0745914. We thank Joel Tetreault and the
anonymous reviewers for their helpful com-
ments and suggestions.
</bodyText>
<sectionHeader confidence="0.987006" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.980154894230769">
Brockett, Chris, William B. Dolan, and Michael
Gamon. 2006. Correcting esl errors using
phrasal smt techniques. In Proceedings of
COLING-ACL 2006, Sydney, Australia, July.
Burstein, Jill, Martin Chodorow, and Claudia Lea-
cock. 2004. Automated essay evaluation: The
criterion online writing service. AI Magazine,
25(3).
Charniak, Eugene, Kevin Knight, and Kenji Ya-
mada. 2003. Syntax-based language models for
machine translation. In Proc. MT Summit IX,
New Orleans, Louisiana, USA.
Chodorow, Martin, Joel Tetreault, and Na-Rae
Han. 2007. Detection of grammatical errors
involving prepositions. In Proceedings of the
4th ACL-SIGSEM Workshop on Prepositions,
Prague, Czech Republic.
Das, Dipanjan and Noah A. Smith. 2009.
Paraphrase identification as probabilistic quasi-
synchronous recognition. In Proceedings of
ACL-IJCNLP 2009, Suntec, Singapore, August.
Foster, Jennifer, Joachim Wagner, and Josef van
Genabith. 2008. Adapting a WSJ-trained
1380
\x0cparser to grammatically noisy text. In Proceed-
ings of the 46th ACL on Human Language Tech-
nologies: Short Papers, Columbus, Ohio.
Gamon, Michael, Jianfeng Gao, Chris Brock-
ett, Alexandre Klementiev, William B. Dolan,
Dmitriy Belenko, and Lucy Vanderwende. 2008.
Using contextual speller techniques and lan-
guage modeling for ESL error correction. In
Proceedings of IJCNLP, Hyderabad, India.
Han, Na-Rae, Martin Chodorow, and Claudia Lea-
cock. 2006. Detecting errors in English article
usage by non-native speakers. Natural Language
Engineering, 12(02).
Han, Na-Rae, Joel Tetreault, Soo-Hwa Lee, and
Jin-Young Han. 2010. Using an error-annotated
learner corpus to develop and ESL/EFL er-
ror correction system. In Proceedings of LREC
2010, Valletta, Malta.
Hermet, Matthieu, Alain Desilets, and Stan Sz-
pakowicz. 2008. Using the web as a linguis-
tic resource to automatically correct Lexico-
Syntactic errors. In Proceedings of the LREC,
volume 8.
Klein, Dan and Christopher Manning. 2004.
Corpus-based induction of syntactic structure:
Models of dependency and constituency. In Pro-
ceedings of ACL 2004, Barcelona, Spain.
Knight, Kevin and Ishwar Chander. 1994. Auto-
mated postediting of documents. In Proceedings
of AAAI-94, Seattle, Washington.
Lee, John and Stephanie Seneff. 2008. Correcting
misuse of verb forms. Proceedings of the 46th
ACL, Columbus.
Liu, Ting, Ming Zhou, Jianfeng Gao, Endong
Xun, and Changning Huang. 2000. PENS: a
machine-aided english writing system for chi-
nese users. In Proceedings of the 38th ACL,
Hong Kong, China.
Lopez, Adam. 2008. Statistical machine transla-
tion. ACM Computing Surveys, 40(3), Septem-
ber.
Melamed, I. Dan, Giorgio Satta, and Ben Welling-
ton. 2004. Generalized multitext grammars. In
Proceedings of the 42nd ACL, Barcelona, Spain.
Nagata, Ryo, Atsuo Kawai, Koichiro Morihiro,
and Naoki Isu. 2006. A feedback-augmented
method for detecting errors in the writing of
learners of english. In Proceedings of COLING-
ACL 2006, Sydney, Australia, July.
Och, Franz Josef and Hermann Ney. 2003. A sys-
tematic comparison of various statistical align-
ment models. Computational Linguistics, 29(1).
Smith, David A. and Jason Eisner. 2006. Quasi-
synchronous grammars: Alignment by soft pro-
jection of syntactic dependencies. In Proceed-
ings on the Workshop on Statistical Machine
Translation, New York City, June.
Smith, David A. and Jason Eisner. 2009.
Parser adaptation and projection with quasi-
synchronous grammar features. In Proceedings
of EMNLP 2009, Singapore, August.
Wang, Mengqiu, Noah A. Smith, and Teruko Mi-
tamura. 2007. What is the Jeopardy model?
a quasi-synchronous grammar for QA. In
Proceedings of EMNLP-CoNLL 2007, Prague,
Czech Republic, June.
Wu, Dekai. 1995. Stochastic inversion transduc-
tion grammars, with application to segmenta-
tion, bracketing, and alignment of parallel cor-
pora. In Proc. of the 14th Intl. Joint Conf. on
Artificial Intelligence, Montreal, Aug.
Yamada, Kenji and Kevin Knight. 2001. A
syntax-based statistical translation model. In
Proceedings of the 39th ACL, Toulouse, France.
Yi, Xing, Jianfeng Gao, and William B Dolan.
2008. A web-based english proofing system for
english as a second language users. In Proceed-
ings of IJCNLP, Hyderabad, India.
1381
\x0c&amp;apos;
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.729928">
<note confidence="0.8716585">b&amp;apos;Coling 2010: Poster Volume, pages 13731381, Beijing, August 2010</note>
<title confidence="0.9831595">Syntax-Driven Machine Translation as a Model of ESL Revision</title>
<author confidence="0.998524">Huichao Xue</author>
<author confidence="0.998524">Rebecca Hwa</author>
<affiliation confidence="0.999979">Department of Computer Science University of Pittsburgh</affiliation>
<email confidence="0.997235">hux10@cs.pitt.edu</email>
<email confidence="0.997235">hwa@cs.pitt.edu</email>
<abstract confidence="0.999104714285714">In this work, we model the writing revision process of English as a Second Language (ESL) students with syntaxdriven machine translation methods. We compare two approaches: tree-tostring transformations (Yamada and Knight, 2001) and tree-to-tree transformations (Smith and Eisner, 2006). Results suggest that while the tree-totree model provides a greater coverage, the tree-to-string approach offers a more plausible model of ESL learners revision writing process.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Chris Brockett</author>
<author>William B Dolan</author>
<author>Michael Gamon</author>
</authors>
<title>Correcting esl errors using phrasal smt techniques.</title>
<date>2006</date>
<booktitle>In Proceedings of COLING-ACL 2006,</booktitle>
<location>Sydney, Australia,</location>
<contexts>
<context position="1909" citStr="Brockett et al. (2006)" startWordPosition="286" endWordPosition="289">et al., 2008), and mass versus count nouns (Nagata et al., 2006). However, previous work suggests that grammar error correction is considerably more challenging than detection (Han et al., 2010). Furthermore, an ESL learners writing may contain multiple interacting errors that are difficult to detect and correct in isolation. A promising research direction is to tackle automatic grammar error correction as a machine translation (MT) problem. The disfluent sentences produced by an ESL learner can be seen as the input source language, and the corrected revision is the result of the translation. Brockett et al. (2006) showed that phrase-based statistical MT can help to correct mistakes made on mass nouns. To our knowledge, phrase-based MT techniques have not been applied for rewriting entire sentences. One major challenge is the lack of appropriate training data such as a sizable parallel corpus. Another concern is that phrasebased MT may not be similar enough to the problem of correcting ESL learner mistakes. While MT rewrites an entire source sentence into the target language, not every word written by an ESL learner needs to be modified. Another alternative that may afford a more general model of ESL er</context>
<context position="25228" citStr="Brockett et al. (2006)" startWordPosition="4279" endWordPosition="4282">centage of identical pairs 0.40 0.95 0.5 0 average O length 14.18 9.00 12.53 17 average R length 14.98 9.05 12.47 16 QG cross entropy N/A 81.85 139.36 N/A YK cross entropy N/A 51.2 N/A 103.75 Table 4: This table compares the two models on a trick test corpus in which the earlier and later drafts are reversed. If a model is trained to prefer more fluent English sentences are the revision, it should be perplexed on this corpus. information retrieval techniques. Chodorow et al. (2007) instead treat it as a classification problem and employed a maximum entropy classifier. Similar to our approach, Brockett et al. (2006) view error correction as a Machine Translation problem. But their translation system is built on phrase level, with the purpose of correcting local errors such as mass noun errors. The problem of error correction at a syntactic level is less explored. Lee and Seneff (2008) examined the task of correcting verb form misuse by applying tree template matching rules. The parse tree transformation rules are learned from synthesized training data. 6 Conclusion This paper investigates the suitability of syntax-driven MT approaches for modeling the revision writing process of ESL learners. We have con</context>
</contexts>
<marker>Brockett, Dolan, Gamon, 2006</marker>
<rawString>Brockett, Chris, William B. Dolan, and Michael Gamon. 2006. Correcting esl errors using phrasal smt techniques. In Proceedings of COLING-ACL 2006, Sydney, Australia, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jill Burstein</author>
<author>Martin Chodorow</author>
<author>Claudia Leacock</author>
</authors>
<title>Automated essay evaluation: The criterion online writing service.</title>
<date>2004</date>
<journal>AI Magazine,</journal>
<volume>25</volume>
<issue>3</issue>
<contexts>
<context position="23962" citStr="Burstein et al., 2004" startWordPosition="4059" endWordPosition="4062">han QG. One possible explanation is that QG allows more flexibility and would require more training. Another possible explanation is that because YK assumes well-formed syntax structure for only the target side, the philosophy behind its design is a better fit with the ESL revision problem. 5 Related Work There are many research directions in the field of ESL error correction. A great deal of the work focuses on the lexical or shallow syntactic level. Typically, local features such as word identity and POS tagging information are combined to deal with some specific kind of error. Among them, (Burstein et al., 2004) developed a tool called Critique that detects collocation errors and word choice errors. Nagata et al. (2006) uses a rule-based approach in distinguishing mass and count nouns. Knight and Chander (1994) and Han et al. (2006) both addressed the misuse of articles. Chodorow et al. (2007), Gamon et al. (2008), Hermet et al. (2008) proposed several techniques in detecting and correcting proposition errors. In detecting errors and giving suggestions, Liu et al. (2000), Gamon et al. (2008) and Hermet et al. (2008) make use of 1379 \x0cNeither DQG DY K DQG DY K DY K DQG number of instances 50 19 30 </context>
</contexts>
<marker>Burstein, Chodorow, Leacock, 2004</marker>
<rawString>Burstein, Jill, Martin Chodorow, and Claudia Leacock. 2004. Automated essay evaluation: The criterion online writing service. AI Magazine, 25(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
<author>Kevin Knight</author>
<author>Kenji Yamada</author>
</authors>
<title>Syntax-based language models for machine translation.</title>
<date>2003</date>
<booktitle>In Proc. MT Summit IX,</booktitle>
<location>New Orleans, Louisiana, USA.</location>
<contexts>
<context position="6980" citStr="Charniak et al., 2003" startWordPosition="1135" endWordPosition="1138">riginal draft and R represents the revised draft. Note that while R is assumed to be an improvement upon O, its quality may fall short of the gold standard revision, G. To train the syntax-driven MT models, we optimize the joint probability of observing the sentence pair, Pr(O, R), through some form of mapping between their parse trees, O and R. An added wrinkle to our problem is that it might not always be possible to assign a sensible syntactic structure to an ungrammatical sentence. It is well-known that an English parser trained on the Penn Treebank is bad at handling disfluent sentences (Charniak et al., 2003; Foster et al., 2008). In our domain, since O (and perhaps also R) might be disfluent, an important question that a translation model must address is: how should the mapping between the trees O and R be handled? 3 Syntax-Driven Models for Essay Revisions There is extensive literature on syntax-driven approaches to MT (cf. a recent survey by 1374 \x0cLopez (2008)); we focus on two particular formalisms that reflects different perspectives on the role of syntax. Our goal is to assess which formalism is a better fit with the domain of essay revision modeling, in which the data largely consist of</context>
</contexts>
<marker>Charniak, Knight, Yamada, 2003</marker>
<rawString>Charniak, Eugene, Kevin Knight, and Kenji Yamada. 2003. Syntax-based language models for machine translation. In Proc. MT Summit IX, New Orleans, Louisiana, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Chodorow</author>
<author>Joel Tetreault</author>
<author>Na-Rae Han</author>
</authors>
<title>Detection of grammatical errors involving prepositions.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th ACL-SIGSEM Workshop on Prepositions,</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="1258" citStr="Chodorow et al., 2007" startWordPosition="183" endWordPosition="186">h offers a more plausible model of ESL learners revision writing process. 1 Introduction When learning a second language, students make mistakes along the way. While some mistakes are idiosyncratic and individual, many are systematic and common to people who share the same primary language. There has been extensive research on grammar error detection. Most previous efforts focus on identifying specific types of problems commonly encountered by English as a Second Language (ESL) learners. Some examples include the proper usage of determiners (Yi et al., 2008; Gamon et al., 2008), prepositions (Chodorow et al., 2007; Gamon et al., 2008; Hermet et al., 2008), and mass versus count nouns (Nagata et al., 2006). However, previous work suggests that grammar error correction is considerably more challenging than detection (Han et al., 2010). Furthermore, an ESL learners writing may contain multiple interacting errors that are difficult to detect and correct in isolation. A promising research direction is to tackle automatic grammar error correction as a machine translation (MT) problem. The disfluent sentences produced by an ESL learner can be seen as the input source language, and the corrected revision is th</context>
<context position="24249" citStr="Chodorow et al. (2007)" startWordPosition="4107" endWordPosition="4110">lem. 5 Related Work There are many research directions in the field of ESL error correction. A great deal of the work focuses on the lexical or shallow syntactic level. Typically, local features such as word identity and POS tagging information are combined to deal with some specific kind of error. Among them, (Burstein et al., 2004) developed a tool called Critique that detects collocation errors and word choice errors. Nagata et al. (2006) uses a rule-based approach in distinguishing mass and count nouns. Knight and Chander (1994) and Han et al. (2006) both addressed the misuse of articles. Chodorow et al. (2007), Gamon et al. (2008), Hermet et al. (2008) proposed several techniques in detecting and correcting proposition errors. In detecting errors and giving suggestions, Liu et al. (2000), Gamon et al. (2008) and Hermet et al. (2008) make use of 1379 \x0cNeither DQG DY K DQG DY K DY K DQG number of instances 50 19 30 1 average edit distance 2.88 0.05 2.17 1 percentage of identical pairs 0.40 0.95 0.5 0 average O length 14.18 9.00 12.53 17 average R length 14.98 9.05 12.47 16 QG cross entropy N/A 81.85 139.36 N/A YK cross entropy N/A 51.2 N/A 103.75 Table 4: This table compares the two models on a tr</context>
</contexts>
<marker>Chodorow, Tetreault, Han, 2007</marker>
<rawString>Chodorow, Martin, Joel Tetreault, and Na-Rae Han. 2007. Detection of grammatical errors involving prepositions. In Proceedings of the 4th ACL-SIGSEM Workshop on Prepositions, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dipanjan Das</author>
<author>Noah A Smith</author>
</authors>
<date>2009</date>
<contexts>
<context position="10246" citStr="Das and Smith, 2009" startWordPosition="1670" endWordPosition="1673">i-Synchronous Grammar formalism (Smith and Eisner, 2006) is a generative model that aims to produce the most likely target tree for a given source tree. It differs from the more strict synchronous grammar formalisms (Wu, 1995; Melamed et al., 2004) because it does not try to perform simultaneous parsing on parallel grammars; instead, the model learns an augmented target-language grammar whose rules make soft alignments with a given source tree. QG has been applied to some NLP tasks other than MT, including answer selection for question-answering (Wang et al., 2007), paraphrase identification (Das and Smith, 2009), and parser adaptation and projection (Smith and Eisner, 2009). In this work we use an instantiation of QG that largely follows the model described by Smith and Eisner (2006). The model is trained on a parallel corpus in which both the first-draft and revised sentences have been parsed. Using EM to estimate its parameters, it learns an augmented target PCFG grammar1 whose production rules form associations with the given source trees. Consider the scenario in Figure 1. Given a source tree O, the trained model generates a target tree by expanding the production rules in the augmented target PC</context>
</contexts>
<marker>Das, Smith, 2009</marker>
<rawString>Das, Dipanjan and Noah A. Smith. 2009.</rawString>
</citation>
<citation valid="true">
<title>Paraphrase identification as probabilistic quasisynchronous recognition.</title>
<date></date>
<booktitle>In Proceedings of ACL-IJCNLP 2009,</booktitle>
<location>Suntec, Singapore,</location>
<marker></marker>
<rawString>Paraphrase identification as probabilistic quasisynchronous recognition. In Proceedings of ACL-IJCNLP 2009, Suntec, Singapore, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jennifer Foster</author>
<author>Joachim Wagner</author>
<author>Josef van Genabith</author>
</authors>
<title>Adapting a WSJ-trained \x0cparser to grammatically noisy text.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th ACL on Human Language Technologies: Short Papers,</booktitle>
<location>Columbus, Ohio.</location>
<marker>Foster, Wagner, van Genabith, 2008</marker>
<rawString>Foster, Jennifer, Joachim Wagner, and Josef van Genabith. 2008. Adapting a WSJ-trained \x0cparser to grammatically noisy text. In Proceedings of the 46th ACL on Human Language Technologies: Short Papers, Columbus, Ohio.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Gamon</author>
<author>Jianfeng Gao</author>
<author>Chris Brockett</author>
<author>Alexandre Klementiev</author>
<author>William B Dolan</author>
<author>Dmitriy Belenko</author>
<author>Lucy Vanderwende</author>
</authors>
<title>Using contextual speller techniques and language modeling for ESL error correction.</title>
<date>2008</date>
<booktitle>In Proceedings of IJCNLP,</booktitle>
<location>Hyderabad, India.</location>
<contexts>
<context position="1221" citStr="Gamon et al., 2008" startWordPosition="178" endWordPosition="181">overage, the tree-to-string approach offers a more plausible model of ESL learners revision writing process. 1 Introduction When learning a second language, students make mistakes along the way. While some mistakes are idiosyncratic and individual, many are systematic and common to people who share the same primary language. There has been extensive research on grammar error detection. Most previous efforts focus on identifying specific types of problems commonly encountered by English as a Second Language (ESL) learners. Some examples include the proper usage of determiners (Yi et al., 2008; Gamon et al., 2008), prepositions (Chodorow et al., 2007; Gamon et al., 2008; Hermet et al., 2008), and mass versus count nouns (Nagata et al., 2006). However, previous work suggests that grammar error correction is considerably more challenging than detection (Han et al., 2010). Furthermore, an ESL learners writing may contain multiple interacting errors that are difficult to detect and correct in isolation. A promising research direction is to tackle automatic grammar error correction as a machine translation (MT) problem. The disfluent sentences produced by an ESL learner can be seen as the input source langu</context>
<context position="24270" citStr="Gamon et al. (2008)" startWordPosition="4111" endWordPosition="4114">e are many research directions in the field of ESL error correction. A great deal of the work focuses on the lexical or shallow syntactic level. Typically, local features such as word identity and POS tagging information are combined to deal with some specific kind of error. Among them, (Burstein et al., 2004) developed a tool called Critique that detects collocation errors and word choice errors. Nagata et al. (2006) uses a rule-based approach in distinguishing mass and count nouns. Knight and Chander (1994) and Han et al. (2006) both addressed the misuse of articles. Chodorow et al. (2007), Gamon et al. (2008), Hermet et al. (2008) proposed several techniques in detecting and correcting proposition errors. In detecting errors and giving suggestions, Liu et al. (2000), Gamon et al. (2008) and Hermet et al. (2008) make use of 1379 \x0cNeither DQG DY K DQG DY K DY K DQG number of instances 50 19 30 1 average edit distance 2.88 0.05 2.17 1 percentage of identical pairs 0.40 0.95 0.5 0 average O length 14.18 9.00 12.53 17 average R length 14.98 9.05 12.47 16 QG cross entropy N/A 81.85 139.36 N/A YK cross entropy N/A 51.2 N/A 103.75 Table 4: This table compares the two models on a trick test corpus in wh</context>
</contexts>
<marker>Gamon, Gao, Brockett, Klementiev, Dolan, Belenko, Vanderwende, 2008</marker>
<rawString>Gamon, Michael, Jianfeng Gao, Chris Brockett, Alexandre Klementiev, William B. Dolan, Dmitriy Belenko, and Lucy Vanderwende. 2008. Using contextual speller techniques and language modeling for ESL error correction. In Proceedings of IJCNLP, Hyderabad, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Na-Rae Han</author>
<author>Martin Chodorow</author>
<author>Claudia Leacock</author>
</authors>
<title>Detecting errors in English article usage by non-native speakers.</title>
<date>2006</date>
<journal>Natural Language Engineering,</journal>
<volume>12</volume>
<issue>02</issue>
<contexts>
<context position="24187" citStr="Han et al. (2006)" startWordPosition="4096" endWordPosition="4099">ind its design is a better fit with the ESL revision problem. 5 Related Work There are many research directions in the field of ESL error correction. A great deal of the work focuses on the lexical or shallow syntactic level. Typically, local features such as word identity and POS tagging information are combined to deal with some specific kind of error. Among them, (Burstein et al., 2004) developed a tool called Critique that detects collocation errors and word choice errors. Nagata et al. (2006) uses a rule-based approach in distinguishing mass and count nouns. Knight and Chander (1994) and Han et al. (2006) both addressed the misuse of articles. Chodorow et al. (2007), Gamon et al. (2008), Hermet et al. (2008) proposed several techniques in detecting and correcting proposition errors. In detecting errors and giving suggestions, Liu et al. (2000), Gamon et al. (2008) and Hermet et al. (2008) make use of 1379 \x0cNeither DQG DY K DQG DY K DY K DQG number of instances 50 19 30 1 average edit distance 2.88 0.05 2.17 1 percentage of identical pairs 0.40 0.95 0.5 0 average O length 14.18 9.00 12.53 17 average R length 14.98 9.05 12.47 16 QG cross entropy N/A 81.85 139.36 N/A YK cross entropy N/A 51.2 </context>
</contexts>
<marker>Han, Chodorow, Leacock, 2006</marker>
<rawString>Han, Na-Rae, Martin Chodorow, and Claudia Leacock. 2006. Detecting errors in English article usage by non-native speakers. Natural Language Engineering, 12(02).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Na-Rae Han</author>
<author>Joel Tetreault</author>
<author>Soo-Hwa Lee</author>
<author>Jin-Young Han</author>
</authors>
<title>Using an error-annotated learner corpus to develop and ESL/EFL error correction system.</title>
<date>2010</date>
<booktitle>In Proceedings of LREC 2010,</booktitle>
<location>Valletta,</location>
<contexts>
<context position="1481" citStr="Han et al., 2010" startWordPosition="218" endWordPosition="221">ematic and common to people who share the same primary language. There has been extensive research on grammar error detection. Most previous efforts focus on identifying specific types of problems commonly encountered by English as a Second Language (ESL) learners. Some examples include the proper usage of determiners (Yi et al., 2008; Gamon et al., 2008), prepositions (Chodorow et al., 2007; Gamon et al., 2008; Hermet et al., 2008), and mass versus count nouns (Nagata et al., 2006). However, previous work suggests that grammar error correction is considerably more challenging than detection (Han et al., 2010). Furthermore, an ESL learners writing may contain multiple interacting errors that are difficult to detect and correct in isolation. A promising research direction is to tackle automatic grammar error correction as a machine translation (MT) problem. The disfluent sentences produced by an ESL learner can be seen as the input source language, and the corrected revision is the result of the translation. Brockett et al. (2006) showed that phrase-based statistical MT can help to correct mistakes made on mass nouns. To our knowledge, phrase-based MT techniques have not been applied for rewriting e</context>
</contexts>
<marker>Han, Tetreault, Lee, Han, 2010</marker>
<rawString>Han, Na-Rae, Joel Tetreault, Soo-Hwa Lee, and Jin-Young Han. 2010. Using an error-annotated learner corpus to develop and ESL/EFL error correction system. In Proceedings of LREC 2010, Valletta, Malta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthieu Hermet</author>
<author>Alain Desilets</author>
<author>Stan Szpakowicz</author>
</authors>
<title>Using the web as a linguistic resource to automatically correct LexicoSyntactic errors.</title>
<date>2008</date>
<booktitle>In Proceedings of the LREC,</booktitle>
<volume>8</volume>
<contexts>
<context position="1300" citStr="Hermet et al., 2008" startWordPosition="191" endWordPosition="194">ners revision writing process. 1 Introduction When learning a second language, students make mistakes along the way. While some mistakes are idiosyncratic and individual, many are systematic and common to people who share the same primary language. There has been extensive research on grammar error detection. Most previous efforts focus on identifying specific types of problems commonly encountered by English as a Second Language (ESL) learners. Some examples include the proper usage of determiners (Yi et al., 2008; Gamon et al., 2008), prepositions (Chodorow et al., 2007; Gamon et al., 2008; Hermet et al., 2008), and mass versus count nouns (Nagata et al., 2006). However, previous work suggests that grammar error correction is considerably more challenging than detection (Han et al., 2010). Furthermore, an ESL learners writing may contain multiple interacting errors that are difficult to detect and correct in isolation. A promising research direction is to tackle automatic grammar error correction as a machine translation (MT) problem. The disfluent sentences produced by an ESL learner can be seen as the input source language, and the corrected revision is the result of the translation. Brockett et a</context>
<context position="24292" citStr="Hermet et al. (2008)" startWordPosition="4115" endWordPosition="4118">irections in the field of ESL error correction. A great deal of the work focuses on the lexical or shallow syntactic level. Typically, local features such as word identity and POS tagging information are combined to deal with some specific kind of error. Among them, (Burstein et al., 2004) developed a tool called Critique that detects collocation errors and word choice errors. Nagata et al. (2006) uses a rule-based approach in distinguishing mass and count nouns. Knight and Chander (1994) and Han et al. (2006) both addressed the misuse of articles. Chodorow et al. (2007), Gamon et al. (2008), Hermet et al. (2008) proposed several techniques in detecting and correcting proposition errors. In detecting errors and giving suggestions, Liu et al. (2000), Gamon et al. (2008) and Hermet et al. (2008) make use of 1379 \x0cNeither DQG DY K DQG DY K DY K DQG number of instances 50 19 30 1 average edit distance 2.88 0.05 2.17 1 percentage of identical pairs 0.40 0.95 0.5 0 average O length 14.18 9.00 12.53 17 average R length 14.98 9.05 12.47 16 QG cross entropy N/A 81.85 139.36 N/A YK cross entropy N/A 51.2 N/A 103.75 Table 4: This table compares the two models on a trick test corpus in which the earlier and la</context>
</contexts>
<marker>Hermet, Desilets, Szpakowicz, 2008</marker>
<rawString>Hermet, Matthieu, Alain Desilets, and Stan Szpakowicz. 2008. Using the web as a linguistic resource to automatically correct LexicoSyntactic errors. In Proceedings of the LREC, volume 8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher Manning</author>
</authors>
<date>2004</date>
<contexts>
<context position="11026" citStr="Klein and Manning, 2004" startWordPosition="1800" endWordPosition="1804">h and Eisner (2006). The model is trained on a parallel corpus in which both the first-draft and revised sentences have been parsed. Using EM to estimate its parameters, it learns an augmented target PCFG grammar1 whose production rules form associations with the given source trees. Consider the scenario in Figure 1. Given a source tree O, the trained model generates a target tree by expanding the production rules in the augmented target PCFG. To apply a 1 For expository purposes, we illustrate the model using a PCFG production rule. In the experiment, a statistical English dependency parser (Klein and Manning, 2004) was used. 1375 \x0cFigure 1: An example of QGs soft alignments between a given source tree and a possible target rule expansion. target-side production rule such as A BC, the model considers which source tree nodes might be associated with each target-side nonterminals: (, A) (, B)(, C) where , , are nodes in O. Thus, assuming that the target symbol A has already been aligned to source node from an earlier derivation step, the likelihood of expanding (, A) with the above production rule depends on three factors: 1. the likelihood of the monolingual target rule, Pr(A BC) 2. the likelihood of a</context>
</contexts>
<marker>Klein, Manning, 2004</marker>
<rawString>Klein, Dan and Christopher Manning. 2004.</rawString>
</citation>
<citation valid="true">
<title>Corpus-based induction of syntactic structure: Models of dependency and constituency.</title>
<date></date>
<booktitle>In Proceedings of ACL 2004,</booktitle>
<location>Barcelona,</location>
<marker></marker>
<rawString>Corpus-based induction of syntactic structure: Models of dependency and constituency. In Proceedings of ACL 2004, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
<author>Ishwar Chander</author>
</authors>
<title>Automated postediting of documents.</title>
<date>1994</date>
<booktitle>In Proceedings of AAAI-94,</booktitle>
<location>Seattle, Washington.</location>
<contexts>
<context position="24165" citStr="Knight and Chander (1994)" startWordPosition="4091" endWordPosition="4094">arget side, the philosophy behind its design is a better fit with the ESL revision problem. 5 Related Work There are many research directions in the field of ESL error correction. A great deal of the work focuses on the lexical or shallow syntactic level. Typically, local features such as word identity and POS tagging information are combined to deal with some specific kind of error. Among them, (Burstein et al., 2004) developed a tool called Critique that detects collocation errors and word choice errors. Nagata et al. (2006) uses a rule-based approach in distinguishing mass and count nouns. Knight and Chander (1994) and Han et al. (2006) both addressed the misuse of articles. Chodorow et al. (2007), Gamon et al. (2008), Hermet et al. (2008) proposed several techniques in detecting and correcting proposition errors. In detecting errors and giving suggestions, Liu et al. (2000), Gamon et al. (2008) and Hermet et al. (2008) make use of 1379 \x0cNeither DQG DY K DQG DY K DY K DQG number of instances 50 19 30 1 average edit distance 2.88 0.05 2.17 1 percentage of identical pairs 0.40 0.95 0.5 0 average O length 14.18 9.00 12.53 17 average R length 14.98 9.05 12.47 16 QG cross entropy N/A 81.85 139.36 N/A YK c</context>
</contexts>
<marker>Knight, Chander, 1994</marker>
<rawString>Knight, Kevin and Ishwar Chander. 1994. Automated postediting of documents. In Proceedings of AAAI-94, Seattle, Washington.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lee</author>
<author>Stephanie Seneff</author>
</authors>
<title>Correcting misuse of verb forms.</title>
<date>2008</date>
<booktitle>Proceedings of the 46th ACL,</booktitle>
<location>Columbus.</location>
<contexts>
<context position="25502" citStr="Lee and Seneff (2008)" startWordPosition="4327" endWordPosition="4330">lier and later drafts are reversed. If a model is trained to prefer more fluent English sentences are the revision, it should be perplexed on this corpus. information retrieval techniques. Chodorow et al. (2007) instead treat it as a classification problem and employed a maximum entropy classifier. Similar to our approach, Brockett et al. (2006) view error correction as a Machine Translation problem. But their translation system is built on phrase level, with the purpose of correcting local errors such as mass noun errors. The problem of error correction at a syntactic level is less explored. Lee and Seneff (2008) examined the task of correcting verb form misuse by applying tree template matching rules. The parse tree transformation rules are learned from synthesized training data. 6 Conclusion This paper investigates the suitability of syntax-driven MT approaches for modeling the revision writing process of ESL learners. We have considered both the Yamada &amp; Knight tree-to-string model, which only considers syntactic information from the typically more fluent revised text, as well as QuasiSynchronous Grammar, a tree-to-tree model that attempts to learn syntactic transformation patterns between the stud</context>
</contexts>
<marker>Lee, Seneff, 2008</marker>
<rawString>Lee, John and Stephanie Seneff. 2008. Correcting misuse of verb forms. Proceedings of the 46th ACL, Columbus.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ting Liu</author>
<author>Ming Zhou</author>
<author>Jianfeng Gao</author>
<author>Endong Xun</author>
<author>Changning Huang</author>
</authors>
<title>PENS: a machine-aided english writing system for chinese users.</title>
<date>2000</date>
<booktitle>In Proceedings of the 38th ACL,</booktitle>
<location>Hong Kong, China.</location>
<contexts>
<context position="24430" citStr="Liu et al. (2000)" startWordPosition="4135" endWordPosition="4138">features such as word identity and POS tagging information are combined to deal with some specific kind of error. Among them, (Burstein et al., 2004) developed a tool called Critique that detects collocation errors and word choice errors. Nagata et al. (2006) uses a rule-based approach in distinguishing mass and count nouns. Knight and Chander (1994) and Han et al. (2006) both addressed the misuse of articles. Chodorow et al. (2007), Gamon et al. (2008), Hermet et al. (2008) proposed several techniques in detecting and correcting proposition errors. In detecting errors and giving suggestions, Liu et al. (2000), Gamon et al. (2008) and Hermet et al. (2008) make use of 1379 \x0cNeither DQG DY K DQG DY K DY K DQG number of instances 50 19 30 1 average edit distance 2.88 0.05 2.17 1 percentage of identical pairs 0.40 0.95 0.5 0 average O length 14.18 9.00 12.53 17 average R length 14.98 9.05 12.47 16 QG cross entropy N/A 81.85 139.36 N/A YK cross entropy N/A 51.2 N/A 103.75 Table 4: This table compares the two models on a trick test corpus in which the earlier and later drafts are reversed. If a model is trained to prefer more fluent English sentences are the revision, it should be perplexed on this co</context>
</contexts>
<marker>Liu, Zhou, Gao, Xun, Huang, 2000</marker>
<rawString>Liu, Ting, Ming Zhou, Jianfeng Gao, Endong Xun, and Changning Huang. 2000. PENS: a machine-aided english writing system for chinese users. In Proceedings of the 38th ACL, Hong Kong, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Lopez</author>
</authors>
<title>Statistical machine translation.</title>
<date>2008</date>
<journal>ACM Computing Surveys,</journal>
<volume>40</volume>
<issue>3</issue>
<contexts>
<context position="7345" citStr="Lopez (2008)" startWordPosition="1200" endWordPosition="1201">oblem is that it might not always be possible to assign a sensible syntactic structure to an ungrammatical sentence. It is well-known that an English parser trained on the Penn Treebank is bad at handling disfluent sentences (Charniak et al., 2003; Foster et al., 2008). In our domain, since O (and perhaps also R) might be disfluent, an important question that a translation model must address is: how should the mapping between the trees O and R be handled? 3 Syntax-Driven Models for Essay Revisions There is extensive literature on syntax-driven approaches to MT (cf. a recent survey by 1374 \x0cLopez (2008)); we focus on two particular formalisms that reflects different perspectives on the role of syntax. Our goal is to assess which formalism is a better fit with the domain of essay revision modeling, in which the data largely consist of imperfect sentences that may not support a plausible syntactic interpretation. 3.1 Tree-to-String Model The Yamada &amp; Knight (henceforth, YK) treeto-string model is an instance of noisy channel translation systems, which assumes that the observed source sentence is the result of transformation performed on the parse tree of the intended target sentence due to a n</context>
</contexts>
<marker>Lopez, 2008</marker>
<rawString>Lopez, Adam. 2008. Statistical machine translation. ACM Computing Surveys, 40(3), September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dan Melamed</author>
<author>Giorgio Satta</author>
<author>Ben Wellington</author>
</authors>
<title>Generalized multitext grammars.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd ACL,</booktitle>
<location>Barcelona,</location>
<contexts>
<context position="9874" citStr="Melamed et al., 2004" startWordPosition="1611" endWordPosition="1614">stituency orderings, can be modeled by a combination of the insert, replace, and reorder operators. The YK model allows us to perform transformations on a higher syntactic level. Another potential benefit is that the model does not attempt to assign syntactic interpretations over the source sentences (i.e., the less fluent original draft). 3.2 Tree-to-Tree Model The Quasi-Synchronous Grammar formalism (Smith and Eisner, 2006) is a generative model that aims to produce the most likely target tree for a given source tree. It differs from the more strict synchronous grammar formalisms (Wu, 1995; Melamed et al., 2004) because it does not try to perform simultaneous parsing on parallel grammars; instead, the model learns an augmented target-language grammar whose rules make soft alignments with a given source tree. QG has been applied to some NLP tasks other than MT, including answer selection for question-answering (Wang et al., 2007), paraphrase identification (Das and Smith, 2009), and parser adaptation and projection (Smith and Eisner, 2009). In this work we use an instantiation of QG that largely follows the model described by Smith and Eisner (2006). The model is trained on a parallel corpus in which </context>
</contexts>
<marker>Melamed, Satta, Wellington, 2004</marker>
<rawString>Melamed, I. Dan, Giorgio Satta, and Ben Wellington. 2004. Generalized multitext grammars. In Proceedings of the 42nd ACL, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryo Nagata</author>
<author>Atsuo Kawai</author>
<author>Koichiro Morihiro</author>
<author>Naoki Isu</author>
</authors>
<title>A feedback-augmented method for detecting errors in the writing of learners of english.</title>
<date>2006</date>
<booktitle>In Proceedings of COLINGACL 2006,</booktitle>
<location>Sydney, Australia,</location>
<contexts>
<context position="1351" citStr="Nagata et al., 2006" startWordPosition="200" endWordPosition="203">learning a second language, students make mistakes along the way. While some mistakes are idiosyncratic and individual, many are systematic and common to people who share the same primary language. There has been extensive research on grammar error detection. Most previous efforts focus on identifying specific types of problems commonly encountered by English as a Second Language (ESL) learners. Some examples include the proper usage of determiners (Yi et al., 2008; Gamon et al., 2008), prepositions (Chodorow et al., 2007; Gamon et al., 2008; Hermet et al., 2008), and mass versus count nouns (Nagata et al., 2006). However, previous work suggests that grammar error correction is considerably more challenging than detection (Han et al., 2010). Furthermore, an ESL learners writing may contain multiple interacting errors that are difficult to detect and correct in isolation. A promising research direction is to tackle automatic grammar error correction as a machine translation (MT) problem. The disfluent sentences produced by an ESL learner can be seen as the input source language, and the corrected revision is the result of the translation. Brockett et al. (2006) showed that phrase-based statistical MT c</context>
<context position="24072" citStr="Nagata et al. (2006)" startWordPosition="4077" endWordPosition="4080">sible explanation is that because YK assumes well-formed syntax structure for only the target side, the philosophy behind its design is a better fit with the ESL revision problem. 5 Related Work There are many research directions in the field of ESL error correction. A great deal of the work focuses on the lexical or shallow syntactic level. Typically, local features such as word identity and POS tagging information are combined to deal with some specific kind of error. Among them, (Burstein et al., 2004) developed a tool called Critique that detects collocation errors and word choice errors. Nagata et al. (2006) uses a rule-based approach in distinguishing mass and count nouns. Knight and Chander (1994) and Han et al. (2006) both addressed the misuse of articles. Chodorow et al. (2007), Gamon et al. (2008), Hermet et al. (2008) proposed several techniques in detecting and correcting proposition errors. In detecting errors and giving suggestions, Liu et al. (2000), Gamon et al. (2008) and Hermet et al. (2008) make use of 1379 \x0cNeither DQG DY K DQG DY K DY K DQG number of instances 50 19 30 1 average edit distance 2.88 0.05 2.17 1 percentage of identical pairs 0.40 0.95 0.5 0 average O length 14.18 </context>
</contexts>
<marker>Nagata, Kawai, Morihiro, Isu, 2006</marker>
<rawString>Nagata, Ryo, Atsuo Kawai, Koichiro Morihiro, and Naoki Isu. 2006. A feedback-augmented method for detecting errors in the writing of learners of english. In Proceedings of COLINGACL 2006, Sydney, Australia, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="18111" citStr="Och and Ney, 2003" startWordPosition="3042" endWordPosition="3045">el, the initial parameters are determined as follows: For the monolingual target parsing model parameters, we first parse the target side of the corpus (i.e., the revised sentences) with the Stanford parser; we then use the maximum likelihood estimates based on these parse trees to initialize the parameters of the target parser, Dependency Model with Valence (DMV). We uniformly initialized the configuration parameters; the parent-child configuration and other configuration each has 0.5 probability. For the alignment parameters, we ran the GIZA++ implementation of the IBM word alignment model (Och and Ney, 2003) on the sentence pairs, and used the resulting translation table as our initial estimation. There may be better initialization setups, but the difference between those setups will become small after a few rounds of EM. Once trained, the two models compute the joint probability of every sentence pair in the test corpus as described in Section 3.3. 4.3 Experiment I To evaluate how well the models describe the ESL revision domain, we want to see which model is less surprised by the test data. We expected that the better model should be able to transform more sentence pair in the test corpus; we a</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Och, Franz Josef and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>David A Smith</author>
<author>Jason Eisner</author>
</authors>
<title>Quasisynchronous grammars: Alignment by soft projection of syntactic dependencies.</title>
<date>2006</date>
<booktitle>In Proceedings on the Workshop on Statistical Machine Translation,</booktitle>
<location>New York City,</location>
<contexts>
<context position="3572" citStr="Smith and Eisner, 2006" startWordPosition="555" endWordPosition="558">ns provide an intuitive description of how second language learners revise their writings: they are transforming structures in their primary language to those in the new language. In this paper, we conduct a first inquiry into the applicability of syntax-driven MT methods to automatic grammar error correction. In particular, we investigate whether a syntaxdriven model can capture ESL students process of writing revisions. We compare two approaches: a tree-to-string mapping proposed by Yamada &amp; Knight (2001) and a tree-totree mapping using the Quasi-Synchronous 1373 \x0cGrammar (QG) formalism (Smith and Eisner, 2006). We train both models on a parallel corpus consisting of multiple drafts of essays by ESL students. The approaches are evaluated on how well they model the revision pairs in an unseen test corpus. Experimental results suggest that 1) the QG model has more flexibility and is able to describe more types of transformations; but 2) the YK model is better at capturing the incremental improvements in the ESL learners revision writing process. 2 Problem Description This paper explores the research question: can ESL learners process of revising their writings be described by a computational model? A </context>
<context position="9682" citStr="Smith and Eisner, 2006" startWordPosition="1578" endWordPosition="1581">ence, O, is the concatenation of the leaf nodes of the transformed G. Common mistakes made by ESL learners, such as misuses of determiners and prepositions, word choice errors, and incorrect constituency orderings, can be modeled by a combination of the insert, replace, and reorder operators. The YK model allows us to perform transformations on a higher syntactic level. Another potential benefit is that the model does not attempt to assign syntactic interpretations over the source sentences (i.e., the less fluent original draft). 3.2 Tree-to-Tree Model The Quasi-Synchronous Grammar formalism (Smith and Eisner, 2006) is a generative model that aims to produce the most likely target tree for a given source tree. It differs from the more strict synchronous grammar formalisms (Wu, 1995; Melamed et al., 2004) because it does not try to perform simultaneous parsing on parallel grammars; instead, the model learns an augmented target-language grammar whose rules make soft alignments with a given source tree. QG has been applied to some NLP tasks other than MT, including answer selection for question-answering (Wang et al., 2007), paraphrase identification (Das and Smith, 2009), and parser adaptation and projecti</context>
<context position="12030" citStr="Smith and Eisner, 2006" startWordPosition="1981" endWordPosition="1984">o source node from an earlier derivation step, the likelihood of expanding (, A) with the above production rule depends on three factors: 1. the likelihood of the monolingual target rule, Pr(A BC) 2. the likelihood of alignments between B and as well as C and . 3. the likelihood that the source nodes form some expected configuration (i.e., between and as well as between and ). In this work, we distinguish between two configuration types: parent-child and other. This restriction doesnt reduce the explanatory power of the resulting QG model, though it may not be as fine-tuned as some models in (Smith and Eisner, 2006). Under QG, the ESL students first drafts are seen as text in a different language that has its own syntactic constructions. QG explains the grammar rules that govern the revised text in terms of how different components map to structures in the original draft. It makes explicit the representation of divergences between the students original mental model and the expected structure. 3.3 Method of Model Comparison Cross entropy can be used as a metric that measures the distance between the learned probabilistic model and the real data. It can be interpreted as measuring the amount of information</context>
</contexts>
<marker>Smith, Eisner, 2006</marker>
<rawString>Smith, David A. and Jason Eisner. 2006. Quasisynchronous grammars: Alignment by soft projection of syntactic dependencies. In Proceedings on the Workshop on Statistical Machine Translation, New York City, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David A Smith</author>
<author>Jason Eisner</author>
</authors>
<date>2009</date>
<contexts>
<context position="10309" citStr="Smith and Eisner, 2009" startWordPosition="1679" endWordPosition="1682">a generative model that aims to produce the most likely target tree for a given source tree. It differs from the more strict synchronous grammar formalisms (Wu, 1995; Melamed et al., 2004) because it does not try to perform simultaneous parsing on parallel grammars; instead, the model learns an augmented target-language grammar whose rules make soft alignments with a given source tree. QG has been applied to some NLP tasks other than MT, including answer selection for question-answering (Wang et al., 2007), paraphrase identification (Das and Smith, 2009), and parser adaptation and projection (Smith and Eisner, 2009). In this work we use an instantiation of QG that largely follows the model described by Smith and Eisner (2006). The model is trained on a parallel corpus in which both the first-draft and revised sentences have been parsed. Using EM to estimate its parameters, it learns an augmented target PCFG grammar1 whose production rules form associations with the given source trees. Consider the scenario in Figure 1. Given a source tree O, the trained model generates a target tree by expanding the production rules in the augmented target PCFG. To apply a 1 For expository purposes, we illustrate the mod</context>
</contexts>
<marker>Smith, Eisner, 2009</marker>
<rawString>Smith, David A. and Jason Eisner. 2009.</rawString>
</citation>
<citation valid="true">
<title>Parser adaptation and projection with quasisynchronous grammar features.</title>
<date></date>
<booktitle>In Proceedings of EMNLP 2009, Singapore,</booktitle>
<marker></marker>
<rawString>Parser adaptation and projection with quasisynchronous grammar features. In Proceedings of EMNLP 2009, Singapore, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mengqiu Wang</author>
<author>Noah A Smith</author>
<author>Teruko Mitamura</author>
</authors>
<title>What is the Jeopardy model? a quasi-synchronous grammar for QA.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLP-CoNLL 2007,</booktitle>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="10197" citStr="Wang et al., 2007" startWordPosition="1663" endWordPosition="1666">riginal draft). 3.2 Tree-to-Tree Model The Quasi-Synchronous Grammar formalism (Smith and Eisner, 2006) is a generative model that aims to produce the most likely target tree for a given source tree. It differs from the more strict synchronous grammar formalisms (Wu, 1995; Melamed et al., 2004) because it does not try to perform simultaneous parsing on parallel grammars; instead, the model learns an augmented target-language grammar whose rules make soft alignments with a given source tree. QG has been applied to some NLP tasks other than MT, including answer selection for question-answering (Wang et al., 2007), paraphrase identification (Das and Smith, 2009), and parser adaptation and projection (Smith and Eisner, 2009). In this work we use an instantiation of QG that largely follows the model described by Smith and Eisner (2006). The model is trained on a parallel corpus in which both the first-draft and revised sentences have been parsed. Using EM to estimate its parameters, it learns an augmented target PCFG grammar1 whose production rules form associations with the given source trees. Consider the scenario in Figure 1. Given a source tree O, the trained model generates a target tree by expandin</context>
</contexts>
<marker>Wang, Smith, Mitamura, 2007</marker>
<rawString>Wang, Mengqiu, Noah A. Smith, and Teruko Mitamura. 2007. What is the Jeopardy model? a quasi-synchronous grammar for QA. In Proceedings of EMNLP-CoNLL 2007, Prague, Czech Republic, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
</authors>
<title>Stochastic inversion transduction grammars, with application to segmentation, bracketing, and alignment of parallel corpora.</title>
<date>1995</date>
<booktitle>In Proc. of the 14th Intl. Joint Conf. on Artificial Intelligence,</booktitle>
<location>Montreal,</location>
<contexts>
<context position="9851" citStr="Wu, 1995" startWordPosition="1609" endWordPosition="1610">orrect constituency orderings, can be modeled by a combination of the insert, replace, and reorder operators. The YK model allows us to perform transformations on a higher syntactic level. Another potential benefit is that the model does not attempt to assign syntactic interpretations over the source sentences (i.e., the less fluent original draft). 3.2 Tree-to-Tree Model The Quasi-Synchronous Grammar formalism (Smith and Eisner, 2006) is a generative model that aims to produce the most likely target tree for a given source tree. It differs from the more strict synchronous grammar formalisms (Wu, 1995; Melamed et al., 2004) because it does not try to perform simultaneous parsing on parallel grammars; instead, the model learns an augmented target-language grammar whose rules make soft alignments with a given source tree. QG has been applied to some NLP tasks other than MT, including answer selection for question-answering (Wang et al., 2007), paraphrase identification (Das and Smith, 2009), and parser adaptation and projection (Smith and Eisner, 2009). In this work we use an instantiation of QG that largely follows the model described by Smith and Eisner (2006). The model is trained on a pa</context>
</contexts>
<marker>Wu, 1995</marker>
<rawString>Wu, Dekai. 1995. Stochastic inversion transduction grammars, with application to segmentation, bracketing, and alignment of parallel corpora. In Proc. of the 14th Intl. Joint Conf. on Artificial Intelligence, Montreal, Aug.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Yamada</author>
<author>Kevin Knight</author>
</authors>
<title>A syntax-based statistical translation model.</title>
<date>2001</date>
<booktitle>In Proceedings of the 39th ACL,</booktitle>
<location>Toulouse, France.</location>
<contexts>
<context position="3461" citStr="Yamada &amp; Knight (2001)" startWordPosition="539" endWordPosition="542"> syntax-driven MT model may not need to train on a very large parallel corpus. Second, syntactic transformations provide an intuitive description of how second language learners revise their writings: they are transforming structures in their primary language to those in the new language. In this paper, we conduct a first inquiry into the applicability of syntax-driven MT methods to automatic grammar error correction. In particular, we investigate whether a syntaxdriven model can capture ESL students process of writing revisions. We compare two approaches: a tree-to-string mapping proposed by Yamada &amp; Knight (2001) and a tree-totree mapping using the Quasi-Synchronous 1373 \x0cGrammar (QG) formalism (Smith and Eisner, 2006). We train both models on a parallel corpus consisting of multiple drafts of essays by ESL students. The approaches are evaluated on how well they model the revision pairs in an unseen test corpus. Experimental results suggest that 1) the QG model has more flexibility and is able to describe more types of transformations; but 2) the YK model is better at capturing the incremental improvements in the ESL learners revision writing process. 2 Problem Description This paper explores the r</context>
</contexts>
<marker>Yamada, Knight, 2001</marker>
<rawString>Yamada, Kenji and Kevin Knight. 2001. A syntax-based statistical translation model. In Proceedings of the 39th ACL, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xing Yi</author>
<author>Jianfeng Gao</author>
<author>William B Dolan</author>
</authors>
<title>A web-based english proofing system for english as a second language users.</title>
<date>2008</date>
<booktitle>In Proceedings of IJCNLP,</booktitle>
<location>Hyderabad,</location>
<contexts>
<context position="1200" citStr="Yi et al., 2008" startWordPosition="174" endWordPosition="177">vides a greater coverage, the tree-to-string approach offers a more plausible model of ESL learners revision writing process. 1 Introduction When learning a second language, students make mistakes along the way. While some mistakes are idiosyncratic and individual, many are systematic and common to people who share the same primary language. There has been extensive research on grammar error detection. Most previous efforts focus on identifying specific types of problems commonly encountered by English as a Second Language (ESL) learners. Some examples include the proper usage of determiners (Yi et al., 2008; Gamon et al., 2008), prepositions (Chodorow et al., 2007; Gamon et al., 2008; Hermet et al., 2008), and mass versus count nouns (Nagata et al., 2006). However, previous work suggests that grammar error correction is considerably more challenging than detection (Han et al., 2010). Furthermore, an ESL learners writing may contain multiple interacting errors that are difficult to detect and correct in isolation. A promising research direction is to tackle automatic grammar error correction as a machine translation (MT) problem. The disfluent sentences produced by an ESL learner can be seen as t</context>
</contexts>
<marker>Yi, Gao, Dolan, 2008</marker>
<rawString>Yi, Xing, Jianfeng Gao, and William B Dolan. 2008. A web-based english proofing system for english as a second language users. In Proceedings of IJCNLP, Hyderabad, India. \x0c&amp;apos;</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>