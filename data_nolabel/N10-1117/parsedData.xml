<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.637507">
b&amp;apos;Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 760768,
</title>
<author confidence="0.476118">
Los Angeles, California, June 2010. c
</author>
<title confidence="0.619279">
2010 Association for Computational Linguistics
Relaxed Marginal Inference and its Application to Dependency Parsing
</title>
<author confidence="0.980533">
Sebastian Riedel David A. Smith
</author>
<affiliation confidence="0.9984575">
Department of Computer Science
University of Massachusetts, Amherst
</affiliation>
<email confidence="0.998382">
{riedel,dasmith}@cs.umass.edu
</email>
<sectionHeader confidence="0.990842" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9955865">
Recently, relaxation approaches have been
successfully used for MAP inference on NLP
problems. In this work we show how to extend
the relaxation approach to marginal inference
used in conditional likelihood training, pos-
terior decoding, confidence estimation, and
other tasks. We evaluate our approach for the
case of second-order dependency parsing and
observe a tenfold increase in parsing speed,
with no loss in accuracy, by performing in-
ference over a small subset of the full factor
graph. We also contribute a bound on the error
of the marginal probabilities by a sub-graph
with respect to the full graph. Finally, while
only evaluated with BP in this paper, our ap-
proach is general enough to be applied with
any marginal inference method in the inner
loop.
</bodyText>
<sectionHeader confidence="0.997597" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99959675">
In statistical natural language processing (NLP) we
are often concerned with finding the marginal proba-
bilities of events in our models or the expectations of
features. When training to optimize conditional like-
lihood, feature expectations are needed to calculate
the gradient. Marginalization also allows a statis-
tical NLP component to give confidence values for
its predictions or to marginalize out latent variables.
Finally, given the marginal probabilities of variables,
we can pick the values that maximize these marginal
probabilities (perhaps subject to hard constraints) in
order to predict a good variable assignment.1
</bodyText>
<page confidence="0.918331">
1
</page>
<bodyText confidence="0.998557222222223">
With a loss function that decomposes on the variables, this
amounts to Minimum Bayes Risk (MBR) decoding, which is
Traditionally, marginal inference in NLP has been
performed via dynamic programming (DP); how-
ever, because this requires the model to factor in
a way that lends itself to DP algorithms, we have
to restrict the class of probabilistic models we con-
sider. For example, since we cannot derive a dy-
namic program for marginal inference in second or-
der non-projective dependency parsing (McDonald
and Satta, 2007), we have non-projective languages
such as Dutch using second order projective mod-
els if we want to apply DP. Some previous work
has circumvented this problem for MAP inference
by starting with a second-order projective solution
and then greedily flipping edges to find a better non-
projective solution (McDonald and Pereira, 2006).
In order to explore richer model structures, the
NLP community has recently started to investigate
the use of other, well-known machine learning tech-
niques for marginal inference. One such technique is
Markov chain Monte Carlo, and in particular Gibbs
sampling (Finkel et al., 2005), another is (loopy)
sum-product belief propagation (Smith and Eisner,
2008). In both cases we usually work in the frame-
work of graphical modelsin our case, with factor
graphs that describe our distributions through vari-
ables, factors, and factor potentials. In theory, meth-
ods such as belief propagation can take any graph
and perform marginal inference. This means that we
gain a great amount of flexibility to represent more
global and joint distributions for NLP tasks.
The graphical models of interest, however, are
often too large and densely connected for efficient
inference in them. For example, in second order
often very effective.
</bodyText>
<page confidence="0.969007">
760
</page>
<bodyText confidence="0.989566095238095">
\x0cdependency parsing models, we have O(n2) vari-
ables and O(n3) factors, each of which may have
to be inspected several times. While belief prop-
agation is still tractable here (assuming we follow
the approach of Smith and Eisner (2008) to enforce
tree constraints), it is still much slower than sim-
pler greedy parsing methods, and the advantage sec-
ond order models give in accuracy is often not sig-
nificant enough to offset the lack of speed in prac-
tice. Moreover, if we extend such parsing models to,
say, penalizing all pairs of crossing edges or scoring
syntax-based alignments, we will need to inspect at
least O n4
\x01
factors, increasing our efficiency con-
cerns.
When looking at the related task of finding the
most likely assignment in large graphical models
(i.e., MAP inference), we notice that several recent
approaches have significantly sped up computation
through relaxation methods (Tromble and Eisner,
2006; Riedel and Clarke, 2006). Here we start with
a small subset of the full graph, and run inference
for this simpler problem. Then we search for factors
that are violated in the solution, and add them to
the graph. This is repeated until no more new factors
can be added. Empirically this approach has shown
impressive success. It often dramatically reduces the
effective network size, with no loss in accuracy.
How can we extend or generalize MAP relax-
ation algorithms to the case of marginal inference?
Roughly speaking, we answer it by introducing a
notion of factor gain that is defined as the KL di-
vergence between the current distribution with and
without the given factor. This quantity is then used
in an algorithm that starts with a sub-model, runs
marginal inference in it and then determines the
gains of the not-yet-added factors. In turn, all fac-
tors for which the gain exceeds some threshold are
added to the current model. This process is repeated
until no more new factors can be found or a maxi-
mum number of iterations is reached.
We evaluate this form of relaxed marginal infer-
ence for the case of second-order dependency pars-
ing. We follow Smith and Eisners tree-aware be-
lief propagation procedure for inference in the inner
loop of our algorithm. This leads to a tenfold in-
crease in parsing speed with no loss in accuracy.
We also contribute a bound on the error on
marginal probabilities the sub-graph defines with re-
spect to the full graph. This bound can be used both
for terminating (although not done here) and under-
standing the dynamics of inference. Finally, while
only evaluated with BP so far, it is general enough
to be applied with any marginal inference method in
the inner loop.
In the following, we first give a sketch of the
graphical model we apply. Then we briefly discuss
marginal inference. In turn we describe our relax-
ation algorithm for marginal inference and some of
its theoretic guarantees. Then we present empirical
support for the effectiveness of our approach, and
conclude.
</bodyText>
<sectionHeader confidence="0.955133" genericHeader="method">
2 Graphical Models of Dependency Trees
</sectionHeader>
<bodyText confidence="0.95948925">
We give a brief overview of the graphical model we
apply in our experiments. We chose the grandpar-
ents and siblings model, together with language spe-
cific multiroot and projectivity options as taken from
Smith and Eisner (2008). All our models are defined
over a set of binary variables Lij that indicate a de-
pendency between token i and j of the input sen-
tence W.
</bodyText>
<subsectionHeader confidence="0.986429">
2.1 Markov Random Fields
</subsectionHeader>
<bodyText confidence="0.9265926">
Following Smith and Eisner (2008), we define a
probability distribution over all dependency trees as
a collection of edges y for a fixed input sentence
W. This distribution is represented by an undirected
graphical model, or Markov random field (MRF):
</bodyText>
<equation confidence="0.999137">
pF (y)
def
=
1
Z
Y
iF
i (y) (1)
</equation>
<bodyText confidence="0.952736666666667">
specified by an index set F and a corresponding
family (i)F of factors i : Y 7 &amp;lt;+. Here Z
is the partition function ZF =
</bodyText>
<equation confidence="0.9871185">
P
y
Q
i i (y).
</equation>
<bodyText confidence="0.999435333333333">
We will restrict our attention to binary factors that
can be represented as i (y) = eii(y) with binary
functions i (y) {0, 1} and weights i &amp;lt;.2 This
</bodyText>
<page confidence="0.980889">
2
</page>
<bodyText confidence="0.9973735">
These i are also called sufficient statistics or feature func-
tions, not to be confused with the features whose weighted sum
forms the weight i. The restriction to binary functions is with-
out loss of generality since we can combine constraints on par-
ticular variable assignments into potential tables with several
dimensions.
</bodyText>
<page confidence="0.96503">
761
</page>
<equation confidence="0.965929">
\x0cleads to
pF (y)
def
=
1
Z
exp
X
iF
ii (y)
!
</equation>
<bodyText confidence="0.978138666666667">
as an alternative representation for pF . Note that
when i (y) = 1 we will say that i fires for y.
Note that a factor function i(y) can depend on
any part of the observed input sentence W; however,
for brevity we will suppress this extra argument to
i.
</bodyText>
<subsectionHeader confidence="0.990851">
2.2 Hard and Soft Constraints on Trees
</subsectionHeader>
<bodyText confidence="0.9886368">
A particular model specifies its preference for set of
dependency edges over another by a set of hard and
soft constraints. We use hard constraints to rule out
a priori illegal structures, such as trees where a word
has two parents, and soft constraints to raise or lower
the score of trees that contain particular good or bad
substructures.
A hard factor (or constraint) i evaluates an as-
signment y with respect to some specified condi-
tion and fires only if this condition is violated; in
this case it evaluates to 0. It is therefore ruling out
all configurations in which the condition does not
hold. Note that a hard constraint i corresponds to
i = in our loglinear representation.
For dependency parsing, we consider two partic-
ular hard constraints, each of which touches all edge
variables in y: the constraint Tree requires that all
edges form a directed spanning tree rooted at the
root node 0; the constraint PTree enforces the more
stringent condition that all edges form a projective
directed tree. As in (Smith and Eisner, 2008), we
used algorithms from edge-factored parsing to com-
pute BP messages for these factors. In our experi-
ments, we enforced one or the other constraint de-
pending on the projectivity of given treebank data.
A soft factor i acts as a soft constraint that
prefers some assignments to others. This is equiv-
alent to saying that its weight i is finite. Note that
the weight of a soft factor is usually itself composed
as a sum of (sub-)weights wj for feature functions
that have the same input-output behavior as i (y)
when conditioned on the current sentence. It is these
wj which are adjusted at training time.
We use three kinds of soft factors from Smith and
Eisner (2008). In the full model, there are: O(n2)
LINKi,j factors that judge dependency edges in iso-
lation; O(n3) GRANDi,j,k factors that judge pairs
of dependency edges in a grandparent-parent-child
chain; and O(n3) SIBi,j,k factors that judge pairs of
dependency edges that share the same parent.
</bodyText>
<sectionHeader confidence="0.987103" genericHeader="method">
3 Marginal Inference
</sectionHeader>
<bodyText confidence="0.9990442">
Formally, given our set of factors F and an observed
sentence W, marginal inference amounts to calcu-
lating the probability F
i that our binary features i
are active. That is, for each factor i
</bodyText>
<equation confidence="0.996383714285714">
F
i
def
=
X
i(y)=1
pF (y) = EF [i] (2)
</equation>
<bodyText confidence="0.901661714285715">
For compactness, we follow the convention of Wain-
wright and Jordan (2008) and represent the belief for
a variable using the marginal probability of its cor-
responding unary factor. Hence, if we want to calcu-
late pF (Lij) we use F
LINKij
in place. Moreover we
</bodyText>
<equation confidence="0.99560125">
will use F
i
def
= 1F
</equation>
<bodyText confidence="0.981951103448276">
i when we need the probability
of the event i (y) = 0.
The two most prominent approaches to marginal
inference in general graphical models are Markov
Chain Monte Carlo (MCMC) and variational meth-
ods. In a nutshell, MCMC iteratively generates a
Markov chain that yields pF as its stationary distri-
bution. Any expectation F
i can then be calculated
simply by counting the corresponding statistics in
the generated chain.
Generally speaking, variational methods frame
marginal inference as an optimization problem. Ei-
ther in the sense of minimizing the KL divergence
of a much simpler distribution to the actual distribu-
tion pF , as in mean field methods. Or in the sense of
maximizing a variational representation of the log-
partition function over the set M of valid mean vec-
tors (Wainwright and Jordan, 2008). Note that the
variational representation of the log partition func-
tion involves an entropy term that is intractable to
calculate in general and therefore usually approxi-
mated. Likewise, the set of constraints that guaran-
tee vectors to be valid mean vectors is intractably
large and is often simplified.
Because we use belief propagation (BP) as base-
line to compare to, and as a subroutine in our pro-
posed algorithm, a brief characterization of it is in
order. BP can be seen as a variational method that
</bodyText>
<page confidence="0.98819">
762
</page>
<bodyText confidence="0.994015928571429">
\x0cuses the Bethe Free Energy as approximation to the
entropy, and the set ML of locally consistent mean
vectors as an outer bound on M. A mean vector is
locally consistent if its beliefs on factors are consis-
tent with the beliefs of the factor neighbors.
BP solves the variational problem by iteratively
updating the beliefs of factors and variables based
on the current beliefs of their neighbors. When ap-
plied to acyclic graphical models BP yields the exact
marginals at convergence. For general graphs, BP is
not guaranteed to converge, and the beliefs it calcu-
lates are generally not the true marginals; however,
in practice BP often does converge and lead to accu-
rate marginals.
</bodyText>
<sectionHeader confidence="0.99139" genericHeader="method">
4 Relaxed Incremental Marginal Inference
</sectionHeader>
<bodyText confidence="0.999341710526316">
Generally the runtime and accuracy of a marginal in-
ference method depends on size, density, tree-width
and interaction strength (i.e. the magnitude of its
weights) of the Graphical Model. For example, in
Belief Propagation the number of messages we have
to send in each iteration scales with the number of
factors (and their degrees). This means that when
we add a large number of extra factors to our model,
such as the O(n3) grandparent and sibling factors
for dependency parsing, we have to pay a price in
terms of speed, sometimes even accuracy.
However, on close inspection often many of the
additional factors we use to model some higher or-
der interactions are somewhat unnecessary or redun-
dant. To illustrate this, let us look at a second or-
der parsing model with grandparent factors. Surely
determiners are not heads of other determiners, and
this should be easy to encourage using LINK fea-
tures only. Hence, a grandparent factor that dis-
courages a determiner-determiner-determiner chain
seems unnecessary.
This raises two questions: (a) can we get away
without most of these factors, and (b) can we effi-
ciently tell which factors should be discarded. We
will see in section 5 that question (a) can be an-
swered affirmatively: with a only fraction of all sec-
ond order factors we can calculate marginals that are
very close to the BP marginals, and when used in
MBR decoding, lead to the same trees.
Question (b) can be approached by looking at how
a similar problem has been tackled in combinato-
rial optimization and MAP inference. Riedel and
Clarke (2006) tackled the MAP problem for depen-
dency parsing by an incremental approach that starts
with a relaxation of the problem, solves it, and adds
additional constraints only if they are violated. If
constraints were added, the process is repeated, oth-
erwise we terminate.
</bodyText>
<subsectionHeader confidence="0.996814">
4.1 Evaluating Candidate Factors
</subsectionHeader>
<bodyText confidence="0.998626125">
To develop such an incremental relaxation approach
to marginal inference, we generalize the notion of a
violated constraint. What does it mean for a factor to
be violated with respect to the solution of a marginal
inference problem?
One answer is to interpret the violation of a con-
straint as adding this constraint will impact our cur-
rent belief. To assess the impact of adding factor
i to a sub-graph F0 F we can then use the fol-
lowing intuition: if the distribution F0 {i} is very
similar to the distribution corresponding to F0, it is
probably safe to say that the marginals we get from
both are close, too. If we use the KL divergence be-
tween the (distributions of) F0 {i} and F0 for our
interpretation of the above mentioned closeness, we
can define a potential gain for adding i as follows:
</bodyText>
<equation confidence="0.9902934">
gF0 (i)
def
= DKL pF0 ||pF0{i}
\x01
.
</equation>
<bodyText confidence="0.971750642857143">
Together with a threshold \x0f on this gain we can
now adapt the relaxation approach to marginal in-
ference by simply replacing the question, Is i vi-
olated? with the question, Is gF0 (i) &amp;gt; \x0f? We
can see the latter question as a generalization of the
former if we interpret MAP inference as the zero-
temperature limit of marginal inference (Wainwright
and Jordan, 2008).
The form of the gain function is chosen to be eas-
ily evaluated using the beliefs we have already avail-
able for the current sub-graph F0. It is easy to show
(see Appendix) that the following holds:
Proposition 1. The gain of a factor i with respect
to the sub-graph F0 F is
</bodyText>
<equation confidence="0.99925425">
gF0 (i) = log
\x10
F0
i + F0
i ei
\x11
F0
i i (3)
</equation>
<bodyText confidence="0.73167475">
That is, the gain of a factor i depends on two
properties of i. First, the expectation F0
i that
i fires under the current model F0, and second,
</bodyText>
<page confidence="0.968114">
763
</page>
<bodyText confidence="0.9602285">
\x0cits loglinear weight i. To get an intuition for this
gain, consider the limit limF0
</bodyText>
<equation confidence="0.9644335">
i 1
gF0 (i) of a fac-
</equation>
<bodyText confidence="0.9879856">
tor with positive weight that is expected to be active
under F0. In this case the gain becomes zero, mean-
ing that the more likely i fires under the current
model, the less useful will it be to add according to
our gain. For limF0
</bodyText>
<equation confidence="0.6536035">
i 0
gF0 (i) the gain also disap-
</equation>
<bodyText confidence="0.984046545454546">
pears. Here the confidence of the current model in i
being inactive is so high that any single factor which
indicates the opposite cannot make a difference.
Fortunately, the marginal probability F0
i is usu-
ally available after inference, or can be approxi-
mated. This allows us to maintain the same basic
algorithm as in the MAP case: in each inspection
step we can use the results of the last run of infer-
ence in order to evaluate whether a factor has to be
added or not.
</bodyText>
<subsectionHeader confidence="0.981232">
4.2 Algorithm
</subsectionHeader>
<bodyText confidence="0.998363074074074">
Algorithm 1 shows our proposed algorithm, Relaxed
Marginal Inference. We are given an initial factor
graph (for example, the first order dependency pars-
ing model), a threshold \x0f on the minimal gain a fac-
tor needs to have in order to be added, and a solver S
for marginal inference in the partial graphs we gen-
erate along the way.
We start by finding the marginals for the initial
graph. These marginals are then used in step 4 to
find the factors that would, when added in isolation,
change the distribution substantially (i.e., by more
than \x0f in terms of KL divergence). We will refer
to this step as separation, in line with cutting plane
terminology. The factors are added to the current
graph, and we start from the top unless there were
no new factors added. In this case we return the last
marginals .
Clearly, this algorithm is guaranteed to converge:
either we add at least one factor per iteration until
we reach the full graph F, or we converge before.
However, it is difficult to make any general state-
ments about the number of iterations it takes until
convergence. Nevertheless, in our experiments we
find that algorithm 1 converges to a much smaller
graph after a small number of iterations, and hence
we are always faster than inference on the full graph.
Finally, note that calculating the gain for all fac-
</bodyText>
<figure confidence="0.7834516">
tors in F \\ F0 in step 4 (separation) takes time pro-
Algorithm 1 Relaxed Marginal Inference.
1: require:
F0:init. graph, \x0f: threshold, S:solver, R: max. it
2: repeat
Find current marginals using solver S
3: marginals(F
0
, S)
Find factors with high gain not yet added
4: F {i F \\ F
0
|gF0 (i) &amp;gt; \x0f}
Add factors to current graph
5: F0 F0 F
Check: no more new factors were added or R reached
6: until F = or iteration &amp;gt;R
return the marginals for the last graph F0
7: return
portional to |F \\ F0|.
</figure>
<subsectionHeader confidence="0.995457">
4.3 Accuracy
</subsectionHeader>
<bodyText confidence="0.991502333333333">
We have seen how to evaluate the potential gain
when adding a single factor. However, this does
not tell us how good the current sub-model is with
respect to the complete graph. After all, while all
remaining factors individually might not contribute
much, in concert they may. We therefore present a
(calculable) bound on the KL divergence of the par-
tial graph from the full graph that can give us confi-
dence in the solutions we return at convergence.
Note that for this bound we still only need fea-
ture expectations from the current model. More-
over, we assume all weights i are positivewithout
loss of generality since we can always replace i
with its negation 1 i and then change the sign
of i (Richardson and Domingos, 2006).
</bodyText>
<figure confidence="0.837813692307692">
Proposition 2. Assume non-negative weights, let
F0 F be a subset of factors, G
def
= F \\ F0 and
def
= kGk1 hG, Gi 0. Then
1. for the KL divergence between F0 and the full
network F we have:
DKL pF0 ||pF
\x01
.
2. for the error we make when estimating is true
expectation F
</figure>
<equation confidence="0.990568444444445">
i by F0
i we have:
(e
1) F0
i F
i F0
i (e
1) F0
i .
</equation>
<page confidence="0.981532">
764
</page>
<bodyText confidence="0.9981426">
\x0cThis says that (1) we get closer to the full distri-
bution and that (2) our marginals closer to the true
marginals, if the remaining factors G either have
a low total weight kGk, or the current belief G
already assigns high probability to the features G
being active (and hence hG, Gi is small). The
latter condition is the probabilistic analog to con-
straints already being satisfied. Finally, since can
be easily calculated, we plan to investigate its utility
as a convergence criterion in future work.
</bodyText>
<subsectionHeader confidence="0.812216">
4.4 Related Work
</subsectionHeader>
<bodyText confidence="0.999461129032258">
Our approach is inspired by earlier work on re-
laxation algorithms for performing MAP inference
by incrementally tightening relaxations of a graph-
ical model (Anguelov et al., 2004; Riedel, 2008),
weighted Finite State Machine (Tromble and Eisner,
2006), Integer Linear Program (Riedel and Clarke,
2006) or Marginal Polytope (Sontag et al., 2008).
However, none of these methods apply to marginal
inference.
Sontag and Jaakkola (2007) compute marginal
probabilities by using a cutting plane approach that
starts with the local polytope and then optimizes
some approximation of the log partition function.
Cycle consistency constraints are added if they are
violated by the current marginals, and the process is
repeated until no more violations appear. While this
approach does tackle marginalization, it is focused
on improving its accuracy. In particular, the opti-
mization problems they solve in each iteration are in
fact larger than the problem we want to relax.
Our approach is also related to edge deletion
in Bayesian networks (Choi and Darwiche, 2006).
Here edges are removed from a Bayesian network in
order to find a close approximation to the full net-
work useful for other inference-related tasks (such
as combined marginal and MAP inference). The
core difference to our approach is the fact that they
ask which edges to remove from the full graph, in-
stead of which to add to a partial graph. This re-
quires inference in the full modelthe very opera-
tion we want to avoid.
</bodyText>
<sectionHeader confidence="0.999329" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999518555555556">
In our experiments we seek to answer the following
questions. First, how fast is our relaxation approach
compared to full marginal inference at comparable
dependency accuracy? This requires us to find the
best tree in terms of marginal probabilities on the
link variables (Smith and Eisner, 2008). Second,
how good is the final relaxed graph as an approxima-
tion of the full graph? Finally, how does incremental
relaxation scale with sentence length?
</bodyText>
<subsectionHeader confidence="0.990985">
5.1 Data and Models
</subsectionHeader>
<bodyText confidence="0.9958844">
We trained and tested on a subset of languages
from the CoNLL Dependency Parsing Shared
Tasks (Nivre et al., 2007): Dutch, Danish, Italian,
and English. We apply non-projective second order
models for Dutch, Danish and Italian, and a projec-
tive second order model for English. To be able to
compare inference on the same model, we trained
using BP on the full set of LINK, GRAND, and SIB
factors.
Note that our models would rank highly among
the shared task submissions, but could surely be fur-
ther improved. For example, we do not use any lan-
guage specific features. Since our focus in this paper
is speeding up marginal inference, we will search for
better models in future work.
</bodyText>
<subsectionHeader confidence="0.994702">
5.2 Runtime and Dependency Accuracy
</subsectionHeader>
<bodyText confidence="0.998362">
In our first set of experiments we explore the speed
and accuracy of relaxed BP in comparison to full BP.
To this end we first tested BP configurations with at
most 5, at most 10, and at most 50 iterations to find
the best setup in terms of speed and accuracy. Smith
and Eisner (2008) use 5 iterations but we found that
by using 10 iterations accuracy could be slightly im-
proved. Running at most 50 iterations led to the
same accuracy but was significantly slower. Hence
we only report BP results with 10 iterations here.
For relaxed BP we tested along three dimensions:
the threshold \x0f on the gain of factors, the maximum
number of BP iterations in the inner loop of relaxed
BP, and the maximum number of relaxation itera-
tions. A configuration with maximum relaxation it-
erations R, threshold \x0f, and maximum BP iterations
B will be identified by RelR,\x0f,B. In all settings we
use the LINK factors and the hard factors as initial
graph F0.
Table 1 shows the results for several configura-
tions and our four languages in terms of unlabeled
dependency accuracy (percentage of correctly iden-
</bodyText>
<page confidence="0.996852">
765
</page>
<table confidence="0.996697">
\x0cDutch Danish English Italian
Configuration Acc. Time Acc. Time Acc. Time Acc. Time
BP 84.9 0.665 88.1 1.44 88.3 2.43 87.4 1.68
Rel,0.0001,5 85.0 0.120 88.1 0.234 88.2 0.575 87.4 0.261
Rel,0.0001,50 84.9 0.121 88.2 0.236 88.3 0.728 87.4 0.266
Rel1,0.0001,50 84.9 0.060 88.2 0.110 88.4 0.352 87.4 0.132
</table>
<tableCaption confidence="0.998562">
Table 1: Dependency accuracy (%) and average parsing time (sec.) using second order models.
</tableCaption>
<bodyText confidence="0.9885334">
tified heads) in comparison to the gold data, and av-
erage parsing time in seconds. Here parsing time
includes both time spent for marginal inference and
the MBR decoding step after the marginals are avail-
able.
We notice that by relaxing BP with no limit on the
number of iterations we gain a 4-6 fold increase in
parsing speed across all languages when using the
threshold \x0f = 0.0001, while accuracy remains as
high as for full BP. This can be achieved with fewer
BP iterations (at most 5) in each round of relaxation
than full BP needs per sentence (at most 10). Intu-
itively this makes sense: since our factor graphs are
smaller in each iteration there will be fewer cycles
to slow down convergence. This only has a small
impact on overall parsing time for languages other
than English, since for most sentences even full BP
converges after less than 10 iterations.
We also observe that running just one iteration of
our relaxation algorithm (Rel1,0.0001,50) is enough to
achieve accurate solutions. This leads to a twofold
speed-up in comparison to running relaxation until
convergence (primarily because of fewer calls to the
separation routine), and a 7-13 fold speed-up (ten-
fold on average) when compared to full BP.
</bodyText>
<subsectionHeader confidence="0.999137">
5.3 Quality of Relaxed Subgraphs
</subsectionHeader>
<bodyText confidence="0.996409636363636">
How large is the fraction of the full graph needed
for accurate marginal probabilities? And do we re-
ally need our relaxation algorithm with repeated in-
ference or could we instead just prune the graph in
advance? Here we try to answer these questions, and
will focus on the Danish dataset. Note that our re-
sults for the other languages follow the same pattern.
In table 2, we present the average ratio of the sizes
of the partial and the full graph in terms of the sec-
ond order factors. We also show the total runtime
needed to find the subgraph and run inference in it.
</bodyText>
<table confidence="0.996447142857143">
Configuration Size Time Err. Acc.
BP 100% 1.44 88.1
Rel,0.1,50 0% 0.12 0.20 87.5
Rel,0.0001,50 0.8% 0.24 0.012 88.2
Rel1,0.0001,50 0.8% 0.11 0.015 88.2
Pruned0.1 42% 0.56 0.022 88.0
Pruned0.5 22% 0.40 0.098 87.7
</table>
<tableCaption confidence="0.997807">
Table 2: Ratio of partial and full graph size (Size),
</tableCaption>
<bodyText confidence="0.992412857142857">
runtime in seconds (Time), avg. error on marginals
(Err.) and tree accuracy (Acc.) for Danish.
As a measure of accuracy for marginal probabilities
we find the average error in marginal probability for
the variables of a sentence. Note that this measure
does not necessarily correspond to the true error of
our marginals because BP itself is approximate and
may not return the correct marginals.
The first row shows the full BP system, working
on 100% of the factor graph. The next three rows
look at relaxed marginal inference. We notice that
with a low threshold \x0f = 0.1 we pick almost no ad-
ditional factors (0.003%), and this does affect accu-
racy. However, by lowering the threshold to 0.0001
and adding about 0.8% of the second order factors,
we already match the dependency accuracy of full
BP. On average we are also very close to the BP
marginals.
Can we find such small graphs without running
extra iterations of inference? One approach could
be to simply cut off factors i with absolute weights
|i |that fall under a certain threshold t. In the final
rows of the table we test such an approach with t =
0.1, 0.5.
We notice that pruning can reduce the second or-
der factors to 42% while yielding (almost) the same
accuracy, and close marginals. However, it is 5 times
slower than our fastest approach. When reducing
</bodyText>
<page confidence="0.95782">
766
</page>
<figure confidence="0.9956519">
\x0c0 20 40 60
0
20
40
60
Sentence Length
Time BP
Pruned
Relaxed
Relaxed 1 It.
</figure>
<figureCaption confidence="0.999787">
Figure 1: Total runtimes by sentence length.
</figureCaption>
<bodyText confidence="0.9827256">
size further to about 20%, accuracy drops below the
values we achieved with our relaxation approach at
0.8% of the second order factors. Hence simple
pruning removes factors that do have a low weight,
but are still important to keep.
</bodyText>
<subsectionHeader confidence="0.576208">
5.4 Runtime with Varying Sentence Length
</subsectionHeader>
<bodyText confidence="0.998837333333333">
We have seen how relaxed BP is faster than full
BP on average. But how does its speed scale with
sentence length? To answer this question figure 1
shows a plot of runtime by sentence length for full
BP, pruned BP with threshold 0.1, Rel,0.0001,50 and
Rel1,0.0001,50.
The graph indicates that the advantage of relaxed
BP over both full BP and Pruned BP becomes even
more significant for longer sentences, in particular
when running only one iteration. This shows that by
using our technique, second order parsing becomes
more practical, in particular for very long sentences.
</bodyText>
<sectionHeader confidence="0.997873" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999810857142857">
We have presented a novel incremental relaxation al-
gorithm that can be applied to marginal inference.
Instead of adding violated constraints in each iter-
ation, it adds factors that significantly change the
distribution of the graph. This notion is formalized
by the introduction of a gain function that calculates
the KL divergence between the current network with
and without the candidate factor. We show how this
gain can be calculated and provide bounds on the er-
ror made by the marginals of the relaxed graph in
place of the full one.
Our algorithm led to a tenfold reduction in run-
time at comparable accuracy when applied to multi-
lingual dependency parsing with Belief Propagation.
It is five times faster than pruning factors by their
absolute weight, and results in smaller graphs with
better marginals.
In future work we plan to apply relaxed marginal
inference to larger joint inference problems within
NLP, and test its effectiveness with other marginal
inference algorithms as solvers in the inner loop.
</bodyText>
<sectionHeader confidence="0.966233" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.943194571428571">
This work was supported in part by the Center for
Intelligent Information Retrieval and in part by SRI
International subcontract #27-001338 and ARFL
prime contract #FA8750-09-C-0181. Any opinions,
findings and conclusions or recommendations ex-
pressed in this material are the authors and do not
necessarily reflect those of the sponsor.
</bodyText>
<figure confidence="0.982343">
Appendix: Proof Sketches
For Proposition 1 we use the primal form of the KL diver-
gence (Wainwright and Jordan, 2008)
D
`
p0
F ||pF
= log
`
ZF Z1
F0
hF 0 , F F0 i
and represent the ratio ZF Z1
F0 of partition functions as
ZF
ZF0
=
X
y
ehF0 ,F0 (y)i
ZF0
ehG,G(y)i
= EF0
h
ehG,Gi
i
where G
def
= F \\ F0
. With G = {i} we get the desired gain.
For Proposition 2, part 1, we first pick a simple upper bound
on ZF Z1
F0 by replacing the expectation with ekGk1 . Insert-
</figure>
<bodyText confidence="0.935873">
ing this into the primal form KL divergence leads to the given
bound. For part 2 we represent pF using pF0
</bodyText>
<equation confidence="0.942251333333333">
pF (y) = ZF0 Z1
F ehG,G(y)i
pF0 (y)
</equation>
<bodyText confidence="0.941065">
and reuse our above representation of ZF Z1
</bodyText>
<equation confidence="0.840107666666667">
F0 . This gives
pF (y) = EF0
h
ehG,G(y)i
i1
pF0 (y) ehG,G(y)i
</equation>
<bodyText confidence="0.938238333333333">
which can be upper bounded by lower bounding the expectation
and upper bounding the log-linear term. For the latter we use
ekGk1 , for the first Jensens inequality gives
</bodyText>
<figure confidence="0.9928223">
EF0
h
ehG,G(y)i
i1
eEF0 [hG,G(y)i]
= e
D
G,F0
G
E
</figure>
<bodyText confidence="0.878661333333334">
where the equality follows from linearity of expectations. This
yields pF (y) pF0 (y) e
and therefore upper bounds on F
i
and F
i. Basic algebra then gives the desired error interval for
</bodyText>
<equation confidence="0.395955666666667">
F
i in terms of F0
i .
</equation>
<page confidence="0.716299">
767
</page>
<reference confidence="0.994392089552239">
\x0cReferences
D. Anguelov, D. Koller, P. Srinivasan, S. Thrun, H.-C.
Pang, and J. Davis. 2004. The correlated correspon-
dence algorithm for unsupervised registration of non-
rigid surfaces. In Advances in Neural Information
Processing Systems (NIPS 04), pages 3340.
Arthur Choi and Adnan Darwiche. 2006. A varia-
tional approach for approximating bayesian networks
by edge deletion. In Proceedings of the Proceedings
of the Twenty-Second Conference Annual Conference
on Uncertainty in Artificial Intelligence (UAI-06), Ar-
lington, Virginia. AUAI Press.
Jenny Rose Finkel, Trond Grenager, and Christopher
Manning. 2005. Incorporating non-local informa-
tion into information extraction systems by gibbs sam-
pling. In Proceedings of the 43rd Annual Meeting of
the Association for Computational Linguistics (ACL
05), pages 363370, June.
R. McDonald and F. Pereira. 2006. Online learning
of approximate dependency parsing algorithms. In
Proceedings of the 11th Conference of the European
Chapter of the ACL (EACL 06), pages 8188.
Ryan McDonald and Giorgio Satta. 2007. On the com-
plexity of non-projective data-driven dependency pars-
ing. In IWPT 07: Proceedings of the 10th Inter-
national Conference on Parsing Technologies, pages
121132, Morristown, NJ, USA. Association for Com-
putational Linguistics.
J. Nivre, J. Hall, S. Kubler, R. McDonald, J. Nilsson,
S. Riedel, and D. Yuret. 2007. The conll 2007 shared
task on dependency parsing. In Conference on Em-
pirical Methods in Natural Language Processing and
Natural Language Learning, pages 915932.
Matt Richardson and Pedro Domingos. 2006. Markov
logic networks. Machine Learning, 62:107136.
Sebastian Riedel and James Clarke. 2006. Incremen-
tal integer linear programming for non-projective de-
pendency parsing. In Proceedings of the Conference
on Empirical methods in natural language processing
(EMNLP 06), pages 129137.
Sebastian Riedel. 2008. Improving the accuracy and ef-
ficiency of MAP inference for markov logic. In Pro-
ceedings of the 24th Annual Conference on Uncer-
tainty in AI (UAI 08), pages 468475.
David A. Smith and Jason Eisner. 2008. Dependency
parsing by belief propagation. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP), pages 145156, Hon-
olulu, October.
D. Sontag and T. Jaakkola. 2007. New outer bounds on
the marginal polytope. In Advances in Neural Infor-
mation Processing Systems (NIPS 07), pages 1393
1400.
David Sontag, T. Meltzer, A. Globerson, T. Jaakkola, and
Y. Weiss. 2008. Tightening LP relaxations for MAP
using message passing. In Proceedings of the 24th An-
nual Conference on Uncertainty in AI (UAI 08).
Roy W. Tromble and Jason Eisner. 2006. A fast
finite-state relaxation method for enforcing global con-
straints on sequence decoding. In Joint Human Lan-
guage Technology Conference/Annual Meeting of the
North American Chapter of the Association for Com-
putational Linguistics (HLT-NAACL 06), pages 423
430.
Martin Wainwright and Michael Jordan. 2008. Graphi-
cal Models, Exponential Families, and Variational In-
ference. Now Publishers.
</reference>
<page confidence="0.966648">
768
</page>
<figure confidence="0.253267">
\x0c&amp;apos;
</figure>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.773936">
<note confidence="0.926266333333333">b&amp;apos;Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 760768, Los Angeles, California, June 2010. c 2010 Association for Computational Linguistics</note>
<title confidence="0.992403">Relaxed Marginal Inference and its Application to Dependency Parsing</title>
<author confidence="0.999956">Sebastian Riedel David A Smith</author>
<affiliation confidence="0.9974115">Department of Computer Science University of Massachusetts, Amherst</affiliation>
<email confidence="0.999691">riedel@cs.umass.edu</email>
<email confidence="0.999691">dasmith@cs.umass.edu</email>
<abstract confidence="0.996284894736842">Recently, relaxation approaches have been successfully used for MAP inference on NLP problems. In this work we show how to extend the relaxation approach to marginal inference used in conditional likelihood training, posterior decoding, confidence estimation, and other tasks. We evaluate our approach for the case of second-order dependency parsing and observe a tenfold increase in parsing speed, with no loss in accuracy, by performing inference over a small subset of the full factor graph. We also contribute a bound on the error of the marginal probabilities by a sub-graph with respect to the full graph. Finally, while only evaluated with BP in this paper, our approach is general enough to be applied with any marginal inference method in the inner loop.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Pang</author>
<author>J Davis</author>
</authors>
<title>The correlated correspondence algorithm for unsupervised registration of nonrigid surfaces.</title>
<date>2004</date>
<booktitle>In Advances in Neural Information Processing Systems (NIPS 04),</booktitle>
<pages>3340</pages>
<marker>Pang, Davis, 2004</marker>
<rawString>Pang, and J. Davis. 2004. The correlated correspondence algorithm for unsupervised registration of nonrigid surfaces. In Advances in Neural Information Processing Systems (NIPS 04), pages 3340.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arthur Choi</author>
<author>Adnan Darwiche</author>
</authors>
<title>A variational approach for approximating bayesian networks by edge deletion.</title>
<date>2006</date>
<booktitle>In Proceedings of the Proceedings of the Twenty-Second Conference Annual Conference on Uncertainty in Artificial Intelligence (UAI-06),</booktitle>
<publisher>AUAI Press.</publisher>
<location>Arlington, Virginia.</location>
<contexts>
<context position="21665" citStr="Choi and Darwiche, 2006" startWordPosition="3739" endWordPosition="3742">compute marginal probabilities by using a cutting plane approach that starts with the local polytope and then optimizes some approximation of the log partition function. Cycle consistency constraints are added if they are violated by the current marginals, and the process is repeated until no more violations appear. While this approach does tackle marginalization, it is focused on improving its accuracy. In particular, the optimization problems they solve in each iteration are in fact larger than the problem we want to relax. Our approach is also related to edge deletion in Bayesian networks (Choi and Darwiche, 2006). Here edges are removed from a Bayesian network in order to find a close approximation to the full network useful for other inference-related tasks (such as combined marginal and MAP inference). The core difference to our approach is the fact that they ask which edges to remove from the full graph, instead of which to add to a partial graph. This requires inference in the full modelthe very operation we want to avoid. 5 Experiments In our experiments we seek to answer the following questions. First, how fast is our relaxation approach compared to full marginal inference at comparable dependen</context>
</contexts>
<marker>Choi, Darwiche, 2006</marker>
<rawString>Arthur Choi and Adnan Darwiche. 2006. A variational approach for approximating bayesian networks by edge deletion. In Proceedings of the Proceedings of the Twenty-Second Conference Annual Conference on Uncertainty in Artificial Intelligence (UAI-06), Arlington, Virginia. AUAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Trond Grenager</author>
<author>Christopher Manning</author>
</authors>
<title>Incorporating non-local information into information extraction systems by gibbs sampling.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL 05),</booktitle>
<pages>363370</pages>
<contexts>
<context position="2952" citStr="Finkel et al., 2005" startWordPosition="449" endWordPosition="452"> 2007), we have non-projective languages such as Dutch using second order projective models if we want to apply DP. Some previous work has circumvented this problem for MAP inference by starting with a second-order projective solution and then greedily flipping edges to find a better nonprojective solution (McDonald and Pereira, 2006). In order to explore richer model structures, the NLP community has recently started to investigate the use of other, well-known machine learning techniques for marginal inference. One such technique is Markov chain Monte Carlo, and in particular Gibbs sampling (Finkel et al., 2005), another is (loopy) sum-product belief propagation (Smith and Eisner, 2008). In both cases we usually work in the framework of graphical modelsin our case, with factor graphs that describe our distributions through variables, factors, and factor potentials. In theory, methods such as belief propagation can take any graph and perform marginal inference. This means that we gain a great amount of flexibility to represent more global and joint distributions for NLP tasks. The graphical models of interest, however, are often too large and densely connected for efficient inference in them. For exam</context>
</contexts>
<marker>Finkel, Grenager, Manning, 2005</marker>
<rawString>Jenny Rose Finkel, Trond Grenager, and Christopher Manning. 2005. Incorporating non-local information into information extraction systems by gibbs sampling. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL 05), pages 363370, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>F Pereira</author>
</authors>
<title>Online learning of approximate dependency parsing algorithms.</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th Conference of the European Chapter of the ACL (EACL 06),</booktitle>
<pages>8188</pages>
<contexts>
<context position="2668" citStr="McDonald and Pereira, 2006" startWordPosition="405" endWordPosition="408">is requires the model to factor in a way that lends itself to DP algorithms, we have to restrict the class of probabilistic models we consider. For example, since we cannot derive a dynamic program for marginal inference in second order non-projective dependency parsing (McDonald and Satta, 2007), we have non-projective languages such as Dutch using second order projective models if we want to apply DP. Some previous work has circumvented this problem for MAP inference by starting with a second-order projective solution and then greedily flipping edges to find a better nonprojective solution (McDonald and Pereira, 2006). In order to explore richer model structures, the NLP community has recently started to investigate the use of other, well-known machine learning techniques for marginal inference. One such technique is Markov chain Monte Carlo, and in particular Gibbs sampling (Finkel et al., 2005), another is (loopy) sum-product belief propagation (Smith and Eisner, 2008). In both cases we usually work in the framework of graphical modelsin our case, with factor graphs that describe our distributions through variables, factors, and factor potentials. In theory, methods such as belief propagation can take an</context>
</contexts>
<marker>McDonald, Pereira, 2006</marker>
<rawString>R. McDonald and F. Pereira. 2006. Online learning of approximate dependency parsing algorithms. In Proceedings of the 11th Conference of the European Chapter of the ACL (EACL 06), pages 8188.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Giorgio Satta</author>
</authors>
<title>On the complexity of non-projective data-driven dependency parsing.</title>
<date>2007</date>
<booktitle>In IWPT 07: Proceedings of the 10th International Conference on Parsing Technologies,</booktitle>
<pages>121132</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="2338" citStr="McDonald and Satta, 2007" startWordPosition="353" endWordPosition="356"> probabilities (perhaps subject to hard constraints) in order to predict a good variable assignment.1 1 With a loss function that decomposes on the variables, this amounts to Minimum Bayes Risk (MBR) decoding, which is Traditionally, marginal inference in NLP has been performed via dynamic programming (DP); however, because this requires the model to factor in a way that lends itself to DP algorithms, we have to restrict the class of probabilistic models we consider. For example, since we cannot derive a dynamic program for marginal inference in second order non-projective dependency parsing (McDonald and Satta, 2007), we have non-projective languages such as Dutch using second order projective models if we want to apply DP. Some previous work has circumvented this problem for MAP inference by starting with a second-order projective solution and then greedily flipping edges to find a better nonprojective solution (McDonald and Pereira, 2006). In order to explore richer model structures, the NLP community has recently started to investigate the use of other, well-known machine learning techniques for marginal inference. One such technique is Markov chain Monte Carlo, and in particular Gibbs sampling (Finkel</context>
</contexts>
<marker>McDonald, Satta, 2007</marker>
<rawString>Ryan McDonald and Giorgio Satta. 2007. On the complexity of non-projective data-driven dependency parsing. In IWPT 07: Proceedings of the 10th International Conference on Parsing Technologies, pages 121132, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
<author>J Hall</author>
<author>S Kubler</author>
<author>R McDonald</author>
<author>J Nilsson</author>
<author>S Riedel</author>
<author>D Yuret</author>
</authors>
<title>The conll</title>
<date>2007</date>
<booktitle>In Conference on Empirical Methods in Natural Language Processing and Natural Language Learning,</booktitle>
<pages>915932</pages>
<contexts>
<context position="22686" citStr="Nivre et al., 2007" startWordPosition="3914" endWordPosition="3917">on we want to avoid. 5 Experiments In our experiments we seek to answer the following questions. First, how fast is our relaxation approach compared to full marginal inference at comparable dependency accuracy? This requires us to find the best tree in terms of marginal probabilities on the link variables (Smith and Eisner, 2008). Second, how good is the final relaxed graph as an approximation of the full graph? Finally, how does incremental relaxation scale with sentence length? 5.1 Data and Models We trained and tested on a subset of languages from the CoNLL Dependency Parsing Shared Tasks (Nivre et al., 2007): Dutch, Danish, Italian, and English. We apply non-projective second order models for Dutch, Danish and Italian, and a projective second order model for English. To be able to compare inference on the same model, we trained using BP on the full set of LINK, GRAND, and SIB factors. Note that our models would rank highly among the shared task submissions, but could surely be further improved. For example, we do not use any language specific features. Since our focus in this paper is speeding up marginal inference, we will search for better models in future work. 5.2 Runtime and Dependency Accur</context>
</contexts>
<marker>Nivre, Hall, Kubler, McDonald, Nilsson, Riedel, Yuret, 2007</marker>
<rawString>J. Nivre, J. Hall, S. Kubler, R. McDonald, J. Nilsson, S. Riedel, and D. Yuret. 2007. The conll 2007 shared task on dependency parsing. In Conference on Empirical Methods in Natural Language Processing and Natural Language Learning, pages 915932.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matt Richardson</author>
<author>Pedro Domingos</author>
</authors>
<title>Markov logic networks.</title>
<date>2006</date>
<booktitle>Machine Learning,</booktitle>
<pages>62--107136</pages>
<contexts>
<context position="19752" citStr="Richardson and Domingos, 2006" startWordPosition="3408" endWordPosition="3411">t tell us how good the current sub-model is with respect to the complete graph. After all, while all remaining factors individually might not contribute much, in concert they may. We therefore present a (calculable) bound on the KL divergence of the partial graph from the full graph that can give us confidence in the solutions we return at convergence. Note that for this bound we still only need feature expectations from the current model. Moreover, we assume all weights i are positivewithout loss of generality since we can always replace i with its negation 1 i and then change the sign of i (Richardson and Domingos, 2006). Proposition 2. Assume non-negative weights, let F0 F be a subset of factors, G def = F \\ F0 and def = kGk1 hG, Gi 0. Then 1. for the KL divergence between F0 and the full network F we have: DKL pF0 ||pF \x01 . 2. for the error we make when estimating is true expectation F i by F0 i we have: (e 1) F0 i F i F0 i (e 1) F0 i . 764 \x0cThis says that (1) we get closer to the full distribution and that (2) our marginals closer to the true marginals, if the remaining factors G either have a low total weight kGk, or the current belief G already assigns high probability to the features G being activ</context>
</contexts>
<marker>Richardson, Domingos, 2006</marker>
<rawString>Matt Richardson and Pedro Domingos. 2006. Markov logic networks. Machine Learning, 62:107136.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Riedel</author>
<author>James Clarke</author>
</authors>
<title>Incremental integer linear programming for non-projective dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of the Conference on Empirical methods in natural language processing (EMNLP 06),</booktitle>
<pages>129137</pages>
<contexts>
<context position="4548" citStr="Riedel and Clarke, 2006" startWordPosition="706" endWordPosition="709">s, and the advantage second order models give in accuracy is often not significant enough to offset the lack of speed in practice. Moreover, if we extend such parsing models to, say, penalizing all pairs of crossing edges or scoring syntax-based alignments, we will need to inspect at least O n4 \x01 factors, increasing our efficiency concerns. When looking at the related task of finding the most likely assignment in large graphical models (i.e., MAP inference), we notice that several recent approaches have significantly sped up computation through relaxation methods (Tromble and Eisner, 2006; Riedel and Clarke, 2006). Here we start with a small subset of the full graph, and run inference for this simpler problem. Then we search for factors that are violated in the solution, and add them to the graph. This is repeated until no more new factors can be added. Empirically this approach has shown impressive success. It often dramatically reduces the effective network size, with no loss in accuracy. How can we extend or generalize MAP relaxation algorithms to the case of marginal inference? Roughly speaking, we answer it by introducing a notion of factor gain that is defined as the KL divergence between the cur</context>
<context position="14347" citStr="Riedel and Clarke (2006)" startWordPosition="2415" endWordPosition="2418">hat discourages a determiner-determiner-determiner chain seems unnecessary. This raises two questions: (a) can we get away without most of these factors, and (b) can we efficiently tell which factors should be discarded. We will see in section 5 that question (a) can be answered affirmatively: with a only fraction of all second order factors we can calculate marginals that are very close to the BP marginals, and when used in MBR decoding, lead to the same trees. Question (b) can be approached by looking at how a similar problem has been tackled in combinatorial optimization and MAP inference. Riedel and Clarke (2006) tackled the MAP problem for dependency parsing by an incremental approach that starts with a relaxation of the problem, solves it, and adds additional constraints only if they are violated. If constraints were added, the process is repeated, otherwise we terminate. 4.1 Evaluating Candidate Factors To develop such an incremental relaxation approach to marginal inference, we generalize the notion of a violated constraint. What does it mean for a factor to be violated with respect to the solution of a marginal inference problem? One answer is to interpret the violation of a constraint as adding </context>
<context position="20909" citStr="Riedel and Clarke, 2006" startWordPosition="3621" endWordPosition="3624">ef G already assigns high probability to the features G being active (and hence hG, Gi is small). The latter condition is the probabilistic analog to constraints already being satisfied. Finally, since can be easily calculated, we plan to investigate its utility as a convergence criterion in future work. 4.4 Related Work Our approach is inspired by earlier work on relaxation algorithms for performing MAP inference by incrementally tightening relaxations of a graphical model (Anguelov et al., 2004; Riedel, 2008), weighted Finite State Machine (Tromble and Eisner, 2006), Integer Linear Program (Riedel and Clarke, 2006) or Marginal Polytope (Sontag et al., 2008). However, none of these methods apply to marginal inference. Sontag and Jaakkola (2007) compute marginal probabilities by using a cutting plane approach that starts with the local polytope and then optimizes some approximation of the log partition function. Cycle consistency constraints are added if they are violated by the current marginals, and the process is repeated until no more violations appear. While this approach does tackle marginalization, it is focused on improving its accuracy. In particular, the optimization problems they solve in each </context>
</contexts>
<marker>Riedel, Clarke, 2006</marker>
<rawString>Sebastian Riedel and James Clarke. 2006. Incremental integer linear programming for non-projective dependency parsing. In Proceedings of the Conference on Empirical methods in natural language processing (EMNLP 06), pages 129137.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Riedel</author>
</authors>
<title>Improving the accuracy and efficiency of MAP inference for markov logic.</title>
<date>2008</date>
<booktitle>In Proceedings of the 24th Annual Conference on Uncertainty in AI (UAI 08),</booktitle>
<pages>468475</pages>
<contexts>
<context position="20801" citStr="Riedel, 2008" startWordPosition="3608" endWordPosition="3609">rue marginals, if the remaining factors G either have a low total weight kGk, or the current belief G already assigns high probability to the features G being active (and hence hG, Gi is small). The latter condition is the probabilistic analog to constraints already being satisfied. Finally, since can be easily calculated, we plan to investigate its utility as a convergence criterion in future work. 4.4 Related Work Our approach is inspired by earlier work on relaxation algorithms for performing MAP inference by incrementally tightening relaxations of a graphical model (Anguelov et al., 2004; Riedel, 2008), weighted Finite State Machine (Tromble and Eisner, 2006), Integer Linear Program (Riedel and Clarke, 2006) or Marginal Polytope (Sontag et al., 2008). However, none of these methods apply to marginal inference. Sontag and Jaakkola (2007) compute marginal probabilities by using a cutting plane approach that starts with the local polytope and then optimizes some approximation of the log partition function. Cycle consistency constraints are added if they are violated by the current marginals, and the process is repeated until no more violations appear. While this approach does tackle marginaliz</context>
</contexts>
<marker>Riedel, 2008</marker>
<rawString>Sebastian Riedel. 2008. Improving the accuracy and efficiency of MAP inference for markov logic. In Proceedings of the 24th Annual Conference on Uncertainty in AI (UAI 08), pages 468475.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David A Smith</author>
<author>Jason Eisner</author>
</authors>
<title>Dependency parsing by belief propagation.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>145156</pages>
<location>Honolulu,</location>
<contexts>
<context position="3028" citStr="Smith and Eisner, 2008" startWordPosition="459" endWordPosition="462"> projective models if we want to apply DP. Some previous work has circumvented this problem for MAP inference by starting with a second-order projective solution and then greedily flipping edges to find a better nonprojective solution (McDonald and Pereira, 2006). In order to explore richer model structures, the NLP community has recently started to investigate the use of other, well-known machine learning techniques for marginal inference. One such technique is Markov chain Monte Carlo, and in particular Gibbs sampling (Finkel et al., 2005), another is (loopy) sum-product belief propagation (Smith and Eisner, 2008). In both cases we usually work in the framework of graphical modelsin our case, with factor graphs that describe our distributions through variables, factors, and factor potentials. In theory, methods such as belief propagation can take any graph and perform marginal inference. This means that we gain a great amount of flexibility to represent more global and joint distributions for NLP tasks. The graphical models of interest, however, are often too large and densely connected for efficient inference in them. For example, in second order often very effective. 760 \x0cdependency parsing models</context>
<context position="6810" citStr="Smith and Eisner (2008)" startWordPosition="1093" endWordPosition="1096"> marginal inference method in the inner loop. In the following, we first give a sketch of the graphical model we apply. Then we briefly discuss marginal inference. In turn we describe our relaxation algorithm for marginal inference and some of its theoretic guarantees. Then we present empirical support for the effectiveness of our approach, and conclude. 2 Graphical Models of Dependency Trees We give a brief overview of the graphical model we apply in our experiments. We chose the grandparents and siblings model, together with language specific multiroot and projectivity options as taken from Smith and Eisner (2008). All our models are defined over a set of binary variables Lij that indicate a dependency between token i and j of the input sentence W. 2.1 Markov Random Fields Following Smith and Eisner (2008), we define a probability distribution over all dependency trees as a collection of edges y for a fixed input sentence W. This distribution is represented by an undirected graphical model, or Markov random field (MRF): pF (y) def = 1 Z Y iF i (y) (1) specified by an index set F and a corresponding family (i)F of factors i : Y 7 &amp;lt;+. Here Z is the partition function ZF = P y Q i i (y). We will restrict </context>
<context position="9252" citStr="Smith and Eisner, 2008" startWordPosition="1541" endWordPosition="1544">some specified condition and fires only if this condition is violated; in this case it evaluates to 0. It is therefore ruling out all configurations in which the condition does not hold. Note that a hard constraint i corresponds to i = in our loglinear representation. For dependency parsing, we consider two particular hard constraints, each of which touches all edge variables in y: the constraint Tree requires that all edges form a directed spanning tree rooted at the root node 0; the constraint PTree enforces the more stringent condition that all edges form a projective directed tree. As in (Smith and Eisner, 2008), we used algorithms from edge-factored parsing to compute BP messages for these factors. In our experiments, we enforced one or the other constraint depending on the projectivity of given treebank data. A soft factor i acts as a soft constraint that prefers some assignments to others. This is equivalent to saying that its weight i is finite. Note that the weight of a soft factor is usually itself composed as a sum of (sub-)weights wj for feature functions that have the same input-output behavior as i (y) when conditioned on the current sentence. It is these wj which are adjusted at training t</context>
<context position="22398" citStr="Smith and Eisner, 2008" startWordPosition="3865" endWordPosition="3868">eful for other inference-related tasks (such as combined marginal and MAP inference). The core difference to our approach is the fact that they ask which edges to remove from the full graph, instead of which to add to a partial graph. This requires inference in the full modelthe very operation we want to avoid. 5 Experiments In our experiments we seek to answer the following questions. First, how fast is our relaxation approach compared to full marginal inference at comparable dependency accuracy? This requires us to find the best tree in terms of marginal probabilities on the link variables (Smith and Eisner, 2008). Second, how good is the final relaxed graph as an approximation of the full graph? Finally, how does incremental relaxation scale with sentence length? 5.1 Data and Models We trained and tested on a subset of languages from the CoNLL Dependency Parsing Shared Tasks (Nivre et al., 2007): Dutch, Danish, Italian, and English. We apply non-projective second order models for Dutch, Danish and Italian, and a projective second order model for English. To be able to compare inference on the same model, we trained using BP on the full set of LINK, GRAND, and SIB factors. Note that our models would ra</context>
</contexts>
<marker>Smith, Eisner, 2008</marker>
<rawString>David A. Smith and Jason Eisner. 2008. Dependency parsing by belief propagation. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 145156, Honolulu, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Sontag</author>
<author>T Jaakkola</author>
</authors>
<title>New outer bounds on the marginal polytope.</title>
<date>2007</date>
<booktitle>In Advances in Neural Information Processing Systems (NIPS 07),</booktitle>
<pages>1393--1400</pages>
<contexts>
<context position="21040" citStr="Sontag and Jaakkola (2007)" startWordPosition="3641" endWordPosition="3644">babilistic analog to constraints already being satisfied. Finally, since can be easily calculated, we plan to investigate its utility as a convergence criterion in future work. 4.4 Related Work Our approach is inspired by earlier work on relaxation algorithms for performing MAP inference by incrementally tightening relaxations of a graphical model (Anguelov et al., 2004; Riedel, 2008), weighted Finite State Machine (Tromble and Eisner, 2006), Integer Linear Program (Riedel and Clarke, 2006) or Marginal Polytope (Sontag et al., 2008). However, none of these methods apply to marginal inference. Sontag and Jaakkola (2007) compute marginal probabilities by using a cutting plane approach that starts with the local polytope and then optimizes some approximation of the log partition function. Cycle consistency constraints are added if they are violated by the current marginals, and the process is repeated until no more violations appear. While this approach does tackle marginalization, it is focused on improving its accuracy. In particular, the optimization problems they solve in each iteration are in fact larger than the problem we want to relax. Our approach is also related to edge deletion in Bayesian networks </context>
</contexts>
<marker>Sontag, Jaakkola, 2007</marker>
<rawString>D. Sontag and T. Jaakkola. 2007. New outer bounds on the marginal polytope. In Advances in Neural Information Processing Systems (NIPS 07), pages 1393 1400.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Sontag</author>
<author>T Meltzer</author>
<author>A Globerson</author>
<author>T Jaakkola</author>
<author>Y Weiss</author>
</authors>
<title>Tightening LP relaxations for MAP using message passing.</title>
<date>2008</date>
<booktitle>In Proceedings of the 24th Annual Conference on Uncertainty in AI (UAI 08).</booktitle>
<contexts>
<context position="20952" citStr="Sontag et al., 2008" startWordPosition="3628" endWordPosition="3631">atures G being active (and hence hG, Gi is small). The latter condition is the probabilistic analog to constraints already being satisfied. Finally, since can be easily calculated, we plan to investigate its utility as a convergence criterion in future work. 4.4 Related Work Our approach is inspired by earlier work on relaxation algorithms for performing MAP inference by incrementally tightening relaxations of a graphical model (Anguelov et al., 2004; Riedel, 2008), weighted Finite State Machine (Tromble and Eisner, 2006), Integer Linear Program (Riedel and Clarke, 2006) or Marginal Polytope (Sontag et al., 2008). However, none of these methods apply to marginal inference. Sontag and Jaakkola (2007) compute marginal probabilities by using a cutting plane approach that starts with the local polytope and then optimizes some approximation of the log partition function. Cycle consistency constraints are added if they are violated by the current marginals, and the process is repeated until no more violations appear. While this approach does tackle marginalization, it is focused on improving its accuracy. In particular, the optimization problems they solve in each iteration are in fact larger than the probl</context>
</contexts>
<marker>Sontag, Meltzer, Globerson, Jaakkola, Weiss, 2008</marker>
<rawString>David Sontag, T. Meltzer, A. Globerson, T. Jaakkola, and Y. Weiss. 2008. Tightening LP relaxations for MAP using message passing. In Proceedings of the 24th Annual Conference on Uncertainty in AI (UAI 08).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roy W Tromble</author>
<author>Jason Eisner</author>
</authors>
<title>A fast finite-state relaxation method for enforcing global constraints on sequence decoding.</title>
<date>2006</date>
<booktitle>In Joint Human Language Technology Conference/Annual Meeting of the North American Chapter of the Association for Computational Linguistics (HLT-NAACL 06),</booktitle>
<pages>423--430</pages>
<contexts>
<context position="4522" citStr="Tromble and Eisner, 2006" startWordPosition="702" endWordPosition="705">pler greedy parsing methods, and the advantage second order models give in accuracy is often not significant enough to offset the lack of speed in practice. Moreover, if we extend such parsing models to, say, penalizing all pairs of crossing edges or scoring syntax-based alignments, we will need to inspect at least O n4 \x01 factors, increasing our efficiency concerns. When looking at the related task of finding the most likely assignment in large graphical models (i.e., MAP inference), we notice that several recent approaches have significantly sped up computation through relaxation methods (Tromble and Eisner, 2006; Riedel and Clarke, 2006). Here we start with a small subset of the full graph, and run inference for this simpler problem. Then we search for factors that are violated in the solution, and add them to the graph. This is repeated until no more new factors can be added. Empirically this approach has shown impressive success. It often dramatically reduces the effective network size, with no loss in accuracy. How can we extend or generalize MAP relaxation algorithms to the case of marginal inference? Roughly speaking, we answer it by introducing a notion of factor gain that is defined as the KL </context>
<context position="20859" citStr="Tromble and Eisner, 2006" startWordPosition="3614" endWordPosition="3617">er have a low total weight kGk, or the current belief G already assigns high probability to the features G being active (and hence hG, Gi is small). The latter condition is the probabilistic analog to constraints already being satisfied. Finally, since can be easily calculated, we plan to investigate its utility as a convergence criterion in future work. 4.4 Related Work Our approach is inspired by earlier work on relaxation algorithms for performing MAP inference by incrementally tightening relaxations of a graphical model (Anguelov et al., 2004; Riedel, 2008), weighted Finite State Machine (Tromble and Eisner, 2006), Integer Linear Program (Riedel and Clarke, 2006) or Marginal Polytope (Sontag et al., 2008). However, none of these methods apply to marginal inference. Sontag and Jaakkola (2007) compute marginal probabilities by using a cutting plane approach that starts with the local polytope and then optimizes some approximation of the log partition function. Cycle consistency constraints are added if they are violated by the current marginals, and the process is repeated until no more violations appear. While this approach does tackle marginalization, it is focused on improving its accuracy. In particu</context>
</contexts>
<marker>Tromble, Eisner, 2006</marker>
<rawString>Roy W. Tromble and Jason Eisner. 2006. A fast finite-state relaxation method for enforcing global constraints on sequence decoding. In Joint Human Language Technology Conference/Annual Meeting of the North American Chapter of the Association for Computational Linguistics (HLT-NAACL 06), pages 423 430.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Wainwright</author>
<author>Michael Jordan</author>
</authors>
<title>Graphical Models, Exponential Families, and Variational Inference.</title>
<date>2008</date>
<publisher>Now Publishers.</publisher>
<contexts>
<context position="10533" citStr="Wainwright and Jordan (2008)" startWordPosition="1765" endWordPosition="1769">d Eisner (2008). In the full model, there are: O(n2) LINKi,j factors that judge dependency edges in isolation; O(n3) GRANDi,j,k factors that judge pairs of dependency edges in a grandparent-parent-child chain; and O(n3) SIBi,j,k factors that judge pairs of dependency edges that share the same parent. 3 Marginal Inference Formally, given our set of factors F and an observed sentence W, marginal inference amounts to calculating the probability F i that our binary features i are active. That is, for each factor i F i def = X i(y)=1 pF (y) = EF [i] (2) For compactness, we follow the convention of Wainwright and Jordan (2008) and represent the belief for a variable using the marginal probability of its corresponding unary factor. Hence, if we want to calculate pF (Lij) we use F LINKij in place. Moreover we will use F i def = 1F i when we need the probability of the event i (y) = 0. The two most prominent approaches to marginal inference in general graphical models are Markov Chain Monte Carlo (MCMC) and variational methods. In a nutshell, MCMC iteratively generates a Markov chain that yields pF as its stationary distribution. Any expectation F i can then be calculated simply by counting the corresponding statistic</context>
<context position="15852" citStr="Wainwright and Jordan, 2008" startWordPosition="2680" endWordPosition="2683">s we get from both are close, too. If we use the KL divergence between the (distributions of) F0 {i} and F0 for our interpretation of the above mentioned closeness, we can define a potential gain for adding i as follows: gF0 (i) def = DKL pF0 ||pF0{i} \x01 . Together with a threshold \x0f on this gain we can now adapt the relaxation approach to marginal inference by simply replacing the question, Is i violated? with the question, Is gF0 (i) &amp;gt; \x0f? We can see the latter question as a generalization of the former if we interpret MAP inference as the zerotemperature limit of marginal inference (Wainwright and Jordan, 2008). The form of the gain function is chosen to be easily evaluated using the beliefs we have already available for the current sub-graph F0. It is easy to show (see Appendix) that the following holds: Proposition 1. The gain of a factor i with respect to the sub-graph F0 F is gF0 (i) = log \x10 F0 i + F0 i ei \x11 F0 i i (3) That is, the gain of a factor i depends on two properties of i. First, the expectation F0 i that i fires under the current model F0, and second, 763 \x0cits loglinear weight i. To get an intuition for this gain, consider the limit limF0 i 1 gF0 (i) of a factor with positive </context>
<context position="30680" citStr="Wainwright and Jordan, 2008" startWordPosition="5276" endWordPosition="5279">nal inference to larger joint inference problems within NLP, and test its effectiveness with other marginal inference algorithms as solvers in the inner loop. Acknowledgments This work was supported in part by the Center for Intelligent Information Retrieval and in part by SRI International subcontract #27-001338 and ARFL prime contract #FA8750-09-C-0181. Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. Appendix: Proof Sketches For Proposition 1 we use the primal form of the KL divergence (Wainwright and Jordan, 2008) D ` p0 F ||pF = log ` ZF Z1 F0 hF 0 , F F0 i and represent the ratio ZF Z1 F0 of partition functions as ZF ZF0 = X y ehF0 ,F0 (y)i ZF0 ehG,G(y)i = EF0 h ehG,Gi i where G def = F \\ F0 . With G = {i} we get the desired gain. For Proposition 2, part 1, we first pick a simple upper bound on ZF Z1 F0 by replacing the expectation with ekGk1 . Inserting this into the primal form KL divergence leads to the given bound. For part 2 we represent pF using pF0 pF (y) = ZF0 Z1 F ehG,G(y)i pF0 (y) and reuse our above representation of ZF Z1 F0 . This gives pF (y) = EF0 h ehG,G(y)i i1 pF0 (y) ehG,G(y)i whic</context>
</contexts>
<marker>Wainwright, Jordan, 2008</marker>
<rawString>Martin Wainwright and Michael Jordan. 2008. Graphical Models, Exponential Families, and Variational Inference. Now Publishers.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>