This is a standard practice to handle large graphs (Agirre and Soroa, 2009; CITATION),,
Following prior work CITATION, we use Open IE triples for modeling relation co-occurrence,,
Similar to previous AMT studies we get judgments from multiple (five) annotators on each task and use the majority labels CITATION,,
5.1 Evaluating Rel-grams What sort of common-sense knowledge is encapsulated in Rel-grams? How often does it indicate an implication between a pair of statements, and how often does it indicate a common real-world event or topic? To answer these questions, we conducted an experiment to identify a subset of our Relgrams database with high precision for two forms of common-sense knowledge: Implication: The Rel-grams express an implication from T to T or from T to T, a bi-directional form of the Recognizing Textual Entailment (RTE) guidelines CITATION,,
CITATION extended schema generation to learn domain-specific ev,,
CITATION extended schema generation to learn domain-specific event templates and associated extractors,,
CITATION extended schema generation to learn domain-specific event templates,,
In order to make the tasks understandable to unskilled AMT workers, we followed the accepted practice of presenting them with grounded instances of the schemas CITATION, e.g., instantiating a schema with a specific argument instead of showing the various possibilities for an actor,,
We use the Stanford Co-reference system CITATION6 to detect co-referring mentions,,
Our basic representation is triples of the form (Arg1, Relation, Arg2), extracted from a text corpus using Open Information Extraction CITATION,,
CITATION.4 This provides relational tuples in the format (Arg1, Relation, Arg2) where each tuple element is a phrase from the sentence,,
They provide essential guidance in extracting information related to events from free text CITATION, and can also aid in other NLP tasks, such as coreference CITATION, summarization CITATION, and inference about temporal ordering and causality,,
Until recently, all event schemas in use in NLP were hand-engineered, e.g., the MUC templates and ACE event relations (CITATION; CITATION; CITATION),,
6 Related Work Prior work by Chambers and Jurafsky CITATION showed that event sequences (narrative chains) mined from text can be used to induce event schemas in a domain-independent fashion,,
In work parallel to ours, CITATION, developed a probabilistic solution for template generation,,
To assign types to arguments, we apply Stanford Named Entity Recognizer CITATION5, and also look up the argument in WordNet 2.1 and record 4 Available at: http://knowitall.github.io/ ollie/ 5 We used the system downloaded from: http://nlp,,
Page rank is a well-known graph analysis algorithm that uses graph connectivity to identify important nodes within a graph CITATION,,
In this work, we adapt the Personalized PageRank algorithm CITATION,,
By using triples rather than a pair-wise representation of subject-verb and verb-object, we achieve more coherent schemas than Chambers and Jurafsky CITATION,,
The seminal work of Chambers and Jurafsky CITATION showed that event schemas can also be induced automatically from text corpora,,
We compare Rel-grams schemas against the stateof-the-art narrative schemas released by Chambers CITATION.8 Chambers 8 Available at http://www.usna.edu/Users/cs/ System Id A1 Rel A2 Relgrams R11 bomb explode in city missile explode in city grenade explode in city ..,,
