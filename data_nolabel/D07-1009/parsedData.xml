<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<bodyText confidence="0.6012125">
b&apos;Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational
Natural Language Learning, pp. 8391, Prague, June 2007. c
</bodyText>
<sectionHeader confidence="0.440963" genericHeader="abstract">
2007 Association for Computational Linguistics
</sectionHeader>
<title confidence="0.846685">
Incremental Text Structuring with Online Hierarchical Ranking
</title>
<author confidence="0.992676">
Erdong Chen, Benjamin Snyder and Regina Barzilay
</author>
<affiliation confidence="0.996045">
Computer Science and Artificial Intelligence Laboratory
Massachusetts Institute of Technology
</affiliation>
<email confidence="0.998366">
{edc,bsnyder,regina}@csail.mit.edu
</email>
<sectionHeader confidence="0.990841" genericHeader="keywords">
Abstract
</sectionHeader>
<bodyText confidence="0.999691666666667">
Many emerging applications require doc-
uments to be repeatedly updated. Such
documents include newsfeeds, webpages,
and shared community resources such as
Wikipedia. In this paper we address the
task of inserting new information into exist-
ing texts. In particular, we wish to deter-
mine the best location in a text for a given
piece of new information. For this process
to succeed, the insertion algorithm should
be informed by the existing document struc-
ture. Lengthy real-world texts are often hier-
archically organized into chapters, sections,
and paragraphs. We present an online rank-
ing model which exploits this hierarchical
structure representationally in its features
and algorithmically in its learning proce-
dure. When tested on a corpus of Wikipedia
articles, our hierarchically informed model
predicts the correct insertion paragraph more
accurately than baseline methods.
</bodyText>
<sectionHeader confidence="0.998306" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999167309523809">
Many emerging applications require documents to
be repeatedly updated. For instance, newsfeed ar-
ticles are continuously revised by editors as new in-
formation emerges, and personal webpages are mod-
ified as the status of the individual changes. This re-
vision strategy has become even more prevalent with
the advent of community edited web resources, the
most notable example being Wikipedia. At present
this process involves massive human effort. For in-
stance, the English language version of Wikipedia
averaged over 3 million edits1 per month in 2006.
Even so, many articles quickly become outdated.
A system that performs such updates automatically
could drastically decrease maintenance efforts and
potentially improve document quality.
Currently there is no effective way to automati-
cally update documents as new information becomes
available. The closest relevant text structuring tech-
nique is the work on sentence ordering, in which a
complete reordering of the text is undertaken. Pre-
dictably these methods are suboptimal for this new
task because they cannot take advantage of existing
text structure.
We introduce an alternative vision of text struc-
turing as a process unfolding over time. Instead of
ordering sentences all at once, we start with a well-
formed draft and add new information at each stage,
while preserving document coherence. The basic
operation of incremental text structuring is the inser-
tion of new information. To automate this process,
we develop a method for determining the best loca-
tion in a text for a given piece of new information.
The main challenge is to maintain the continuity
and coherence of the original text. These proper-
ties may be maintained by examining sentences ad-
jacent to each potential insertion point. However, a
local sentence comparison method such as this may
fail to account for global document coherence (e.g.
by allowing the mention of some fact in an inappro-
priate section). This problem is especially acute in
the case of lengthy, real-world texts such as books,
technical reports, and web pages. These documents
</bodyText>
<figure confidence="0.684664">
1
http://stats.wikimedia.org/EN/
TablesWikipediaEN.htm
</figure>
<page confidence="0.998939">
83
</page>
<bodyText confidence="0.998982177777778">
\x0care commonly organized hierarchically into sections
and paragraphs to aid reader comprehension. For
documents where hierarchical information is not ex-
plicitly provided, such as automatic speech tran-
scripts, we can use automatic segmentation methods
to induce such a structure (Hearst, 1994). Rather
than ignoring the inherent hierarchical structure of
these texts, we desire to directly model such hierar-
chies and use them to our advantage both repre-
sentationally in our features and algorithmically in
our learning procedure.
To achieve this goal, we introduce a novel method
for sentence insertion that operates over a hierarchi-
cal structure. Our document representation includes
features for each layer of the hierarchy. For ex-
ample, the word overlap between the inserted sen-
tence and a section header would be included as an
upper-level section feature, whereas a comparison
of the sentence with all the words in a paragraph
would be a lower-level paragraph feature. We pro-
pose a linear model which simultaneously considers
the features of every layer when making insertion
decisions. We develop a novel update mechanism
in the online learning framework which exploits the
hierarchical decomposition of features. This mecha-
nism limits model updates to those features found at
the highest incorrectly predicted layer, without un-
necessarily disturbing the parameter values for the
lower reaches of the tree. This conservative update
approach maintains as much knowledge as possible
from previously encountered training examples.
We evaluate our method using real-world data
where multiple authors have revised preexisting doc-
uments over time. We obtain such a corpus from
Wikipedia articles,2 which are continuously updated
by multiple authors. Logs of these updates are pub-
licly available, and are used for training and testing
of our algorithm. Figure 1 shows an example of a
Wikipedia insertion. We believe this data will more
closely mirror potential applications than synthetic
collections used in previous work on text structur-
ing.
Our hierarchical training method yields signifi-
cant improvement when compared to a similar non-
hierarchical model which instead uses the standard
</bodyText>
<page confidence="0.940516">
2
</page>
<bodyText confidence="0.945495866666667">
Data and code used in this paper are available at
http://people.csail.mit.edu/edc/emnlp07/
perceptron update of Collins (2002). We also report
human performance on the insertion task in order to
provide a reasonable upper-bound on machine per-
formance. An analysis of these results shows that
our method closes the gap between machine and hu-
man performance substantially.
In the following section, we provide an overview
of existing work on text structuring and hierarchi-
cal learning. Then, we define the insertion task and
introduce our hierarchical ranking approach to sen-
tence insertion. Next, we present our experimental
framework and data. We conclude the paper by pre-
senting and discussing our results.
</bodyText>
<sectionHeader confidence="0.999461" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.986425481481481">
Text Structuring The insertion task is closely re-
lated to the extensively studied problem of sentence
ordering.3 Most of the existing algorithms repre-
sent text structure as a linear sequence and are driven
by local coherence constraints (Lapata, 2003; Kara-
manis et al., 2004; Okazaki et al., 2004; Barzi-
lay and Lapata, 2005; Bollegala et al., 2006; El-
sner and Charniak, 2007). These methods induce
a total ordering based on pairwise relations between
sentences. Researchers have shown that identifying
precedence relations does not require deep semantic
interpretation of input sentences: shallow distribu-
tional features are sufficient for accurate prediction.
Our approach employs similar features to represent
nodes at the lowest level of the hierarchy.
The key departure of our work from previous re-
search is the incorporation of hierarchical structure
into a corpus-based approach to ordering. While in
symbolic generation and discourse analysis a text is
typically analyzed as a tree-like structure (Reiter and
Dale, 1990), a linear view is prevalent in data-driven
methods to text structuring.4 Moving beyond a lin-
ear representation enables us to handle longer texts
where a local view of coherence does not suffice. At
the same time, our approach does not require any
manual rules for handling tree insertions, in contrast
to symbolic text planners.
</bodyText>
<page confidence="0.990924">
3
</page>
<bodyText confidence="0.994649333333333">
Independently and simultaneously with our work, Elsner
and Charniak (2007) have studied the sentence insertion task in
a different setting.
</bodyText>
<page confidence="0.987659">
4
</page>
<bodyText confidence="0.891622">
Though statistical methods have been used to induce such
trees (Soricut and Marcu, 2003), they are not used for ordering
and other text-structuring tasks.
</bodyText>
<page confidence="0.996379">
84
</page>
<table confidence="0.935764230769231">
\x0cShaukat Aziz (born March 6, 1949, Karachi, Pakistan) has been the Finance Minister of Pakistan since November 1999.
He was nominated for the position of Prime Minister after the resignation of Zafarullah Khan Jamali on June 6, 2004.
Education
Aziz attended Saint Patricks school, Karachi and Abbottabad Public School. He graduated with a Bachelor of Science degree
from Gordon College, Rawalpindi, in 1967. He obtained an MBA Degree in 1969 from the Institute of Business
Administration, Karachi.
Career
In November, 1999, Mr. Aziz became Pakistans Minister of Finance. As Minister of finance, Mr. Aziz also heads the
Economic Coordination Committee of the Cabinet, and the Cabinet Committee on Privatization.
Mr. Aziz was named as Prime Minister by interim Prime Minister Chaudhry Shujaat Hussain after the resignation of Zafarullah
Khan Jamali on June 6, 2004. He is expected to retain his position as Minister of Finance.
In 2001, Mr Aziz was declared Finance Minister of the Year by
Euromoney and Bankers Magazine.
</table>
<figureCaption confidence="0.995635">
Figure 1: An example of Wikipedia insertion.
</figureCaption>
<bodyText confidence="0.995439277777778">
Hierarchical Learning There has been much re-
cent research on multiclass hierarchical classifica-
tion. In this line of work, the set of possible la-
bels is organized hierarchically, and each input must
be assigned a node in the resulting tree. A pro-
totype weight vector is learned for each node, and
classification decisions are based on all the weights
along the path from node to root. The essence of
this scheme is that the more ancestors two nodes
have in common, the more parameters they are
forced to share. Many learning methods have been
proposed, including SVM-style optimization (Cai
and Hofmann, 2004), incremental least squares es-
timation (Cesa-Bianchi et al., 2006b), and percep-
tron (Dekel et al., 2004).
This previous work rests on the assumption that a
predetermined set of atomic labels with a fixed hi-
erarchy is given. In our task, however, the set of
possible insertion points along with their hierar-
chical organization is unique to each input docu-
ment. Furthermore, nodes exhibit rich internal fea-
ture structure and cannot be identified across docu-
ments, except insofar as their features overlap. As
is commonly done in NLP tasks, we make use of a
feature function which produces one feature vector
for each possible insertion point. We then choose
among these feature vectors using a single weight
vector (casting the task as a structured ranking prob-
lem rather than a classification problem). In this
framework, an explicit hierarchical view is no longer
necessary to achieve parameter tying. In fact, each
parameter will be shared by exactly those insertion
points which exhibit the corresponding feature, both
across documents and within a single document.
Higher level parameters will thus naturally be shared
by all paragraphs within a single section.
In fact, when the perceptron update rule of (Dekel
et al., 2004) which modifies the weights of every
divergent node along the predicted and true paths
is used in the ranking framework, it becomes virtu-
ally identical with the standard, flat, ranking percep-
tron of Collins (2002).5 In contrast, our approach
shares the idea of (Cesa-Bianchi et al., 2006a) that
if a parent class has been predicted wrongly, then
errors in the children should not be taken into ac-
count. We also view this as one of the key ideas
of the incremental perceptron algorithm of (Collins
and Roark, 2004), which searches through a com-
plex decision space step-by-step and is immediately
updated at the first wrong move.
Our work fuses this idea of selective hierarchical
updates with the simplicity of the perceptron algo-
rithm and the flexibility of arbitrary feature sharing
inherent in the ranking framework.
</bodyText>
<sectionHeader confidence="0.996903" genericHeader="method">
3 The Algorithm
</sectionHeader>
<bodyText confidence="0.9993536">
In this section, we present our sentence inser-
tion model and a method for parameter estima-
tion. Given a hierarchically structured text com-
posed of sections and paragraphs, the sentence in-
sertion model determines the best paragraph within
</bodyText>
<page confidence="0.974402">
5
</page>
<bodyText confidence="0.998069">
The main remaining difference is that Dekel et al. (2004)
use a passive-aggressive update rule (Crammer et al., 2006) and
in doing so enforce a margin based on tree distance.
</bodyText>
<page confidence="0.992042">
85
</page>
<bodyText confidence="0.998736571428571">
\x0cwhich to place the new sentence. To identify the
exact location of the sentence within the chosen
paragraph, local ordering methods such as (Lapata,
2003) could be used. We formalize the insertion task
as a structured ranking problem, and our model is
trained using an online algorithm. The distinguish-
ing feature of the algorithm is a selective correction
mechanism that focuses the model update on the rel-
evant layer of the documents feature hierarchy.
The algorithm described below can be applied to
any hierarchical ranking problem. For concreteness,
we use the terminology of the sentence insertion
task, where a hierarchy corresponds to a document
with sections and paragraphs.
</bodyText>
<subsectionHeader confidence="0.999589">
3.1 Problem Formulation
</subsectionHeader>
<bodyText confidence="0.973977">
In a sentence insertion problem, we are
given a training sequence of instances
(s1, T 1, `1), . . . , (sm, T m, `m). Each instance
contains a sentence s, a hierarchically structured
document T , and a node ` representing the correct
insertion point of s into T . Although ` can generally
be any node in the tree, in our problem we need
only consider leaf nodes. We cast this problem in
the ranking framework, where a feature vector is as-
sociated with each sentence-node pair. For example,
the feature vector of an internal, section-level node
may consider the word overlap between the inserted
sentence and the section title. At the leaf level,
features may include an analysis of the overlap
between the corresponding text and sentence. In
practice, we use disjoint feature sets for different
layers of the hierarchy, though in theory they could
be shared.
Our goal then is to choose a leaf node by taking
into account its feature vector as well as feature vec-
tors of all its ancestors in the tree.
More formally, for each sentence s and hierarchi-
cally structured document T , we are given a set of
feature vectors, with one for each node: {(s, n) :
n T }. We denote the set of leaf nodes by L(T )
and the path from the root of the tree to a node n
by P(n). Our model must choose one leaf node
among the set L(T ) by examining its feature vec-
tor (s, `) as well as all the feature vectors along its
path: {(s, n) : n P(`)}.
</bodyText>
<equation confidence="0.870500666666667">
Input : (s1, T 1, `1), . . . , (sm, T m, `m).
Initialize : Set w1 = 0
Loop : For t = 1, 2, ..., N :
</equation>
<listItem confidence="0.9951856">
1. Get a new instance st, T t.
2. Predict
`t = arg max`L(T ) wt (st, `).
3. Get the new label `t.
4. If
</listItem>
<equation confidence="0.6934195">
`t = `t:
wt+1 wt
</equation>
<figure confidence="0.72987775">
Else:
i max{i : P(`t)i = P(
`t)i}
a P(`t)i+1
b P(
`t)i+1
wt+1 wt + (s, a) (s, b)
Output : wN+1.
</figure>
<figureCaption confidence="0.988996">
Figure 2: Training algorithm for the hierarchical
ranking model.
</figureCaption>
<subsectionHeader confidence="0.968859">
3.2 The Model
</subsectionHeader>
<bodyText confidence="0.999353">
Our model consists of a weight vector w, each
weight corresponding to a single feature. The fea-
tures of a leaf are aggregated with the features of all
its ancestors in the tree. The leaf score is then com-
puted by taking the inner product of this aggregate
feature vector with the weights w. The leaf with the
highest score is then selected.
More specifically, we define the aggregate feature
vector of a leaf ` to be the sum of all features found
along the path to the root:
</bodyText>
<equation confidence="0.997744">
(s, `) =
X
nP(`)
(s, n) (1)
</equation>
<bodyText confidence="0.978379666666667">
This has the effect of stacking together features
found in a single layer, and adding the values of fea-
tures found at more than one layer.
Our model then outputs the leaf with the highest
scoring aggregate feature vector:
arg max
</bodyText>
<equation confidence="0.950174">
`L(T )
w (s, `) (2)
</equation>
<bodyText confidence="0.997107">
Note that by using this criterion, our decoding
method is equivalent to that of the standard linear
ranking model. The novelty of our approach lies in
our training algorithm which uses the hierarchical
feature decomposition of Equation 1 to pinpoint its
updates along the path in the tree.
</bodyText>
<figure confidence="0.935921333333333">
86
\x0cn1
n2 n3
!1 !2 !3 !4
(s, T )
4
2
3 1
2
1
!
!
</figure>
<figureCaption confidence="0.925218">
Figure 3: An example of a tree with the correspond-
ing model scores. The path surrounded by solid lines
</figureCaption>
<bodyText confidence="0.855187666666667">
leads to the correct node `1. The path surrounded by
dotted lines leads to `3, the predicted output based
on the current model.
</bodyText>
<subsectionHeader confidence="0.995052">
3.3 Training
</subsectionHeader>
<bodyText confidence="0.967012884615384">
Our training procedure is implemented in the online
learning framework. The model receives each train-
ing instance, and predicts a leaf node according to its
current parameters. If an incorrect leaf node is pre-
dicted, the weights are updated based on the diver-
gence between the predicted path and the true path.
We trace the paths down the tree, and only update
the weights of the features found at the split point.
Updates for shared nodes along the paths would of
course cancel out. In contrast to the standard rank-
ing perceptron as well as the hierarchical perceptron
of (Dekel et al., 2004), no features further down the
divergent paths are incorporated in the update. For
example, if the model incorrectly predicts the sec-
tion, then only the weights of the section features
are updated whereas the paragraph feature weights
remain untouched.
More formally, let
` be the predicted leaf node and
let ` 6=
` be the true leaf node. Denote by P(`)i the
ith node on the path from the root to `. Let i be
the depth of the lowest common ancestor of ` and
` (i.e., i = max{i : P(`)i = P(
`)i}). Then the
update rule for this round is:
</bodyText>
<figure confidence="0.930399">
w w +
3
s, P(`)i+1
3
s, P(
`)i+1
(3)
</figure>
<bodyText confidence="0.989103117647059">
Full pseudo-code for our hierarchical online training
algorithm is shown in Figure 2.
We illustrate the selective update mechanism on
the simple example shown on Figure 3. The cor-
rect prediction is the node `1 with an aggregate path
score of 5, but `3 with the higher score of 6 is pre-
dicted. In this case, both the section and the para-
graph are incorrectly predicted. In response to this
mistake, the features associated with the correct sec-
tion, n2, are added to the weights, and the features of
the incorrectly predicted section, n3, are subtracted
from the weights. An alternative update strategy
would be to continue to update the feature weights
of the leaf nodes, `1 and `3. However, by identifying
the exact source of path divergence we preserve the
previously learned balance between leaf node fea-
tures.
</bodyText>
<sectionHeader confidence="0.997582" genericHeader="method">
4 Features
</sectionHeader>
<bodyText confidence="0.990556958333333">
Features used in our experiments are inspired by
previous work on corpus-based approaches for dis-
course analysis (Marcu and Echihabi, 2002; Lapata,
2003; Elsner et al., 2007). We consider three types
of features: lexical, positional, and temporal. This
section gives a general overview of these features
(see code for further details.)
Lexical Features Lexical features have been
shown to provide strong cues for sentence position-
ing. To preserve text cohesion, an inserted sentence
has to be topically close to its surrounding sentences.
At the paragraph level, we measure topical over-
lap using the TF*IDF weighted cosine similarity be-
tween an inserted sentence and a paragraph. We also
use a more linguistically refined similarity measure
that computes overlap considering only subjects and
objects. Syntactic analysis is performed using the
MINIPAR parser (Lin, 1998).
The overlap features are computed at the section
level in a similar way. We also introduce an addi-
tional section-level overlap feature that computes the
cosine similarity between an inserted sentence and
the first sentence in a section. In our corpus, the
opening sentence of a section is typically strongly
</bodyText>
<page confidence="0.994983">
87
</page>
<bodyText confidence="0.996415208333334">
\x0cindicative of its topic, thus providing valuable cues
for section level insertions.
In addition to overlap, we use lexical features
that capture word co-occurrence patterns in coherent
texts. This measure was first introduced in the con-
text of sentence ordering by Lapata (2003). Given
a collection of documents in a specific domain, we
compute the likelihood that a pair of words co-occur
in adjacent sentences. From these counts, we in-
duce the likelihood that two sentences are adjacent
to each other. For a given paragraph and an in-
serted sentence, the highest adjacency probability
between the inserted sentence and paragraph sen-
tences is recorded. This feature is also computed
at the section level.
Positional Features These features aim to cap-
ture user preferences when positioning new infor-
mation into the body of a document. For instance,
in the Wikipedia data, insertions are more likely to
appear at the end of a document than at its begin-
ning. We track positional information at the section
and paragraph level. At the section level, we record
whether a section is the first or last of the document.
At the paragraph level, there are four positional fea-
tures which indicate the paragraphs position (i.e.,
start or end) within its individual section and within
the document as a whole.
Temporal Features The text organization may be
influenced by temporal relations between underly-
ing events. In temporally coherent text, events that
happen in the same time frame are likely to be de-
scribed in the same segment. Our computation of
temporal features does not require full fledged tem-
poral interpretation. Instead, we extract these fea-
tures based on two categories of temporal cues: verb
tense and date information. The verb tense feature
captures whether a paragraph contains at least one
sentence using the same tense as the inserted sen-
tence. For instance, this feature would occur for the
inserted sentence in Figure 1 since both the sentence
and chosen paragraph employ the past tense.
Another set of features takes into account the re-
lation between the dates in a paragraph and those in
an inserted sentence. We extract temporal expres-
sions using the TIMEX2 tagger (Mani and Wilson,
2000), and compute the time interval for a paragraph
bounded by its earliest and latest dates. We record
the degree of overlap between the paragraph time in-
</bodyText>
<table confidence="0.9956826">
Section Paragraph Tree Dist
T1 J1 0.575 0.5 1.85
J2 0.7 0.525 1.55
T2 J3 0.675 0.55 1.55
J4 0.725 0.55 1.45
</table>
<tableCaption confidence="0.99861">
Table 1: Accuracy of human insertions compared
</tableCaption>
<bodyText confidence="0.951043">
against gold standard from Wikipedias update log.
T1 is a subset of the data annotated by judges J1 and
J2, while T2 is annotated by J3 and J4.
terval and insertion sentence time interval.
</bodyText>
<sectionHeader confidence="0.998962" genericHeader="method">
5 Experimental Set-Up
</sectionHeader>
<bodyText confidence="0.997280193548387">
Corpus Our corpus consists of Wikipedia articles
that belong to the category Living People. We
focus on this category because these articles are
commonly updated: when new facts about a person
are featured in the media, a corresponding entry in
Wikipedia is likely to be modified. Unlike entries
in a professionally edited encyclopedia, these arti-
cles are collaboratively written by multiple users,
resulting in significant stylistic and content varia-
tions across texts in our corpus. This property dis-
tinguishes our corpus from more stylistically homo-
geneous collections of biographies used in text gen-
eration research (Duboue and McKeown, 2003).
We obtain data on insertions6 from the update log
that accompanies every Wikipedia entry. For each
change in the articles history, the log records an ar-
ticle before and after the change. From this informa-
tion, we can identify the location of every inserted
sentence. In cases where multiple insertions occur
over time to the same article, they are treated in-
dependently of each other. To eliminate spam, we
place constraints on inserted sentences: (1) a sen-
tence has at least 8 tokens and at most 120 tokens;
(2) the MINIPAR parser (Lin, 1998) can identify a
subject or an object in a sentence.
This process yields 4051 insertion/article pairs,
from which 3240 pairs are used for training and 811
pairs for testing. These insertions are derived from
1503 Wikipedia articles. Relative to other corpora
used in text structuring research (Barzilay and Lee,
2004; Lapata, 2003; Karamanis et al., 2004), texts in
</bodyText>
<page confidence="0.986539">
6
</page>
<bodyText confidence="0.895741">
Insertion is only one type of recorded update, others in-
clude deletions and sentence rewriting.
</bodyText>
<page confidence="0.989708">
88
</page>
<bodyText confidence="0.9979019375">
\x0cour collection are long: an average article has 32.9
sentences, organized in 3.61 sections and 10.9 para-
graphs. Our corpus only includes articles that have
more than one section. When sentences are inserted
between paragraphs, by convention we treat them as
part of the previous paragraph.
Evaluation Measures We evaluate our model us-
ing insertion accuracy at the section and paragraph
level. This measure computes the percentage of
matches between the predicted location of the in-
sertion and the true placement. We also report the
tree distance between the predicted position and the
true location of an inserted sentence. Tree distance
is defined as the length of the path through the tree
which connects the predicted and the true paragraph
positions. This measure captures section level errors
(which raise the connecting path higher up the tree)
as well as paragraph level errors (which widen the
path across the tree).
Baselines Our first three baselines correspond to
naive insertion strategies. The RANDOMINS method
randomly selects a paragraph for a new sentence,
while FIRSTINS and LASTINS insert a sentence into
the first and the last paragraph, respectively.
We also compare our HIERARCHICAL method
against two competitive baselines, PIPELINE and
FLAT. The PIPELINE method separately trains two
rankers, one for section selection and one for para-
graph selection. During decoding, the PIPELINE
method first chooses the best section according to
the section-layer ranker, and then selects the best
paragraph within the chosen section according to the
paragraph-layer ranker. The FLAT method uses the
same decoding criterion as our model (Equation 2),
thus making use of all the same features. However,
FLAT is trained with the standard ranking percep-
tron update, without making use of the hierarchical
decomposition of features in Equation 1.
Human Performance To estimate the difficulty
of sentence insertion, we conducted experiments
that evaluate human performance on the task. Four
judges collectively processed 80 sentence/article
pairs which were randomly extracted from the test
set. Each insertion was processed by two annotators.
Table 1 shows the insertion accuracy for each
judge when compared against the Wikipedia gold
standard. On average, the annotators achieve 66%
accuracy in section placement and 53% accuracy
</bodyText>
<table confidence="0.995210571428571">
Section Paragraph Tree Dist
RANDOMINS 0.318* 0.134* 3.10*
FIRSTINS 0.250* 0.136* 3.23*
LASTINS 0.305* 0.215* 2.96*
PIPELINE 0.579 0.314* 2.21*
FLAT 0.593 0.313* 2.19*
HIERARCHY 0.598 0.383 2.04
</table>
<tableCaption confidence="0.998959">
Table 2: Accuracy of automatic insertion meth-
</tableCaption>
<bodyText confidence="0.995239866666667">
ods compared against the gold standard from
Wikipedias update log. The third column gives tree
distance, where a lower score corresponds to bet-
ter performance. Diacritic * (p &amp;lt; 0.01) indicates
whether differences in accuracy between the given
model and the Hierarchical model is significant (us-
ing a Fisher Sign Test).
in paragraph placement. We obtain similar re-
sults when we compare the agreement of the judges
against each other: 65% of section inserts and 48%
of paragraph inserts are identical between two anno-
tators. The degree of variability observed in this ex-
periment is consistent with human performance on
other text structuring tasks such as sentence order-
ing (Barzilay et al., 2002; Lapata, 2003).
</bodyText>
<sectionHeader confidence="0.999968" genericHeader="evaluation">
6 Results
</sectionHeader>
<bodyText confidence="0.99958705">
Table 2 shows the insertion performance of our
model and the baselines in terms of accuracy and
tree distance error. The two evaluation measures are
consistent in that they yield roughly identical rank-
ings of the systems. Assessment of statistical sig-
nificance is performed using a Fisher Sign Test. We
apply this test to compare the accuracy of the HIER-
ARCHICAL model against each of the baselines.
The results in Table 2 indicate that the naive inser-
tion baselines (RANDOMINS, FIRSTINS, LASTINS)
fall substantially behind the more sophisticated,
trainable strategies (PIPELINE, FLAT, HIERARCHI-
CAL). Within the latter group, our HIERARCHI-
CAL model slightly outperforms the others based on
the coarse measure of accuracy at the section level.
However, in the final paragraph-level analysis, the
performance gain of our model over its counterparts
is quite significant. Moreover, according to tree dis-
tance error, which incorporates error at both the sec-
tion and the paragraph level, the performance of the
</bodyText>
<page confidence="0.980231">
89
</page>
<bodyText confidence="0.9990897">
\x0cHIERARCHICAL method is clearly superior. This
result confirms the benefit of our selective update
mechanism as well as the overall importance of joint
learning.
Viewing human performance as an upper bound
for machine performance highlights the gains of our
algorithm. We observe that the gap between our
method and human performance at the paragraph
level is 32% smaller than that between the PIPELINE
model and human performance, as well as the FLAT
model and human performance.
Sentence-level Evaluation Until this point, we
have evaluated the accuracy of insertions at the para-
graph level, remaining agnostic as to the specific
placement within the predicted paragraph. We per-
form one final evaluation to test whether the global
hierarchical view of our algorithm helps in deter-
mining the exact insertion point. To make sentence-
level insertion decisions, we use a local model in
line with previous sentence-ordering work (Lapata,
2003; Bollegala et al., 2006). This model examines
the two surrounding sentences of each possible in-
sertion point and extracts a feature vector that in-
cludes lexical, positional, and temporal properties.
The model weights are trained using the standard
ranking perceptron (Collins, 2002).
We apply this local insertion model in two dif-
ferent scenarios. In the first, we ignore the global
hierarchical structure of the document and apply the
local insertion model to every possible sentence pair.
Using this strategy, we recover 24% of correct inser-
tion points. The second strategy takes advantage of
global document structure by first applying our hier-
archical paragraph selection method and only then
applying the local insertion to pairs of sentences
within the selected paragraph. This approach yields
35% of the correct insertion points. This statistically
significant difference in performance indicates that
purely local methods are insufficient when applied
to complete real-world documents.
</bodyText>
<sectionHeader confidence="0.984644" genericHeader="conclusions">
7 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999743068965517">
We have introduced the problem of sentence inser-
tion and presented a novel corpus-based method for
this task. The main contribution of our work is the
incorporation of a rich hierarchical text representa-
tion into a flexible learning approach for text struc-
turing. Our learning approach makes key use of
the hierarchy by selecting to update only the layer
found responsible for the incorrect prediction. Em-
pirical tests on a large collection of real-world inser-
tion data confirm the advantage of this approach.
Sentence ordering algorithms too are likely to
benefit from a hierarchical representation of text.
However, accounting for long-range discourse de-
pendencies in the unconstrained ordering framework
is challenging since these dependencies only appear
when a particular ordering (or partial ordering) is
considered. An appealing future direction lies in si-
multaneously inducing hierarchical and linear struc-
ture on the input sentences. In such a model, tree
structure could be a hidden variable that is influ-
enced by the observed linear order.
We are also interested in further developing our
system for automatic update of Wikipedia pages.
Currently, our system is trained on insertions in
which the sentences of the original text are not mod-
ified. However, in some cases additional text revi-
sions are required to guarantee coherence of the gen-
erated text. Further research is required to automat-
ically identify and handle such complex insertions.
</bodyText>
<sectionHeader confidence="0.98394" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<reference confidence="0.7370663">
The authors acknowledge the support of the Na-
tional Science Foundation (CAREER grant IIS-
0448168 and grant IIS-0415865) and the Mi-
crosoft Research Faculty Fellowship. Any opin-
ions, findings, and conclusions or recommenda-
tions expressed above are those of the authors
and do not necessarily reflect the views of the
NSF. Thanks to S.R.K. Branavan, Eugene Charniak,
Michael Collins, Micha Elsner, Jacob Eisenstein,
Dina Katabi, Igor Malioutov, Christina Sauper, Luke
</reference>
<bodyText confidence="0.808497">
Zettlemoyer, and the anonymous reviewers for help-
ful comments and suggestions. Data used in this
work was collected and processed by Christina
Sauper.
</bodyText>
<sectionHeader confidence="0.917108" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9880428">
Regina Barzilay and Mirella Lapata. 2005. Modeling
local coherence: An entity-based approach. In Pro-
ceedings of the ACL, pages 141148.
Regina Barzilay and Lillian Lee. 2004. Catching the
drift: Probabilistic content models, with applications
</reference>
<page confidence="0.911856">
90
</page>
<reference confidence="0.997687653333333">
\x0cto generation and summarization. In Proceedings of
HLT-NAACL, pages 113120.
Regina Barzilay, Noemie Elhadad, and Kathleen McKe-
own. 2002. Inferring strategies for sentence ordering
in multidocument news summarization. JAIR, 17:35
55.
Danushka Bollegala, Naoaki Okazaki, and Mitsuru
Ishizuka. 2006. A bottom-up approach to sentence
ordering for multi-document summarization. In Pro-
ceedings of the COLING/ACL, pages 385392.
Lijuan Cai and Thomas Hofmann. 2004. Hierarchi-
cal document categorization with support vector ma-
chines. In Proceedings of the CIKM, pages 7887.
Nicolo Cesa-Bianchi, Claudio Gentile, and Luca Zani-
boni. 2006a. Hierarchical classification: Combining
bayes with SVM. In Proceedings of the ICML, pages
177184.
Nicolo Cesa-Bianchi, Claudio Gentile, and Luca Zani-
boni. 2006b. Incremental algorithms for hierarchical
classification. JMLR, 7:3154.
Michael Collins and Brian Roark. 2004. Incremental
parsing with the perceptron algorithm. In Proceedings
of the ACL, pages 111118.
Michael Collins. 2002. Discriminative training meth-
ods for hidden markov models: Theory and experi-
ments with perceptron algorithms. In Proceedings of
the EMNLP, pages 18.
Koby Crammer, Ofer Dekel, Joseph Keshet, Shai Shalev-
Shwartz, and Yoram Singer. 2006. Online passive-
aggressive algorithms. JMLR, 7:551585.
Ofer Dekel, Joseph Keshet, and Yoram Singer. 2004.
Large margin hierarchical classification. In Proceed-
ings of the ICML, pages 209216.
Pablo Duboue and Kathleen McKeown. 2003. Statis-
tical acquisition of content selection rules for natural
language generation. In Proceedings of the EMNLP,
pages 121128.
Micha Elsner and Eugene Charniak. 2007. A genera-
tive discourse-new model for text coherence. Techni-
cal Report CS-07-04, Brown University.
Micha Elsner, Joseph Austerweil, and Eugene Charniak.
2007. A unified local and global model for discourse
coherence. In Proceedings of the HLT-NAACL, pages
436443.
Marti Hearst. 1994. Multi-paragraph segmentation of
expository text. In Proceedings of the ACL, pages 9
16.
Nikiforos Karamanis, Massimo Poesio, Chris Mellish,
and Jon Oberlander. 2004. Evaluating centering-
based metrics of coherence for text structuring using a
reliably annotated corpus. In Proceedings of the ACL,
pages 391398.
Mirella Lapata. 2003. Probabilistic text structuring: Ex-
periments with sentence ordering. In Proceedings of
the ACL, pages 545552.
Dekang Lin. 1998. Dependency-based evaluation of
minipar. In Proceedings of the Workshop on the Eval-
uation of Parsing Systems, LREC, pages 4856.
Inderjeet Mani and George Wilson. 2000. Robust tem-
poral processing of news. In Proceedings of the ACL,
pages 6976.
Daniel Marcu and Abdessamad Echihabi. 2002. An
unsupervised approach to recognizing discourse rela-
tions. In Proceedings of the ACL, pages 368375.
Naoaki Okazaki, Yutaka Matsuo, and Mitsuru Ishizuka.
2004. Improving chronological sentence ordering by
precedence relation. In Proceedings of the COLING,
pages 750756.
Ehud Reiter and Robert Dale. 1990. Building Natural
Language Generation Systems. Cambridge University
Press, Cambridge.
Radu Soricut and Daniel Marcu. 2003. Sentence level
discourse parsing using syntactic and lexical informa-
tion. In Proceedings of the HLT-NAACL, pages 149
156.
</reference>
<page confidence="0.876694">
91
</page>
<figure confidence="0.325944">
\x0c&apos;
</figure>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.813869">
<note confidence="0.967092666666667">b&apos;Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pp. 8391, Prague, June 2007. c 2007 Association for Computational Linguistics</note>
<title confidence="0.903308">Incremental Text Structuring with Online Hierarchical Ranking</title>
<author confidence="0.992076">Erdong Chen</author>
<author confidence="0.992076">Benjamin Snyder</author>
<author confidence="0.992076">Regina Barzilay</author>
<affiliation confidence="0.999988">Computer Science and Artificial Intelligence Laboratory Massachusetts Institute of Technology</affiliation>
<email confidence="0.999318">edc@csail.mit.edu</email>
<email confidence="0.999318">bsnyder@csail.mit.edu</email>
<email confidence="0.999318">regina@csail.mit.edu</email>
<abstract confidence="0.999810409090909">Many emerging applications require documents to be repeatedly updated. Such documents include newsfeeds, webpages, and shared community resources such as Wikipedia. In this paper we address the task of inserting new information into existing texts. In particular, we wish to determine the best location in a text for a given piece of new information. For this process to succeed, the insertion algorithm should be informed by the existing document structure. Lengthy real-world texts are often hierarchically organized into chapters, sections, and paragraphs. We present an online ranking model which exploits this hierarchical structure representationally in its features and algorithmically in its learning procedure. When tested on a corpus of Wikipedia articles, our hierarchically informed model predicts the correct insertion paragraph more accurately than baseline methods.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Lapata</author>
</authors>
<title>The authors acknowledge the support of the National Science Foundation (CAREER grant IIS0448168 and grant IIS-0415865) and the Microsoft Research Faculty Fellowship. Any opinions, findings, and conclusions or recommendations expressed above are those of the authors and do not necessarily reflect the views of the NSF. Thanks to S.R.K. Branavan,</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL,</booktitle>
<pages>141148</pages>
<institution>Eisenstein, Dina Katabi, Igor Malioutov, Christina Sauper, Luke Regina Barzilay and Mirella</institution>
<location>Eugene Charniak, Michael Collins, Micha Elsner, Jacob</location>
<contexts>
<context position="6730" citStr="Lapata, 2005" startWordPosition="1015" endWordPosition="1016">rk on text structuring and hierarchical learning. Then, we define the insertion task and introduce our hierarchical ranking approach to sentence insertion. Next, we present our experimental framework and data. We conclude the paper by presenting and discussing our results. 2 Related Work Text Structuring The insertion task is closely related to the extensively studied problem of sentence ordering.3 Most of the existing algorithms represent text structure as a linear sequence and are driven by local coherence constraints (Lapata, 2003; Karamanis et al., 2004; Okazaki et al., 2004; Barzilay and Lapata, 2005; Bollegala et al., 2006; Elsner and Charniak, 2007). These methods induce a total ordering based on pairwise relations between sentences. Researchers have shown that identifying precedence relations does not require deep semantic interpretation of input sentences: shallow distributional features are sufficient for accurate prediction. Our approach employs similar features to represent nodes at the lowest level of the hierarchy. The key departure of our work from previous research is the incorporation of hierarchical structure into a corpus-based approach to ordering. While in symbolic generat</context>
</contexts>
<marker>Lapata, 2005</marker>
<rawString>The authors acknowledge the support of the National Science Foundation (CAREER grant IIS0448168 and grant IIS-0415865) and the Microsoft Research Faculty Fellowship. Any opinions, findings, and conclusions or recommendations expressed above are those of the authors and do not necessarily reflect the views of the NSF. Thanks to S.R.K. Branavan, Eugene Charniak, Michael Collins, Micha Elsner, Jacob Eisenstein, Dina Katabi, Igor Malioutov, Christina Sauper, Luke Regina Barzilay and Mirella Lapata. 2005. Modeling local coherence: An entity-based approach. In Proceedings of the ACL, pages 141148.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Lillian Lee</author>
</authors>
<title>Catching the drift: Probabilistic content models, with applications \x0cto generation and summarization.</title>
<date>2004</date>
<booktitle>In Proceedings of HLT-NAACL,</booktitle>
<pages>113120</pages>
<contexts>
<context position="23500" citStr="Barzilay and Lee, 2004" startWordPosition="3865" endWordPosition="3868">on of every inserted sentence. In cases where multiple insertions occur over time to the same article, they are treated independently of each other. To eliminate spam, we place constraints on inserted sentences: (1) a sentence has at least 8 tokens and at most 120 tokens; (2) the MINIPAR parser (Lin, 1998) can identify a subject or an object in a sentence. This process yields 4051 insertion/article pairs, from which 3240 pairs are used for training and 811 pairs for testing. These insertions are derived from 1503 Wikipedia articles. Relative to other corpora used in text structuring research (Barzilay and Lee, 2004; Lapata, 2003; Karamanis et al., 2004), texts in 6 Insertion is only one type of recorded update, others include deletions and sentence rewriting. 88 \x0cour collection are long: an average article has 32.9 sentences, organized in 3.61 sections and 10.9 paragraphs. Our corpus only includes articles that have more than one section. When sentences are inserted between paragraphs, by convention we treat them as part of the previous paragraph. Evaluation Measures We evaluate our model using insertion accuracy at the section and paragraph level. This measure computes the percentage of matches betw</context>
</contexts>
<marker>Barzilay, Lee, 2004</marker>
<rawString>Regina Barzilay and Lillian Lee. 2004. Catching the drift: Probabilistic content models, with applications \x0cto generation and summarization. In Proceedings of HLT-NAACL, pages 113120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Noemie Elhadad</author>
<author>Kathleen McKeown</author>
</authors>
<title>Inferring strategies for sentence ordering in multidocument news summarization.</title>
<date>2002</date>
<journal>JAIR,</journal>
<pages>17--35</pages>
<contexts>
<context position="26926" citStr="Barzilay et al., 2002" startWordPosition="4397" endWordPosition="4400">ird column gives tree distance, where a lower score corresponds to better performance. Diacritic * (p &amp;lt; 0.01) indicates whether differences in accuracy between the given model and the Hierarchical model is significant (using a Fisher Sign Test). in paragraph placement. We obtain similar results when we compare the agreement of the judges against each other: 65% of section inserts and 48% of paragraph inserts are identical between two annotators. The degree of variability observed in this experiment is consistent with human performance on other text structuring tasks such as sentence ordering (Barzilay et al., 2002; Lapata, 2003). 6 Results Table 2 shows the insertion performance of our model and the baselines in terms of accuracy and tree distance error. The two evaluation measures are consistent in that they yield roughly identical rankings of the systems. Assessment of statistical significance is performed using a Fisher Sign Test. We apply this test to compare the accuracy of the HIERARCHICAL model against each of the baselines. The results in Table 2 indicate that the naive insertion baselines (RANDOMINS, FIRSTINS, LASTINS) fall substantially behind the more sophisticated, trainable strategies (PIP</context>
</contexts>
<marker>Barzilay, Elhadad, McKeown, 2002</marker>
<rawString>Regina Barzilay, Noemie Elhadad, and Kathleen McKeown. 2002. Inferring strategies for sentence ordering in multidocument news summarization. JAIR, 17:35 55.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danushka Bollegala</author>
<author>Naoaki Okazaki</author>
<author>Mitsuru Ishizuka</author>
</authors>
<title>A bottom-up approach to sentence ordering for multi-document summarization.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL,</booktitle>
<pages>385392</pages>
<contexts>
<context position="6754" citStr="Bollegala et al., 2006" startWordPosition="1017" endWordPosition="1020">ucturing and hierarchical learning. Then, we define the insertion task and introduce our hierarchical ranking approach to sentence insertion. Next, we present our experimental framework and data. We conclude the paper by presenting and discussing our results. 2 Related Work Text Structuring The insertion task is closely related to the extensively studied problem of sentence ordering.3 Most of the existing algorithms represent text structure as a linear sequence and are driven by local coherence constraints (Lapata, 2003; Karamanis et al., 2004; Okazaki et al., 2004; Barzilay and Lapata, 2005; Bollegala et al., 2006; Elsner and Charniak, 2007). These methods induce a total ordering based on pairwise relations between sentences. Researchers have shown that identifying precedence relations does not require deep semantic interpretation of input sentences: shallow distributional features are sufficient for accurate prediction. Our approach employs similar features to represent nodes at the lowest level of the hierarchy. The key departure of our work from previous research is the incorporation of hierarchical structure into a corpus-based approach to ordering. While in symbolic generation and discourse analys</context>
<context position="28928" citStr="Bollegala et al., 2006" startWordPosition="4711" endWordPosition="4714"> paragraph level is 32% smaller than that between the PIPELINE model and human performance, as well as the FLAT model and human performance. Sentence-level Evaluation Until this point, we have evaluated the accuracy of insertions at the paragraph level, remaining agnostic as to the specific placement within the predicted paragraph. We perform one final evaluation to test whether the global hierarchical view of our algorithm helps in determining the exact insertion point. To make sentencelevel insertion decisions, we use a local model in line with previous sentence-ordering work (Lapata, 2003; Bollegala et al., 2006). This model examines the two surrounding sentences of each possible insertion point and extracts a feature vector that includes lexical, positional, and temporal properties. The model weights are trained using the standard ranking perceptron (Collins, 2002). We apply this local insertion model in two different scenarios. In the first, we ignore the global hierarchical structure of the document and apply the local insertion model to every possible sentence pair. Using this strategy, we recover 24% of correct insertion points. The second strategy takes advantage of global document structure by </context>
</contexts>
<marker>Bollegala, Okazaki, Ishizuka, 2006</marker>
<rawString>Danushka Bollegala, Naoaki Okazaki, and Mitsuru Ishizuka. 2006. A bottom-up approach to sentence ordering for multi-document summarization. In Proceedings of the COLING/ACL, pages 385392.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lijuan Cai</author>
<author>Thomas Hofmann</author>
</authors>
<title>Hierarchical document categorization with support vector machines.</title>
<date>2004</date>
<booktitle>In Proceedings of the CIKM,</booktitle>
<pages>7887</pages>
<contexts>
<context position="9743" citStr="Cai and Hofmann, 2004" startWordPosition="1487" endWordPosition="1490">a insertion. Hierarchical Learning There has been much recent research on multiclass hierarchical classification. In this line of work, the set of possible labels is organized hierarchically, and each input must be assigned a node in the resulting tree. A prototype weight vector is learned for each node, and classification decisions are based on all the weights along the path from node to root. The essence of this scheme is that the more ancestors two nodes have in common, the more parameters they are forced to share. Many learning methods have been proposed, including SVM-style optimization (Cai and Hofmann, 2004), incremental least squares estimation (Cesa-Bianchi et al., 2006b), and perceptron (Dekel et al., 2004). This previous work rests on the assumption that a predetermined set of atomic labels with a fixed hierarchy is given. In our task, however, the set of possible insertion points along with their hierarchical organization is unique to each input document. Furthermore, nodes exhibit rich internal feature structure and cannot be identified across documents, except insofar as their features overlap. As is commonly done in NLP tasks, we make use of a feature function which produces one feature v</context>
</contexts>
<marker>Cai, Hofmann, 2004</marker>
<rawString>Lijuan Cai and Thomas Hofmann. 2004. Hierarchical document categorization with support vector machines. In Proceedings of the CIKM, pages 7887.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicolo Cesa-Bianchi</author>
<author>Claudio Gentile</author>
<author>Luca Zaniboni</author>
</authors>
<title>Hierarchical classification: Combining bayes with SVM.</title>
<date>2006</date>
<booktitle>In Proceedings of the ICML,</booktitle>
<pages>177184</pages>
<contexts>
<context position="9808" citStr="Cesa-Bianchi et al., 2006" startWordPosition="1496" endWordPosition="1499">research on multiclass hierarchical classification. In this line of work, the set of possible labels is organized hierarchically, and each input must be assigned a node in the resulting tree. A prototype weight vector is learned for each node, and classification decisions are based on all the weights along the path from node to root. The essence of this scheme is that the more ancestors two nodes have in common, the more parameters they are forced to share. Many learning methods have been proposed, including SVM-style optimization (Cai and Hofmann, 2004), incremental least squares estimation (Cesa-Bianchi et al., 2006b), and perceptron (Dekel et al., 2004). This previous work rests on the assumption that a predetermined set of atomic labels with a fixed hierarchy is given. In our task, however, the set of possible insertion points along with their hierarchical organization is unique to each input document. Furthermore, nodes exhibit rich internal feature structure and cannot be identified across documents, except insofar as their features overlap. As is commonly done in NLP tasks, we make use of a feature function which produces one feature vector for each possible insertion point. We then choose among the</context>
<context position="11259" citStr="Cesa-Bianchi et al., 2006" startWordPosition="1732" endWordPosition="1735">ter tying. In fact, each parameter will be shared by exactly those insertion points which exhibit the corresponding feature, both across documents and within a single document. Higher level parameters will thus naturally be shared by all paragraphs within a single section. In fact, when the perceptron update rule of (Dekel et al., 2004) which modifies the weights of every divergent node along the predicted and true paths is used in the ranking framework, it becomes virtually identical with the standard, flat, ranking perceptron of Collins (2002).5 In contrast, our approach shares the idea of (Cesa-Bianchi et al., 2006a) that if a parent class has been predicted wrongly, then errors in the children should not be taken into account. We also view this as one of the key ideas of the incremental perceptron algorithm of (Collins and Roark, 2004), which searches through a complex decision space step-by-step and is immediately updated at the first wrong move. Our work fuses this idea of selective hierarchical updates with the simplicity of the perceptron algorithm and the flexibility of arbitrary feature sharing inherent in the ranking framework. 3 The Algorithm In this section, we present our sentence insertion m</context>
</contexts>
<marker>Cesa-Bianchi, Gentile, Zaniboni, 2006</marker>
<rawString>Nicolo Cesa-Bianchi, Claudio Gentile, and Luca Zaniboni. 2006a. Hierarchical classification: Combining bayes with SVM. In Proceedings of the ICML, pages 177184.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicolo Cesa-Bianchi</author>
<author>Claudio Gentile</author>
<author>Luca Zaniboni</author>
</authors>
<title>Incremental algorithms for hierarchical classification.</title>
<date>2006</date>
<journal>JMLR,</journal>
<pages>7--3154</pages>
<contexts>
<context position="9808" citStr="Cesa-Bianchi et al., 2006" startWordPosition="1496" endWordPosition="1499">research on multiclass hierarchical classification. In this line of work, the set of possible labels is organized hierarchically, and each input must be assigned a node in the resulting tree. A prototype weight vector is learned for each node, and classification decisions are based on all the weights along the path from node to root. The essence of this scheme is that the more ancestors two nodes have in common, the more parameters they are forced to share. Many learning methods have been proposed, including SVM-style optimization (Cai and Hofmann, 2004), incremental least squares estimation (Cesa-Bianchi et al., 2006b), and perceptron (Dekel et al., 2004). This previous work rests on the assumption that a predetermined set of atomic labels with a fixed hierarchy is given. In our task, however, the set of possible insertion points along with their hierarchical organization is unique to each input document. Furthermore, nodes exhibit rich internal feature structure and cannot be identified across documents, except insofar as their features overlap. As is commonly done in NLP tasks, we make use of a feature function which produces one feature vector for each possible insertion point. We then choose among the</context>
<context position="11259" citStr="Cesa-Bianchi et al., 2006" startWordPosition="1732" endWordPosition="1735">ter tying. In fact, each parameter will be shared by exactly those insertion points which exhibit the corresponding feature, both across documents and within a single document. Higher level parameters will thus naturally be shared by all paragraphs within a single section. In fact, when the perceptron update rule of (Dekel et al., 2004) which modifies the weights of every divergent node along the predicted and true paths is used in the ranking framework, it becomes virtually identical with the standard, flat, ranking perceptron of Collins (2002).5 In contrast, our approach shares the idea of (Cesa-Bianchi et al., 2006a) that if a parent class has been predicted wrongly, then errors in the children should not be taken into account. We also view this as one of the key ideas of the incremental perceptron algorithm of (Collins and Roark, 2004), which searches through a complex decision space step-by-step and is immediately updated at the first wrong move. Our work fuses this idea of selective hierarchical updates with the simplicity of the perceptron algorithm and the flexibility of arbitrary feature sharing inherent in the ranking framework. 3 The Algorithm In this section, we present our sentence insertion m</context>
</contexts>
<marker>Cesa-Bianchi, Gentile, Zaniboni, 2006</marker>
<rawString>Nicolo Cesa-Bianchi, Claudio Gentile, and Luca Zaniboni. 2006b. Incremental algorithms for hierarchical classification. JMLR, 7:3154.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Brian Roark</author>
</authors>
<title>Incremental parsing with the perceptron algorithm.</title>
<date>2004</date>
<booktitle>In Proceedings of the ACL,</booktitle>
<pages>111118</pages>
<contexts>
<context position="11485" citStr="Collins and Roark, 2004" startWordPosition="1773" endWordPosition="1776">red by all paragraphs within a single section. In fact, when the perceptron update rule of (Dekel et al., 2004) which modifies the weights of every divergent node along the predicted and true paths is used in the ranking framework, it becomes virtually identical with the standard, flat, ranking perceptron of Collins (2002).5 In contrast, our approach shares the idea of (Cesa-Bianchi et al., 2006a) that if a parent class has been predicted wrongly, then errors in the children should not be taken into account. We also view this as one of the key ideas of the incremental perceptron algorithm of (Collins and Roark, 2004), which searches through a complex decision space step-by-step and is immediately updated at the first wrong move. Our work fuses this idea of selective hierarchical updates with the simplicity of the perceptron algorithm and the flexibility of arbitrary feature sharing inherent in the ranking framework. 3 The Algorithm In this section, we present our sentence insertion model and a method for parameter estimation. Given a hierarchically structured text composed of sections and paragraphs, the sentence insertion model determines the best paragraph within 5 The main remaining difference is that </context>
</contexts>
<marker>Collins, Roark, 2004</marker>
<rawString>Michael Collins and Brian Roark. 2004. Incremental parsing with the perceptron algorithm. In Proceedings of the ACL, pages 111118.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms.</title>
<date>2002</date>
<booktitle>In Proceedings of the EMNLP,</booktitle>
<pages>18</pages>
<contexts>
<context position="5810" citStr="Collins (2002)" startWordPosition="867" endWordPosition="868">h are continuously updated by multiple authors. Logs of these updates are publicly available, and are used for training and testing of our algorithm. Figure 1 shows an example of a Wikipedia insertion. We believe this data will more closely mirror potential applications than synthetic collections used in previous work on text structuring. Our hierarchical training method yields significant improvement when compared to a similar nonhierarchical model which instead uses the standard 2 Data and code used in this paper are available at http://people.csail.mit.edu/edc/emnlp07/ perceptron update of Collins (2002). We also report human performance on the insertion task in order to provide a reasonable upper-bound on machine performance. An analysis of these results shows that our method closes the gap between machine and human performance substantially. In the following section, we provide an overview of existing work on text structuring and hierarchical learning. Then, we define the insertion task and introduce our hierarchical ranking approach to sentence insertion. Next, we present our experimental framework and data. We conclude the paper by presenting and discussing our results. 2 Related Work Tex</context>
<context position="11185" citStr="Collins (2002)" startWordPosition="1722" endWordPosition="1723">icit hierarchical view is no longer necessary to achieve parameter tying. In fact, each parameter will be shared by exactly those insertion points which exhibit the corresponding feature, both across documents and within a single document. Higher level parameters will thus naturally be shared by all paragraphs within a single section. In fact, when the perceptron update rule of (Dekel et al., 2004) which modifies the weights of every divergent node along the predicted and true paths is used in the ranking framework, it becomes virtually identical with the standard, flat, ranking perceptron of Collins (2002).5 In contrast, our approach shares the idea of (Cesa-Bianchi et al., 2006a) that if a parent class has been predicted wrongly, then errors in the children should not be taken into account. We also view this as one of the key ideas of the incremental perceptron algorithm of (Collins and Roark, 2004), which searches through a complex decision space step-by-step and is immediately updated at the first wrong move. Our work fuses this idea of selective hierarchical updates with the simplicity of the perceptron algorithm and the flexibility of arbitrary feature sharing inherent in the ranking frame</context>
<context position="29186" citStr="Collins, 2002" startWordPosition="4751" endWordPosition="4752">ostic as to the specific placement within the predicted paragraph. We perform one final evaluation to test whether the global hierarchical view of our algorithm helps in determining the exact insertion point. To make sentencelevel insertion decisions, we use a local model in line with previous sentence-ordering work (Lapata, 2003; Bollegala et al., 2006). This model examines the two surrounding sentences of each possible insertion point and extracts a feature vector that includes lexical, positional, and temporal properties. The model weights are trained using the standard ranking perceptron (Collins, 2002). We apply this local insertion model in two different scenarios. In the first, we ignore the global hierarchical structure of the document and apply the local insertion model to every possible sentence pair. Using this strategy, we recover 24% of correct insertion points. The second strategy takes advantage of global document structure by first applying our hierarchical paragraph selection method and only then applying the local insertion to pairs of sentences within the selected paragraph. This approach yields 35% of the correct insertion points. This statistically significant difference in </context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>Michael Collins. 2002. Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms. In Proceedings of the EMNLP, pages 18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koby Crammer</author>
<author>Ofer Dekel</author>
<author>Joseph Keshet</author>
<author>Shai ShalevShwartz</author>
<author>Yoram Singer</author>
</authors>
<title>Online passiveaggressive algorithms.</title>
<date>2006</date>
<journal>JMLR,</journal>
<pages>7--551585</pages>
<contexts>
<context position="12164" citStr="Crammer et al., 2006" startWordPosition="1881" endWordPosition="1884">step and is immediately updated at the first wrong move. Our work fuses this idea of selective hierarchical updates with the simplicity of the perceptron algorithm and the flexibility of arbitrary feature sharing inherent in the ranking framework. 3 The Algorithm In this section, we present our sentence insertion model and a method for parameter estimation. Given a hierarchically structured text composed of sections and paragraphs, the sentence insertion model determines the best paragraph within 5 The main remaining difference is that Dekel et al. (2004) use a passive-aggressive update rule (Crammer et al., 2006) and in doing so enforce a margin based on tree distance. 85 \x0cwhich to place the new sentence. To identify the exact location of the sentence within the chosen paragraph, local ordering methods such as (Lapata, 2003) could be used. We formalize the insertion task as a structured ranking problem, and our model is trained using an online algorithm. The distinguishing feature of the algorithm is a selective correction mechanism that focuses the model update on the relevant layer of the documents feature hierarchy. The algorithm described below can be applied to any hierarchical ranking problem</context>
</contexts>
<marker>Crammer, Dekel, Keshet, ShalevShwartz, Singer, 2006</marker>
<rawString>Koby Crammer, Ofer Dekel, Joseph Keshet, Shai ShalevShwartz, and Yoram Singer. 2006. Online passiveaggressive algorithms. JMLR, 7:551585.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ofer Dekel</author>
<author>Joseph Keshet</author>
<author>Yoram Singer</author>
</authors>
<title>Large margin hierarchical classification.</title>
<date>2004</date>
<booktitle>In Proceedings of the ICML,</booktitle>
<pages>209216</pages>
<contexts>
<context position="9847" citStr="Dekel et al., 2004" startWordPosition="1503" endWordPosition="1506">ation. In this line of work, the set of possible labels is organized hierarchically, and each input must be assigned a node in the resulting tree. A prototype weight vector is learned for each node, and classification decisions are based on all the weights along the path from node to root. The essence of this scheme is that the more ancestors two nodes have in common, the more parameters they are forced to share. Many learning methods have been proposed, including SVM-style optimization (Cai and Hofmann, 2004), incremental least squares estimation (Cesa-Bianchi et al., 2006b), and perceptron (Dekel et al., 2004). This previous work rests on the assumption that a predetermined set of atomic labels with a fixed hierarchy is given. In our task, however, the set of possible insertion points along with their hierarchical organization is unique to each input document. Furthermore, nodes exhibit rich internal feature structure and cannot be identified across documents, except insofar as their features overlap. As is commonly done in NLP tasks, we make use of a feature function which produces one feature vector for each possible insertion point. We then choose among these feature vectors using a single weigh</context>
<context position="12104" citStr="Dekel et al. (2004)" startWordPosition="1872" endWordPosition="1875">, which searches through a complex decision space step-by-step and is immediately updated at the first wrong move. Our work fuses this idea of selective hierarchical updates with the simplicity of the perceptron algorithm and the flexibility of arbitrary feature sharing inherent in the ranking framework. 3 The Algorithm In this section, we present our sentence insertion model and a method for parameter estimation. Given a hierarchically structured text composed of sections and paragraphs, the sentence insertion model determines the best paragraph within 5 The main remaining difference is that Dekel et al. (2004) use a passive-aggressive update rule (Crammer et al., 2006) and in doing so enforce a margin based on tree distance. 85 \x0cwhich to place the new sentence. To identify the exact location of the sentence within the chosen paragraph, local ordering methods such as (Lapata, 2003) could be used. We formalize the insertion task as a structured ranking problem, and our model is trained using an online algorithm. The distinguishing feature of the algorithm is a selective correction mechanism that focuses the model update on the relevant layer of the documents feature hierarchy. The algorithm descri</context>
<context position="16689" citStr="Dekel et al., 2004" startWordPosition="2729" endWordPosition="2732">rrent model. 3.3 Training Our training procedure is implemented in the online learning framework. The model receives each training instance, and predicts a leaf node according to its current parameters. If an incorrect leaf node is predicted, the weights are updated based on the divergence between the predicted path and the true path. We trace the paths down the tree, and only update the weights of the features found at the split point. Updates for shared nodes along the paths would of course cancel out. In contrast to the standard ranking perceptron as well as the hierarchical perceptron of (Dekel et al., 2004), no features further down the divergent paths are incorporated in the update. For example, if the model incorrectly predicts the section, then only the weights of the section features are updated whereas the paragraph feature weights remain untouched. More formally, let ` be the predicted leaf node and let ` 6= ` be the true leaf node. Denote by P(`)i the ith node on the path from the root to `. Let i be the depth of the lowest common ancestor of ` and ` (i.e., i = max{i : P(`)i = P( `)i}). Then the update rule for this round is: w w + 3 s, P(`)i+1 3 s, P( `)i+1 (3) Full pseudo-code for our h</context>
</contexts>
<marker>Dekel, Keshet, Singer, 2004</marker>
<rawString>Ofer Dekel, Joseph Keshet, and Yoram Singer. 2004. Large margin hierarchical classification. In Proceedings of the ICML, pages 209216.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pablo Duboue</author>
<author>Kathleen McKeown</author>
</authors>
<title>Statistical acquisition of content selection rules for natural language generation.</title>
<date>2003</date>
<booktitle>In Proceedings of the EMNLP,</booktitle>
<pages>121128</pages>
<contexts>
<context position="22640" citStr="Duboue and McKeown, 2003" startWordPosition="3721" endWordPosition="3724">sists of Wikipedia articles that belong to the category Living People. We focus on this category because these articles are commonly updated: when new facts about a person are featured in the media, a corresponding entry in Wikipedia is likely to be modified. Unlike entries in a professionally edited encyclopedia, these articles are collaboratively written by multiple users, resulting in significant stylistic and content variations across texts in our corpus. This property distinguishes our corpus from more stylistically homogeneous collections of biographies used in text generation research (Duboue and McKeown, 2003). We obtain data on insertions6 from the update log that accompanies every Wikipedia entry. For each change in the articles history, the log records an article before and after the change. From this information, we can identify the location of every inserted sentence. In cases where multiple insertions occur over time to the same article, they are treated independently of each other. To eliminate spam, we place constraints on inserted sentences: (1) a sentence has at least 8 tokens and at most 120 tokens; (2) the MINIPAR parser (Lin, 1998) can identify a subject or an object in a sentence. Thi</context>
</contexts>
<marker>Duboue, McKeown, 2003</marker>
<rawString>Pablo Duboue and Kathleen McKeown. 2003. Statistical acquisition of content selection rules for natural language generation. In Proceedings of the EMNLP, pages 121128.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Micha Elsner</author>
<author>Eugene Charniak</author>
</authors>
<title>A generative discourse-new model for text coherence.</title>
<date>2007</date>
<tech>Technical Report CS-07-04,</tech>
<institution>Brown University.</institution>
<contexts>
<context position="6782" citStr="Elsner and Charniak, 2007" startWordPosition="1021" endWordPosition="1025">l learning. Then, we define the insertion task and introduce our hierarchical ranking approach to sentence insertion. Next, we present our experimental framework and data. We conclude the paper by presenting and discussing our results. 2 Related Work Text Structuring The insertion task is closely related to the extensively studied problem of sentence ordering.3 Most of the existing algorithms represent text structure as a linear sequence and are driven by local coherence constraints (Lapata, 2003; Karamanis et al., 2004; Okazaki et al., 2004; Barzilay and Lapata, 2005; Bollegala et al., 2006; Elsner and Charniak, 2007). These methods induce a total ordering based on pairwise relations between sentences. Researchers have shown that identifying precedence relations does not require deep semantic interpretation of input sentences: shallow distributional features are sufficient for accurate prediction. Our approach employs similar features to represent nodes at the lowest level of the hierarchy. The key departure of our work from previous research is the incorporation of hierarchical structure into a corpus-based approach to ordering. While in symbolic generation and discourse analysis a text is typically analy</context>
</contexts>
<marker>Elsner, Charniak, 2007</marker>
<rawString>Micha Elsner and Eugene Charniak. 2007. A generative discourse-new model for text coherence. Technical Report CS-07-04, Brown University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Micha Elsner</author>
<author>Joseph Austerweil</author>
<author>Eugene Charniak</author>
</authors>
<title>A unified local and global model for discourse coherence.</title>
<date>2007</date>
<booktitle>In Proceedings of the HLT-NAACL,</booktitle>
<pages>436443</pages>
<contexts>
<context position="18261" citStr="Elsner et al., 2007" startWordPosition="3011" endWordPosition="3014">se to this mistake, the features associated with the correct section, n2, are added to the weights, and the features of the incorrectly predicted section, n3, are subtracted from the weights. An alternative update strategy would be to continue to update the feature weights of the leaf nodes, `1 and `3. However, by identifying the exact source of path divergence we preserve the previously learned balance between leaf node features. 4 Features Features used in our experiments are inspired by previous work on corpus-based approaches for discourse analysis (Marcu and Echihabi, 2002; Lapata, 2003; Elsner et al., 2007). We consider three types of features: lexical, positional, and temporal. This section gives a general overview of these features (see code for further details.) Lexical Features Lexical features have been shown to provide strong cues for sentence positioning. To preserve text cohesion, an inserted sentence has to be topically close to its surrounding sentences. At the paragraph level, we measure topical overlap using the TF*IDF weighted cosine similarity between an inserted sentence and a paragraph. We also use a more linguistically refined similarity measure that computes overlap considering</context>
</contexts>
<marker>Elsner, Austerweil, Charniak, 2007</marker>
<rawString>Micha Elsner, Joseph Austerweil, and Eugene Charniak. 2007. A unified local and global model for discourse coherence. In Proceedings of the HLT-NAACL, pages 436443.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti Hearst</author>
</authors>
<title>Multi-paragraph segmentation of expository text.</title>
<date>1994</date>
<booktitle>In Proceedings of the ACL,</booktitle>
<pages>9--16</pages>
<contexts>
<context position="3787" citStr="Hearst, 1994" startWordPosition="560" endWordPosition="561">ay fail to account for global document coherence (e.g. by allowing the mention of some fact in an inappropriate section). This problem is especially acute in the case of lengthy, real-world texts such as books, technical reports, and web pages. These documents 1 http://stats.wikimedia.org/EN/ TablesWikipediaEN.htm 83 \x0care commonly organized hierarchically into sections and paragraphs to aid reader comprehension. For documents where hierarchical information is not explicitly provided, such as automatic speech transcripts, we can use automatic segmentation methods to induce such a structure (Hearst, 1994). Rather than ignoring the inherent hierarchical structure of these texts, we desire to directly model such hierarchies and use them to our advantage both representationally in our features and algorithmically in our learning procedure. To achieve this goal, we introduce a novel method for sentence insertion that operates over a hierarchical structure. Our document representation includes features for each layer of the hierarchy. For example, the word overlap between the inserted sentence and a section header would be included as an upper-level section feature, whereas a comparison of the sent</context>
</contexts>
<marker>Hearst, 1994</marker>
<rawString>Marti Hearst. 1994. Multi-paragraph segmentation of expository text. In Proceedings of the ACL, pages 9 16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nikiforos Karamanis</author>
<author>Massimo Poesio</author>
<author>Chris Mellish</author>
<author>Jon Oberlander</author>
</authors>
<title>Evaluating centeringbased metrics of coherence for text structuring using a reliably annotated corpus.</title>
<date>2004</date>
<booktitle>In Proceedings of the ACL,</booktitle>
<pages>391398</pages>
<contexts>
<context position="6681" citStr="Karamanis et al., 2004" startWordPosition="1003" endWordPosition="1007">he following section, we provide an overview of existing work on text structuring and hierarchical learning. Then, we define the insertion task and introduce our hierarchical ranking approach to sentence insertion. Next, we present our experimental framework and data. We conclude the paper by presenting and discussing our results. 2 Related Work Text Structuring The insertion task is closely related to the extensively studied problem of sentence ordering.3 Most of the existing algorithms represent text structure as a linear sequence and are driven by local coherence constraints (Lapata, 2003; Karamanis et al., 2004; Okazaki et al., 2004; Barzilay and Lapata, 2005; Bollegala et al., 2006; Elsner and Charniak, 2007). These methods induce a total ordering based on pairwise relations between sentences. Researchers have shown that identifying precedence relations does not require deep semantic interpretation of input sentences: shallow distributional features are sufficient for accurate prediction. Our approach employs similar features to represent nodes at the lowest level of the hierarchy. The key departure of our work from previous research is the incorporation of hierarchical structure into a corpus-base</context>
<context position="23539" citStr="Karamanis et al., 2004" startWordPosition="3871" endWordPosition="3874">s where multiple insertions occur over time to the same article, they are treated independently of each other. To eliminate spam, we place constraints on inserted sentences: (1) a sentence has at least 8 tokens and at most 120 tokens; (2) the MINIPAR parser (Lin, 1998) can identify a subject or an object in a sentence. This process yields 4051 insertion/article pairs, from which 3240 pairs are used for training and 811 pairs for testing. These insertions are derived from 1503 Wikipedia articles. Relative to other corpora used in text structuring research (Barzilay and Lee, 2004; Lapata, 2003; Karamanis et al., 2004), texts in 6 Insertion is only one type of recorded update, others include deletions and sentence rewriting. 88 \x0cour collection are long: an average article has 32.9 sentences, organized in 3.61 sections and 10.9 paragraphs. Our corpus only includes articles that have more than one section. When sentences are inserted between paragraphs, by convention we treat them as part of the previous paragraph. Evaluation Measures We evaluate our model using insertion accuracy at the section and paragraph level. This measure computes the percentage of matches between the predicted location of the inser</context>
</contexts>
<marker>Karamanis, Poesio, Mellish, Oberlander, 2004</marker>
<rawString>Nikiforos Karamanis, Massimo Poesio, Chris Mellish, and Jon Oberlander. 2004. Evaluating centeringbased metrics of coherence for text structuring using a reliably annotated corpus. In Proceedings of the ACL, pages 391398.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mirella Lapata</author>
</authors>
<title>Probabilistic text structuring: Experiments with sentence ordering.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL,</booktitle>
<pages>545552</pages>
<contexts>
<context position="6657" citStr="Lapata, 2003" startWordPosition="1001" endWordPosition="1002">antially. In the following section, we provide an overview of existing work on text structuring and hierarchical learning. Then, we define the insertion task and introduce our hierarchical ranking approach to sentence insertion. Next, we present our experimental framework and data. We conclude the paper by presenting and discussing our results. 2 Related Work Text Structuring The insertion task is closely related to the extensively studied problem of sentence ordering.3 Most of the existing algorithms represent text structure as a linear sequence and are driven by local coherence constraints (Lapata, 2003; Karamanis et al., 2004; Okazaki et al., 2004; Barzilay and Lapata, 2005; Bollegala et al., 2006; Elsner and Charniak, 2007). These methods induce a total ordering based on pairwise relations between sentences. Researchers have shown that identifying precedence relations does not require deep semantic interpretation of input sentences: shallow distributional features are sufficient for accurate prediction. Our approach employs similar features to represent nodes at the lowest level of the hierarchy. The key departure of our work from previous research is the incorporation of hierarchical stru</context>
<context position="12383" citStr="Lapata, 2003" startWordPosition="1920" endWordPosition="1921">e ranking framework. 3 The Algorithm In this section, we present our sentence insertion model and a method for parameter estimation. Given a hierarchically structured text composed of sections and paragraphs, the sentence insertion model determines the best paragraph within 5 The main remaining difference is that Dekel et al. (2004) use a passive-aggressive update rule (Crammer et al., 2006) and in doing so enforce a margin based on tree distance. 85 \x0cwhich to place the new sentence. To identify the exact location of the sentence within the chosen paragraph, local ordering methods such as (Lapata, 2003) could be used. We formalize the insertion task as a structured ranking problem, and our model is trained using an online algorithm. The distinguishing feature of the algorithm is a selective correction mechanism that focuses the model update on the relevant layer of the documents feature hierarchy. The algorithm described below can be applied to any hierarchical ranking problem. For concreteness, we use the terminology of the sentence insertion task, where a hierarchy corresponds to a document with sections and paragraphs. 3.1 Problem Formulation In a sentence insertion problem, we are given </context>
<context position="18239" citStr="Lapata, 2003" startWordPosition="3009" endWordPosition="3010">ted. In response to this mistake, the features associated with the correct section, n2, are added to the weights, and the features of the incorrectly predicted section, n3, are subtracted from the weights. An alternative update strategy would be to continue to update the feature weights of the leaf nodes, `1 and `3. However, by identifying the exact source of path divergence we preserve the previously learned balance between leaf node features. 4 Features Features used in our experiments are inspired by previous work on corpus-based approaches for discourse analysis (Marcu and Echihabi, 2002; Lapata, 2003; Elsner et al., 2007). We consider three types of features: lexical, positional, and temporal. This section gives a general overview of these features (see code for further details.) Lexical Features Lexical features have been shown to provide strong cues for sentence positioning. To preserve text cohesion, an inserted sentence has to be topically close to its surrounding sentences. At the paragraph level, we measure topical overlap using the TF*IDF weighted cosine similarity between an inserted sentence and a paragraph. We also use a more linguistically refined similarity measure that comput</context>
<context position="19552" citStr="Lapata (2003)" startWordPosition="3212" endWordPosition="3213">parser (Lin, 1998). The overlap features are computed at the section level in a similar way. We also introduce an additional section-level overlap feature that computes the cosine similarity between an inserted sentence and the first sentence in a section. In our corpus, the opening sentence of a section is typically strongly 87 \x0cindicative of its topic, thus providing valuable cues for section level insertions. In addition to overlap, we use lexical features that capture word co-occurrence patterns in coherent texts. This measure was first introduced in the context of sentence ordering by Lapata (2003). Given a collection of documents in a specific domain, we compute the likelihood that a pair of words co-occur in adjacent sentences. From these counts, we induce the likelihood that two sentences are adjacent to each other. For a given paragraph and an inserted sentence, the highest adjacency probability between the inserted sentence and paragraph sentences is recorded. This feature is also computed at the section level. Positional Features These features aim to capture user preferences when positioning new information into the body of a document. For instance, in the Wikipedia data, inserti</context>
<context position="23514" citStr="Lapata, 2003" startWordPosition="3869" endWordPosition="3870">tence. In cases where multiple insertions occur over time to the same article, they are treated independently of each other. To eliminate spam, we place constraints on inserted sentences: (1) a sentence has at least 8 tokens and at most 120 tokens; (2) the MINIPAR parser (Lin, 1998) can identify a subject or an object in a sentence. This process yields 4051 insertion/article pairs, from which 3240 pairs are used for training and 811 pairs for testing. These insertions are derived from 1503 Wikipedia articles. Relative to other corpora used in text structuring research (Barzilay and Lee, 2004; Lapata, 2003; Karamanis et al., 2004), texts in 6 Insertion is only one type of recorded update, others include deletions and sentence rewriting. 88 \x0cour collection are long: an average article has 32.9 sentences, organized in 3.61 sections and 10.9 paragraphs. Our corpus only includes articles that have more than one section. When sentences are inserted between paragraphs, by convention we treat them as part of the previous paragraph. Evaluation Measures We evaluate our model using insertion accuracy at the section and paragraph level. This measure computes the percentage of matches between the predic</context>
<context position="26941" citStr="Lapata, 2003" startWordPosition="4401" endWordPosition="4402">istance, where a lower score corresponds to better performance. Diacritic * (p &amp;lt; 0.01) indicates whether differences in accuracy between the given model and the Hierarchical model is significant (using a Fisher Sign Test). in paragraph placement. We obtain similar results when we compare the agreement of the judges against each other: 65% of section inserts and 48% of paragraph inserts are identical between two annotators. The degree of variability observed in this experiment is consistent with human performance on other text structuring tasks such as sentence ordering (Barzilay et al., 2002; Lapata, 2003). 6 Results Table 2 shows the insertion performance of our model and the baselines in terms of accuracy and tree distance error. The two evaluation measures are consistent in that they yield roughly identical rankings of the systems. Assessment of statistical significance is performed using a Fisher Sign Test. We apply this test to compare the accuracy of the HIERARCHICAL model against each of the baselines. The results in Table 2 indicate that the naive insertion baselines (RANDOMINS, FIRSTINS, LASTINS) fall substantially behind the more sophisticated, trainable strategies (PIPELINE, FLAT, HI</context>
<context position="28903" citStr="Lapata, 2003" startWordPosition="4709" endWordPosition="4710">ormance at the paragraph level is 32% smaller than that between the PIPELINE model and human performance, as well as the FLAT model and human performance. Sentence-level Evaluation Until this point, we have evaluated the accuracy of insertions at the paragraph level, remaining agnostic as to the specific placement within the predicted paragraph. We perform one final evaluation to test whether the global hierarchical view of our algorithm helps in determining the exact insertion point. To make sentencelevel insertion decisions, we use a local model in line with previous sentence-ordering work (Lapata, 2003; Bollegala et al., 2006). This model examines the two surrounding sentences of each possible insertion point and extracts a feature vector that includes lexical, positional, and temporal properties. The model weights are trained using the standard ranking perceptron (Collins, 2002). We apply this local insertion model in two different scenarios. In the first, we ignore the global hierarchical structure of the document and apply the local insertion model to every possible sentence pair. Using this strategy, we recover 24% of correct insertion points. The second strategy takes advantage of glob</context>
</contexts>
<marker>Lapata, 2003</marker>
<rawString>Mirella Lapata. 2003. Probabilistic text structuring: Experiments with sentence ordering. In Proceedings of the ACL, pages 545552.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Dependency-based evaluation of minipar.</title>
<date>1998</date>
<booktitle>In Proceedings of the Workshop on the Evaluation of Parsing Systems, LREC,</booktitle>
<pages>4856</pages>
<contexts>
<context position="18957" citStr="Lin, 1998" startWordPosition="3118" endWordPosition="3119"> gives a general overview of these features (see code for further details.) Lexical Features Lexical features have been shown to provide strong cues for sentence positioning. To preserve text cohesion, an inserted sentence has to be topically close to its surrounding sentences. At the paragraph level, we measure topical overlap using the TF*IDF weighted cosine similarity between an inserted sentence and a paragraph. We also use a more linguistically refined similarity measure that computes overlap considering only subjects and objects. Syntactic analysis is performed using the MINIPAR parser (Lin, 1998). The overlap features are computed at the section level in a similar way. We also introduce an additional section-level overlap feature that computes the cosine similarity between an inserted sentence and the first sentence in a section. In our corpus, the opening sentence of a section is typically strongly 87 \x0cindicative of its topic, thus providing valuable cues for section level insertions. In addition to overlap, we use lexical features that capture word co-occurrence patterns in coherent texts. This measure was first introduced in the context of sentence ordering by Lapata (2003). Giv</context>
<context position="23185" citStr="Lin, 1998" startWordPosition="3817" endWordPosition="3818">phies used in text generation research (Duboue and McKeown, 2003). We obtain data on insertions6 from the update log that accompanies every Wikipedia entry. For each change in the articles history, the log records an article before and after the change. From this information, we can identify the location of every inserted sentence. In cases where multiple insertions occur over time to the same article, they are treated independently of each other. To eliminate spam, we place constraints on inserted sentences: (1) a sentence has at least 8 tokens and at most 120 tokens; (2) the MINIPAR parser (Lin, 1998) can identify a subject or an object in a sentence. This process yields 4051 insertion/article pairs, from which 3240 pairs are used for training and 811 pairs for testing. These insertions are derived from 1503 Wikipedia articles. Relative to other corpora used in text structuring research (Barzilay and Lee, 2004; Lapata, 2003; Karamanis et al., 2004), texts in 6 Insertion is only one type of recorded update, others include deletions and sentence rewriting. 88 \x0cour collection are long: an average article has 32.9 sentences, organized in 3.61 sections and 10.9 paragraphs. Our corpus only in</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. 1998. Dependency-based evaluation of minipar. In Proceedings of the Workshop on the Evaluation of Parsing Systems, LREC, pages 4856.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Inderjeet Mani</author>
<author>George Wilson</author>
</authors>
<title>Robust temporal processing of news.</title>
<date>2000</date>
<booktitle>In Proceedings of the ACL,</booktitle>
<pages>6976</pages>
<contexts>
<context position="21477" citStr="Mani and Wilson, 2000" startWordPosition="3530" endWordPosition="3533"> fledged temporal interpretation. Instead, we extract these features based on two categories of temporal cues: verb tense and date information. The verb tense feature captures whether a paragraph contains at least one sentence using the same tense as the inserted sentence. For instance, this feature would occur for the inserted sentence in Figure 1 since both the sentence and chosen paragraph employ the past tense. Another set of features takes into account the relation between the dates in a paragraph and those in an inserted sentence. We extract temporal expressions using the TIMEX2 tagger (Mani and Wilson, 2000), and compute the time interval for a paragraph bounded by its earliest and latest dates. We record the degree of overlap between the paragraph time inSection Paragraph Tree Dist T1 J1 0.575 0.5 1.85 J2 0.7 0.525 1.55 T2 J3 0.675 0.55 1.55 J4 0.725 0.55 1.45 Table 1: Accuracy of human insertions compared against gold standard from Wikipedias update log. T1 is a subset of the data annotated by judges J1 and J2, while T2 is annotated by J3 and J4. terval and insertion sentence time interval. 5 Experimental Set-Up Corpus Our corpus consists of Wikipedia articles that belong to the category Living</context>
</contexts>
<marker>Mani, Wilson, 2000</marker>
<rawString>Inderjeet Mani and George Wilson. 2000. Robust temporal processing of news. In Proceedings of the ACL, pages 6976.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
<author>Abdessamad Echihabi</author>
</authors>
<title>An unsupervised approach to recognizing discourse relations.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL,</booktitle>
<pages>368375</pages>
<contexts>
<context position="18225" citStr="Marcu and Echihabi, 2002" startWordPosition="3005" endWordPosition="3008">aph are incorrectly predicted. In response to this mistake, the features associated with the correct section, n2, are added to the weights, and the features of the incorrectly predicted section, n3, are subtracted from the weights. An alternative update strategy would be to continue to update the feature weights of the leaf nodes, `1 and `3. However, by identifying the exact source of path divergence we preserve the previously learned balance between leaf node features. 4 Features Features used in our experiments are inspired by previous work on corpus-based approaches for discourse analysis (Marcu and Echihabi, 2002; Lapata, 2003; Elsner et al., 2007). We consider three types of features: lexical, positional, and temporal. This section gives a general overview of these features (see code for further details.) Lexical Features Lexical features have been shown to provide strong cues for sentence positioning. To preserve text cohesion, an inserted sentence has to be topically close to its surrounding sentences. At the paragraph level, we measure topical overlap using the TF*IDF weighted cosine similarity between an inserted sentence and a paragraph. We also use a more linguistically refined similarity measu</context>
</contexts>
<marker>Marcu, Echihabi, 2002</marker>
<rawString>Daniel Marcu and Abdessamad Echihabi. 2002. An unsupervised approach to recognizing discourse relations. In Proceedings of the ACL, pages 368375.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Naoaki Okazaki</author>
<author>Yutaka Matsuo</author>
<author>Mitsuru Ishizuka</author>
</authors>
<title>Improving chronological sentence ordering by precedence relation.</title>
<date>2004</date>
<booktitle>In Proceedings of the COLING,</booktitle>
<pages>750756</pages>
<contexts>
<context position="6703" citStr="Okazaki et al., 2004" startWordPosition="1008" endWordPosition="1011"> provide an overview of existing work on text structuring and hierarchical learning. Then, we define the insertion task and introduce our hierarchical ranking approach to sentence insertion. Next, we present our experimental framework and data. We conclude the paper by presenting and discussing our results. 2 Related Work Text Structuring The insertion task is closely related to the extensively studied problem of sentence ordering.3 Most of the existing algorithms represent text structure as a linear sequence and are driven by local coherence constraints (Lapata, 2003; Karamanis et al., 2004; Okazaki et al., 2004; Barzilay and Lapata, 2005; Bollegala et al., 2006; Elsner and Charniak, 2007). These methods induce a total ordering based on pairwise relations between sentences. Researchers have shown that identifying precedence relations does not require deep semantic interpretation of input sentences: shallow distributional features are sufficient for accurate prediction. Our approach employs similar features to represent nodes at the lowest level of the hierarchy. The key departure of our work from previous research is the incorporation of hierarchical structure into a corpus-based approach to ordering</context>
</contexts>
<marker>Okazaki, Matsuo, Ishizuka, 2004</marker>
<rawString>Naoaki Okazaki, Yutaka Matsuo, and Mitsuru Ishizuka. 2004. Improving chronological sentence ordering by precedence relation. In Proceedings of the COLING, pages 750756.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ehud Reiter</author>
<author>Robert Dale</author>
</authors>
<title>Building Natural Language Generation Systems.</title>
<date>1990</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge.</location>
<contexts>
<context position="7434" citStr="Reiter and Dale, 1990" startWordPosition="1116" endWordPosition="1119"> ordering based on pairwise relations between sentences. Researchers have shown that identifying precedence relations does not require deep semantic interpretation of input sentences: shallow distributional features are sufficient for accurate prediction. Our approach employs similar features to represent nodes at the lowest level of the hierarchy. The key departure of our work from previous research is the incorporation of hierarchical structure into a corpus-based approach to ordering. While in symbolic generation and discourse analysis a text is typically analyzed as a tree-like structure (Reiter and Dale, 1990), a linear view is prevalent in data-driven methods to text structuring.4 Moving beyond a linear representation enables us to handle longer texts where a local view of coherence does not suffice. At the same time, our approach does not require any manual rules for handling tree insertions, in contrast to symbolic text planners. 3 Independently and simultaneously with our work, Elsner and Charniak (2007) have studied the sentence insertion task in a different setting. 4 Though statistical methods have been used to induce such trees (Soricut and Marcu, 2003), they are not used for ordering and o</context>
</contexts>
<marker>Reiter, Dale, 1990</marker>
<rawString>Ehud Reiter and Robert Dale. 1990. Building Natural Language Generation Systems. Cambridge University Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Radu Soricut</author>
<author>Daniel Marcu</author>
</authors>
<title>Sentence level discourse parsing using syntactic and lexical information.</title>
<date>2003</date>
<booktitle>In Proceedings of the HLT-NAACL,</booktitle>
<pages>149--156</pages>
<contexts>
<context position="7996" citStr="Soricut and Marcu, 2003" startWordPosition="1206" endWordPosition="1209">ally analyzed as a tree-like structure (Reiter and Dale, 1990), a linear view is prevalent in data-driven methods to text structuring.4 Moving beyond a linear representation enables us to handle longer texts where a local view of coherence does not suffice. At the same time, our approach does not require any manual rules for handling tree insertions, in contrast to symbolic text planners. 3 Independently and simultaneously with our work, Elsner and Charniak (2007) have studied the sentence insertion task in a different setting. 4 Though statistical methods have been used to induce such trees (Soricut and Marcu, 2003), they are not used for ordering and other text-structuring tasks. 84 \x0cShaukat Aziz (born March 6, 1949, Karachi, Pakistan) has been the Finance Minister of Pakistan since November 1999. He was nominated for the position of Prime Minister after the resignation of Zafarullah Khan Jamali on June 6, 2004. Education Aziz attended Saint Patricks school, Karachi and Abbottabad Public School. He graduated with a Bachelor of Science degree from Gordon College, Rawalpindi, in 1967. He obtained an MBA Degree in 1969 from the Institute of Business Administration, Karachi. Career In November, 1999, Mr.</context>
</contexts>
<marker>Soricut, Marcu, 2003</marker>
<rawString>Radu Soricut and Daniel Marcu. 2003. Sentence level discourse parsing using syntactic and lexical information. In Proceedings of the HLT-NAACL, pages 149 156.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>