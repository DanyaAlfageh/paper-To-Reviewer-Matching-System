<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000597">
<address confidence="0.305448">
b&apos;Coling 2010: Demonstration Volume, pages 4144,
Beijing, August 2010
</address>
<title confidence="0.916143">
Antelogue: Pronoun Resolution for Text and Dialogue
</title>
<author confidence="0.969496">
Eleni Miltsakaki
</author>
<affiliation confidence="0.997952">
University of Pennsylvania
</affiliation>
<email confidence="0.996935">
elenimi@seas.upenn.edu
</email>
<sectionHeader confidence="0.990654" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999249071428571">
Antelogue is a pronoun resolution prototype de-
signed to be released as off-the-shelf software to
be used autonomously or integrated with larger
anaphora resolution or other NLP systems. It has
modules to handle pronouns in both text and dia-
logue. In Antelogue, the problem of pronoun reso-
lution is addressed as a two-step process: a) acquir-
ing information about properties of words and the
entities they represent and b) determining an algo-
rithm that utilizes these features to make resolution
decisions. A hybrid approach is implemented that
combines known statistical and machine learning
techniques for feature acquisition and a symbolic
algorithm for resolution.
</bodyText>
<sectionHeader confidence="0.997837" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997387903225806">
Pronoun resolution is the well-known problem of
identifying antecedents for pronominal references
in text or dialogue. We present a prototype of
new system for pronoun resolution, Antelogue,
that handles both text and dialogues. In our ap-
proach, pronoun resolution is done in two steps:
a) feature acquisition of properties of words and
the entities they represent and b) resolution algo-
rithm. We adopt a hybrid approach to the problem,
using statistical and machine learning techniques
widely available in the NLP literature to collect
features and a symbolic algorithm informed by
prior research in anaphora resolution and models
of entity salience to appropriately rank and evalu-
ate antecedents.
The design and architecture of Antelogue is
modular and flexible and will soon be released
for off-the-shelf use as an independent compo-
nent or for possible integration of larger anaphora
resolution systems, such as the GuiTAR (Gen-
eral Tool for Anaphora Resolution) (Poesio and
Kabadjov, 2004) that currently is released with
(Mitkov et al., 2002)s statistical pronoun resolu-
tion algorithm, MARS, that processes pronouns in
text. Motivation for building a new algorithm for
text and dialogues has been the problem of align-
ment between caption dialogues and stage direc-
tions on one hand and video content in movies on
the other. While pronoun resolution in stage direc-
tions proved to be a fairly easy task, in dialogues
we are facing the following challenges:
</bodyText>
<listItem confidence="0.952772916666667">
1. Part of speech taggers trained on text (typically
the Wall Street Journal texts of Penn Treebank)
perform poorly on dialogues, primarily due to the
fragmented nature of spoken language. As a result
NP tags are overgenerated.
2. Fragmentary speech and disfluencies or false
starts common in dialogues cannot be handled by
parsers trained on text.
3. First and second person pronouns are common.
Special algorithms are needed to handle them.
4. Special addressee patterns need to be identified
to block first and second person named references
(e.g., Hey, John, where did he go?) becoming
antecedents for third person pronouns.
5. In dialogues, pronouns can be used for ref-
erence to people or objects that are visually but
not textually accessible. Special algorithms are
needed to identify when an antecedent is not
present in the text.
6. Pronouns are used for reference to people or
objects that are visually salient in the scene but not
mentioned explicitly in the dialogue, i.e., there are
no textual antecedents.
7. Multi-party dialogues, sometimes 3rd person
</listItem>
<bodyText confidence="0.918525">
pronouns are used to refer to other speakers. It is
hard to identify when an instance of a 3rd person
pronoun has an antecedent in the prior discourse
</bodyText>
<page confidence="0.99879">
41
</page>
<bodyText confidence="0.99497875">
\x0cor another speaker.
In what follows, we present the systems de-
sign and architecture and the components that
have already been implemented. In the demo, the
users will be able to use Antelogues GUI to enter
their own data and evaluate the systems perfor-
mance in real time. The current version handles
first, second, and third person singular pronouns,
including a classification recognizing referential
and non-referential instances of it. Antelogue
does not, yet, handle plural pronouns or recognize
impersonal uses of singular you.
</bodyText>
<figure confidence="0.995901285714286">
Resource
Processor
Resource
Processor
Resource
Processor
Input text
Antelogue Repository
Pronoun Resolution
XML-
annotation
E-Grid
representation
Resource Resource Resource
</figure>
<figureCaption confidence="0.999871">
Figure 1: General System Architecture
</figureCaption>
<sectionHeader confidence="0.736256" genericHeader="method">
2 System design
</sectionHeader>
<bodyText confidence="0.99335387804878">
The problem of pronoun resolution is addressed
as a two-step process: a) acquiring information
about properties of words and the entities they
represent and b) determining an algorithm that uti-
lizes these features to make resolution decisions.
A hybrid approach is implemented that combines
known statistical and machine learning techniques
for feature acquisition and a symbolic algorithm
for resolution.
For the feature acquisition step, any number
of feature acquisition sub-modules can be imple-
mented. The architecture is flexible such that new
feature acquisition modules can be added as they
may become available or deemed crucial for spe-
cific applications. The demo version acquires fea-
tures from a sentence tokenizer, word tokenizer,
NER tagger, gender and number database and
POS tagger. For every sub-module a correspond-
ing parser analyzes the output of the submodules
to retrieve the features and store them in the Ante-
logue repository.
The resolution step implements an algorithm
for utilizing the features in the repository to make
resolution decisions. The resolution module needs
to communicate only with the repository to get
feature information and outputs xml annotated
text or, what we call, e-grid output in which pro-
nouns have been replaced by their antecedents. If
the identified antecedent is a pronoun, it is fur-
ther looked-up until a non-pronominal antecedent
is found. A pronominal antecedent is shown only
in case there is no nominal antecedent available.
The architecture of Antelogue is illustrated in
Fig. 1. Antelogue can be set to perform pro-
noun resolution in both dialogue and text. A pre-
processing step is required to ensure that the files
are in the appropriate format. Because Antelogue
was built to perform pronoun resolution in the di-
alogues and stage directions of screenplays, the
pre-processing steps required to extract dialogues
and text from the TV seriesLost, are available.
</bodyText>
<sectionHeader confidence="0.945939" genericHeader="method">
3 System architecture
</sectionHeader>
<bodyText confidence="0.991963411764706">
Feature acquisition Sentence and word tok-
enization: built based on (Ratnaparkhi, 1996).
To address dialogue idiosyncrasies, sentence to-
kenization is forced to respect speaker turns thus
blocking forming sentences across speaker turns.
Word processor. This module processes the word
tokenized file and creates an indexed entry for ev-
ery word in the Antelogue repository.
Named Entity Recognizer tagging (NER): We in-
tegrated Stanfords NER tagger (Finkel et al.,
2005).
NER processor. This module processor the NER
tagged file and associates identified NER tags
with the corresponding words in the Antelogue
repository.
Gender and Animacy processor: This modules
collects gender information from the gender cor-
</bodyText>
<footnote confidence="0.486332">
pus1 (Bergsma and Lin, 2006) and checks a self-
1
http://www.cs.ualberta.ca/ bergsma/
Gender.
</footnote>
<page confidence="0.983403">
42
</page>
<bodyText confidence="0.996537244444444">
\x0cmade corpus for profession (teacher, doctor, etc)
and family relations (mother, father, etc), ex-
tracted from web searches. In the gender corpus,
gender and number data are collected statistically
and are not always reliable. We developed a sim-
ple confidence metric to evaluate the reliability of
the gender and number data. If the ratio of the
highest probability to the sum of all other proba-
bilities is lower than 60% we mark gender or num-
ber unknown.2 Part-of-speech tagging (POS). We
trained (Ratnaparkhi, 1996)s POS tagger on di-
alogue data obtained from the English CTS Tree-
bank with Structural Metadata released by LDC in
2009. POS parser. This modules parses the POS-
tagged input and updates the Antelogue reposi-
tory.
Pronoun resolution The pronoun resolution
submodule, currently, has three submodules: a)
first and second person pronouns, b) third person
singular masculine and feminine pronouns, and c)
third person singular neuter pronouns.
For the first and second person pronouns, Ante-
logue identifies and resolves all instances of I to
the speaker name and all instances of you to the
next speaker. It there is no other speaker (when
you is in the last turn), the algorithm will pick
the speaker from the previous turn. If there is no
previous turn, it is declared unresolvable.
For the third person he and she module, the
algorithmAntelogue searches for pronouns back-
wards starting at the last sentence of the dialogue.
For every sentence we construct a list of potential
antecedents identified as nouns or pronouns by the
POS tagger. A number of filters, then apply, to fil-
ter out incompatible antecedents. A category of
incompatible antecedents for he and she that
is almost unique to dialogues are addressee ref-
erences. We identify references to addressee us-
ing surface punctuation features. Resolution starts
with a look-up at antecedents of the current sen-
tences, processing them from left-to-right. If the
first antecedent is identified in the human cor-
pus and has compatible gender information, it is
picked. If not, the gender corpus is searched for
reliable matches. Once a match is identified, it
</bodyText>
<page confidence="0.958791">
2
</page>
<bodyText confidence="0.996349854166667">
(Charniak and Elsner, 2009)s system learns gender in-
formation using Expectation Maximization.
is filtered by NER. The gender corpus often as-
signs feminine or masculine gender to common
nouns. Only those entities that have a NER tag
pass the compatibility test. If no compatible an-
tecedent is found in the current sentence, Antel-
ogue continues search in the previous sentence. If
the dialogues have scene boundaries, as the case
is in Lost, the search for an antecedents stops at
a scene boundary. Otherwise it will not stop be-
fore the first sentence of the dialogue is reached.
If no compatible antecedent is found, it is declared
unresolvable. Correctly declaring pronouns un-
resolvable is extremely useful in dialogues, espe-
cially from movies, in which a referent of a third
person pronoun may be visually available but not
introduced in the prior discourse. Correctly un-
resolvable feminine and masculine pronouns sig-
nal a cue for search in the visuals scene, a cross-
modal direction that we are pursuing as part of fu-
ture work.
For the third person it, we first need to ad-
dress the issue of identifying referential and non-
referential instances of it.3 Non-referential in-
stances of it include pleonastic it (e.g., it
rains, or it is certain that...) and references to
a verbal or other clausal antecedent (e.g., it in
Mary got the award. Its wonderful!). For the
it classification task, we follow (Bergsma et al.,
2008) approach. We generate 4 and 5 word pat-
terns out using the found occurrences of it then
replace it/its with they/theirs/them. Frequen-
cies of the substituted versions are computed us-
ing data from the Google n-gram corpus. If substi-
tutions with they/theirs/them are not common,
it is classified as non-referential.
Antelogue outputs a)an XML file with annota-
tions of entities, pronouns and antecedents, and
b)an e-grid representation file in which all pro-
nouns have been replaced with their referents. In
the XML file, pronouns are either resolved or
declared unresolvable if no antecedent is identi-
fied. The pronoun it can, additionally, be de-
clared non-referential. The e-grid representation
file is useful for evaluating text coherence using
the file directly as input to the (Barzilay and La-
pata, 2008)s e-grid model, a direction we want
</bodyText>
<page confidence="0.985253">
3
</page>
<bodyText confidence="0.9862835">
For simplicity, we are sloppy here using the term non-
referential to mean non-referring to a nominal entity.
</bodyText>
<page confidence="0.999445">
43
</page>
<bodyText confidence="0.999757821428571">
\x0cto take in the future to explore its strengths in
automatically identifying scene boundaries. De-
spite well-known problems in making meaningful
comparisons in pronoun resolution systems, An-
telogues performance is comparable to some of
the highest reported performances, either identify-
ing correctly an antecedent or correctly declaring
a pronoun unresolvable or non-referential in 85%
of 600 annotated pronouns.
Text module: Antelogues architecture for re-
solving pronouns in text is identical to dialogues
except that a)the pre-processing text extracts text
from the stage directions in the screenplay, b)
addressee patterns are not used to filter out an-
tecedents for he and she and instances of I
and you are ignored. In the future we plan to
implement resolution of I and you as well as
a dialogue style resolution of he and she for
instances of embedded speech. These instances
were extremely rare in our data but they need to
be catered for in the future. Antelogues perfor-
mance exceeds 90% for stage directions because
stage directions are relatively simple and fairly
unambiguous. For this reason, a syntactic parse
which slows down the system considerably was
not used. However, to retain similar levels of per-
formance in different domains, the use of syntac-
tic parse will be needed.
</bodyText>
<sectionHeader confidence="0.99109" genericHeader="method">
4 Antelogue API and demo
</sectionHeader>
<bodyText confidence="0.999223933333333">
Antelogue is implemented in Java. Its API in-
cludes an executable file, an empty database for
the repository and command line instructions for
running the system. The dialogue POS tagger is
also available. The other feature acquisition sub-
modules, text POS tagger, NER tagger and gen-
der database are publicly available. Antelogue
makes use of the google n-gram corpus, available
through the Linguistic Data Consortium.4
As an off-the-shelf application, designed both
for integration but also for experimentation, eval-
uation and comparison with other systems, Ante-
logue runs on a single unix command. The user
is prompted to choose the dialogue or text module
and then is asked to determine the path with the
</bodyText>
<figure confidence="0.563897333333333">
4
http://www.ldc.upenn.edu/Catalog/
CatalogEntry.jsp?catalogId=LDC2006T13
</figure>
<bodyText confidence="0.99150945">
data. Antelogue returns annotated files with re-
solved pronouns in seconds for a reasonably sized
file (approx. 2,000-3,000 words) or in couple of
minutes for very large files. These processing
time estimates apply to the demo version. Pro-
cessing time will carry depending on the number
of submodule implemented in the feature acquisi-
tion step.
For the demo, we built a special Graphical User
Interface. In the left part of the GUI, the user can
either type in his or her own text or dialogue, paste
text or dialogue, or select a local file. There are se-
lections for the text/dialogue mode and xml/e-grid
outputs. Antelogue performs pronoun resolution
in real time and show the results on the right hand
side part of the GUI.
Acknowledgments: Special thanks to Ben
Taskar for his help and guidance in this project
and to NSF IIS-0803538 grant for financial
support.
</bodyText>
<sectionHeader confidence="0.990349" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999544777777778">
Barzilay, R. and M. Lapata. 2008. Modeling local co-
herence: An entity-based approach. Computational
Linguistics.
Bergsma, S. and D. Lin. 2006. Bootstrapping path-
based pronoun resolution. In ACL06, pages 3340.
Bergsma, S., D. Lin, and R. Goebel. 2008. Distribu-
tional identification of non-referential pronouns. In
ACL08, pages 1018.
Charniak, E. and M. Elsner. 2009. Em works for pro-
noun resolution. In Proceedings of EACL 2009.
Finkel, J.R., T. Grenager, and C. Manning. 2005. In-
corporating Non-local Information into Information
Extraction Systems by Gibbs Sampling. Ann Arbor,
100.
Mitkov, R., R. Evans, and C. Orasan. 2002. A new,
fully automatic version of Mitkovs knowledge-poor
pronoun resolution method. Lecture notes in com-
puter science, pages 168186.
Poesio, M. and M.A. Kabadjov. 2004. A general-
purpose, off-the-shelf anaphora resolution module:
Implementation and preliminary evaluation. In
Proc. of the 4th International Conference on Lan-
guage Resources and Evaluation. Lisbon, Portugal.
Citeseer.
Ratnaparkhi, A. 1996. A maximum entropy model
for part-of-speech tagging. In In Proceedings of
EMNLP96, pages 133142.
</reference>
<page confidence="0.967185">
44
</page>
<figure confidence="0.262394">
\x0c&apos;
</figure>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.436915">
<note confidence="0.7029345">b&apos;Coling 2010: Demonstration Volume, pages 4144, Beijing, August 2010</note>
<title confidence="0.970063">Antelogue: Pronoun Resolution for Text and Dialogue</title>
<author confidence="0.997956">Eleni Miltsakaki</author>
<affiliation confidence="0.999885">University of Pennsylvania</affiliation>
<email confidence="0.999911">elenimi@seas.upenn.edu</email>
<abstract confidence="0.997534533333333">Antelogue is a pronoun resolution prototype designed to be released as off-the-shelf software to be used autonomously or integrated with larger anaphora resolution or other NLP systems. It has modules to handle pronouns in both text and dialogue. In Antelogue, the problem of pronoun resolution is addressed as a two-step process: a) acquiring information about properties of words and the entities they represent and b) determining an algorithm that utilizes these features to make resolution decisions. A hybrid approach is implemented that combines known statistical and machine learning techniques for feature acquisition and a symbolic algorithm for resolution.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R Barzilay</author>
<author>M Lapata</author>
</authors>
<title>Modeling local coherence: An entity-based approach. Computational Linguistics.</title>
<date>2008</date>
<contexts>
<context position="11416" citStr="Barzilay and Lapata, 2008" startWordPosition="1800" endWordPosition="1804"> using data from the Google n-gram corpus. If substitutions with they/theirs/them are not common, it is classified as non-referential. Antelogue outputs a)an XML file with annotations of entities, pronouns and antecedents, and b)an e-grid representation file in which all pronouns have been replaced with their referents. In the XML file, pronouns are either resolved or declared unresolvable if no antecedent is identified. The pronoun it can, additionally, be declared non-referential. The e-grid representation file is useful for evaluating text coherence using the file directly as input to the (Barzilay and Lapata, 2008)s e-grid model, a direction we want 3 For simplicity, we are sloppy here using the term nonreferential to mean non-referring to a nominal entity. 43 \x0cto take in the future to explore its strengths in automatically identifying scene boundaries. Despite well-known problems in making meaningful comparisons in pronoun resolution systems, Antelogues performance is comparable to some of the highest reported performances, either identifying correctly an antecedent or correctly declaring a pronoun unresolvable or non-referential in 85% of 600 annotated pronouns. Text module: Antelogues architecture</context>
</contexts>
<marker>Barzilay, Lapata, 2008</marker>
<rawString>Barzilay, R. and M. Lapata. 2008. Modeling local coherence: An entity-based approach. Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bergsma</author>
<author>D Lin</author>
</authors>
<title>Bootstrapping pathbased pronoun resolution.</title>
<date>2006</date>
<booktitle>In ACL06,</booktitle>
<pages>3340</pages>
<contexts>
<context position="6999" citStr="Bergsma and Lin, 2006" startWordPosition="1077" endWordPosition="1080">yncrasies, sentence tokenization is forced to respect speaker turns thus blocking forming sentences across speaker turns. Word processor. This module processes the word tokenized file and creates an indexed entry for every word in the Antelogue repository. Named Entity Recognizer tagging (NER): We integrated Stanfords NER tagger (Finkel et al., 2005). NER processor. This module processor the NER tagged file and associates identified NER tags with the corresponding words in the Antelogue repository. Gender and Animacy processor: This modules collects gender information from the gender corpus1 (Bergsma and Lin, 2006) and checks a self1 http://www.cs.ualberta.ca/ bergsma/ Gender. 42 \x0cmade corpus for profession (teacher, doctor, etc) and family relations (mother, father, etc), extracted from web searches. In the gender corpus, gender and number data are collected statistically and are not always reliable. We developed a simple confidence metric to evaluate the reliability of the gender and number data. If the ratio of the highest probability to the sum of all other probabilities is lower than 60% we mark gender or number unknown.2 Part-of-speech tagging (POS). We trained (Ratnaparkhi, 1996)s POS tagger o</context>
</contexts>
<marker>Bergsma, Lin, 2006</marker>
<rawString>Bergsma, S. and D. Lin. 2006. Bootstrapping pathbased pronoun resolution. In ACL06, pages 3340.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bergsma</author>
<author>D Lin</author>
<author>R Goebel</author>
</authors>
<title>Distributional identification of non-referential pronouns.</title>
<date>2008</date>
<booktitle>In ACL08,</booktitle>
<pages>1018</pages>
<contexts>
<context position="10612" citStr="Bergsma et al., 2008" startWordPosition="1673" endWordPosition="1676">visually available but not introduced in the prior discourse. Correctly unresolvable feminine and masculine pronouns signal a cue for search in the visuals scene, a crossmodal direction that we are pursuing as part of future work. For the third person it, we first need to address the issue of identifying referential and nonreferential instances of it.3 Non-referential instances of it include pleonastic it (e.g., it rains, or it is certain that...) and references to a verbal or other clausal antecedent (e.g., it in Mary got the award. Its wonderful!). For the it classification task, we follow (Bergsma et al., 2008) approach. We generate 4 and 5 word patterns out using the found occurrences of it then replace it/its with they/theirs/them. Frequencies of the substituted versions are computed using data from the Google n-gram corpus. If substitutions with they/theirs/them are not common, it is classified as non-referential. Antelogue outputs a)an XML file with annotations of entities, pronouns and antecedents, and b)an e-grid representation file in which all pronouns have been replaced with their referents. In the XML file, pronouns are either resolved or declared unresolvable if no antecedent is identifie</context>
</contexts>
<marker>Bergsma, Lin, Goebel, 2008</marker>
<rawString>Bergsma, S., D. Lin, and R. Goebel. 2008. Distributional identification of non-referential pronouns. In ACL08, pages 1018.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Charniak</author>
<author>M Elsner</author>
</authors>
<title>Em works for pronoun resolution.</title>
<date>2009</date>
<booktitle>In Proceedings of EACL</booktitle>
<contexts>
<context position="9220" citStr="Charniak and Elsner, 2009" startWordPosition="1438" endWordPosition="1441">nouns by the POS tagger. A number of filters, then apply, to filter out incompatible antecedents. A category of incompatible antecedents for he and she that is almost unique to dialogues are addressee references. We identify references to addressee using surface punctuation features. Resolution starts with a look-up at antecedents of the current sentences, processing them from left-to-right. If the first antecedent is identified in the human corpus and has compatible gender information, it is picked. If not, the gender corpus is searched for reliable matches. Once a match is identified, it 2 (Charniak and Elsner, 2009)s system learns gender information using Expectation Maximization. is filtered by NER. The gender corpus often assigns feminine or masculine gender to common nouns. Only those entities that have a NER tag pass the compatibility test. If no compatible antecedent is found in the current sentence, Antelogue continues search in the previous sentence. If the dialogues have scene boundaries, as the case is in Lost, the search for an antecedents stops at a scene boundary. Otherwise it will not stop before the first sentence of the dialogue is reached. If no compatible antecedent is found, it is decla</context>
</contexts>
<marker>Charniak, Elsner, 2009</marker>
<rawString>Charniak, E. and M. Elsner. 2009. Em works for pronoun resolution. In Proceedings of EACL 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Finkel</author>
<author>T Grenager</author>
<author>C Manning</author>
</authors>
<title>Incorporating Non-local Information into Information Extraction Systems by Gibbs Sampling.</title>
<date>2005</date>
<journal>Ann Arbor,</journal>
<volume>100</volume>
<contexts>
<context position="6729" citStr="Finkel et al., 2005" startWordPosition="1037" endWordPosition="1040">ge directions of screenplays, the pre-processing steps required to extract dialogues and text from the TV seriesLost, are available. 3 System architecture Feature acquisition Sentence and word tokenization: built based on (Ratnaparkhi, 1996). To address dialogue idiosyncrasies, sentence tokenization is forced to respect speaker turns thus blocking forming sentences across speaker turns. Word processor. This module processes the word tokenized file and creates an indexed entry for every word in the Antelogue repository. Named Entity Recognizer tagging (NER): We integrated Stanfords NER tagger (Finkel et al., 2005). NER processor. This module processor the NER tagged file and associates identified NER tags with the corresponding words in the Antelogue repository. Gender and Animacy processor: This modules collects gender information from the gender corpus1 (Bergsma and Lin, 2006) and checks a self1 http://www.cs.ualberta.ca/ bergsma/ Gender. 42 \x0cmade corpus for profession (teacher, doctor, etc) and family relations (mother, father, etc), extracted from web searches. In the gender corpus, gender and number data are collected statistically and are not always reliable. We developed a simple confidence m</context>
</contexts>
<marker>Finkel, Grenager, Manning, 2005</marker>
<rawString>Finkel, J.R., T. Grenager, and C. Manning. 2005. Incorporating Non-local Information into Information Extraction Systems by Gibbs Sampling. Ann Arbor, 100.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mitkov</author>
<author>R Evans</author>
<author>C Orasan</author>
</authors>
<title>A new, fully automatic version of Mitkovs knowledge-poor pronoun resolution method. Lecture notes in computer science,</title>
<date>2002</date>
<pages>168186</pages>
<contexts>
<context position="1926" citStr="Mitkov et al., 2002" startWordPosition="286" endWordPosition="289">e problem, using statistical and machine learning techniques widely available in the NLP literature to collect features and a symbolic algorithm informed by prior research in anaphora resolution and models of entity salience to appropriately rank and evaluate antecedents. The design and architecture of Antelogue is modular and flexible and will soon be released for off-the-shelf use as an independent component or for possible integration of larger anaphora resolution systems, such as the GuiTAR (General Tool for Anaphora Resolution) (Poesio and Kabadjov, 2004) that currently is released with (Mitkov et al., 2002)s statistical pronoun resolution algorithm, MARS, that processes pronouns in text. Motivation for building a new algorithm for text and dialogues has been the problem of alignment between caption dialogues and stage directions on one hand and video content in movies on the other. While pronoun resolution in stage directions proved to be a fairly easy task, in dialogues we are facing the following challenges: 1. Part of speech taggers trained on text (typically the Wall Street Journal texts of Penn Treebank) perform poorly on dialogues, primarily due to the fragmented nature of spoken language.</context>
</contexts>
<marker>Mitkov, Evans, Orasan, 2002</marker>
<rawString>Mitkov, R., R. Evans, and C. Orasan. 2002. A new, fully automatic version of Mitkovs knowledge-poor pronoun resolution method. Lecture notes in computer science, pages 168186.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Poesio</author>
<author>M A Kabadjov</author>
</authors>
<title>A generalpurpose, off-the-shelf anaphora resolution module: Implementation and preliminary evaluation.</title>
<date>2004</date>
<booktitle>In Proc. of the 4th International Conference on Language Resources and Evaluation.</booktitle>
<location>Lisbon, Portugal. Citeseer.</location>
<contexts>
<context position="1872" citStr="Poesio and Kabadjov, 2004" startWordPosition="277" endWordPosition="280">nd b) resolution algorithm. We adopt a hybrid approach to the problem, using statistical and machine learning techniques widely available in the NLP literature to collect features and a symbolic algorithm informed by prior research in anaphora resolution and models of entity salience to appropriately rank and evaluate antecedents. The design and architecture of Antelogue is modular and flexible and will soon be released for off-the-shelf use as an independent component or for possible integration of larger anaphora resolution systems, such as the GuiTAR (General Tool for Anaphora Resolution) (Poesio and Kabadjov, 2004) that currently is released with (Mitkov et al., 2002)s statistical pronoun resolution algorithm, MARS, that processes pronouns in text. Motivation for building a new algorithm for text and dialogues has been the problem of alignment between caption dialogues and stage directions on one hand and video content in movies on the other. While pronoun resolution in stage directions proved to be a fairly easy task, in dialogues we are facing the following challenges: 1. Part of speech taggers trained on text (typically the Wall Street Journal texts of Penn Treebank) perform poorly on dialogues, prim</context>
</contexts>
<marker>Poesio, Kabadjov, 2004</marker>
<rawString>Poesio, M. and M.A. Kabadjov. 2004. A generalpurpose, off-the-shelf anaphora resolution module: Implementation and preliminary evaluation. In Proc. of the 4th International Conference on Language Resources and Evaluation. Lisbon, Portugal. Citeseer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ratnaparkhi</author>
</authors>
<title>A maximum entropy model for part-of-speech tagging. In</title>
<date>1996</date>
<booktitle>In Proceedings of EMNLP96,</booktitle>
<pages>133142</pages>
<contexts>
<context position="6350" citStr="Ratnaparkhi, 1996" startWordPosition="982" endWordPosition="983">ecedent is shown only in case there is no nominal antecedent available. The architecture of Antelogue is illustrated in Fig. 1. Antelogue can be set to perform pronoun resolution in both dialogue and text. A preprocessing step is required to ensure that the files are in the appropriate format. Because Antelogue was built to perform pronoun resolution in the dialogues and stage directions of screenplays, the pre-processing steps required to extract dialogues and text from the TV seriesLost, are available. 3 System architecture Feature acquisition Sentence and word tokenization: built based on (Ratnaparkhi, 1996). To address dialogue idiosyncrasies, sentence tokenization is forced to respect speaker turns thus blocking forming sentences across speaker turns. Word processor. This module processes the word tokenized file and creates an indexed entry for every word in the Antelogue repository. Named Entity Recognizer tagging (NER): We integrated Stanfords NER tagger (Finkel et al., 2005). NER processor. This module processor the NER tagged file and associates identified NER tags with the corresponding words in the Antelogue repository. Gender and Animacy processor: This modules collects gender informatio</context>
<context position="7585" citStr="Ratnaparkhi, 1996" startWordPosition="1172" endWordPosition="1173"> corpus1 (Bergsma and Lin, 2006) and checks a self1 http://www.cs.ualberta.ca/ bergsma/ Gender. 42 \x0cmade corpus for profession (teacher, doctor, etc) and family relations (mother, father, etc), extracted from web searches. In the gender corpus, gender and number data are collected statistically and are not always reliable. We developed a simple confidence metric to evaluate the reliability of the gender and number data. If the ratio of the highest probability to the sum of all other probabilities is lower than 60% we mark gender or number unknown.2 Part-of-speech tagging (POS). We trained (Ratnaparkhi, 1996)s POS tagger on dialogue data obtained from the English CTS Treebank with Structural Metadata released by LDC in 2009. POS parser. This modules parses the POStagged input and updates the Antelogue repository. Pronoun resolution The pronoun resolution submodule, currently, has three submodules: a) first and second person pronouns, b) third person singular masculine and feminine pronouns, and c) third person singular neuter pronouns. For the first and second person pronouns, Antelogue identifies and resolves all instances of I to the speaker name and all instances of you to the next speaker. It </context>
</contexts>
<marker>Ratnaparkhi, 1996</marker>
<rawString>Ratnaparkhi, A. 1996. A maximum entropy model for part-of-speech tagging. In In Proceedings of EMNLP96, pages 133142.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>