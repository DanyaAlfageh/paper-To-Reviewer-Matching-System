<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<bodyText confidence="0.520153">
b&amp;apos;Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 734742,
</bodyText>
<address confidence="0.542986">
Beijing, August 2010
</address>
<title confidence="0.983352">
Exploiting Structured Ontology to Organize Scattered Online Opinions
</title>
<author confidence="0.998376">
Yue Lu, Huizhong Duan, Hongning Wang, ChengXiang Zhai
</author>
<affiliation confidence="0.9983325">
Department of Computer Science
University of Illinois at Urbana-Champaign
</affiliation>
<email confidence="0.996401">
{yuelu2,duan9,wang296,czhai}@illinois.edu
</email>
<sectionHeader confidence="0.990787" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99921435">
We study the problem of integrating scat-
tered online opinions. For this purpose,
we propose to exploit structured ontology
to obtain well-formed relevant aspects to
a topic and use them to organize scattered
opinions to generate a structured sum-
mary. Particularly, we focus on two main
challenges in implementing this idea, (1)
how to select the most useful aspects from
a large number of aspects in the ontology
and (2) how to order the selected aspects
to optimize the readability of the struc-
tured summary. We propose and explore
several methods for solving these chal-
lenges. Experimental results on two dif-
ferent data sets (US Presidents and Digital
Cameras) show that the proposed methods
are effective for selecting aspects that can
represent the major opinions and for gen-
erating coherent ordering of aspects.
</bodyText>
<sectionHeader confidence="0.998218" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998085709090909">
The explosive growth of online opinions raises in-
teresting challenges for opinion integration and
summarization. It is especially interesting to in-
tegrate and summarize scattered opinions in blog
articles and forums as they tend to represent the
general opinions of a large number of people and
get refreshed quickly as people dynamically gen-
erate new content, making them valuable for un-
derstanding the current views of a topic.
However, opinions in blogs and forums are
usually fragmental, scattered around, and buried
among other off-topic content, so it is quite chal-
lenging to organize them in a meaningful way.
Traditional text summarization techniques gener-
ate an unstructured list of sentences as a sum-
mary, which cannot reveal representative opinions
on different aspects of a topic or effectively facil-
itate navigation into the huge opinion space. To
address this limitation, recent work has shown the
usefulness of generating a structured summary of
opinions, in which related opinions are grouped
into topical aspects with explicit labeling of all the
aspects. A major challenge in producing such a
structured summary is how to generate these as-
pects for an arbitrary topic (e.g., products, politi-
cal figures, policies, etc.). Intuitively, the aspects
should be concise phrases that can both be easily
interpreted in the context of the topic under con-
sideration and capture the major opinions. How-
ever, where can we find such phrases and which
phrases should we select as aspects? Furthermore,
once we selected aspects, how should we order
them to improve the readability of a structured
summary? One way to generate aspects is to clus-
ter all the opinion sentences and then identify rep-
resentative phrases in each cluster. Although as-
pects selected in this way can effectively capture
the major opinions, a major limitation is that it is
generally hard to ensure that the selected phrases
are well connected with the given topic (Chen and
Dumais, 2000).
In this paper, we propose a novel approach
to generating aspects by leveraging the ontolo-
gies with structured information that are available
online, such as open domain knowledge base in
Freebase1. Such kind of ontology data is not in
small scale by any measure. For example, Free-
base alone contains more than 10 million topics,
3000 types, and 30,000 properties; moreover, it is
constantly growing as people collaboratively con-
tribute. Freebase provides different properties for
different types of topics such as personal infor-
mation for a US President and product features
for a Digital Camera. Since this kind of re-
sources can provide related entities/relations for a
</bodyText>
<footnote confidence="0.7812535">
1
http://www.freebase.com
</footnote>
<page confidence="0.999524">
734
</page>
<bodyText confidence="0.999583825396825">
\x0cwide range of topics , our general idea is to lever-
age them as guidance for more informed organi-
zation of scattered online opinions, and in partic-
ular, to select the most important properties of a
topic from such structured ontology as aspects to
generate a structured opinion summary. A signif-
icant advantage of this approach to aspect genera-
tion is that the selected aspects are guaranteed to
be very well connected with the topic, but it also
raises an additional challenge in selecting the as-
pects to best capture the major opinions from a
large number of aspects provided for each topic in
the ontology. Different from some existing work
on exploiting ontologies, e.g., (Sauper and Barzi-
lay, 2009), which relies on training data, we focus
on exploring unsupervised approaches, which can
be applied to a larger scope of topics.
Specifically, given a topic with entries in an on-
tology and a collection of scattered online opin-
ions about the topic, our goal is to generate a
structured summary where representative major
opinions are organized with well aligned aspects
and in an order easy for human to follow. We
propose the following general approach: First, re-
trieval techniques are employed to align opinions
to relevant aspects. Second, a subset of most inter-
esting aspects are selected. Third, we will further
order the selected aspects to present them in a rea-
sonable order. Finally, for the opinions uncovered
by the selected aspects from the ontology, we use
a phrase ranking method to suggest new aspects to
add to the ontology for increasing its coverage.
Implementing the second and third steps in-
volves special challenges. In particular, without
any training data, it is unclear how we should
show the most interesting aspects in ontology with
major opinions aligned and which presentation
order of aspects is natural and intuitive for hu-
man. Solving these two challenges is the main
focus of this paper. We propose three meth-
ods for aspect selection, i.e., size-based, opinion
coverage-based, and conditional entropy-based
methods, and two methods for aspect ordering,
i.e., ontology-ordering and coherence ordering.
We evaluate our methods on two different types of
topics: US Presidents and Digital Cameras. Qual-
itative results demonstrate the utility of integrating
opinions based on structured ontology as well as
the generalizability of proposed methods. Quan-
titative evaluation is also conducted to show the
effectiveness of our methods.
Note that we use the term opinion to broadly
refer to any discussion in opinionated sources
such as blogs and reviews. This allows us to for-
mulate and solve the problem in a general way.
Indeed, the main goal of our work is to extract
and organize the major opinions about a topic that
are buried in many scattered opinionated sources
rather than perform deeper understanding of opin-
ions (e.g., distinguishing positive from negative
opinions), which can be done by using any exist-
ing sentiment analysis technique as an orthogonal
post-processing step after applying our method.
</bodyText>
<sectionHeader confidence="0.999596" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.99684535483871">
Aspect summarization, i.e., structured opinion
summarization over topical aspects, has attracted
much attention recently. Existing work iden-
tifies aspects using frequent-pattern/association-
rule mining, e.g. (Liu et al., 2005; Popescu and
Etzioni, 2005), sentence clustering, e.g. (Ga-
mon et al., 2005; Leouski and Croft, 1996), or
topic modeling, e.g. (Mei et al., 2006; Titov and
McDonald, 2008). After that, meaningful and
prominent phrases need to be selected to repre-
sent the aspects, e.g. (Zhao and He, 2006; Mei
et al., 2007). However, these methods suffer from
the problem of producing trivial aspects. Conse-
quently, some of the aspects generated are very
difficult to interpret (Chen and Dumais, 2000). In
this paper, we propose a different kind of approach
that is to use aspects provided by ontology which
are known to be relevant and easy to interpret.
Ontology is used in (Carenini et al., 2005) but
only for mapping product features. The closest
work to ours are (Lu and Zhai, 2008; Sauper and
Barzilay, 2009); both try to use well-written arti-
cles for summarization. However, (Lu and Zhai,
2008) assumes the well-written article is struc-
tured with explicit or implicit aspect information,
which does not always hold in practice, while
(Sauper and Barzilay, 2009) needs a relatively
large amount of training data in the given domain.
In comparison, our work only needs the ontology
information for the given topic which is much eas-
ier to obtain from resources such as Freebase.
</bodyText>
<page confidence="0.99834">
735
</page>
<sectionHeader confidence="0.873046" genericHeader="method">
\x0c3 Methods
</sectionHeader>
<bodyText confidence="0.978618611111111">
Given (1) an input topic T, (2) a large number of
aspects/properties A = {A1, ..., Am} from an on-
tology that are related to T, and (3) a huge col-
lection of scattered opinion sentences about the
topic DT = {s1, . . . , sn}, our goal is to gener-
ate a structured organization of opinions that are
both aligned well with the interesting aspects and
representative of major opinions about the topic.
The envisioned structured organization consists
of a sequence of selected aspects from ontol-
ogy ordered to optimize readability and a set of
sentences matching each selected aspect. Once
we obtain a set of sentences in each aspect, we
can easily apply a standard text summarization
method to further summarize these sentences, thus
the unique challenges related to our main idea of
exploiting ontology are the following, which are
also the main focus of our study:
</bodyText>
<construct confidence="0.415417">
Aspect Selection: How can we select a subset of
aspects A0 A to capture the major opinions in
our opinion set DT ?
Aspect Ordering: How can we order a subset of
selected aspects A0 so as to present them in an or-
</construct>
<bodyText confidence="0.8206584">
der (A0) that is most natural with respect to hu-
man perception?
New Aspects Suggestion: Can we exploit the
opinions in DT to suggest new aspects to be added
to the ontology?
</bodyText>
<subsectionHeader confidence="0.998508">
3.1 Aspect Selection
</subsectionHeader>
<bodyText confidence="0.95999481632653">
In order to align the scattered opinions to the
most relevant aspects, we first use each aspect la-
bel Ai A as a query to retrieve a set of rel-
evant opinions in the collection Si DT with
a standard language modeling approach, i.e., the
KL-divergence retrieval model (Zhai and Lafferty,
2001). Up to 1000 opinion sentences are retrieved
for each aspect; each opinion sentence can be po-
tentially aligned to several aspects. In this way,
scattered online discussion are linked to the most
relevant aspects in the ontology, which enables a
user to use aspects as semantic bridges to navi-
gate into the opinion space..
However, there are usually a lot of candidate
aspects in an ontology, and only some are heav-
ily commented in online discussions, so showing
all the aspects is not only unnecessary, but also
overwhelming for users. To solve this problem,
we propose to utilize the aligned opinions to fur-
ther select a subset of the most interesting aspects
A0 A with size k. Several approaches are pos-
sible for this subset selection problem.
Size-based: Intuitively, the selected subset A0
should reflect the major opinions. So a straightfor-
ward method is to order the aspects Ai by the size
of the aligned opinion sentences Si, i.e., the num-
ber of relevant opinion sentences, and then select
the top k ones.
Opinion Coverage-based: The previous method
does not consider possible redundancy among the
aspects. A better approach is to select the subset
that covers as many distinct opinion sentences as
possible. This can be formulated as a maximum
coverage problem, for which a greedy algorithm
is known to be a good approximation: we select
one aspect at a time that is aligned with the largest
number of uncovered sentences.
Conditional Entropy-based: Aspects from a struc-
tured ontology are generally quite meaningful, but
they are not designed specifically for organizing
the opinions in our data set. Thus, they do not
necessarily correspond well to the natural clus-
ters in scattered opinions. To obtain aspects that
are aligned well with the natural clusters in scat-
tered opinions, we can first cluster DT into l
clusters C = {C1, . . . , Cl} using K-means with
TF IDF as features, and then choose the sub-
set of aspects that minimize Conditional Entropy
of the cluster label given the aspect:
</bodyText>
<equation confidence="0.919718">
A0
= arg min H(C|A0
) = arg min
X
AiA0,CiC
p(Ai, Ci) log
p(Ai, Ci)
p(Ai)
</equation>
<bodyText confidence="0.98862725">
This Conditional Entropy measures the uncer-
tainty about the cluster label of a sentence given
the knowledge of its aspect. Intuitively, if the as-
pects are aligned well with the clusters, we would
be able to predict well the cluster label of a sen-
tence if we know its aspect, thus there would be
less uncertainty about the cluster label. In the
extreme case when the cluster label can be com-
pletely determined by the aspect, the conditional
entropy would reach its minimum (i.e., 0). Intu-
itively, the conditional entropy-based method es-
sentially selects the most appropriate aspects from
</bodyText>
<page confidence="0.993781">
736
</page>
<figure confidence="0.626981086956522">
\x0cAlgorithm 1 Greedy Algorithm for
Conditional Entropy Based Aspect Selection
Input: A = {A1, ..., Am}
Output: k-sized A0
A
1: A0
= {m
i=1Ai}
2: for j=1 to k do
3: bestH = ; bestA = A0
4: for each Ai in A do
5: tempA0
= {Ai, A0
\\ Ai}
6: if H(C|tempA0
) &amp;lt; bestH then
7: bestH = H(C|tempA0
)
8: bestA = Ai
9: A0
= {bestA, A0
\\ bestA}
10: output A0
</figure>
<bodyText confidence="0.9910765">
the ontology to label clusters of opinions.
The exact solution of this combinatorial optimiza-
tion problem is NP-complete, so we employ a
polynomial time greedy algorithm to approximate
it: in the i-th iteration, we select the aspect that
can minimize the conditional entropy given the
previous i 1 selected aspects. Pseudo code is
given in Algorithm 1.
</bodyText>
<subsectionHeader confidence="0.999765">
3.2 Aspect Ordering
</subsectionHeader>
<bodyText confidence="0.996083166666667">
In order to present the selected aspects to users
in a most natural way, it is important to obtain a
coherent order of them, i.e., generating an order
consistent with human perception. To achieve this
goal, our idea is to use human written articles on
the topic to learn how to organize the aspects au-
tomatically. Specifically, we would order aspects
so that the relative order of the sentences in all the
aspects would be as consistent with their order in
the original online discussions as possible.
Formally, the input is a subset of selected as-
pects A0; each Ai A0 is aligned with a set of
relevant opinion sentences Si = {Si,1, Si,2, ...}.
We define a coherence measurement function over
sentence pairs Co(Si,k, Sj,l), which is set to 1 iff
Si,k appears before Sj,l in the same article. Other-
wise, it is set to 0. Then a coherence measurement
function over an aspect pair can be calculated as
</bodyText>
<figure confidence="0.868581722222222">
Co(Ai, Aj) =
P
Si,kSi,Sj,lSj
Co(Si,k, Sj,l)
|Si||Sj|
As an output, we would like to find a permutation
(A0) that maximizes the coherence of all pair-
wise aspects, i.e.,
(A0
) = arg max
(A0)
X
Ai,AjA0,AiAj
Co(Ai, Aj)
Algorithm 2 Greedy Algorithm for
Coherence Based Aspect Ordering
Input: A
Output: (A)
</figure>
<listItem confidence="0.950435785714286">
1: for each Ai, Aj in A do
2: calculate Co(Ai, Aj)
3: for p = 1 to len = A.size() do
4: Max = A[1]
5: for each aspect Ai in A do
6: Ai.coherence = 0
7: for each aspect Aj in (A) do
8: Ai.coherence+ = Co(Aj, Ai)
9: for each aspect Aj in A, j 6= i do
10: Ai.coherence+ = Co(Ai, Aj)
11: if Ai.coherence &amp;gt; Max.coherence then
12: Max = Ai
13: remove Max from A; add Max to (A)
14: output (A)
</listItem>
<bodyText confidence="0.997627555555555">
where Ai Aj means that Ai is before Aj. It
is easy to prove that the problem is NP-complete.
Therefore, we resort to greedy algorithms to find
approximations of the solution. Particularly we
view the problem as a ranking problem. The al-
gorithm proceeds by finding at each ranking po-
sition an aspect that can maximize the coherence
measurement, starting from the top of the rank list.
The detailed algorithm is given in Algorithm 2.
</bodyText>
<subsectionHeader confidence="0.99548">
3.3 New Aspects Suggestion
</subsectionHeader>
<bodyText confidence="0.9669268">
Finally, if the opinions cover more aspects than in
the ontology, we also want to identify informative
phrases to label such extra aspects; such phrases
can also be used to further augment the ontology
with new aspects.
This problem is similar to existing work on gen-
erating labels for clusters (Zeng et al., 2004) or
topic models (Mei et al., 2007). Here we employ
a simple but representative technique to demon-
strate the feasibility of discovering interesting new
aspects for augmenting the ontology. We first ex-
tract named entities from scattered opinions DT
using Stanford Named Entity Recognizer (Finkel
et al., 2005). After that, we rank the phrases by
pointwise Mutual Information (MI):
</bodyText>
<equation confidence="0.986005">
MI(T, ph) = log
P(T, ph)
P(T)P(ph)
</equation>
<bodyText confidence="0.9886998">
where T is the given topic and ph refers to a candi-
date entity phrase. P(T, ph) is proportional to the
number of opinion sentences they co-occur; P(T)
or P(ph) are proportional to the number of times
T or ph appears. A higher MI value indicates a
</bodyText>
<page confidence="0.979863">
737
</page>
<table confidence="0.9892506">
\x0cStatistics Category 1 Category 2
US president Digital Camera
Number of Topics 36 110
Number of Aspects 6526 324
Number of Opinions 10011542 170249
</table>
<tableCaption confidence="0.998309">
Table 1: Statistics of Data Sets
</tableCaption>
<bodyText confidence="0.930151666666667">
stronger association. We can then suggest the top
ranked entity phrases that are not in the selected
aspects as new aspects.
</bodyText>
<sectionHeader confidence="0.998429" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.97928">
4.1 Data Sets
</subsectionHeader>
<bodyText confidence="0.993580928571429">
To examine the generalizability of our methods,
we test on two very different categories of top-
ics: US Presidents and Digital Cameras.2 For the
ontology, we leverage Freebase, downloading the
structured ontology for each topic. For the opin-
ion corpus, we use blog data for US Presidents and
customer reviews for Digital Cameras. The blog
entries for US Presidents were collected by using
Google Blog Search3 with the name of a president
as the query. Customer reviews for Digital Cam-
eras were crawled from CNET4. The basic statis-
tics of our data sets is shown in Table 1. For all the
data collections, Porter stemmer (Porter, 1997) is
applied and stop words are removed.
</bodyText>
<subsectionHeader confidence="0.990026">
4.2 Sample Results
</subsectionHeader>
<bodyText confidence="0.995676">
We first show sample results of automatic orga-
nization of online opinions. We use the opin-
ion coverage-based algorithm to select 10 aspects
(10-20 aspects were found to be optimal in (Kaki,
2005)) and then apply the coherence-based aspect
ordering method. The number of clusters is set so
that there are on average 15 opinions per cluster.
Opinion Organization: Table 2 and Table 3
present sample results for President Ronald Rea-
gan and Sony Cybershot DSC-W200 camera re-
spectively5. We can see that (1) although Freebase
aspects provide objective and accurate informa-
tion about the given topics, extracted opinion sen-
tences offer additional subjective information; (2)
aligning scattered opinion sentences to most rel-
evant aspects in the ontology helps digestion and
</bodyText>
<page confidence="0.933025">
2
</page>
<bodyText confidence="0.93689">
We have made our data sets available at http://
</bodyText>
<figure confidence="0.5263172">
timan.cs.uiuc.edu/downloads.html .
3
http://blogsearch.google.com
4
http://www.cnet.com
</figure>
<page confidence="0.900317">
5
</page>
<bodyText confidence="0.985329128205128">
Due to space limit, we only show the first few aspects as
output by our methods.
navigation; and (3) the support number, which is
the number of opinion sentences aligned to an as-
pect, can show the popularity of the aspect in the
online discussions.
Adaptability of Aspect Selection: Being un-
supervised is a significant advantage of our meth-
ods over most existing work. It provides flexibil-
ity of applying the methods in different domains
without the requirement of training data, benefit-
ing from both the ontology based template guid-
ance as well as data-driven approaches. As a re-
sult, we can generate different results for differ-
ent topics even in the same domain. In Table 4,
we show the top three selected and ordered as-
pects for Abraham Lincoln and Richard Nixon.
Although they belong to the same category, differ-
ent aspects are picked up due to the differences in
online opinions. People talk a lot about Lincolns
role in American Civil War and his famous quo-
tation, but when talking about Nixon, people fo-
cus on ending the Vietnam war and the Watergate
scandal. Date of birth and Government posi-
tion are ranked first because people tend to start
talking from these aspects, which is more natural
than starting from aspects like Place of death.
Baseline Comparison: We also show below the
aspects for Lincoln generated by a representative
approach using clustering method (e.g. (Gamon et
al., 2005)). i.e., we label the largest clusters by se-
lecting phrases with top mutual information. We
can see that although some phrases make sense,
not all are well connected with the given topic;
using aspects in ontology circumvents this prob-
lem. This example confirms the finding in pre-
vious work that the popular existing clustering-
based approach to aspects generation cannot gen-
erate meaningful labels (Chen and Dumais, 2000).
</bodyText>
<figure confidence="0.970918">
Vincent
New Salem State Historic Site
USS Abraham Lincoln
Martin Luther King Jr
Gettysburg
John F.
New Aspect Discovery: Finally, in Table 5 we
</figure>
<bodyText confidence="0.988748">
show some phrases ranked among top 10 using
the method described in Section 3.3. They reveal
additional aspects covered in online discussions
and serve as candidate new aspects to be added to
Freebase. Interestingly, John Wilkes Booth, who
assassinated President Lincoln, is not explicitly
</bodyText>
<page confidence="0.994328">
738
</page>
<table confidence="0.6756818">
\x0cFreeBase Aspects Supt Representative Opinion Sentences
Appointees: 897 Martin Feldstein, whose criticism of Reagan era deficits has not been forgotten.
- Martin Feldstein Reagans first National Security advisor was quoted as declaring...
- Chief Economic Advisor
Government Positions Held: 967 1981 Jan 20, Ronald Reagan was sworn in as president as 52 American hostages
</table>
<listItem confidence="0.82566925">
- President of the United States boarded a plane in Tehran and headed toward freedom.
- Jan 20, 1981 to Jan 20, 1989 40th president of the US Ronald Reagan broke the so called 20 year curse...
Vice president: 847 8 years, 1981-1988 George H. W. Bush as vice president under Ronald Reagan...
- George H. W. Bush ...exception to the rule was in 1976, when George H W Bush beat Ronald.
</listItem>
<tableCaption confidence="0.930205">
Table 2: Opinion Organization Result for President Ronald Reagan
</tableCaption>
<table confidence="0.980987">
FreeBase Aspects Supt Representative Opinion Sentences
Format: 13 Quality pictures in a compact package.
- Compact ... amazing is that this is such a small and compact unit but packs so much power.
Supported Storage Types: 11 This camera can use Memory Stick Pro Duo up to 8 GB
- Memory Stick Duo Using a universal storage card and cable (cmon Sony)
Sensor type: 10 I think the larger ccd makes a difference.
- CCD but remember this is a small CCD in a compact point-and-shoot.
Digital zoom: 47 once the digital :smart zoom kicks in you get another 3x of zoom
-2 I would like a higher optical zoom, the W200 does a great digital zoom translation...
</table>
<tableCaption confidence="0.981184">
Table 3: Opinion Organization Result for Sony Cybershot DSC-W200 Camera
listed in Freebase, but we can find it in peoples
online discussion using mutual information.
</tableCaption>
<subsectionHeader confidence="0.99972">
4.3 Evaluation of Aspect Selection
</subsectionHeader>
<bodyText confidence="0.996434576923077">
Measures: Aspect selection is a new challenge,
so there is no standard way to evaluate it. It is also
very hard for human to read all of the aspects and
opinions and then select a gold standard subset.
Therefore, we opt to use indirect measures captur-
ing different characteristics of the aspect selection
problem (1) Aspect Coverage (AC): we first as-
sign each aspect Ai to the cluster Cj that has the
most overlapping sentences with Ai, approximat-
ing the cluster that would come into mind when
a reader sees Ai. Then AC is defined as the per-
centage of the clusters covered by at least one as-
pect. (2) Aspect Precision (AP): for each cov-
ered cluster Ci, AP measures the Jaccard similar-
ity between Ci as a set of opinions and the union
of all aspects assigned to Ci. (3) Average Aspect
Precision (AAP): defines averaged AP for all
clusters where an uncovered Ci has a zero AP;
it essentially combines AC and AP. We also re-
port Sentence Coverage (SC), i.e., how many dis-
tinct opinion sentences can be covered by the se-
lected aspects and Conditional Entropy (H), i.e.,
how well the selected aspects align with the nat-
ural clusters in the opinions; a smaller H value
indicates a better alignment.
Results: We summarize the evaluation results in
</bodyText>
<table confidence="0.997873909090909">
Measures SC H AC AP AAP
PRESIDENTS
Random 503 1.9069 0.5140 0.0933 0.1223
Size-based 500 1.9656 0.3108 0.1508 0.0949
Opin Cover 746 1.8852 0.5463 0.0913 0.1316
Cond Ent. 479 1.7687 0.5770 0.0856 0.1552
CAMERAS
Random 55 1.6389 0.6554 0.0871 0.1271
Size-based 70 1.6463 0.6071 0.1077 0.1340
Opin Cover 82 1.5866 0.6998 0.0914 0.1564
Cond Ent. 70 1.5598 0.7497 0.0789 0.1574
</table>
<tableCaption confidence="0.999695">
Table 6: Evaluation Results for Aspect Selection
Table 6. In addition to the three methods de-
</tableCaption>
<bodyText confidence="0.946038823529412">
scribed in Section 3.1, we also include one base-
line of averaging 10 runs of random selection. The
best performance by each measure on each data
set is highlighted in bold font. Not surprisingly,
opinion coverage-based approach has the best
sentence coverage (SC) performance and condi-
tional entropy-based greedy algorithm achieves
the lowest H. Size-based approach is best in as-
pect precision but at the cost of lowest aspect cov-
erage. The trade-off between AP and AC is com-
parable to that between precision and recall as
in information retrieval while AAP summarizes
the combination of these two. The greedy algo-
rithm based on conditional entropy outperforms
all other approaches in AC and also in AAP, sug-
gesting that it can provide a good balance between
AP and AC.
</bodyText>
<page confidence="0.984879">
739
</page>
<listItem confidence="0.861607714285714">
\x0cSupt Richard-Nixon Supt Abraham-Lincoln
50 Date of birth: 419 Government Positions Held:
- Jan 9, 1913 - United States Representative Mar 4,1847-Mar 3,1849
108 Tracks Recorded: 558 Military Commands:
- 23-73 Broadcast: End of the Vietnam War - American Civil War - United States of America
120 Works Written About This Topic: 810 Quotations: - Nearly all men can stand adversity, but if
- Watergate you want to test a mans character, give him power.
</listItem>
<tableCaption confidence="0.9993">
Table 4: Comparison of Aspect Selection for Two Presidents (aligned opinions are omitted here)
</tableCaption>
<table confidence="0.880621">
Suggested Phrases Supporting Opinion Sentences
Abraham Lincoln Presidential Library CDB projects include the Abraham Lincoln Presidential Library and Museum
Abraham Lincoln Memorial ..., eventually arriving at Abraham Lincoln Memorial.
John Wilkes Booth John Wilkes Booth shoots President Abraham Lincoln at Fords Theatre ...
</table>
<tableCaption confidence="0.994256">
Table 5: New Phrases for Abraham Lincoln
</tableCaption>
<subsectionHeader confidence="0.999533">
4.4 Evaluation of Aspect Ordering
</subsectionHeader>
<bodyText confidence="0.998119470588235">
Human Annotation: In order to quantitatively
evaluate the effectiveness of aspect ordering, we
conduct user studies to establish gold standard or-
dering. Three users were each given k selected as-
pects and asked to perform two tasks for each US
President: (1) identify clusters of aspects that are
more natural to be presented together (cluster con-
straints) and (2) identify aspect pairs where one
aspect is preferred to appear before the other from
the viewpoint of readability. (order constraints).
We did not ask them to provide a full order of
the k aspects, because we suspect that there are
usually more than one perfect order. Instead,
identifying partial orders or constraints is easier
for human to perform, thus provides more robust
gold standard.
Human Agreement: After obtaining the human
annotation results, we first study human consen-
sus on the ordering task. For both types of human
identified constraints, we convert them into pair-
wise relations of aspects, e.g., Ai and Aj should
be presented together or Ai should be displayed
before Aj. Then we calculate the agreement per-
centage among the three users. In Table 7, we can
see that only a very small percentage of pair-wise
partial orders (15.92% of the cluster constraints
and none of the order constraints) are agreed by
all the three users, though the agreement of clus-
tering is much higher than that of ordering. This
indicates that ordering the aspects is a subjective
and difficult task.
Measures: Given the human generated gold stan-
dard of partial constraints, we use the follow-
ing measures to evaluate the automatically gen-
</bodyText>
<table confidence="0.9726335">
AgreedBy Cluster Constraint Order Constraint
1 37.14% 89.22%
2 46.95% 10.78%
3 15.92% 0.00%
</table>
<tableCaption confidence="0.998107">
Table 7: Human Agreement on Ordering
</tableCaption>
<bodyText confidence="0.974714433333333">
erated full ordering of aspects: (1) Cluster Pre-
cision (prc): for all the aspect pairs placed in
the same cluster by human, we calculate the per-
centage of them that are also placed together in
the system output. (2) Cluster Penalty (pc): for
each aspect pair placed in the same cluster by hu-
man, we give a linear penalty proportional to the
number of aspects in between the pair that the
system places; pc can be interpreted as the aver-
age number of aspects between aspect pairs that
should be presented together in the case of mis-
ordering. Smaller penalty corresponds to better
ordering performance. (3) Order Precision (pro):
the percentage of correctly predicted aspect pairs
compared with human specified order.
Results: In Table 8, we report the ordering
performance based on two selection algorithms:
opinion coverage-based and conditional entropy-
based. Different selection algorithms provide dif-
ferent subsets of aspects for the ordering algo-
rithms to operate on. For comparison with our
coherence-based ordering algorithm, we include a
random baseline and Freebase ontology ordering.
Note that Freebase order is a very strong baseline
because it is edited by human even though the pur-
pose was not for organizing opinions. To take into
account the variation of human annotation, we use
four versions of gold standard: three are from the
individual annotators and one from the union of
their annotation. We did not include the gold stan-
</bodyText>
<page confidence="0.979475">
740
</page>
<table confidence="0.9966795">
\x0cSelection Gold Cluster Precision (prc) Cluster Penalty (pc) Order Precision (pro)
Algo STD Random Freebase Coherence Random Freebase Coherence Random Freebase Coherence
Opin Cover 1 0.3290 0.9547 0.9505 1.8798 0.1547 0.1068 0.4804 0.7059 0.4510
Opin Cover 2 0.3266 0.9293 0.8838 1.7944 0.3283 0.1818 0.4600 0.4000 0.4000
Opin Cover 3 0.2038 0.4550 0.4417 2.5208 1.3628 1.7994 0.5202 0.4561 0.5263
Opin Cover union 0.3234 0.7859 0.7237 1.8378 0.6346 0.4609 0.4678 0.4635 0.4526
Cond Entropy 1 0.2540 0.9355 0.8978 2.0656 0.2957 0.2016 0.5106 0.7111 0.5444
Cond Entropy 2 0.2535 0.7758 0.8323 2.1790 0.7530 0.5222 0.4759 0.6759 0.5093
Cond Entropy 3 0.2523 0.4030 0.5545 2.3079 2.1328 1.1611 0.5294 0.7143 0.8175
Cond Entropy union 0.3067 0.7268 0.7488 1.9735 1.0720 0.7196 0.5006 0.6500 0.6833
</table>
<tableCaption confidence="0.998944">
Table 8: Evaluation Results on Aspect Ordering
</tableCaption>
<bodyText confidence="0.998845666666667">
dard that is the intersection of three annotators be-
cause that would leave us with too little overlap.
We have several observations: (1) In general, re-
sults show large variations when using different
versions of gold standard, indicating the subjec-
tive nature of the ordering task. (2) Coherence-
based ordering shows similar performance to
Freebase order-based in cluster precision (prc),
but when we take into consideration the distance-
based penalty (pc) of separating aspects pairs in
the same cluster, coherence-based ordering is al-
most always significantly better except in one
case. This shows that our method can effectively
learn the coherence of aspects based on how their
aligned opinion sentences are presented in online
discussions. (3) Order precision (pro) can hardly
distinguish different ordering algorithm. This in-
dicates that people vary a lot in their preferences
as which aspects should be presented first. How-
ever, in cases when the random baseline outper-
forms others the margin is fairly small, while
Freebase order and coherence-based order have a
much larger margin of improvement when show-
ing superior performance.
</bodyText>
<sectionHeader confidence="0.997146" genericHeader="conclusions">
5 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.995515581395349">
A major challenge in automatic integration of
scattered online opinions is how to organize all
the diverse opinions in a meaningful way for any
given topic. In this paper, we propose to solve this
challenge by exploiting related aspects in struc-
tured ontology which are guaranteed to be mean-
ingful and well connected to the topic. We pro-
posed three different methods for selecting a sub-
set of aspects from the ontology that can best
capture the major opinions, including size-based,
opinion coverage-based, and conditional entropy-
based methods. We also explored two ways to
order aspects, i.e., ontology-order and coherence
optimization. In addition, we also proposed ap-
propriate measures for quantitative evaluation of
both aspect selection and ordering.
Experimental evaluation on two data sets (US
President and Digital Cameras) shows that by ex-
ploiting structured ontology, we can generate in-
teresting aspects to organize scattered opinions.
The conditional entropy method is shown to be
most effective for aspect selection, and the coher-
ence optimization method is more effective than
ontology-order in optimizing the coherence of the
aspect ordering, though ontology-order also ap-
pears to perform reasonably well. In addition, by
extracting salient phrases from the major opinions
that cannot be covered well by any aspect in an
existing ontology, we can also discover interest-
ing new aspects to extend the existing ontology.
Complementary with most existing summariza-
tion work, this work proposes a new direction of
using structured information to organize and sum-
marize unstructured opinions, opening up many
interesting future research directions. For in-
stance, in order to focus on studying aspect selec-
tion and ordering, we have not tried to optimize
sentences matching with aspects in the ontology;
it would be very interesting to further study how
to accurately retrieve sentences matching each as-
pect. Another promising future work is to orga-
nize opinions using both structured ontology in-
formation and well-written overview articles.
</bodyText>
<sectionHeader confidence="0.847248" genericHeader="references">
Acknowledgment
</sectionHeader>
<bodyText confidence="0.975141">
We thank the anonymous reviewers for their use-
ful comments. This paper is based upon work sup-
ported in part by an IBM Faculty Award, an Alfred
</bodyText>
<reference confidence="0.7055235">
P. Sloan Research Fellowship, an AFOSR MURI
Grant FA9550-08-1-0265, and by the National
Science Foundation under grants IIS-0347933,
IIS-0713581, IIS-0713571, and CNS-0834709.
</reference>
<page confidence="0.943943">
741
</page>
<reference confidence="0.997681582417583">
\x0cReferences
Carenini, Giuseppe, Raymond T. Ng, and Ed Zwart.
2005. Extracting knowledge from evaluative text.
In K-CAP 05: Proceedings of the 3rd international
conference on Knowledge capture, pages 1118,
New York, NY, USA. ACM.
Chen, Hao and Susan Dumais. 2000. Bringing or-
der to the web: automatically categorizing search
results. In CHI 00: Proceedings of the SIGCHI
conference on Human factors in computing systems,
pages 145152, New York, NY, USA. ACM.
Finkel, Jenny Rose, Trond Grenager, and Christopher
Manning. 2005. Incorporating non-local informa-
tion into information extraction systems by gibbs
sampling. In ACL 05: Proceedings of the 43rd
Annual Meeting on Association for Computational
Linguistics, pages 363370, Morristown, NJ, USA.
Association for Computational Linguistics.
Gamon, Michael, Anthony Aue, Simon Corston-
Oliver, and Eric K. Ringger. 2005. Pulse: Min-
ing customer opinions from free text. In Famili,
A. Fazel, Joost N. Kok, Jose Mara Pena, Arno
Siebes, and A. J. Feelders, editors, IDA, volume
3646 of Lecture Notes in Computer Science, pages
121132. Springer.
Kaki, Mika. 2005. Optimizing the number of search
result categories. In CHI 05: CHI 05 extended
abstracts on Human factors in computing systems,
pages 15171520, New York, NY, USA. ACM.
Leouski, Anton V. and W. Bruce Croft. 1996. An eval-
uation of techniques for clustering search results.
Technical report.
Liu, Bing, Minqing Hu, and Junsheng Cheng. 2005.
Opinion observer: analyzing and comparing opin-
ions on the web. In WWW 05: Proceedings of the
14th international conference on World Wide Web,
pages 342351, New York, NY, USA. ACM.
Lu, Yue and Chengxiang Zhai. 2008. Opinion in-
tegration through semi-supervised topic modeling.
In Huai, Jinpeng, Robin Chen, Hsiao-Wuen Hon,
Yunhao Liu, Wei-Ying Ma, Andrew Tomkins, and
Xiaodong Zhang, editors, WWW, pages 121130.
ACM.
Mei, Qiaozhu, Chao Liu, Hang Su, and ChengXiang
Zhai. 2006. A probabilistic approach to spatiotem-
poral theme pattern mining on weblogs. In WWW
06: Proceedings of the 15th international confer-
ence on World Wide Web, pages 533542.
Mei, Qiaozhu, Xuehua Shen, and ChengXiang Zhai.
2007. Automatic labeling of multinomial topic
models. In Berkhin, Pavel, Rich Caruana, and Xin-
dong Wu, editors, KDD, pages 490499. ACM.
Pang, Bo and Lillian Lee. 2007. Opinion mining and
sentiment analysis. Foundations and Trends in In-
formation Retrieval, 2(1-2):1135.
Popescu, Ana-Maria and Oren Etzioni. 2005. Ex-
tracting product features and opinions from reviews.
In HLT 05, pages 339346, Morristown, NJ, USA.
Association for Computational Linguistics.
Porter, M. F. 1997. An algorithm for suffix stripping.
pages 313316.
Sauper, Christina and Regina Barzilay. 2009. Auto-
matically generating wikipedia articles: A structure-
aware approach. In Proceedings of the Joint Confer-
ence of the 47th Annual Meeting of the ACL and the
4th International Joint Conference on Natural Lan-
guage Processing of the AFNLP, pages 208216,
Suntec, Singapore, August. Association for Compu-
tational Linguistics.
Titov, Ivan and Ryan McDonald. 2008. Modeling
online reviews with multi-grain topic models. In
WWW 08: Proceeding of the 17th international
conference on World Wide Web, pages 111120,
New York, NY, USA. ACM.
Zeng, Hua-Jun, Qi-Cai He, Zheng Chen, Wei-Ying
Ma, and Jinwen Ma. 2004. Learning to cluster
web search results. In SIGIR 04: Proceedings
of the 27th annual international ACM SIGIR con-
ference on Research and development in informa-
tion retrieval, pages 210217, New York, NY, USA.
ACM.
Zhai, Chengxiang and John Lafferty. 2001. Model-
based feedback in the language modeling approach
to information retrieval. In Proceedings of CIKM
2001, pages 403410.
Zhao, Jing and Jing He. 2006. Learning to generate
labels for organizing search results from a domain-
specified corpus. In WI 06: Proceedings of the
2006 IEEE/WIC/ACM International Conference on
Web Intelligence, pages 390396, Washington, DC,
USA. IEEE Computer Society.
</reference>
<page confidence="0.970983">
742
</page>
<figure confidence="0.252551">
\x0c&amp;apos;
</figure>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.749366">
<note confidence="0.882242">b&amp;apos;Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 734742, Beijing, August 2010</note>
<title confidence="0.999253">Exploiting Structured Ontology to Organize Scattered Online Opinions</title>
<author confidence="0.999458">Yue Lu</author>
<author confidence="0.999458">Huizhong Duan</author>
<author confidence="0.999458">Hongning Wang</author>
<author confidence="0.999458">ChengXiang Zhai</author>
<affiliation confidence="0.999935">Department of Computer Science University of Illinois at Urbana-Champaign</affiliation>
<email confidence="0.963243">yuelu2@illinois.edu</email>
<email confidence="0.963243">duan9@illinois.edu</email>
<email confidence="0.963243">wang296@illinois.edu</email>
<email confidence="0.963243">czhai@illinois.edu</email>
<abstract confidence="0.998631476190476">We study the problem of integrating scattered online opinions. For this purpose, we propose to exploit structured ontology to obtain well-formed relevant aspects to a topic and use them to organize scattered opinions to generate a structured summary. Particularly, we focus on two main challenges in implementing this idea, (1) how to select the most useful aspects from a large number of aspects in the ontology and (2) how to order the selected aspects to optimize the readability of the structured summary. We propose and explore several methods for solving these challenges. Experimental results on two different data sets (US Presidents and Digital Cameras) show that the proposed methods are effective for selecting aspects that can represent the major opinions and for generating coherent ordering of aspects.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>\x0cReferences Carenini</author>
<author>Raymond T Ng Giuseppe</author>
<author>Ed Zwart</author>
</authors>
<title>Extracting knowledge from evaluative text.</title>
<date>2005</date>
<contexts>
<context position="7841" citStr="Carenini et al., 2005" startWordPosition="1239" endWordPosition="1242">on et al., 2005; Leouski and Croft, 1996), or topic modeling, e.g. (Mei et al., 2006; Titov and McDonald, 2008). After that, meaningful and prominent phrases need to be selected to represent the aspects, e.g. (Zhao and He, 2006; Mei et al., 2007). However, these methods suffer from the problem of producing trivial aspects. Consequently, some of the aspects generated are very difficult to interpret (Chen and Dumais, 2000). In this paper, we propose a different kind of approach that is to use aspects provided by ontology which are known to be relevant and easy to interpret. Ontology is used in (Carenini et al., 2005) but only for mapping product features. The closest work to ours are (Lu and Zhai, 2008; Sauper and Barzilay, 2009); both try to use well-written articles for summarization. However, (Lu and Zhai, 2008) assumes the well-written article is structured with explicit or implicit aspect information, which does not always hold in practice, while (Sauper and Barzilay, 2009) needs a relatively large amount of training data in the given domain. In comparison, our work only needs the ontology information for the given topic which is much easier to obtain from resources such as Freebase. 735 \x0c3 Method</context>
</contexts>
<marker>Carenini, Giuseppe, Zwart, 2005</marker>
<rawString>\x0cReferences Carenini, Giuseppe, Raymond T. Ng, and Ed Zwart. 2005. Extracting knowledge from evaluative text.</rawString>
</citation>
<citation valid="false">
<booktitle>In K-CAP 05: Proceedings of the 3rd international conference on Knowledge capture,</booktitle>
<pages>1118</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<marker></marker>
<rawString>In K-CAP 05: Proceedings of the 3rd international conference on Knowledge capture, pages 1118, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hao Chen</author>
<author>Susan Dumais</author>
</authors>
<title>Bringing order to the web: automatically categorizing search results.</title>
<date>2000</date>
<booktitle>In CHI 00: Proceedings of the SIGCHI conference on Human factors in computing systems,</booktitle>
<pages>145152</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="3174" citStr="Chen and Dumais, 2000" startWordPosition="490" endWordPosition="493">f the topic under consideration and capture the major opinions. However, where can we find such phrases and which phrases should we select as aspects? Furthermore, once we selected aspects, how should we order them to improve the readability of a structured summary? One way to generate aspects is to cluster all the opinion sentences and then identify representative phrases in each cluster. Although aspects selected in this way can effectively capture the major opinions, a major limitation is that it is generally hard to ensure that the selected phrases are well connected with the given topic (Chen and Dumais, 2000). In this paper, we propose a novel approach to generating aspects by leveraging the ontologies with structured information that are available online, such as open domain knowledge base in Freebase1. Such kind of ontology data is not in small scale by any measure. For example, Freebase alone contains more than 10 million topics, 3000 types, and 30,000 properties; moreover, it is constantly growing as people collaboratively contribute. Freebase provides different properties for different types of topics such as personal information for a US President and product features for a Digital Camera. S</context>
<context position="7643" citStr="Chen and Dumais, 2000" startWordPosition="1203" endWordPosition="1206"> attracted much attention recently. Existing work identifies aspects using frequent-pattern/associationrule mining, e.g. (Liu et al., 2005; Popescu and Etzioni, 2005), sentence clustering, e.g. (Gamon et al., 2005; Leouski and Croft, 1996), or topic modeling, e.g. (Mei et al., 2006; Titov and McDonald, 2008). After that, meaningful and prominent phrases need to be selected to represent the aspects, e.g. (Zhao and He, 2006; Mei et al., 2007). However, these methods suffer from the problem of producing trivial aspects. Consequently, some of the aspects generated are very difficult to interpret (Chen and Dumais, 2000). In this paper, we propose a different kind of approach that is to use aspects provided by ontology which are known to be relevant and easy to interpret. Ontology is used in (Carenini et al., 2005) but only for mapping product features. The closest work to ours are (Lu and Zhai, 2008; Sauper and Barzilay, 2009); both try to use well-written articles for summarization. However, (Lu and Zhai, 2008) assumes the well-written article is structured with explicit or implicit aspect information, which does not always hold in practice, while (Sauper and Barzilay, 2009) needs a relatively large amount </context>
<context position="20171" citStr="Chen and Dumais, 2000" startWordPosition="3379" endWordPosition="3382">than starting from aspects like Place of death. Baseline Comparison: We also show below the aspects for Lincoln generated by a representative approach using clustering method (e.g. (Gamon et al., 2005)). i.e., we label the largest clusters by selecting phrases with top mutual information. We can see that although some phrases make sense, not all are well connected with the given topic; using aspects in ontology circumvents this problem. This example confirms the finding in previous work that the popular existing clusteringbased approach to aspects generation cannot generate meaningful labels (Chen and Dumais, 2000). Vincent New Salem State Historic Site USS Abraham Lincoln Martin Luther King Jr Gettysburg John F. New Aspect Discovery: Finally, in Table 5 we show some phrases ranked among top 10 using the method described in Section 3.3. They reveal additional aspects covered in online discussions and serve as candidate new aspects to be added to Freebase. Interestingly, John Wilkes Booth, who assassinated President Lincoln, is not explicitly 738 \x0cFreeBase Aspects Supt Representative Opinion Sentences Appointees: 897 Martin Feldstein, whose criticism of Reagan era deficits has not been forgotten. - Ma</context>
</contexts>
<marker>Chen, Dumais, 2000</marker>
<rawString>Chen, Hao and Susan Dumais. 2000. Bringing order to the web: automatically categorizing search results. In CHI 00: Proceedings of the SIGCHI conference on Human factors in computing systems, pages 145152, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Trond Grenager</author>
<author>Christopher Manning</author>
</authors>
<title>Incorporating non-local information into information extraction systems by gibbs sampling.</title>
<date>2005</date>
<booktitle>In ACL 05: Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>363370</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="16055" citStr="Finkel et al., 2005" startWordPosition="2694" endWordPosition="2697">nally, if the opinions cover more aspects than in the ontology, we also want to identify informative phrases to label such extra aspects; such phrases can also be used to further augment the ontology with new aspects. This problem is similar to existing work on generating labels for clusters (Zeng et al., 2004) or topic models (Mei et al., 2007). Here we employ a simple but representative technique to demonstrate the feasibility of discovering interesting new aspects for augmenting the ontology. We first extract named entities from scattered opinions DT using Stanford Named Entity Recognizer (Finkel et al., 2005). After that, we rank the phrases by pointwise Mutual Information (MI): MI(T, ph) = log P(T, ph) P(T)P(ph) where T is the given topic and ph refers to a candidate entity phrase. P(T, ph) is proportional to the number of opinion sentences they co-occur; P(T) or P(ph) are proportional to the number of times T or ph appears. A higher MI value indicates a 737 \x0cStatistics Category 1 Category 2 US president Digital Camera Number of Topics 36 110 Number of Aspects 6526 324 Number of Opinions 10011542 170249 Table 1: Statistics of Data Sets stronger association. We can then suggest the top ranked e</context>
</contexts>
<marker>Finkel, Grenager, Manning, 2005</marker>
<rawString>Finkel, Jenny Rose, Trond Grenager, and Christopher Manning. 2005. Incorporating non-local information into information extraction systems by gibbs sampling. In ACL 05: Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, pages 363370, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Gamon</author>
<author>Anthony Aue</author>
<author>Simon CorstonOliver</author>
<author>Eric K Ringger</author>
</authors>
<title>Pulse: Mining customer opinions from free text.</title>
<date>2005</date>
<booktitle>of Lecture Notes in Computer Science,</booktitle>
<volume>3646</volume>
<pages>121132</pages>
<editor>In Famili, A. Fazel, Joost N. Kok, Jose Mara Pena, Arno Siebes, and A. J. Feelders, editors, IDA,</editor>
<publisher>Springer.</publisher>
<contexts>
<context position="7234" citStr="Gamon et al., 2005" startWordPosition="1135" endWordPosition="1139"> topic that are buried in many scattered opinionated sources rather than perform deeper understanding of opinions (e.g., distinguishing positive from negative opinions), which can be done by using any existing sentiment analysis technique as an orthogonal post-processing step after applying our method. 2 Related Work Aspect summarization, i.e., structured opinion summarization over topical aspects, has attracted much attention recently. Existing work identifies aspects using frequent-pattern/associationrule mining, e.g. (Liu et al., 2005; Popescu and Etzioni, 2005), sentence clustering, e.g. (Gamon et al., 2005; Leouski and Croft, 1996), or topic modeling, e.g. (Mei et al., 2006; Titov and McDonald, 2008). After that, meaningful and prominent phrases need to be selected to represent the aspects, e.g. (Zhao and He, 2006; Mei et al., 2007). However, these methods suffer from the problem of producing trivial aspects. Consequently, some of the aspects generated are very difficult to interpret (Chen and Dumais, 2000). In this paper, we propose a different kind of approach that is to use aspects provided by ontology which are known to be relevant and easy to interpret. Ontology is used in (Carenini et al.</context>
<context position="19750" citStr="Gamon et al., 2005" startWordPosition="3311" endWordPosition="3314">long to the same category, different aspects are picked up due to the differences in online opinions. People talk a lot about Lincolns role in American Civil War and his famous quotation, but when talking about Nixon, people focus on ending the Vietnam war and the Watergate scandal. Date of birth and Government position are ranked first because people tend to start talking from these aspects, which is more natural than starting from aspects like Place of death. Baseline Comparison: We also show below the aspects for Lincoln generated by a representative approach using clustering method (e.g. (Gamon et al., 2005)). i.e., we label the largest clusters by selecting phrases with top mutual information. We can see that although some phrases make sense, not all are well connected with the given topic; using aspects in ontology circumvents this problem. This example confirms the finding in previous work that the popular existing clusteringbased approach to aspects generation cannot generate meaningful labels (Chen and Dumais, 2000). Vincent New Salem State Historic Site USS Abraham Lincoln Martin Luther King Jr Gettysburg John F. New Aspect Discovery: Finally, in Table 5 we show some phrases ranked among to</context>
</contexts>
<marker>Gamon, Aue, CorstonOliver, Ringger, 2005</marker>
<rawString>Gamon, Michael, Anthony Aue, Simon CorstonOliver, and Eric K. Ringger. 2005. Pulse: Mining customer opinions from free text. In Famili, A. Fazel, Joost N. Kok, Jose Mara Pena, Arno Siebes, and A. J. Feelders, editors, IDA, volume 3646 of Lecture Notes in Computer Science, pages 121132. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mika Kaki</author>
</authors>
<title>Optimizing the number of search result categories.</title>
<date>2005</date>
<booktitle>In CHI 05: CHI 05 extended abstracts on Human factors in computing systems,</booktitle>
<pages>15171520</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="17635" citStr="Kaki, 2005" startWordPosition="2968" endWordPosition="2969">S Presidents and customer reviews for Digital Cameras. The blog entries for US Presidents were collected by using Google Blog Search3 with the name of a president as the query. Customer reviews for Digital Cameras were crawled from CNET4. The basic statistics of our data sets is shown in Table 1. For all the data collections, Porter stemmer (Porter, 1997) is applied and stop words are removed. 4.2 Sample Results We first show sample results of automatic organization of online opinions. We use the opinion coverage-based algorithm to select 10 aspects (10-20 aspects were found to be optimal in (Kaki, 2005)) and then apply the coherence-based aspect ordering method. The number of clusters is set so that there are on average 15 opinions per cluster. Opinion Organization: Table 2 and Table 3 present sample results for President Ronald Reagan and Sony Cybershot DSC-W200 camera respectively5. We can see that (1) although Freebase aspects provide objective and accurate information about the given topics, extracted opinion sentences offer additional subjective information; (2) aligning scattered opinion sentences to most relevant aspects in the ontology helps digestion and 2 We have made our data sets</context>
</contexts>
<marker>Kaki, 2005</marker>
<rawString>Kaki, Mika. 2005. Optimizing the number of search result categories. In CHI 05: CHI 05 extended abstracts on Human factors in computing systems, pages 15171520, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anton V Leouski</author>
<author>W Bruce Croft</author>
</authors>
<title>An evaluation of techniques for clustering search results.</title>
<date>1996</date>
<tech>Technical report.</tech>
<contexts>
<context position="7260" citStr="Leouski and Croft, 1996" startWordPosition="1140" endWordPosition="1143">ed in many scattered opinionated sources rather than perform deeper understanding of opinions (e.g., distinguishing positive from negative opinions), which can be done by using any existing sentiment analysis technique as an orthogonal post-processing step after applying our method. 2 Related Work Aspect summarization, i.e., structured opinion summarization over topical aspects, has attracted much attention recently. Existing work identifies aspects using frequent-pattern/associationrule mining, e.g. (Liu et al., 2005; Popescu and Etzioni, 2005), sentence clustering, e.g. (Gamon et al., 2005; Leouski and Croft, 1996), or topic modeling, e.g. (Mei et al., 2006; Titov and McDonald, 2008). After that, meaningful and prominent phrases need to be selected to represent the aspects, e.g. (Zhao and He, 2006; Mei et al., 2007). However, these methods suffer from the problem of producing trivial aspects. Consequently, some of the aspects generated are very difficult to interpret (Chen and Dumais, 2000). In this paper, we propose a different kind of approach that is to use aspects provided by ontology which are known to be relevant and easy to interpret. Ontology is used in (Carenini et al., 2005) but only for mappi</context>
</contexts>
<marker>Leouski, Croft, 1996</marker>
<rawString>Leouski, Anton V. and W. Bruce Croft. 1996. An evaluation of techniques for clustering search results. Technical report.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
<author>Minqing Hu</author>
<author>Junsheng Cheng</author>
</authors>
<title>Opinion observer: analyzing and comparing opinions on the web. In</title>
<date>2005</date>
<booktitle>WWW 05: Proceedings of the 14th international conference on World Wide Web,</booktitle>
<pages>342351</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="7159" citStr="Liu et al., 2005" startWordPosition="1124" endWordPosition="1127">in goal of our work is to extract and organize the major opinions about a topic that are buried in many scattered opinionated sources rather than perform deeper understanding of opinions (e.g., distinguishing positive from negative opinions), which can be done by using any existing sentiment analysis technique as an orthogonal post-processing step after applying our method. 2 Related Work Aspect summarization, i.e., structured opinion summarization over topical aspects, has attracted much attention recently. Existing work identifies aspects using frequent-pattern/associationrule mining, e.g. (Liu et al., 2005; Popescu and Etzioni, 2005), sentence clustering, e.g. (Gamon et al., 2005; Leouski and Croft, 1996), or topic modeling, e.g. (Mei et al., 2006; Titov and McDonald, 2008). After that, meaningful and prominent phrases need to be selected to represent the aspects, e.g. (Zhao and He, 2006; Mei et al., 2007). However, these methods suffer from the problem of producing trivial aspects. Consequently, some of the aspects generated are very difficult to interpret (Chen and Dumais, 2000). In this paper, we propose a different kind of approach that is to use aspects provided by ontology which are known</context>
</contexts>
<marker>Liu, Hu, Cheng, 2005</marker>
<rawString>Liu, Bing, Minqing Hu, and Junsheng Cheng. 2005. Opinion observer: analyzing and comparing opinions on the web. In WWW 05: Proceedings of the 14th international conference on World Wide Web, pages 342351, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Lu</author>
<author>Chengxiang Zhai</author>
</authors>
<title>Opinion integration through semi-supervised topic modeling.</title>
<date>2008</date>
<pages>121130</pages>
<editor>In Huai, Jinpeng, Robin Chen, Hsiao-Wuen Hon, Yunhao Liu, Wei-Ying Ma, Andrew Tomkins, and Xiaodong Zhang, editors, WWW,</editor>
<publisher>ACM.</publisher>
<contexts>
<context position="7928" citStr="Lu and Zhai, 2008" startWordPosition="1255" endWordPosition="1258">and McDonald, 2008). After that, meaningful and prominent phrases need to be selected to represent the aspects, e.g. (Zhao and He, 2006; Mei et al., 2007). However, these methods suffer from the problem of producing trivial aspects. Consequently, some of the aspects generated are very difficult to interpret (Chen and Dumais, 2000). In this paper, we propose a different kind of approach that is to use aspects provided by ontology which are known to be relevant and easy to interpret. Ontology is used in (Carenini et al., 2005) but only for mapping product features. The closest work to ours are (Lu and Zhai, 2008; Sauper and Barzilay, 2009); both try to use well-written articles for summarization. However, (Lu and Zhai, 2008) assumes the well-written article is structured with explicit or implicit aspect information, which does not always hold in practice, while (Sauper and Barzilay, 2009) needs a relatively large amount of training data in the given domain. In comparison, our work only needs the ontology information for the given topic which is much easier to obtain from resources such as Freebase. 735 \x0c3 Methods Given (1) an input topic T, (2) a large number of aspects/properties A = {A1, ..., Am</context>
</contexts>
<marker>Lu, Zhai, 2008</marker>
<rawString>Lu, Yue and Chengxiang Zhai. 2008. Opinion integration through semi-supervised topic modeling. In Huai, Jinpeng, Robin Chen, Hsiao-Wuen Hon, Yunhao Liu, Wei-Ying Ma, Andrew Tomkins, and Xiaodong Zhang, editors, WWW, pages 121130. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qiaozhu Mei</author>
<author>Chao Liu</author>
<author>Hang Su</author>
<author>ChengXiang Zhai</author>
</authors>
<title>A probabilistic approach to spatiotemporal theme pattern mining on weblogs.</title>
<date>2006</date>
<booktitle>In WWW 06: Proceedings of the 15th international conference on World Wide Web,</booktitle>
<pages>533542</pages>
<contexts>
<context position="7303" citStr="Mei et al., 2006" startWordPosition="1148" endWordPosition="1151">n perform deeper understanding of opinions (e.g., distinguishing positive from negative opinions), which can be done by using any existing sentiment analysis technique as an orthogonal post-processing step after applying our method. 2 Related Work Aspect summarization, i.e., structured opinion summarization over topical aspects, has attracted much attention recently. Existing work identifies aspects using frequent-pattern/associationrule mining, e.g. (Liu et al., 2005; Popescu and Etzioni, 2005), sentence clustering, e.g. (Gamon et al., 2005; Leouski and Croft, 1996), or topic modeling, e.g. (Mei et al., 2006; Titov and McDonald, 2008). After that, meaningful and prominent phrases need to be selected to represent the aspects, e.g. (Zhao and He, 2006; Mei et al., 2007). However, these methods suffer from the problem of producing trivial aspects. Consequently, some of the aspects generated are very difficult to interpret (Chen and Dumais, 2000). In this paper, we propose a different kind of approach that is to use aspects provided by ontology which are known to be relevant and easy to interpret. Ontology is used in (Carenini et al., 2005) but only for mapping product features. The closest work to ou</context>
</contexts>
<marker>Mei, Liu, Su, Zhai, 2006</marker>
<rawString>Mei, Qiaozhu, Chao Liu, Hang Su, and ChengXiang Zhai. 2006. A probabilistic approach to spatiotemporal theme pattern mining on weblogs. In WWW 06: Proceedings of the 15th international conference on World Wide Web, pages 533542.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qiaozhu Mei</author>
<author>Xuehua Shen</author>
<author>ChengXiang Zhai</author>
</authors>
<title>Automatic labeling of multinomial topic models.</title>
<date>2007</date>
<pages>490499</pages>
<editor>In Berkhin, Pavel, Rich Caruana, and Xindong Wu, editors, KDD,</editor>
<publisher>ACM.</publisher>
<contexts>
<context position="7465" citStr="Mei et al., 2007" startWordPosition="1176" endWordPosition="1179">hnique as an orthogonal post-processing step after applying our method. 2 Related Work Aspect summarization, i.e., structured opinion summarization over topical aspects, has attracted much attention recently. Existing work identifies aspects using frequent-pattern/associationrule mining, e.g. (Liu et al., 2005; Popescu and Etzioni, 2005), sentence clustering, e.g. (Gamon et al., 2005; Leouski and Croft, 1996), or topic modeling, e.g. (Mei et al., 2006; Titov and McDonald, 2008). After that, meaningful and prominent phrases need to be selected to represent the aspects, e.g. (Zhao and He, 2006; Mei et al., 2007). However, these methods suffer from the problem of producing trivial aspects. Consequently, some of the aspects generated are very difficult to interpret (Chen and Dumais, 2000). In this paper, we propose a different kind of approach that is to use aspects provided by ontology which are known to be relevant and easy to interpret. Ontology is used in (Carenini et al., 2005) but only for mapping product features. The closest work to ours are (Lu and Zhai, 2008; Sauper and Barzilay, 2009); both try to use well-written articles for summarization. However, (Lu and Zhai, 2008) assumes the well-writ</context>
<context position="15782" citStr="Mei et al., 2007" startWordPosition="2653" endWordPosition="2656">view the problem as a ranking problem. The algorithm proceeds by finding at each ranking position an aspect that can maximize the coherence measurement, starting from the top of the rank list. The detailed algorithm is given in Algorithm 2. 3.3 New Aspects Suggestion Finally, if the opinions cover more aspects than in the ontology, we also want to identify informative phrases to label such extra aspects; such phrases can also be used to further augment the ontology with new aspects. This problem is similar to existing work on generating labels for clusters (Zeng et al., 2004) or topic models (Mei et al., 2007). Here we employ a simple but representative technique to demonstrate the feasibility of discovering interesting new aspects for augmenting the ontology. We first extract named entities from scattered opinions DT using Stanford Named Entity Recognizer (Finkel et al., 2005). After that, we rank the phrases by pointwise Mutual Information (MI): MI(T, ph) = log P(T, ph) P(T)P(ph) where T is the given topic and ph refers to a candidate entity phrase. P(T, ph) is proportional to the number of opinion sentences they co-occur; P(T) or P(ph) are proportional to the number of times T or ph appears. A h</context>
</contexts>
<marker>Mei, Shen, Zhai, 2007</marker>
<rawString>Mei, Qiaozhu, Xuehua Shen, and ChengXiang Zhai. 2007. Automatic labeling of multinomial topic models. In Berkhin, Pavel, Rich Caruana, and Xindong Wu, editors, KDD, pages 490499. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Opinion mining and sentiment analysis.</title>
<date>2007</date>
<booktitle>Foundations and Trends in Information Retrieval,</booktitle>
<pages>2--1</pages>
<marker>Pang, Lee, 2007</marker>
<rawString>Pang, Bo and Lillian Lee. 2007. Opinion mining and sentiment analysis. Foundations and Trends in Information Retrieval, 2(1-2):1135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ana-Maria Popescu</author>
<author>Oren Etzioni</author>
</authors>
<title>Extracting product features and opinions from reviews.</title>
<date>2005</date>
<booktitle>In HLT 05,</booktitle>
<pages>339346</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="7187" citStr="Popescu and Etzioni, 2005" startWordPosition="1128" endWordPosition="1131">k is to extract and organize the major opinions about a topic that are buried in many scattered opinionated sources rather than perform deeper understanding of opinions (e.g., distinguishing positive from negative opinions), which can be done by using any existing sentiment analysis technique as an orthogonal post-processing step after applying our method. 2 Related Work Aspect summarization, i.e., structured opinion summarization over topical aspects, has attracted much attention recently. Existing work identifies aspects using frequent-pattern/associationrule mining, e.g. (Liu et al., 2005; Popescu and Etzioni, 2005), sentence clustering, e.g. (Gamon et al., 2005; Leouski and Croft, 1996), or topic modeling, e.g. (Mei et al., 2006; Titov and McDonald, 2008). After that, meaningful and prominent phrases need to be selected to represent the aspects, e.g. (Zhao and He, 2006; Mei et al., 2007). However, these methods suffer from the problem of producing trivial aspects. Consequently, some of the aspects generated are very difficult to interpret (Chen and Dumais, 2000). In this paper, we propose a different kind of approach that is to use aspects provided by ontology which are known to be relevant and easy to </context>
</contexts>
<marker>Popescu, Etzioni, 2005</marker>
<rawString>Popescu, Ana-Maria and Oren Etzioni. 2005. Extracting product features and opinions from reviews. In HLT 05, pages 339346, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M F Porter</author>
</authors>
<title>An algorithm for suffix stripping.</title>
<date>1997</date>
<pages>313316</pages>
<contexts>
<context position="17381" citStr="Porter, 1997" startWordPosition="2925" endWordPosition="2926">eralizability of our methods, we test on two very different categories of topics: US Presidents and Digital Cameras.2 For the ontology, we leverage Freebase, downloading the structured ontology for each topic. For the opinion corpus, we use blog data for US Presidents and customer reviews for Digital Cameras. The blog entries for US Presidents were collected by using Google Blog Search3 with the name of a president as the query. Customer reviews for Digital Cameras were crawled from CNET4. The basic statistics of our data sets is shown in Table 1. For all the data collections, Porter stemmer (Porter, 1997) is applied and stop words are removed. 4.2 Sample Results We first show sample results of automatic organization of online opinions. We use the opinion coverage-based algorithm to select 10 aspects (10-20 aspects were found to be optimal in (Kaki, 2005)) and then apply the coherence-based aspect ordering method. The number of clusters is set so that there are on average 15 opinions per cluster. Opinion Organization: Table 2 and Table 3 present sample results for President Ronald Reagan and Sony Cybershot DSC-W200 camera respectively5. We can see that (1) although Freebase aspects provide obje</context>
</contexts>
<marker>Porter, 1997</marker>
<rawString>Porter, M. F. 1997. An algorithm for suffix stripping. pages 313316.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christina Sauper</author>
<author>Regina Barzilay</author>
</authors>
<title>Automatically generating wikipedia articles: A structureaware approach.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP,</booktitle>
<pages>208216</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Suntec, Singapore,</location>
<contexts>
<context position="4583" citStr="Sauper and Barzilay, 2009" startWordPosition="719" endWordPosition="723">more informed organization of scattered online opinions, and in particular, to select the most important properties of a topic from such structured ontology as aspects to generate a structured opinion summary. A significant advantage of this approach to aspect generation is that the selected aspects are guaranteed to be very well connected with the topic, but it also raises an additional challenge in selecting the aspects to best capture the major opinions from a large number of aspects provided for each topic in the ontology. Different from some existing work on exploiting ontologies, e.g., (Sauper and Barzilay, 2009), which relies on training data, we focus on exploring unsupervised approaches, which can be applied to a larger scope of topics. Specifically, given a topic with entries in an ontology and a collection of scattered online opinions about the topic, our goal is to generate a structured summary where representative major opinions are organized with well aligned aspects and in an order easy for human to follow. We propose the following general approach: First, retrieval techniques are employed to align opinions to relevant aspects. Second, a subset of most interesting aspects are selected. Third,</context>
<context position="7956" citStr="Sauper and Barzilay, 2009" startWordPosition="1259" endWordPosition="1262">. After that, meaningful and prominent phrases need to be selected to represent the aspects, e.g. (Zhao and He, 2006; Mei et al., 2007). However, these methods suffer from the problem of producing trivial aspects. Consequently, some of the aspects generated are very difficult to interpret (Chen and Dumais, 2000). In this paper, we propose a different kind of approach that is to use aspects provided by ontology which are known to be relevant and easy to interpret. Ontology is used in (Carenini et al., 2005) but only for mapping product features. The closest work to ours are (Lu and Zhai, 2008; Sauper and Barzilay, 2009); both try to use well-written articles for summarization. However, (Lu and Zhai, 2008) assumes the well-written article is structured with explicit or implicit aspect information, which does not always hold in practice, while (Sauper and Barzilay, 2009) needs a relatively large amount of training data in the given domain. In comparison, our work only needs the ontology information for the given topic which is much easier to obtain from resources such as Freebase. 735 \x0c3 Methods Given (1) an input topic T, (2) a large number of aspects/properties A = {A1, ..., Am} from an ontology that are </context>
</contexts>
<marker>Sauper, Barzilay, 2009</marker>
<rawString>Sauper, Christina and Regina Barzilay. 2009. Automatically generating wikipedia articles: A structureaware approach. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, pages 208216, Suntec, Singapore, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Titov</author>
<author>Ryan McDonald</author>
</authors>
<title>Modeling online reviews with multi-grain topic models.</title>
<date>2008</date>
<booktitle>In WWW 08: Proceeding of the 17th international conference on World Wide Web,</booktitle>
<pages>111120</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="7330" citStr="Titov and McDonald, 2008" startWordPosition="1152" endWordPosition="1155">nderstanding of opinions (e.g., distinguishing positive from negative opinions), which can be done by using any existing sentiment analysis technique as an orthogonal post-processing step after applying our method. 2 Related Work Aspect summarization, i.e., structured opinion summarization over topical aspects, has attracted much attention recently. Existing work identifies aspects using frequent-pattern/associationrule mining, e.g. (Liu et al., 2005; Popescu and Etzioni, 2005), sentence clustering, e.g. (Gamon et al., 2005; Leouski and Croft, 1996), or topic modeling, e.g. (Mei et al., 2006; Titov and McDonald, 2008). After that, meaningful and prominent phrases need to be selected to represent the aspects, e.g. (Zhao and He, 2006; Mei et al., 2007). However, these methods suffer from the problem of producing trivial aspects. Consequently, some of the aspects generated are very difficult to interpret (Chen and Dumais, 2000). In this paper, we propose a different kind of approach that is to use aspects provided by ontology which are known to be relevant and easy to interpret. Ontology is used in (Carenini et al., 2005) but only for mapping product features. The closest work to ours are (Lu and Zhai, 2008; </context>
</contexts>
<marker>Titov, McDonald, 2008</marker>
<rawString>Titov, Ivan and Ryan McDonald. 2008. Modeling online reviews with multi-grain topic models. In WWW 08: Proceeding of the 17th international conference on World Wide Web, pages 111120, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hua-Jun Zeng</author>
<author>Qi-Cai He</author>
<author>Zheng Chen</author>
<author>Wei-Ying Ma</author>
<author>Jinwen Ma</author>
</authors>
<title>Learning to cluster web search results.</title>
<date>2004</date>
<booktitle>In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>210217</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="15747" citStr="Zeng et al., 2004" startWordPosition="2646" endWordPosition="2649">ns of the solution. Particularly we view the problem as a ranking problem. The algorithm proceeds by finding at each ranking position an aspect that can maximize the coherence measurement, starting from the top of the rank list. The detailed algorithm is given in Algorithm 2. 3.3 New Aspects Suggestion Finally, if the opinions cover more aspects than in the ontology, we also want to identify informative phrases to label such extra aspects; such phrases can also be used to further augment the ontology with new aspects. This problem is similar to existing work on generating labels for clusters (Zeng et al., 2004) or topic models (Mei et al., 2007). Here we employ a simple but representative technique to demonstrate the feasibility of discovering interesting new aspects for augmenting the ontology. We first extract named entities from scattered opinions DT using Stanford Named Entity Recognizer (Finkel et al., 2005). After that, we rank the phrases by pointwise Mutual Information (MI): MI(T, ph) = log P(T, ph) P(T)P(ph) where T is the given topic and ph refers to a candidate entity phrase. P(T, ph) is proportional to the number of opinion sentences they co-occur; P(T) or P(ph) are proportional to the n</context>
</contexts>
<marker>Zeng, He, Chen, Ma, Ma, 2004</marker>
<rawString>Zeng, Hua-Jun, Qi-Cai He, Zheng Chen, Wei-Ying Ma, and Jinwen Ma. 2004. Learning to cluster web search results. In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 210217, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chengxiang Zhai</author>
<author>John Lafferty</author>
</authors>
<title>Modelbased feedback in the language modeling approach to information retrieval.</title>
<date>2001</date>
<booktitle>In Proceedings of CIKM</booktitle>
<pages>403410</pages>
<contexts>
<context position="9999" citStr="Zhai and Lafferty, 2001" startWordPosition="1618" endWordPosition="1621">the major opinions in our opinion set DT ? Aspect Ordering: How can we order a subset of selected aspects A0 so as to present them in an order (A0) that is most natural with respect to human perception? New Aspects Suggestion: Can we exploit the opinions in DT to suggest new aspects to be added to the ontology? 3.1 Aspect Selection In order to align the scattered opinions to the most relevant aspects, we first use each aspect label Ai A as a query to retrieve a set of relevant opinions in the collection Si DT with a standard language modeling approach, i.e., the KL-divergence retrieval model (Zhai and Lafferty, 2001). Up to 1000 opinion sentences are retrieved for each aspect; each opinion sentence can be potentially aligned to several aspects. In this way, scattered online discussion are linked to the most relevant aspects in the ontology, which enables a user to use aspects as semantic bridges to navigate into the opinion space.. However, there are usually a lot of candidate aspects in an ontology, and only some are heavily commented in online discussions, so showing all the aspects is not only unnecessary, but also overwhelming for users. To solve this problem, we propose to utilize the aligned opinion</context>
</contexts>
<marker>Zhai, Lafferty, 2001</marker>
<rawString>Zhai, Chengxiang and John Lafferty. 2001. Modelbased feedback in the language modeling approach to information retrieval. In Proceedings of CIKM 2001, pages 403410.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jing Zhao</author>
<author>Jing He</author>
</authors>
<title>Learning to generate labels for organizing search results from a domainspecified corpus.</title>
<date>2006</date>
<booktitle>In WI 06: Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence,</booktitle>
<pages>390396</pages>
<publisher>IEEE Computer Society.</publisher>
<location>Washington, DC, USA.</location>
<contexts>
<context position="7446" citStr="Zhao and He, 2006" startWordPosition="1172" endWordPosition="1175">timent analysis technique as an orthogonal post-processing step after applying our method. 2 Related Work Aspect summarization, i.e., structured opinion summarization over topical aspects, has attracted much attention recently. Existing work identifies aspects using frequent-pattern/associationrule mining, e.g. (Liu et al., 2005; Popescu and Etzioni, 2005), sentence clustering, e.g. (Gamon et al., 2005; Leouski and Croft, 1996), or topic modeling, e.g. (Mei et al., 2006; Titov and McDonald, 2008). After that, meaningful and prominent phrases need to be selected to represent the aspects, e.g. (Zhao and He, 2006; Mei et al., 2007). However, these methods suffer from the problem of producing trivial aspects. Consequently, some of the aspects generated are very difficult to interpret (Chen and Dumais, 2000). In this paper, we propose a different kind of approach that is to use aspects provided by ontology which are known to be relevant and easy to interpret. Ontology is used in (Carenini et al., 2005) but only for mapping product features. The closest work to ours are (Lu and Zhai, 2008; Sauper and Barzilay, 2009); both try to use well-written articles for summarization. However, (Lu and Zhai, 2008) as</context>
</contexts>
<marker>Zhao, He, 2006</marker>
<rawString>Zhao, Jing and Jing He. 2006. Learning to generate labels for organizing search results from a domainspecified corpus. In WI 06: Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence, pages 390396, Washington, DC, USA. IEEE Computer Society.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>