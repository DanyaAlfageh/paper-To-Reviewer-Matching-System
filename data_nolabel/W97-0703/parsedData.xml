<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<table confidence="0.177866636363636">
b&amp;apos;Using Lexical Chains for Text Summarization
Regina Barzilay
Mathematics and Computer S~nenceDept
Ben Gunon University m the Negev
Beer-Sheva, 84105 Israel
regana@cs.bEu ac. ~1
Michael Elhadad
Mathemat~s and Computer Saence Dept
Ben Gunon Umveraty m the Negev
Beer-Sheva, 84105 Israel
http //mr cs.bgu ac.xl/ elhadad
</table>
<sectionHeader confidence="0.959727" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.97827312987013">
We investigate one techmque to produce a summary
of an original text without requmng zts full seman-
ttc interpretation, but instead relying on a model of
the topic progresston m the text derived from lex-
lcal chains We present a new algonthm to com-
pute lexlcal chains m a text, merging several robust
knowledge sources the WordNet thesaurus, a part-
of-speech tagger and shallow parser for the identifi-
cation of nominal groups, and a segmentatton algo-
rithm dernved from (Hearst, 1994) Summarization
proceeds m three steps the ongmal text is first seg-
mented, lexxcal chmns are constructed, strong chains
are ldsnhfied and ssgnzflcant sentences are extracted
from the text We present m tins paper empirical
results on the tdent~catlon of strong chains and of
slgmfieant sentences
Introduction
Summarization ts the process of condensing a source
text into a shorter Version preserving its reformation
content It can serve several goals -- from survey
analysis of a sctenttfic field to qmck mchcatzve notes
on the general toplc of a text Producing a quahty
reformative summary of an arbitrary text remams
a challenge winch reqmres full understanding of the
text Indtcattves, lm~artes, winch can be used to
qmckly decide whether a text is worth reading, are
naturally easter to produce In tins paper we investi-
gate a method for the production of such mdxcatlve
summaries from arintrary text
(Jones, 1993) descnbes summarization as a two-
step process (1) Building from the source text a
source representatton, (2) Summary generation-
fonmng summary representation from the source
representation bmlt m the first step and synthesismg
the output summary text
Within this framework, the relevantquestion is
what reformation has to be included m the source
representation m order to create a summary There
are three types of source text reformation hngms-
tlc, domain and commumcatlve Each of these text
aspects can be chosen as a barns for source represen-
tatlon
Summaries can be bmlt on a deep semantic anal=
ysis of the source text For example, (McKcown and
Radsv, !905)investigate ways to produce a coher-
ent summary of several texts describing the same
event, when a detaded semantic representation of
the source texts m available (m their case, they use
MUC-style systems to interpret the source texts)
Alternatzvely, early summarisatzon
systems (Luhn, 1968) used only hngumtlc source m-
formation The mtmtlon was that the moat frequent
words represent the tmportant concepts of the text
In this approach the source representation was the
frequency table of text words Tins representation
abstracts the text into the umon of its words w~thout
conmdermg any connectlon among them
In contrast to these two extreme pcsltlous (using
as a source representation a full semantic representa-
tion of the text or reducing ltto a simple frequency
table), we deal m tins paper wttb the issue of pro-
ducmg a summary from an arbitrary text without re-
qmrmg zts full understanding, but using wtdely avad-
able knowledge sources Our mare goal is therefore
to find a middle ground for source representation,
rich enough to braid quality indicative summaries,
but easy enough to extract from the source text to
work on arbltrary text
Over-slmphficatlon can harm the quahty of the
source representation As a trivial illustration, con-
sider the following two sequences
1 &quot;Dr Kenny has sn~ented an anesthetsc maehsne
Thss devwe controls the rate at wh:ch an ana-
esthctsc ss pumped into the blood&quot;
2 &quot;Dr Kenny has :nvented an anesthet:c machsne
The Doctor spent two years on thu research&quot;
~Dr Kenny ~ appears once m both sequences and
</bodyText>
<equation confidence="0.353416545454545">
I0
I
I
I
I
i
I
II
II
I
!
</equation>
<bodyText confidence="0.991714934579439">
\x0cso does ~nach:n ~ But sequence 1 ts about the roa-
ch:he, and sequence 2 m about the *doctor~ Tlus
example mchcates that zf the source representation
does not supply mformatlon about semantically re-
lated terms, one cannot capture the %boutnesg\&amp;apos; of
the text, and therefore the summary will not capture
the mare point of the original text
The norton of cohemon, introduced m (Halhday
and Hasan, 1976) captures part of the mtmtmn Co-
hereon is a dewce for &quot;sticking together&quot; different
parts of the text Cohesion m achmved through the
use of semantmaUy related terms, reference, elhpsm
and conjunctlous
Among these dtfferent means, the most easdy zde-
ntfllable and the most frequent type m lemcal cohe-
&quot; slon (as discussed m (Hoey,~1991)) Lexlcal cohe-
sion is created by usmg semantically related words
Halhday and Hasan classflled lemcal cohesion into
relteratlon category and collocatlon category Rezt-
eratlon can be achmved by repetltlon, synonyms and
hyponyms Collocatmn relatzons spectfy the relation
between words that tend to co-occur m the same lex-
zeal contexts (e g, &quot;She works as a teacher m the
.School~)
Collocation relations are more problematzc for ld-
enttticat~on than rezterat|on, but both of t~hesecat-
egones are Identifiable on the surface oi~the text
Lextcal cohemon occurs not only between two terms,
but among sequences of related words ~ called/ez-
~cal chains (Morns and Hlrst, 1991) Lemcal chains
provide a representahon of the lemcal cohemvestruc-
tare of the text Lemcal chains have also been used
for mfo~nahon retrieval (Stamnand, 1996)and for
correction ofmalaproptsms (Htrst and St-Onge, 1997
(to appear)) In tlus paper, we mveshgate how lem-
cal chmns can be used as a source representation for
summarization
Another nnportant dunenmon of the lmgumtzc str-
ucture of a source ,text m captured under the re-
lated not,on of coherence Coherence defines the
macro-level semantic structure of a connected dLs-
course, while cohesion creates connectedness m a
non-structural manner Coherence m represented m
terms of coherence relat~ous between text segments,
such as cla~orahon, cause and ezplanat|on Some
researchers, e g, (Ono, Kazuo, and Seljl, 1994),
use chscourse structure (encoded umng RST (MAnn
and Thompson, 1987) as a source representatxon for
summanzatxon) Clearly, thin representation ms ex-
presmve enough, the question m whether ~t m com-
putable In contrast to lemcal cohemon, coherence
m chfl~cultto zdent|fymthout complete understand-
mg of the text and complex reference In ad&amp;tton,
there m no prease criteria for clasmficat~on of differ-
ent relatlous Consider the following example from
Hobbs(1978) &quot;John can open the safe He Imows
the combmahon &quot;
(Morns and H~mt, 1991) show that the relation
between these two sentences can he interpreted as
daborahon or as ezplanahon, depen&amp;ng on %on-
text, knowledge and behefs&quot;
There m, however, a close connechon between din-
course structure and cohemon Related words tend
to co-occur mthm a dmcourse umt of the text So
cohemon mone of the surface mgns of dmcourse struc-
ture and lexlcal chaln~ can\&amp;apos; be used to Identify it
Other mgns can be used to ldentzfy dmcourse struc-
ture as well (connect,yes, paragraph markers, tense
shifts)
In thls paper, we investigate the use oflemcal
chains as a model of the source text for the pur-
pose of producing a summary Obviously, other
pects of the source text need to be integrated m the
text representation to produce quahty summaries,
but we want to empmcally investigate how far one
can go exploiting mainly lemcal chains In the rest
of the paper we first present our algorithm for lex-
zeal chain construct,on We then present empmcal
results on the ldentlficatzon of strong chains among
the posmble can&amp;dates produced by our algorithm
Finally, we describe how lexlcal chains are used to
identify mgmficant sentences mtlnn the source text
and eventually produce a surQmary
Algorithm for Chain Computing
One of the clnef advantages of lemcal cohesmn m
that zt m an easdy reco~m~able relatmn, enabhng
lexlcal chains computation The first computational
model for lemcal chains was presented m (Morns and
Hlrst, 1991) They define lexlcal cohesmn relatzons
m terms of categories, index entries and pointers m
Roget\&amp;apos;s Thesaurus Morns and Hlrst evaluated that
their relatedness criterion covered over 90% of the
mtmttve lexzcal relatzons Cham~ are created by tak-
ing a new text word and findtng a related chain for
it according to relatedness criteria Morns and HLrst
introduce the notion of &quot;actzvated chain~ and ~cham
returns&quot;, to take into account the dmtance between
occurrences of related words They also analyze fac-
tors contributing to the strength of a chain -- rep-
etltxon, density and length Morns and Hn\&amp;apos;st &amp;d
not ~nplement their algorithm, because there was
no machine-readable vermon of Roget\&amp;apos;s Thesaurus
at the tzme
One of the drawbacks of thelr approach was that
they chd not reqmre the same word to appear ruth
the same sense m ~ts &amp;ffexent occurrences for tt
to belong to a chain For semantically ambiguous
</bodyText>
<page confidence="0.999445">
11
</page>
<bodyText confidence="0.998652898148148">
\x0cwords, this can lead to confnslous (e g, mixing two
senses of taSle as aptece 0f furniture or an array)
Note that choosing the appropriate chain for a word
is eqmvalent to dzsamblguatmg tins word m context,
which is a well-known d~fl~cult problem m text un-
derstanding
More recently, two algorithms for the calculation
of lexlcal chains have been presented m Hirst and St-
Onge (1995) and Stairmand (1996) Both of these
algornthms use the WordNet lexlcal database for de-
termining relatedness of the words (Miller et al,
1990) Senses m the WordNet database are repre-
sented relatlonally by synonym sets (\&amp;apos;synsets\&amp;apos;) --
which are the sets of all the words sharing a com-
mon sense For example two senses of &quot;computer&quot;
are represented as {calculator, reckoner, figurer, es-
timator, computer) (s e, a person who computes)
and {computer, data processor, electromc computer,
reformation processing system) WordNet contains
more than 118,000 dflferent word forms Words of
the same category are hnked through semantic rela-
tions hke synonymy and hyponymy
Polysemous words appear m more than one syn-
sets (for example, comptdcr occurs m two synsets)
Approxtmately 17% of the words m WordNet are
polysemous But, as noted by Stairmand, this fig-
ure is very tmsleadmg &quot;a slguxficant proportion of
WordNet nouns are Latin labels for biological en-
titles, which by their nature are monosemons and
our experience wtth the news-report texts we have
processed ts that approxtmately half of the nouns
encountered are polysemous&quot; (Stairmand, 1996)
Generally, a procedure for constructing lexlcal ch-
ains follows three steps (1) Select a set of can&amp;date
words, (2) For each candldate word, find an appro-
priate chain relying on a relatedness cute.on among
members of the chains, (3) If It is found, insert the
word m the chain and update It accorchngly
An example of such a procedure was represented
by Hlrst and St-Onge (H&amp;S) In the preprocessor
step, all words that appear as a noun entry m Word-
Net are chosen Relatedness of words xs dstermmed
m terms of the distance between their occurrences
and the shape of the path connecting them m the
WordNet thesaurus Three kinds of relation are de-
fined extra-strong (between a word and tts rep-
etxt~on), strong (between two words connected by
a Wordnet relatxon) and mechum-stroug when the
hnk between the synsets of the words is longer than
one (only paths satisfying certain restrictions are ac-
cepted as vahd connectxons)
The maxtmum distance between related words de-
pends on the kind of relatxon for extra-strong rela-
ttons, there is not hxmt m &amp;stance, for strong rela-
tlons, it is hmlted to a window of seven sentences,
and for mechum-strong relations, It is wltinn three
sentences back
To find a chain m winch to insert a given can-
dtdate word, extra-strong relattons are preferred to
strong-relations and both of them are preferred to
medmm-strong relations If a chain is found, then
the candtdate word is inserted with the appropriate
sense, and the senses of the other words m the receiv-
ing chain are updated, so that every word connected
to the new word m the chain relates to Its selected
senses only If no chaan is found, then a new chain Is
created and the can&amp;date word ts inserted with all
its possible senses m WordNet
The greedy &amp;samblguatzon strategy Implemented
m this algorithm has some lmntatlonsdinstrated by
the following example
Mr. Kenny ~s the person that invented an anaesthehc
machine whsch uses micro-computers to control the
rate at whsch an anaesthehc ,s pumped into the blood
Such machines are nothing new But hu device uses
two micro-computers to achseee much closer momtor-
mg o/the pump ]eedmg the anaesthehc into the pahent
Accor&amp;ug to H&amp;S\&amp;apos;s algorithm, the chain for the
word &quot;Mr&quot; is first created [lex &quot;Kr.&quot;, sense
{mzster, Mr. }] &quot;Mr&quot; belongs only to one synset,
so it is chsamblguated from the beginning The word
&quot;person&quot; is related to tins chain m the sense &quot;a
human be,ng&quot; by a medmm-stroug relation, so the
chain now contains two entries
[lex &quot;Mr\&amp;apos;.&quot;, sense {m.ster, Mr.)]
[lex &quot;person&quot;, sense {person, :t.nd~.v~dual,
someone, man, mortal, huma.u, sou1}]
When the algorithm processes the word &quot;machineD,
It relates it to this cham, because &quot;roach:hen m
the first WordNet sense (&quot;an eOiczent person&quot;) is
a holonym of apersonn m the chosen sense In other
words, &quot;machine&quot; and &quot;person&quot; are related by a
strong relation In tins case, &quot;machine&quot; ts disam-
blguated m the wrong way, even though after tins
first occurrence of &quot;machine&quot;, there is strong evi-
dence supporting the selechon of xts more common
sense &quot;macro-computer&quot;, &quot;demce&quot; and &quot;pemp&quot; all
point to its correct sense m tins context ~ &quot;any me-
chanzcal or electrzcal devzce thaZ performs or assgs~s
zn the performance&quot;
Tins example mdtcates that disamblguatlon can-
not be a greedy decision In order to choose the right
sense of the word the \&amp;apos;whole ptcture\&amp;apos; of chain distn-
butwn m the text must be conmdered We propose
to develop a chaining model according to all possxble
alternatives of word senses and then choose the best
one among them
Let us dlustrate tins method on the above exam-
</bodyText>
<page confidence="0.714306">
12
</page>
<figure confidence="0.973871857142857">
I
I
I
I
II
II
II
I
I
II
I
!
II
!
</figure>
<bodyText confidence="0.787970714285714">
\x0cpie First, a node for the word =Mr&quot; Is created [lex
&quot;ltr\&amp;apos;.&quot;, sense {mister, Kr }3 The next candi-
date word Is &quot;person&quot; It has two senses &quot;haman
besngn (person &quot;1) and erratum=heal cafegory of
pronouns and verbforms&quot; (person -- 2) The choice
of sense for ~person&quot; sphts the chain world to two
dflferent interpretations as shown m Figure 1
</bodyText>
<equation confidence="0.96462">
I
Figure I Step I
lpen%}
</equation>
<bodyText confidence="0.987238078947368">
Interpretations 1 and 2
We define a component as a list of interpretations
that are exclusive of each other Component Words
influence each other in the selection of their respec-
tive senses
The next candidate word =anaesthetsc&quot; Is not re-
lated to any word m the first component, so we cxe-
ate a new component for it with a single lntexpreta-
taon
The word &quot;machsne&quot; has 5 senses mach:nei to
machine5 In its first sense; &quot;an e.0ic:ent person&quot;,
it m related to the senses =person&quot; and =Mr&quot; It
therefore influences the selection of thexr senses, thus
&quot;machine&quot; has to be ~ m the first component
After its msertmn the picture of the first component
becomes the one shown m Figure 2
But ff we continue the process and insert the wor-
ds =micro-compeer\&amp;apos;, =
dcmcen and =pump\&amp;apos;, the nu-
mber of nlternatlve greatly increases The strongest
interpretations are given m Figures 3 and 4
Under the assumption that the text Is cohessve,
we define the best interpretation as the interpreta-
tion with the most connections (edges m the graph)
In tins case, the second interpretation at the end of
Step 3 is selected, which predicts the right sense for
&quot;machine&quot; We define the score of an interpretation
as the sum of its chain scores Chain seore is deter-
mined by the number and weight of the relations be-
tween chain members Expenlnentally, we fixed the
weight of reiteration and synonym to 10, of antonym
to 7, and of hyperonym and holonym to 4\&amp;apos; Our al-
gorithm develops all possible interpretations, main-
tainmg each one without self contradiction When
the number of possible interpretations is larger than
a certain threshold, we prune the weak interpreta-
tions according to tins criteria In the end, we select
from each component, the strongest interpretation
</bodyText>
<figure confidence="0.979109470588235">
(Mr . m |
[pe~ntlZlt mdtvtdttal
mmeoae I
Imaclunea} S
Step 2: Interpretauon 1
tMr,numer}
lpenm}
{marina% machine
s I&quot;
Step 2: Interpretation 2
(pez-~ individual
me, )
(~ehme a m~h,ne s )
Step 2&quot; InterpretaUon 3
iMr.n~tef}
[permn}
{n,aclane,I
</figure>
<subsubsectionHeader confidence="0.569347">
Step 2: Interpret=non 4
</subsubsectionHeader>
<bodyText confidence="0.980737961538461">
FFtgure 2 Step 2 Interpretations I to 4
.\&amp;apos;~.-. .
In snmmary, our algorithm differs from H&amp;S\&amp;apos;s al-
gorithm m that It introduces, m addition to the re-
latedness criterion for members~p to a chain, a non-
greedy dzsainbiguatlon heuristic to select the appro-
priate senses of chain members
The two algonthms differ m two other major as-
pects the criterion for the selection of candidate
words and the operative defimhon of a text unit
We choose as candidate words simple nouns and
noun compounds As mentioned above, nouns are
the main contributors to the =aboutness&quot; of a text,
and noun synsets dominate m WordNet Both
(Stairmand, 1996) and H&amp;S rely only on nouns as
candidate words In our algorithm, we rely on the
results of Brdl\&amp;apos;s part-of-speech tagging algorithm to
idsntlfy nouns, whl]e H&amp;S do not go through this
step and only select tokens that happen to occur as
nouns m WordNet
In addition, we extend the set of candidate words
to include noan compound We first empmcally eval-
uated the unportance of noun compounds by taking
mto account the noun compounds exphcttly present
m WordNet (some 50,000 entries m WordNet are
noun compounds such as &quot;sea level&quot; or co].locatlons
</bodyText>
<page confidence="0.966936">
13
</page>
<figure confidence="0.767661714285714">
\x0c(Mr,lms~e}
~(\&amp;apos;MLczq-~__\&amp;apos;~
{PC,
rmaro-
computer,
}
t Iperso~
</figure>
<figureCaption confidence="0.914372">
Figure 3 Step 3 Interpretation 1
Figure 4 Step 3 Interpretation 2
</figureCaption>
<bodyText confidence="0.996691586956522">
such as &quot;digital computeff) However, Enghsh in-
cludes a productive system of noun comp0hnds, and
m each domain, new noun-compounds and colloca-
tions not present m WordNet play a major role
We addreseed the issue, by usmg a shallow parser
(developed by Ido Dagan\&amp;apos;s team at Bar Ilan Um-
verslty) to identify noun-compounds using a snnple
characterization of noun sequences Tins has two
major benefits (1) it ldentflles Important concepts
m the domain (for example, m a text on &quot;quan-
tum computing&quot;, the mare token was the noun com-
pound ``~uantum computing&quot; winch was not present
m WordNet), (2) it chromates words that occur as
modn~ere as posmble can&amp;dates for chain member-
sinp For example, when ``quantum computing&quot; m
selected as a smgle umt, the word ``uantum~ is not
selected This Is beneficial because m tins example,
the text was not about-&quot;quantum\&amp;apos;, but more about
computers When a noun compound ~sselected, the
relatedness criterion in WordNet ~sused by couslder-
mg its head noun only Thus, &quot;quantum computer~
~s related to ``machine~ as a ~computer~
The second dflfexence m our algorithm hes m
the operative defuntion we gwe to the notion of
text umt We use as text umts the segments ob-
tained from Hearst\&amp;apos;s algorithm of text segmentation
(Hearst, 1994) We braid chains m every segment
according to relatedness criteria, and in a second
stage, we merge chains from the dflferent segments
using much stronger criteria for connectedness only
two chains are merged across a segment boundary
only if they contain a common word with the same
sense Our mira-segment relatedness criterion.is less
strict members of the same synsets are related, a
node and its offspnng m the hyperonym graph are
related, mbhngs m the hyperonym graph are related
only ffthe length of the path mless thana threshold
The relation between text segmentation and lex-
lcal chain is dehcate, since they are both derived
from partially common source of knowledge lexlcal
&amp;stnbutlon and repetitions In fact, lexlcal chains
could serve as a barns for an algorithm for segmen-
tation We have found empmcally, however, that
Hearst\&amp;apos;s algorithm behaves well on the type of texts
we checked and that it prowdes effectively a sohd
basLSfor lexlcal chains construction
</bodyText>
<subsectionHeader confidence="0.987476">
Building Summaries Using
Lexical Chains
</subsectionHeader>
<bodyText confidence="0.997434617647059">
We now investigate how lexlcal chains can serve as
a source representation of the original text to budd
a summary The next question m how to build.sum-
mary representation from tins source representation
The most prevalent dmcourse topic will play an
important role m the summary We first present
the mtmtlon why lex~cal chains are a good m&amp;cator
of the central topic of a text G!ven an approprn-
ate measure of strength, we show that picking the
concepts represented by strong lexlcal chains glves a
better mchcatlon of the central toplc of a text than
snnply plckmg the most frequent words m the text
(which forms the zero-hypothesis)
For example, we show m Appendix a sample
text about Bayeman Network technology There, the
concept of network was represented by the words
&quot;network&quot; with 6 occurrences, %ct&quot; with 2, and
``system~ ruth 4 But the summary representa-
tion has to reflect that all these words represent
the same concept Otherwise, the summary gen-
eration stage would extract information separately
for each term The chain representation approach
avmds completely this problem, because all tl~ese
terms occur m the same chain, winch reflects that
they represent the same concept
An ad&amp;tlonal argument for the chain representa-
tion as opposed to a rumple word frequency model
is the case when a tangle concept is represented by a
number of words, each with relatively low fTequency
In the same Bayesian Network sample text, the con-
cept of &quot;reformat:on&quot; was represented by the words
&quot;,nformatson&quot; (3), &quot;datum&quot; (2), &quot;Irnowledge&quot; (3),
&quot;concept&quot; (1) and &quot;model&quot; 1 In tins text, &quot;mforma.
tzon&quot; m a more important concept than &quot;computer&quot;
</bodyText>
<page confidence="0.968498">
14
</page>
<equation confidence="0.999455894736842">
I
i
I
I
I
I
i
I
I
I
I
I
I
I
I
I
I
I
I
</equation>
<bodyText confidence="0.89749">
\x0cwhtfh occurs 4 times Because the &quot;mformatson&quot;
chmn combines the number of occurrences of all its
members, It can overcome the weight of the single
word &quot;computer&quot;
</bodyText>
<subsectionHeader confidence="0.978576">
Scoring Chains
</subsectionHeader>
<bodyText confidence="0.9994019">
In order to use leemcalchains as outlined above, one
must first identify the strongest chains among all
those that are produced by our algorithm As is
frequent m summarization, there Is no formal way
to evaluate chain strength (as there m no formal
method to evaluate a summary quality) We there-
fore rely on an empmcal methodology We have
developed an envxronment to compute and graph-
lcally visuallze lexxcal chains to evaluate experimen-
tally how they capture the mare topics of the texts
Figure 5 shows how lemcal chains are visualized to
help human testers evaluate therr importance
Figure 5 Visual representa~on of lexlcal chRm~
We have collected data for a set of 30 texts
extracted from popular magazmes (from &quot;The
Econommt&quot; and ``Scientific American&quot;), all of them
are popular science genre For each text, we manu-
ally ranked chains m terms of relevance to the mare
toplcs We then computed different formal measures
on the chmns, including chmn length, hstnbution
m the text, text span covered by the chain, density,
graph topology (diameter of the graph of the words)
and number of repetitious The results on our data
set indicate that only the following parameters are
good predictors of the strength of a chmn
Length: The number of occurrences of members of
the chain
Homogeneity index: 1 - the number of distract
occurrences divided by the length
We demgned a score function for chains as
</bodyText>
<equation confidence="0.749187">
Score(Chain) = Length Homogene=ty
</equation>
<bodyText confidence="0.9884255">
When ranking CbamR according to thexr score, we
evaluated that strong chamR are those winch satlsfy
</bodyText>
<equation confidence="0.802161666666667">
our &quot;Strength Criterion&quot;
5core(Cha:n) &amp;gt; Auerage(Seores) +
2 . ~tandardDeemtson( Scorea)
</equation>
<bodyText confidence="0.983889071428572">
These are prehmmary results but they are con-
firmed by our experience on 30 texts analyzed ex-
tensively We have expertraenteedwsth d~erent nor-
mahzation methods for the score function, but they
do not seem to nnprove the results We plan on
extending the empmcal analym m the future and
to use formal learmng methods to determine a good
scoring function
The average number of strong chains selected by
thxs selection method was 5 for texts of 1055 words
on average (474 words mmunum, 3198 words mare-
mum), when 32 chmnR were originally generated on
average The strongest chmn of the sample text are
represented m Appendix
</bodyText>
<subsectionHeader confidence="0.708194">
Extracting Significant Sentences
</subsectionHeader>
<bodyText confidence="0.996582486486487">
Once strong chains have been selected, the next step
of the summarization algorithm is to extract full sen-
tences from the original text based on chain distn- .
butlon
We investigated three alternatives for tlus Step
Heuristic 1 For each chain m the summary rep-
resentation choose the sentence that contains the
first appearance of a chain member m the text
Thls heuristic produced the followingsummary for
the text shown in Appendix
When Mscroaoft Semor Vsce Pressdcnt Steve Ballmer
first heard h~ company was planning to make a huge m-
vestment m an Internet oermec offering mome remews
and local entertainment mformahon m ma3or cstwzs
across the nahon, he trent to Cfiasrman Bdl Gates wlth
hu concerns M.crasoft\&amp;apos;s compehhve advantage, he re-
sponded, tvas its exparhse m Bayesian networks
Bayessan nettvorks an~ cort~pl~ diagraras that o~gamze
the body of knowledge m any gwen area by mapping out
cause and effect relatmnshlpa among key varmbl~ and
encoding them vsthnumbers that repr~ent the eztent to
tvhsch one varmble ss hkely to a~ect another
Programmed into computers, these systems can auto.
mahcally generate optimal pred,chon8 or decisions even
tohen key pieces of mformahon are mtsslng
When Mserosoft tn 1993 hired Eric Horustz, David Heck-
erman and Jack Brecse, pioneers m the development of
Bayesmn systems, colleague8 m the field were surprised
The problem wxth tins approach m that all words
m a chain reflect the same concept, but to a &amp;fferent
extent For example, m the AI chain, (AppendL~,
Chain 3) the token %czence&quot; ts related to the con-
cept aA~\&amp;apos;, but the words ``AF\&amp;apos; and ``)~eid&quot; are more
suitable to represent the mare topic ``AI&quot; m the con-
text of the text That is, not all chain members are
good representatives of the topic (even though they
all contribute to its meamng)
</bodyText>
<page confidence="0.927088">
15
</page>
<equation confidence="0.342952">
I
</equation>
<bodyText confidence="0.999309685185185">
\x0cWe therefore defined a criterion to evaluate the
approprlateness of a cham member to represent, its
chain based on its frequency of occurrence m the
chani ~ ~We found experimentally that such words,
call them represenfafs~e words, have a frequency m
the chain no less than the average word frequency
m the chain For example, m the third chain the
representative words are &quot;field&quot; and &quot;AI&quot;
Heuristic 2 We therefore defined a second heu-
ristic based on the notion of representative words
For each chain m the summary representation,
choose the sentence that contains the first appear-
ance of a representative chain member m the text
In this special case this heuristic gives the same
result as the first one
Heuristic 3 Often, the same topic is dmcussed
in a number of places in the text, so its chain is
dL~tnbuted across the whole text Still, m some text
unit, this global topic is the central topic (focus) of
the segment We try to identify this umt and extract
sentences related to the topic from this segment (or
successive segments) only
We characterize this text umt as a cluster of suc-
cessive segments with high density of chain mere-
beers Our tlnrd heuristic Is based on thts approach
For each chain, find the text umt where the chain
Is highly concentrated Extract the sentence with
the first chain appearance m tins central umt Con-
centratlon m computed as the number of chain mem-
bers occurrences m a segment &amp;vlded by the number
of nouns m the segment A chain has high concen-
tratton ff its concentrat|on is the mammum of all
chains Cluster is group of successive segments such
that every segment contains chain members
Note that m all these three techmques only one
sentence is extracted for each chain (regardless of
its strength)
For most texts we tested, the first and second tech-
niques produce the same results, but when they are
dflferent, the output of the second teclmlque Is bet-
tex Generally, the second techmque produces the
best summary We checked these methods on our
30 texts data set Surprisingly, the tlnrd heuris-
tic, winch intuition predicts as the most sophisti-
cated, gives the least indicative results TIns may
be due to several factors our criteria for \&amp;apos;cen-
trahty\&amp;apos; or \&amp;apos;clustering\&amp;apos; may be insufficient or, more
hkely, the problem seems to be related to the in-
teraction with text structure The third heuristics
tends to extract sentences from the middle of the
text and to extract several sentences from dmtant
places m the text for a single chain The complete
results of our experiments are avatlable onohne at
htl;p://~ cs bgu. ac 3.1/sllmm,a.r~.za3.on-tesl;
</bodyText>
<subsectionHeader confidence="0.636703">
Limitations and Future Work
</subsectionHeader>
<bodyText confidence="0.992104510204082">
We have identified the following maul problems with
our. method
Sentence granularity all our methods extract
whole sentences as single umts Ttus has several
drawbacks long sentences have mgnflicantly ln-
gher hkehhood to be selected, they also include
many constituents which would not have been
selected on theu own merit The alternative
Is extremely costly it revolves some parsing of
the sentences, the extraction of only the central
constituents from the source text and the regen-
eration of a summary text using text generation
techniques
Extracted sentences contain anaphera hnks to
the rest of the text This has been investigated
and observed by (Black, 1994) Several heurls-
ties have been proposed m the hterature to ad-
dress flus problem (Pmce, 1990), (Patce and
Husk, 1991) and (Black, 1994) The strongest
seems to be to include together wtth the ex-
tracted sentence the one lmme&amp;ately precechng
it Unfortunately, when we select the first sen-
tence in a segment, the preceding sentence does
not belong to the paragraph and its insertion
has a detrimental effect on the overall coherence
of the summary A preferable solution would
be to replace anaphora wzth theLr referent, but
again fins m an extremely costly solution
Our method does not provide any way to control
the length and level of detad of the summary
In all of the methods, we extract one sentence
for each chain The number of strong chamR re-
mmns smaU (around 5 or 6 for the texts we have
tested, regardless of then length), and the re-
mmmng chains would introduce too much nmse
to be of interest m ad&amp;ng details The best so-
lution seems to be to extract more material for
the strongest chains
The method presented m thin paper m obviously
partial mthat it only considers lemcal chains as a
source representation, and ignores any other clues
that could be gathered from the text Still, our
first mformalevaluatlon indicates our results are of a
quahty superior to that of summarizers usually em-
ployed m commercial systems such as search systems
on the World Wide Web on the texts we investigated
A large-scale evaluation of the method and how sen-
sltlve It IS to the quahty of the thesaurus and to its
parameters is under way
</bodyText>
<page confidence="0.428407">
16
</page>
<figure confidence="0.98538265">
I
I
I
I
I
I
I
I
I
I
I
I
!
!
I
I
I
I
\x0cBayesian Networks Text
When \&amp;apos;M~rosoft Semor VICUP~esKhmtSteve BalJm~ fn\&amp;apos;st heard hascompany yves
</figure>
<bodyText confidence="0.980817675675676">
planning to mekea huge mveatment In an Interoeteenncaoffenngmowe reins end
Ioca |entu~tainment mfonlnntmn m majorcmea ao~ea the notun he went to Chanmun
Bd] Gates wth his concern
After ell Bellme~ has bflhom of dollars of lus own money m M~\&amp;apos;osoft stock, and
~tertumment tsn t exactlythe compuny\&amp;apos;e strong point
Out Gates dmrmesedsuch realvaruns M~:rosoft\&amp;apos;s compehUve advantage, he re-
sponded, me mt expertem In Bayeamnnetw0cke
Asked recently when computers mum fnaagy beipn to understand human speech
Gates begun dncussmgthe r.ntal role of Baystun\&amp;apos; systems
Ask any other software executive about anything Bay~mn and you\&amp;apos;re hable to set
blunk tare
I Gates onto orneUung? I tim abm4oundmg technology Mmrosoft new secret
wenpoN?
Bayeslunnetvmrk ere complex dmgram that organize the body of knowledgem any
Ipven area by rnapping out cause-and-effect relat~onshnpsamong key vamblea end
encoding them with numbeesthat representthe extent to which one ramble n 5kth7
to affect another ( )
Programmed into comlmt4m~,these ystems can autometzcuHygenerate optunzdpre-
dlct4onsor deastons even when key piecesof Informabon are m~n g
When Miorozoftin 1993 hired Eric Homtz, David H~:kermun and Jack Brine pro-
nearsm the devdopment of Baystun systems,colleaguesm the field were mlmsed
The held was still an obscure, lergdy academic enterlmea
Bayesiannets prowde an oeararchmggraphtcal framework&quot; that Imngs togetlm\&amp;apos;cb-
verseelementsofAI and Increase\&amp;apos;therange of Ks hkely epphcabon to the real world
says Michael Jordon profes~mrof bram\&amp;apos;and cogrove menea et the Massachusetts
Institute of TechnoloW
Mmrosoft ts unquestionably the most aKfFessJvein expkntmg the new epproach The
cumpeny offers \&amp;apos;free Web sentee that helps customers dtegnose pnntmg problems
ruth their cornputae and recommends the qmdoett way to resolve them Another
Web se~ncahelp parents diagnosethew chlklren\&amp;apos;e health problems ( )
Horm~ who with two colleaguesfounded Knowledse Induutneato develop tools for
developing Ba.~slan systems saysheand theothersleft theeompanytojom Microsoft
In part becausethey wanted to seetheir theoretu:ol work more broadly apphed
Althoughthe cornpanydid important workfor the Natmnal Aeronautics and Space Ad-
mimstmbon and on medw.aldiagnostics Homtz says \&amp;apos;it not Ilk your grundmothef
vnll use it
Miorosoft\&amp;apos; eehvmeam the held am now helping to build a groundsv.~dlof support for
</bodyText>
<figure confidence="0.884146727272727">
BayesianKleas
People look up So M~osoft \&amp;apos; says Pearl. who wrote one of the key early texts on
0ayeon networks tn 1988 and has become an unoflu:~d pokesrcan for the hdd
&quot;They ve Ipven a boost to the whole area&quot;
M~\&amp;apos;osoft m wodtms on technques that wdl enable the Bayeamnnetworks to ke~rn
or updatethemdyes automatu:;dly basedon new knowledge 8 task that m currently
cumbersome
Bayesian Network Text: the
Strongest Chain
The Criterion t~ 3 ~8, here are the five strong chasn~
OHAIN I Score = 14 0
</figure>
<construct confidence="0.660327">
mzcro~oft 10 concern I company 6
enterta~tment-~ervlce 1 enterprbe 1
ma~ttchu~et t e-matsut e 1
~HA/,N Score ffi 9 0
ba~\&amp;apos;e~l&amp;n-~y~tem 2 ~y~tem 2 baye~za~s-net 2
network 1 baye~z~n-network 5 weapon 1 :
CHAIN 3 Score ----7 0
m 2 a~ttficzal-mtolhgunce /~
field 7 technology 1 t,czence I
CHAIN ~ Score ffi 6 O
tochmquo 1 b&amp;ye~tsn-techmque I condztzon I
datum 2 model I mformatton 3 area I
</construct>
<figure confidence="0.787066888888889">
knowledge 3
~HAIN S Score = 3 0
computer 4
Acknowledgements
Tkts work has been supported by the Israeh Mlmstry
of Science We axe grateful to Graeme Ktrst, Dragonnr
Radev and Claude Bneson for thezr feedback on a previ-
ous vermon
References
</figure>
<reference confidence="0.7092095">
Black, Wflham J 1994 Parsing, lmgmstlc resources and
semantic analysis, for abstzactmg and categorization
Halhday, lqhchael and Ruqatya Hasan 1976 Cohesion
in Enghsh Longman, London
</reference>
<page confidence="0.989003">
17
</page>
<reference confidence="0.987749826923077">
Hearst, Marti A 1994 Multi-paragraph segmentation
of exposltoZT text In Proceedmgsof the 3~ndAnnual
Meetmg of the Assocmhonfor ComputationalLmguts-
hcs
HLmt, Graeme and Dared St-Onge 1997 (to appear)
Lemca] chains as representation of context for the de-
tection and correction of malapropisms In Chns-
tiane Fellbanm, edxtor, WordNet An electmmc lez-
tcal database and some of ,ts appheat:ons Cambridge,
MA The MIT Press
Hoey, M 1991 Patterns of Leats m Tezt Oxford Um-
vermty Press, Oxford
Jones,.KarenSpaxck 1993 What mightbe m summary?
Informahon Retrleval
Lulm, H P 1968 The automatxc ereatzon of hterature
abstracts In Schultz, edttor, H P Luhn Pioneer of
lnformahon Science Spartan
Mann, W C and S Thompson 1987 RhetoncaJ. struc-
ture theory description and constructions of text
structures In Gerard Kempen, echtor, Natural Lan-
guage Generahon New Results m Arhfictal Intellh-
gence, Psychology and Lmgutst:cs Maxtmus Nmjhot~
Pubhshers, pages 85-96
McKeown, Kathleen and Dragonur Radev 1995 Gen-
eratmg summaries of multiple news articles In SIGIR
95 Proceedings
Mdler, George A, P,~chard Beckwlth, Chnstiane Fell-
bans, Derek Gross, and Kathenne J ~ 1990
Introduction to WordNet An on-lme lexxcal database
Internat,onal Journal of Lazwcographg(special issue),
3(4) 23,5,-312
Morns, J and G Hzrst 1991 Lexzcal coheszon com-
puted by thesanra] relations as an re&amp;cater of the
structure of the text Computahonal Lmgutsttos,
17(1) pp 21.--45
Onq, Ken3h Sunuta Ksno, and Mnke Seql 1994 Ab-
stract genezation based on rhetorical structure extruc-
tzon In Proceedings of the International Conference
on Computahonal Lmgutshcs (Cohng 9~), pages 344--
348, Japan
Pa~ce, C D and G D Husk 1991 Towards the au-
tomatic recognntlon of anaphonc features m enghsh
text The nnpexsonal pronoun &quot;zt~ Computer Speech
and Language,(2) pp 109-132
Patce, Chris D 1990 Constructing hterature abstracts
by computer techmqu~ and prospects lnformahon
Processmg and Management, 26(1) 171-186
Statrmand, Mark A 1996 A Computahonal Analysts of
LexscalCohesion wtth Apphcattons :n Informatton Re-
trievai Ph D thesis, Center for Computational Lm-
gmstics, UMIST, Manchester
\x0c&amp;apos;
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.083334">
<title confidence="0.999761">b&amp;apos;Using Lexical Chains for Text Summarization</title>
<author confidence="0.811615">Regina Barzilay</author>
<title confidence="0.887402">Mathematics and Computer S~nenceDept</title>
<author confidence="0.904561">Ben Gunon University m the Negev</author>
<address confidence="0.895244">Beer-Sheva, 84105 Israel</address>
<email confidence="0.526254">regana@cs.bEuac.~1</email>
<author confidence="0.784396">Michael Elhadad</author>
<title confidence="0.840173">Mathemat~s and Computer Saence Dept</title>
<author confidence="0.846045">Ben Gunon Umveraty m the Negev</author>
<address confidence="0.924537">Beer-Sheva, 84105 Israel</address>
<email confidence="0.421347">http//mrcs.bguac.xl/elhadad</email>
<abstract confidence="0.992621117647059">We investigate one techmque to produce a summary of an original text without requmng zts full semanttc interpretation, but instead relying on a model of the topic progresston m the text derived from lexlcal chains We present a new algonthm to compute lexlcal chains m a text, merging several robust knowledge sources the WordNet thesaurus, a partof-speech tagger and shallow parser for the identification of nominal groups, and a segmentatton algorithm dernved from (Hearst, 1994) Summarization proceeds m three steps the ongmal text is first segmented, lexxcal chmns are constructed, strong chains are ldsnhfied and ssgnzflcant sentences are extracted from the text We present m tins paper empirical results on the tdent~catlon of strong chains and of slgmfieant sentences</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Wflham J Black</author>
</authors>
<title>Parsing, lmgmstlc resources and semantic analysis, for abstzactmg and categorization Halhday, lqhchael and Ruqatya Hasan</title>
<date>1994</date>
<journal>H P</journal>
<booktitle>Onq, Ken3h Sunuta Ksno, and Mnke Seql</booktitle>
<volume>3</volume>
<issue>4</issue>
<pages>85--96</pages>
<publisher>MA The MIT Press</publisher>
<institution>McKeown, Kathleen and Dragonur Radev</institution>
<location>Oxford Jones,.KarenSpaxck</location>
<contexts>
<context position="29232" citStr="Black, 1994" startWordPosition="4880" endWordPosition="4881"> our. method Sentence granularity all our methods extract whole sentences as single umts Ttus has several drawbacks long sentences have mgnflicantly lngher hkehhood to be selected, they also include many constituents which would not have been selected on theu own merit The alternative Is extremely costly it revolves some parsing of the sentences, the extraction of only the central constituents from the source text and the regeneration of a summary text using text generation techniques Extracted sentences contain anaphera hnks to the rest of the text This has been investigated and observed by (Black, 1994) Several heurlsties have been proposed m the hterature to address flus problem (Pmce, 1990), (Patce and Husk, 1991) and (Black, 1994) The strongest seems to be to include together wtth the extracted sentence the one lmme&amp;ately precechng it Unfortunately, when we select the first sentence in a segment, the preceding sentence does not belong to the paragraph and its insertion has a detrimental effect on the overall coherence of the summary A preferable solution would be to replace anaphora wzth theLr referent, but again fins m an extremely costly solution Our method does not provide any way to c</context>
</contexts>
<marker>Black, 1994</marker>
<rawString>Black, Wflham J 1994 Parsing, lmgmstlc resources and semantic analysis, for abstzactmg and categorization Halhday, lqhchael and Ruqatya Hasan 1976 Cohesion in Enghsh Longman, London Hearst, Marti A 1994 Multi-paragraph segmentation of exposltoZT text In Proceedmgsof the 3~ndAnnual Meetmg of the Assocmhonfor ComputationalLmgutshcs HLmt, Graeme and Dared St-Onge 1997 (to appear) Lemca] chains as representation of context for the detection and correction of malapropisms In Chnstiane Fellbanm, edxtor, WordNet An electmmc leztcal database and some of ,ts appheat:ons Cambridge, MA The MIT Press Hoey, M 1991 Patterns of Leats m Tezt Oxford Umvermty Press, Oxford Jones,.KarenSpaxck 1993 What mightbe m summary? Informahon Retrleval Lulm, H P 1968 The automatxc ereatzon of hterature abstracts In Schultz, edttor, H P Luhn Pioneer of lnformahon Science Spartan Mann, W C and S Thompson 1987 RhetoncaJ. structure theory description and constructions of text structures In Gerard Kempen, echtor, Natural Language Generahon New Results m Arhfictal Intellhgence, Psychology and Lmgutst:cs Maxtmus Nmjhot~ Pubhshers, pages 85-96 McKeown, Kathleen and Dragonur Radev 1995 Generatmg summaries of multiple news articles In SIGIR 95 Proceedings Mdler, George A, P,~chard Beckwlth, Chnstiane Fellbans, Derek Gross, and Kathenne J ~ 1990 Introduction to WordNet An on-lme lexxcal database Internat,onal Journal of Lazwcographg(special issue), 3(4) 23,5,-312 Morns, J and G Hzrst 1991 Lexzcal coheszon computed by thesanra] relations as an re&amp;cater of the structure of the text Computahonal Lmgutsttos, 17(1) pp 21.--45 Onq, Ken3h Sunuta Ksno, and Mnke Seql 1994 Abstract genezation based on rhetorical structure extructzon In Proceedings of the International Conference on Computahonal Lmgutshcs (Cohng 9~), pages 344--348, Japan Pa~ce, C D and G D Husk 1991 Towards the automatic recognntlon of anaphonc features m enghsh text The nnpexsonal pronoun &quot;zt~ Computer Speech and Language,(2) pp 109-132 Patce, Chris D 1990 Constructing hterature abstracts by computer techmqu~ and prospects lnformahon Processmg and Management, 26(1) 171-186 Statrmand, Mark A 1996 A Computahonal Analysts of LexscalCohesion wtth Apphcattons :n Informatton Retrievai Ph D thesis, Center for Computational Lmgmstics, UMIST, Manchester \x0c&amp;apos;</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>