2 Maximum Entropy Models Maximum entropy (ME) models (CITATION; CITATION), also known as log-linear and exponential learning models, provide a general purpose machine learning technique for classification and prediction which has been successfully applied to natural language processing including part of speech tagging, named entity recognition etc.,,
This is different to previous work including (CITATION; CITATION) which has suggested a contiguous span of words (a group of turkeys in this example).,,
A syntactic parser CITATION and the Collins rules CITATION are modified to extract such head words.,,
The classic Lesk algorithm CITATION is used to compute the most probable sense for a head word in the question context, and then the hypernyms are extracted based on that sense.,,
5.5 Dependency validity features Like CITATION, we extract the dependency path from the question word to the common word (existing in both question and sentence), and the path from candidate answer (such as CoNLL NE and numerical entity) to the common word for each pair of question and candidate sentence using Stanford dependency parser (CITATION; CITATION).,,
To facilitate the comparison to others work (CITATION; CITATION), we first retrieve all relevant documents which are compiled by Ken Litkowski8 to create training and test datasets.,,
Table 7 shows performance of various question answer systems including (CITATION; CITATION; CITATION; Shen and Klakow, 0 5 10 15 20 25 30 35 40 45 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 question id MRR QC3 QC2 Figure 1: Individual MRR scores for questions which have different predicted question types using QC3 and QC2.,,
However, due to the lack of a fine grained NER tool at hand, we employ the Stanford NER package CITATION which identifies only four types of named entities.,,
5.1 CoNLL named entities presence feature We use Stanford named entity recognizer (NER) CITATION to identify CoNLL style NEs7 as possible answer strings in a candidate sentence for a given type of question.,,
3 Question Classification Features CITATION have developed a machine learning approach which uses the SNoW learning architecture.,,
The UIUC dataset has laid a platform for the follow-up research including (CITATION; CITATION; CITATION; 1 Available at http://12r.cs.uiuc.edu/cogcomp/Data/QA/QC.,,
cognition is a key approach in modern question answering systems CITATION.,,
As with the previous work of (CITATION; CITATION; CITATION; CITATION), we propose a feature driven statistical question classifier CITATION.,,
term city percent event vehicle country speed food word mountain temp instrument DESC other size lang definition state weight CITATION; CITATION).,,
In contrast to Li and Roth CITATIONs approach which makes use of a very rich feature set, we propose to use a compact yet effective feature set.,,
More detailed information can be found at CITATION.,,
This is different to previous work including (CITATION; CITATION) which has suggested a contiguous span of words (a group of turkeys in this example).,,
The individual feature contributions were discussed in greater detail in CITATION.,,
5.5 Dependency validity features Like CITATION, we extract the dependency path from the question word to the common word (existing in both question and sentence), and the path from candidate answer (such as CoNLL NE and numerical entity) to the common word for each pair of question and candidate sentence using Stanford dependency parser (CITATION; CITATION).,,
In fact, the combination of question classification and the named entity recognition is a key approach in modern question answering systems CITATION.,,
As with the previous work of (CITATION; CITATION; CITATION; CITATION), we propose a feature driven statistical question classifier CITATION.,,
 and Ward, 2003; CITATION; CITATION; 1 Available at http://12r.cs.uiuc.edu/cogcomp/Data/QA/QC.,,
term city percent event vehicle country speed food word mountain temp instrument DESC other size lang definition state weight CITATION; CITATION).,,
In contrast to Li and Roth CITATIONs approach which makes use of a very rich feature set, we propose to use a compact yet effective feature set.,,
More detailed information can be found at CITATION.,,
This is different to previous work including (CITATION; CITATION) which has suggested a contiguous span of words (a group of turkeys in this example).,,
A syntactic parser CITATION and the Collins rules CITATION are modified to extract such head words.,,
The classic Lesk algorithm CITATION is used to compute the most probable sense for a head word in the question context, and then the hypernyms are extracted based on that sense.,,
In fact, the combination of question classification and the named entity recognition is a key approach in modern question answering systems CITATION.,,
As with the previous work of (CITATION; CITATION; CITATION; CITATION), we propose a feature driven statistical question classifier CITATION.,,
3 Question Classification Features CITATION have developed a machine learning approach which uses the SNoW learning architecture.,,
The UIUC dataset has laid a platform for the follow-up research including (CITATION; CITATION; CITATION; 1 Available at http://12r.cs.uiuc.edu/cogcomp/Data/QA/QC.,,
More detailed information can be found at CITATION.,,
This is different to previous work including (CITATION; CITATION) which has suggested a contiguous span of words (a group of turkeys in this example).,,
A syntactic parser CITATION and the Collins rules CITATION are modified to extract such head words.,,
The classic Lesk algorithm CITATION is used to compute the most probable sense for a head word in the question context, and then the hypernyms are e,,
Compared to the over feature size of 200000 in CITATION, our feature space is much more compact, yet turned out to be more informative as suggested by the experiments.,,
The result is 89.051.25 and 83.731.61 for 6 and 50 classes,6 which outperforms the best result of 86.11.1 for 6 classes as reported in CITATION.,,
In fact, the combination of question classification and the named entity recognition is a key approach in modern question answering systems CITATION.,,
As with the previous work of (CITATION; CITATION; CITATION; CITATION), we propose a feature driven statistical question classifier CITATION.,,
3 Question Classification Features CITATION have developed a machine learning approach which uses the SNoW learning architecture.,,
The UIUC dataset has laid a platform for the follow-up research including (CITATION; CITATION; CITATION; 1 Available at http://12r.cs.uiuc.edu/cogcomp/Data/QA/QC.,,
term city percent event vehicle country speed food word mountain temp instrument DESC other size lang definition state weight CITATION; CITATION).,,
2 Maximum Entropy Models Maximum entropy (ME) models (CITATION; CITATION), also known as log-linear and exponential learning models, provide a general purpose machine learning technique for classification and prediction which has been successfully applied to natural language processing including part of speech tagging, named entity recognition etc.,,
5.5 Dependency validity features Like CITATION, we extract the dependency path from the question word to the common word (existing in both question and sentence), and the path from candidate answer (such as CoNLL NE and numerical entity) to the common word for each pair of question and candidate sentence using Stanford dependency parser (CITATION; CITATION).,,
In fact, the combination of question classification and the named entity recognition is a key approach in modern question answering systems CITATION.,,
As with the previous work of (CITATION; CITATION; CITATION; CITATION), we propose a feature driven statistical question classifier CITATION.,,
and Lee, 2003; CITATION; 1 Available at http://12r.cs.uiuc.edu/cogcomp/Data/QA/QC.,,
term city percent event vehicle country speed food word mountain temp instrument DESC other size lang definition state weight CITATION; CITATION).,,
In contrast to Li and Roth CITATIONs approach which makes use of a very rich feature set, we propose to use a compact yet effective feature set.,,
More detailed information can be found at CITATION.,,
pared to the over feature size of 200000 in CITATION, our feature space is much more compact, yet turned out to be more informative as suggested by the experiments.,,
The result is 89.051.25 and 83.731.61 for 6 and 50 classes,6 which outperforms the best result of 86.11.1 for 6 classes as reported in CITATION.,,
This is different to previous work including (CITATION; CITATION) which has suggested a contiguous span of words (a group of turkeys in this example).,,
A syntactic parser CITATION and the Collins rules CITATION are modified to extract such head words.,,
The classic Lesk algorithm CITATION is used to compute the most probable sense for a head word in the question context, and then the hypernyms are extracted based on that sense.,,
1 Introduction Question answering has drawn significant attention from the last decade CITATION.,,
term city percent event vehicle country speed food word mountain temp instrument DESC other size lang definition state weight CITATION; CITATION).,,
In contrast to Li and Roth CITATIONs approach which makes use of a very rich feature set, we propose to use a compact yet effective feature set.,,
More detailed information can be found at CITATION.,,
5.2 Dictionary entities presence feature As four types of CoNLL named entities are not enough to cover 50 question types, we include the 101 dictionary files compiled in the Ephyra project CITATION.,,
To facilitate the comparison to others work (CITATION; CITATION), we first retrieve all relevant documents which are compiled by Ken Litkowski8 to create training and test datasets.,,
2004 60.0 53.0 70.0 CITATION 67.0 62.0 74.0 This work 66.3 62.4 73.8 549 \x0c7 Conclusion In this paper, we have presented a question classifier which makes use of a compact yet efficient feature set.,,
term city percent event vehicle country speed food word mountain temp instrument DESC other size lang definition state weight CITATION; CITATION).,,
In contrast to Li and Roth CITATIONs approach which makes use of a very rich feature set, we propose to use a compact yet effective feature set.,,
More detailed information can be found at CITATION.,,
Table 7 shows performance of various question answer systems including (CITATION; CITATION; CITATION; Shen and Klakow, 0 5 10 15 20 25 30 35 40 45 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 question id MRR QC3 QC2 Figure 1: Individual MRR scores for questions which have different predicted question types using QC3 and QC2.,,
In fact, the combination of question classification and the named entity recognition is a key approach in modern question answering systems CITATION.,,
As with the previous work of (CITATION; CITATION; CITATION; CITATION), we propose a feature driven statistical question classifier CITATION.,,
Table 7 shows performance of various question answer systems including (CITATION; CITATION; CITATION; Shen and Klakow, 0 5 10 15 20 25 30 35 40 45 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 question id MRR QC3 QC2 Figure 1: Individual MRR scores for questions which have different predicted question types using QC3 and QC2.,,
3 Question Classification Features CITATION have developed a machine learning approach which uses the SNoW learning architecture.,,
The UIUC dataset has laid a platform for the follow-up research including (CITATION; CITATION; CITATION; 1 Available at http://12r.cs.uiuc.edu/cogcomp/Data/QA/QC.,,
term city percent event vehicle country speed food word mountain temp instrument DESC other size lang definition state weight CITATION; Moschitti et,,
