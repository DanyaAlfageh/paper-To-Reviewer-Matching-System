A syntactic parser CITATION and the Collins rules CITATION are modified to extract such head words,,
The UIUC dataset has laid a platform for the follow-up research including (CITATION; CITATION; CITATION; 1 Available at http://12r.cs.uiuc.edu/cogcomp/Data/QA/QC,,
term city percent event vehicle country speed food word mountain temp instrument DESC other size lang definition state weight CITATION; Moschitti et ,,
As with the previous work of (CITATION; CITATION; CITATION; CITATION), we propose a feature driven statistical question classifier CITATION,,
and Lee, 2003; CITATION; 1 Available at http://12r.cs.uiuc.edu/cogcomp/Data/QA/QC,,
pared to the over feature size of 200000 in CITATION, our feature space is much more compact, yet turned out to be more informative as suggested by the experiments,,
Compared to the over feature size of 200000 in CITATION, our feature space is much more compact, yet turned out to be more informative as suggested by the experiments,,
5.1 CoNLL named entities presence feature We use Stanford named entity recognizer (NER) CITATION to identify CoNLL style NEs7 as possible answer strings in a candidate sentence for a given type of question,,
1 Introduction Question answering has drawn significant attention from the last decade CITATION,,
The individual feature contributions were discussed in greater detail in CITATION,,
In contrast to Li and Roth CITATIONs approach which makes use of a very rich feature set, we propose to use a compact yet effective feature set,,
term city percent event vehicle country speed food word mountain temp instrument DESC other size lang definition state weight CITATION; CITATION),,
 and Ward, 2003; CITATION; CITATION; 1 Available at http://12r.cs.uiuc.edu/cogcomp/Data/QA/QC,,
2004 60.0 53.0 70.0 CITATION 67.0 62.0 74.0 This work 66.3 62.4 73.8 549 \x0c7 Conclusion In this paper, we have presented a question classifier which makes use of a compact yet efficient feature set,,
cognition is a key approach in modern question answering systems CITATION,,
The classic Lesk algorithm CITATION is used to compute the most probable sense for a head word in the question context, and then the hypernyms are e,,
In fact, the combination of question classification and the named entity recognition is a key approach in modern question answering systems CITATION,,
5.2 Dictionary entities presence feature As four types of CoNLL named entities are not enough to cover 50 question types, we include the 101 dictionary files compiled in the Ephyra project CITATION,,
Table 7 shows performance of various question answer systems including (CITATION; CITATION; CITATION; Shen and Klakow, 0 5 10 15 20 25 30 35 40 45 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 question id MRR QC3 QC2 Figure 1: Individual MRR scores for questions which have different predicted question types using QC3 and QC2,,
The classic Lesk algorithm CITATION is used to compute the most probable sense for a head word in the question context, and then the hypernyms are extracted based on that sense,,
The result is 89.051.25 and 83.731.61 for 6 and 50 classes,6 which outperforms the best result of 86.11.1 for 6 classes as reported in CITATION,,
To facilitate the comparison to others work (CITATION; CITATION), we first retrieve all relevant documents which are compiled by Ken Litkowski8 to create training and test datasets,,
However, due to the lack of a fine grained NER tool at hand, we employ the Stanford NER package CITATION which identifies only four types of named entities,,
This is different to previous work including (CITATION; CITATION) which has suggested a contiguous span of words (a group of turkeys in this example),,
5.5 Dependency validity features Like CITATION, we extract the dependency path from the question word to the common word (existing in both question and sentence), and the path from candidate answer (such as CoNLL NE and numerical entity) to the common word for each pair of question and candidate sentence using Stanford dependency parser (CITATION; CITATION),,
2 Maximum Entropy Models Maximum entropy (ME) models (CITATION; CITATION), also known as log-linear and exponential learning models, provide a general purpose machine learning technique for classification and prediction which has been successfully applied to natural language processing including part of speech tagging, named entity recognition etc,,
3 Question Classification Features CITATION have developed a machine learning approach which uses the SNoW learning architecture,,
More detailed information can be found at CITATION,,
