<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000070">
<bodyText confidence="0.478403">
b&apos;Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 564571,
</bodyText>
<figure confidence="0.569661">
Beijing, August 2010
A Cross-lingual Annotation Projection Approach
for Relation Detection
Seokhwan Kim
, Minwoo Jeong
, Jonghoon Lee
, Gary Geunbae Lee
</figure>
<affiliation confidence="0.993848">
Department of Computer Science and Engineering,
Pohang University of Science and Technology
</affiliation>
<email confidence="0.951194">
{megaup|jh21983|gblee}@postech.ac.kr
</email>
<affiliation confidence="0.984892">
Saarland University
</affiliation>
<email confidence="0.986666">
m.jeong@mmci.uni-saarland.de
</email>
<sectionHeader confidence="0.990445" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999105875">
While extensive studies on relation ex-
traction have been conducted in the last
decade, statistical systems based on su-
pervised learning are still limited because
they require large amounts of training data
to achieve high performance. In this pa-
per, we develop a cross-lingual annota-
tion projection method that leverages par-
allel corpora to bootstrap a relation detec-
tor without significant annotation efforts
for a resource-poor language. In order to
make our method more reliable, we intro-
duce three simple projection noise reduc-
tion methods. The merit of our method is
demonstrated through a novel Korean re-
lation detection task.
</bodyText>
<sectionHeader confidence="0.998291" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.996965423076923">
Relation extraction aims to identify semantic re-
lations of entities in a document. Many rela-
tion extraction studies have followed the Rela-
tion Detection and Characterization (RDC) task
organized by the Automatic Content Extraction
project (Doddington et al., 2004) to make multi-
lingual corpora of English, Chinese and Ara-
bic. Although these datasets encourage the de-
velopment and evaluation of statistical relation
extractors for such languages, there would be a
scarcity of labeled training samples when learn-
ing a new system for another language such as
Korean. Since manual annotation of entities and
their relations for such resource-poor languages
is very expensive, we would like to consider in-
stead a weakly-supervised learning technique in
order to learn the relation extractor without sig-
nificant annotation efforts. To do this, we propose
to leverage parallel corpora to project the relation
annotation on the source language (e.g. English)
to the target (e.g. Korean).
While many supervised machine learning ap-
proaches have been successfully applied to the
RDC task (Kambhatla, 2004; Zhou et al., 2005;
Zelenko et al., 2003; Culotta and Sorensen, 2004;
Bunescu and Mooney, 2005; Zhang et al., 2006),
few have focused on weakly-supervised relation
extraction. For example, (Zhang, 2004) and (Chen
et al., 2006) utilized weakly-supervised learning
techniques for relation extraction, but they did
not consider weak supervision in the context of
cross-lingual relation extraction. Our key hypoth-
esis on the use of parallel corpora for learning
the relation extraction system is referred to as
cross-lingual annotation projection. Early stud-
ies of cross-lingual annotation projection were ac-
complished for lexically-based tasks; for exam-
ple part-of-speech tagging (Yarowsky and Ngai,
2001), named-entity tagging (Yarowsky et al.,
2001), and verb classification (Merlo et al., 2002).
Recently, there has been increasing interest in ap-
plications of annotation projection such as depen-
dency parsing (Hwa et al., 2005), mention de-
tection (Zitouni and Florian, 2008), and semantic
role labeling (Pado and Lapata, 2009). However,
to the best of our knowledge, no work has reported
on the RDC task.
In this paper, we apply a cross-lingual anno-
tation projection approach to binary relation de-
tection, a task of identifying the relation between
two entities. A simple projection method propa-
gates the relations in source language sentences to
</bodyText>
<page confidence="0.996817">
564
</page>
<bodyText confidence="0.992300677419355">
\x0cword-aligned target sentences, and a target rela-
tion detector can bootstrap from projected annota-
tion. However, this automatic annotation is unre-
liable because of mis-classification of source text
and word alignment errors, so it causes a critical
falling-off in annotation projection quality. To al-
leviate this problem, we present three noise reduc-
tion strategies: a heuristic filtering; an alignment
correction with dictionary; and an instance selec-
tion based on assessment, and combine these to
yield a better result.
We provide a quantitive evaluation of our
method on a new Korean RDC dataset. In our
experiment, we leverage an English-Korean par-
allel corpus collected from the Web, and demon-
strate that the annotation projection approach and
noise reduction method are beneficial to build an
initial Korean relation detection system. For ex-
ample, the combined model of three noise reduc-
tion methods achieves F1-scores of 36.9% (59.8%
precision and 26.7% recall), favorably comparing
with the 30.5% shown by the supervised base-
line.1
The remainder of this paper is structured as fol-
lows. In Section 2, we describe our cross-lingual
annotation projection approach to relation detec-
tion task. Then, we present the noise reduction
methods in Section 3. Our experiment on the pro-
posed Korean RDC evaluation set is shown in Sec-
tion 4 and Section 5, and we conclude this paper
in Section 6.
</bodyText>
<sectionHeader confidence="0.932831" genericHeader="method">
2 Cross-lingual Annotation Projection
</sectionHeader>
<subsectionHeader confidence="0.534838">
for Relation Detection
</subsectionHeader>
<bodyText confidence="0.9954045">
The annotation projection from a resource-rich
language L1 to a resource-poor language L2 is
performed by a series of three subtasks: annota-
tion, projection and assessment.
The annotation projection for relation detection
can be performed as follows:
1) For a given pair of bi-sentences in parallel cor-
pora between a resource-rich language L1 and
a target language L2, the relation detection task
is carried out for the sentence in L1.
</bodyText>
<page confidence="0.91111">
1
</page>
<bodyText confidence="0.860181666666667">
The dataset and the parallel corpus are available on the
authors website,
http://isoft.postech.ac.kr/megaup/research/resources/.
2) The annotations obtained by analyzing the sen-
tence in L1 are projected onto the sentence in
L2 based on the word alignment information.
3) The projected annotations on the sentence in
L2 are utilized as resources to perform the re-
lation detection task for the language L2.
</bodyText>
<subsectionHeader confidence="0.986453">
2.1 Annotation
</subsectionHeader>
<bodyText confidence="0.998477444444445">
The first step to projecting annotations from L1
onto L2 is obtaining annotations for the sentences
in L1. Since each instance for relation detection
is composed of a pair of entity mentions, the in-
formation about entity mentions on the given sen-
tences should be identified first. We detect the
entities in the L1 sentences of the parallel cor-
pora. Entity identification generates a number of
instances for relation detection by coupling two
entities within each sentence. For each instance,
the existence of semantic relation between entity
mentions is explored, which is called relation de-
tection. We assume that there exist available mod-
els or systems for all annotation processes, includ-
ing not only an entity tagger and a relation de-
tector themselves, but also required preprocessors
such as a part-of-speech tagger, base-phrase chun-
ker, and syntax parser for analyzing text in L1.
Figure 1 shows an example of annotation pro-
jection for relation detection of a bitext in En-
glish and Korean. The annotation of the sentence
in English shows that Jan Mullins and Com-
puter Recycler Incorporated are entity mentions
of a person and an organization, respectively. Fur-
thermore, the result indicates that the pair of en-
tities has a semantic relationship categorized as
ROLE.Owner type.
</bodyText>
<subsectionHeader confidence="0.999177">
2.2 Projection
</subsectionHeader>
<bodyText confidence="0.9986599">
In order to project the annotations from the sen-
tences in L1 onto the sentences in L2, we utilize
the information of word alignment which plays
an important role in statistical machine transla-
tion techniques. The word alignment task aims
to identify translational relationships among the
words in a bitext and produces a bipartite graph
with a set of edges between words with transla-
tional relationships as shown in Figure 1. In the
same manner as the annotation in L1, entities are
</bodyText>
<page confidence="0.987819">
565
</page>
<figure confidence="0.997553125">
\x0c
(keom-pyu-teo-ri-sa-i-keul-reo)
(ui)
(sa-jang)
(eun)
...
(ra-go)
(mal-haet-da)
Mullins, owner of Incorporated said that ...
(jan)
(meol-rin-seu)
Jan Computer Recycler
ROLE.Owner
PER ORG
ORG PER
ROLE.Owner
</figure>
<figureCaption confidence="0.999717">
Figure 1: An example of annotation projection for relation detection of a bitext in English and Korean
</figureCaption>
<bodyText confidence="0.996876666666667">
considered as the first units to be projected. We as-
sume that the words of the sentences in L2 aligned
with a given entity mention in L1 inherit the infor-
mation about the original entity in L1.
After projecting the annotations of entity men-
tions, the projections for relational instances fol-
low. A projection is performed on a projected in-
stance in L2 which is a pair of projected entities
by duplicating annotations of the original instance
in L1.
Figure 1 presents an example of projection of a
positive relational instance between Jan Mullins
and Computer Recycler Incorporated in the
English sentence onto its translational counter-
part sentence in Korean. Jan meol-rin-seu and
keom-pyu-teo-ri-sa-i-keul-reo are labeled as en-
tity mentions with types of a persons name and an
organizations name respectively. In addition, the
instance composed of the two projected entities is
annotated as a positive instance, because its orig-
inal instance on the English sentence also has a
semantic relationship.
As the description suggests, the annotation pro-
jection approach is highly dependant on the qual-
ity of word alignment. However, the results of au-
tomatic word alignment may include several noisy
or incomplete alignments because of technical dif-
ficulties. We present details to tackle the problem
by relieving the influence of alignment errors in
Section 3.
</bodyText>
<subsectionHeader confidence="0.997509">
2.3 Assessment
</subsectionHeader>
<bodyText confidence="0.999603388888889">
The most important challenge for annotation pro-
jection approaches is how to improve the robust-
ness against the erroneous projections. The noise
produced by not only word alignment but also
mono-lingual annotations in L1 accumulates and
brings about a drastic decline in the quality of pro-
jected annotations.
The simplest policy of utilizing the projected
annotations for relation detection in L2 is to con-
sider that all projected instances are equivalently
reliable and to employ entire projections as train-
ing instances for the task without any filtering. In
contrast with this policy, which is likely to be sub-
standard, we propose an alternative policy where
the projected instances are assessed and only the
instances judged as reliable by the assessment are
utilized for the task. Details about the assessment
are provided in Section 3.
</bodyText>
<sectionHeader confidence="0.988154" genericHeader="method">
3 Noise Reduction Strategies
</sectionHeader>
<bodyText confidence="0.998378428571429">
The efforts to reduce noisy projections are consid-
ered indispensable parts of the projection-based
relation detection method in a resource-poor lan-
guage. Our noise reduction approach includes the
following three strategies: heuristic-based align-
ment filtering, dictionary-based alignment correc-
tion, and assessment-based instance selection.
</bodyText>
<subsectionHeader confidence="0.99837">
3.1 Heuristic-based Alignment Filtering
</subsectionHeader>
<bodyText confidence="0.999164857142857">
In order to improve the performance of annotation
projection approaches, we should break the bottle-
neck caused by the low quality of automatic word
alignment results. As relation detection is carried
out for each instance consisting of two entity men-
tions, the annotation projection for relation detec-
tion concerns projecting only entity mentions and
</bodyText>
<page confidence="0.994867">
566
</page>
<bodyText confidence="0.999064882352941">
\x0ctheir relational instances. Since this is different
from other shallower tasks such as part-of-speech
tagging, base phrase chunking, and dependency
parsing which should consider projections for all
word units, we define and apply some heuristics
specialized to projections of entity mentions and
relation instances to improve robustness of the
method against erroneous alignments, as follows:
A projection for an entity mention should
be based on alignments between contiguous
word sequences. If there are one or more
gaps in the word sequence in L2 aligned
with an entity mention in the sentence in
L1, we assume that the corresponding align-
ments are likely to be erroneous. Thus, the
alignments of non-contiguous words are ex-
cluded in projection.
Both an entity mention in L1 and its projec-
tion in L2 should include at least one base
noun phrase. If no base noun phrase oc-
curs in the original entity mention in L1, it
may suggest some errors in annotation for
the sentence in L1. The same case for the
projected instance raises doubts about align-
ment errors. The alignments between word
sequences without any base noun phrase are
filtered out.
The projected instance in L2 should sat-
isfy the clausal agreement with the original
instance in L1. If entities of an instance
are located in the same clause (or differ-
ent clauses), its projected instance should be
in the same manner. The instances without
clausal agreement are ruled out.
</bodyText>
<subsectionHeader confidence="0.99847">
3.2 Dictionary-based Alignment Correction
</subsectionHeader>
<bodyText confidence="0.9994076">
The errors in word alignment are composed of
not only imprecise alignments but also incomplete
alignments. If an alignment of an entity among
two entities of a relation instance is not provided
in the result of the word alignment task, the pro-
jection for the corresponding instance is unavail-
able. Unfortunately, the above-stated alignment
filtering heuristics for improving the quality of
projections make the annotation loss problems
worse by filtering out several alignments likely to
be noisy.
In order to solve this problem, a dictionary-
based alignment correction strategy is incorpo-
rated in our method. The strategy requires a bilin-
gual dictionary for entity mentions. Each entry of
the dictionary is a pair of entity mention in L1 and
its translation or transliteration in L2. For each
entity to be projected from the sentence in L1,
its counterpart in L2 is retrieved from the bilin-
gual dictionary. Then, we seek the retrieved entity
mention from the sentence in L2 by finding the
longest common subsequence. If a subsequence
matched to the retrieved mention is found in the
sentence in L2, we make a new alignment between
it and its original entity on the L1 sentence.
</bodyText>
<subsectionHeader confidence="0.997602">
3.3 Assessment-based Instance Selection
</subsectionHeader>
<bodyText confidence="0.999813538461539">
The reliabilities of instances projected via a series
of independent modules are different from each
other. Thus, we propose an assessment strategy
for each projected instance. To evaluate the reli-
ability of a projected instance in L2, we use the
confidence score of monolingual relation detec-
tion for the original counterpart instance in L1.
The acceptance of a projected instance is deter-
mined by whether the score of the instance is
larger than a given threshold value . Only ac-
cepted instances are considered as the results of
annotation projection and applied to solve the re-
lation detection task in target language L2.
</bodyText>
<sectionHeader confidence="0.996792" genericHeader="method">
4 Experimental Setup
</sectionHeader>
<bodyText confidence="0.9941034">
To demonstrate the effectiveness of our cross-
lingual annotation projection approach for rela-
tion detection, we performed an experiment on
relation detection in Korean text with propagated
annotations from English resources.
</bodyText>
<subsectionHeader confidence="0.998264">
4.1 Annotation
</subsectionHeader>
<bodyText confidence="0.996952">
The first step to evaluate our method was annotat-
ing the English sentences in a given parallel cor-
pus. We use an English-Korean parallel corpus
crawled from an English-Korean dictionary on the
web. The parallel corpus consists of 454,315 bi-
sentence pairs in English and Korean 2. The En-
glish sentences in the parallel corpus were prepro-
</bodyText>
<page confidence="0.921524">
2
</page>
<bodyText confidence="0.96154">
The parallel corpus collected and other resources are all
available in our website
</bodyText>
<equation confidence="0.34339">
http://isoft.postech.ac.kr/megaup/research/resources/
</equation>
<page confidence="0.96706">
567
</page>
<bodyText confidence="0.998647857142857">
\x0ccessed by the Stanford Parser 3 (Klein and Man-
ning, 2003) which provides a set of analyzed re-
sults including part-of-speech tag sequences, a de-
pendency tree, and a constituent parse tree for a
sentence.
The annotation for English sentences is di-
vided into two subtasks: entity mention recogni-
tion and relation detection. We utilized an off-
the-shelf system, Stanford Named Entity Recog-
nizer 4 (Finkel et al., 2005) for detecting entity
mentions on the English sentences. The total
number of English entities detected was 285,566.
Each pair of recognized entities within a sentence
was considered as an instance for relation detec-
tion.
A classification model learned with the train-
ing set of the ACE 2003 corpus which con-
sists of 674 documents and 9,683 relation in-
stances was built for relation detection in English.
In our implementation, we built a tree kernel-
based SVM model using SVM-Light 5 (Joachims,
1998) and Tree Kernel Tools 6 (Moschitti, 2006).
The subtree kernel method (Moschitti, 2006) for
shortest path enclosed subtrees (Zhang et al.,
2006) was adopted in our model. Our rela-
tion detection model achieved 81.2/69.8/75.1 in
Precision/Recall/F-measure on the test set of the
ACE 2003 corpus, which consists of 97 docu-
ments and 1,386 relation instances.
The annotation of relations was performed by
determining the existence of semantic relations
for all 115,452 instances with the trained model
for relation detection. The annotation detected
22,162 instances as positive which have semantic
relations.
</bodyText>
<subsectionHeader confidence="0.997558">
4.2 Projection
</subsectionHeader>
<bodyText confidence="0.999411">
The labels about entities and relations in the En-
glish sentences of the parallel corpora were propa-
gated into the corresponding sentences in Korean.
The Korean sentences were preprocessed by our
part-of-speech tagger 7 (Lee et al., 2002) and a de-
pendency parser implemented by MSTParser with
</bodyText>
<page confidence="0.577032">
3
</page>
<figure confidence="0.978369857142857">
http://nlp.stanford.edu/software/lex-parser.shtml
4
http://nlp.stanford.edu/software/CRF-NER.shtml
5
http://svmlight.joachims.org/
6
http://disi.unitn.it/moschitt/Tree-Kernel.htm
</figure>
<page confidence="0.822009">
7
</page>
<table confidence="0.9132422">
http://isoft.postech.ac.kr/megaup/research/postag/
Filter Without assessing With assessing
none 97,239 39,203
+ heuristics 31,652 12,775
+ dictionary 39,891 17,381
</table>
<tableCaption confidence="0.998845">
Table 1: Numbers of projected instances
</tableCaption>
<bodyText confidence="0.996071344827586">
a model trained on the Sejong corpus (Kim, 2006).
The annotation projections were performed on
the bi-sentences of the parallel corpus followed
by descriptions mentioned in Section 2.2. The
bi-sentences were processed by the GIZA++ soft-
ware (Och and Ney, 2003) in the standard con-
figuration in both English-Korean and Korean-
English directions. The bi-direcional alignments
were joined by the grow-diag-final algorithm,
which is widely used in bilingual phrase extrac-
tion (Koehn et al., 2003) for statistical machine
translation. This system achieved 65.1/41.6/50.8
in Precision/Recall/F-measure in our evaluation
of 201 randomly sampled English-Korean bi-
sentences with manually annotated alignments.
The number of projected instances varied with
the applied strategies for reducing noise as shown
in Table 1. Many projected instances were fil-
tered out by heuristics, and only 32.6% of the in-
stances were left. However, several instances were
rescued by dictionary-based alignment correction
and the number of projected instances increased
from 31,652 to 39,891. For all cases of noise re-
duction strategies, we performed the assessment-
based instance selection with a threshold value
of 0.7, which was determined empirically through
the grid search method. About 40% of the pro-
jected instances were accepted by instance selec-
tion.
</bodyText>
<subsectionHeader confidence="0.998412">
4.3 Evaluation
</subsectionHeader>
<bodyText confidence="0.999622888888889">
In order to evaluate our proposed method, we pre-
pared a dataset for the Korean RDC task. The
dataset was built by annotating the information
about entities and relations in 100 news docu-
ments in Korean. The annotations were performed
by two annotators following the guidelines for the
ACE corpus processed by LDC. Our Korean RDC
corpus consists of 835 sentences, 3,331 entity
mentions, and 8,354 relation instances. The sen-
</bodyText>
<page confidence="0.997081">
568
</page>
<table confidence="0.986595">
\x0cModel
w/o assessing with assessing
P R F P R F
Baseline 60.5 20.4 30.5 - - -
Non-filtered 22.5 6.5 10.0 29.1 13.2 18.2
Heuristic 51.4 15.5 23.8 56.1 22.9 32.5
Heuristic + Dictionary 55.3 19.4 28.7 59.8 26.7 36.9
</table>
<tableCaption confidence="0.979449">
Table 2: Experimental Results
</tableCaption>
<bodyText confidence="0.99884969047619">
tences of the corpus were preprocessed by equiva-
lent systems used for analyzing Korean sentences
for projection. We randomly divided the dataset
into two subsets with the same number of in-
stances for use as a training set to build the base-
line system and for evaluation.
For evaluating our approach, training instance
sets to learn models were prepared for relation
detection in Korean. The instances of the train-
ing set (half of the manually built Korean RDC
corpufs) were used to train the baseline model.
All other sets of instances include these baseline
instances and additional instances propagated by
the annotation projection approach. The train-
ing sets with projected instances are categorized
into three groups by the level of applied strategies
for noise reduction. While the first set included
all projections without any noise reduction strate-
gies, the second included only the instances ac-
cepted by the heuristics. The last set consisted of
the results of a series of heuristic-based filtering
and dictionary-based correction. For each training
set with projected instances, an additional set was
derived by performing assessment-based instance
selection.
We built the relation detection models for all
seven training sets (a baseline set, three pro-
jected sets without assessing, and three pro-
jected sets with assessing). Our implementations
are based on the SVM-Light and Tree Kernel
Tools described in the former subsection. The
shortest path dependency kernel (Bunescu and
Mooney, 2005) implemented by the subtree kernel
method (Moschitti, 2006) was adopted to learn all
models.
The performance for each model was evaluated
with the predictions of the model on the test set,
which was the other half of Korean RDC corpus.
We measured the performances of the models on
true entity mentions with true chaining of coref-
erence. Precision, Recall and F-measure were
adopted for our evaluation.
</bodyText>
<sectionHeader confidence="0.997181" genericHeader="evaluation">
5 Experimental Results
</sectionHeader>
<bodyText confidence="0.997607344827586">
Table 2 compares the performances of the differ-
ent models which are distinguished by the applied
strategies for noise reduction. It shows that:
The model with non-filtered projections
achieves extremely poor performance due to
a large number of erroneous instances. This
indicates that the efforts for reducing noise
are urgently needed.
The heuristic-based alignment filtering helps
to improve the performance. However, it is
much worse than the baseline performance
because of a falling-off in recall.
The dictionary-based correction to our pro-
jections increased both precision and recall
compared with the former models with pro-
jected instances. Nevertheless, it still fails to
achieve performance improvement over the
baseline model.
For all models with projection, the
assessment-based instance selection boosts
the performances significantly. This means
that this selection strategy is crucial in
improving the performance of the models
by excluding unreliable instances with low
confidence.
The model with heuristics and assessments
finally achieves better performance than the
baseline model. This suggests that the pro-
jected instances have a beneficial influence
</bodyText>
<page confidence="0.988129">
569
</page>
<bodyText confidence="0.999029714285714">
\x0con the relation detection task when at least
these two strategies are adopted for reducing
noises.
The final model incorporating all proposed
noise reduction strategies outperforms the
baseline model by 6 in F-measure. This is
due to largely increased recall by absorbing
more useful features from the well-refined
set of projected instances.
The experimental results show that our pro-
posed techniques effectively improve the perfor-
mance of relation detection in the resource-poor
Korean language with a set of annotations pro-
jected from the resource-rich English language.
</bodyText>
<sectionHeader confidence="0.997864" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999892918918919">
This paper presented a novel cross-lingual annota-
tion projection method for relation extraction in a
resource-poor language. We proposed methods of
propagating annotations from a resource-rich lan-
guage to a target language via parallel corpora. In
order to relieve the bad influence of noisy projec-
tions, we focused on the strategies for reducing the
noise generated during the projection. We applied
our methods to the relation detection task in Ko-
rean. Experimental results show that the projected
instances from an English-Korean parallel corpus
help to improve the performance of the task when
our noise reduction strategies are adopted.
We would like to introduce our method to the
other subtask of relation extraction, which is re-
lation categorization. While relation detection is
a binary classification problem, relation catego-
rization can be solved by a classifier for multi-
ple classes. Since the fundamental approaches
of the two tasks are similar, we expect that our
projection-based relation detection methods can
be easily adapted to the relation categorization
task.
For this further work, we are concerned about
the problem of low performance for Korean,
which was below 40 for relation detection. The re-
lation categorization performance is mostly lower
than detection because of the larger number of
classes to be classified, so the performance of
projection-based approaches has to be improved
in order to apply them. An experimental result
of this work shows that the most important factor
in improving the performance is how to select the
reliable instances from a large number of projec-
tions. We plan to develop more elaborate strate-
gies for instance selection to improve the projec-
tion performance for relation extraction.
</bodyText>
<sectionHeader confidence="0.725648" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.880396666666667">
This research was supported by the MKE (The
Ministry of Knowledge Economy), Korea, un-
der the ITRC (Information Technology Research
Center) support program supervised by the NIPA
(National IT Industry Promotion Agency) (NIPA-
2010-C1090-1031-0009).
</bodyText>
<sectionHeader confidence="0.8952" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.8839075">
Bunescu, Razvan C. and Raymond J. Mooney. 2005.
A shortest path dependency kernel for relation ex-
</bodyText>
<reference confidence="0.992725466666667">
traction. In Proceedings of the conference on Hu-
man Language Technology and Empirical Methods
in Natural Language Processing, page 724731.
Chen, Jinxiu, Donghong Ji, Chew Lim Tan, and
Zhengyu Niu. 2006. Relation extraction using la-
bel propagation based semi-supervised learning. In
Proceedings of the 21st International Conference
on Computational Linguistics and the 44th annual
meeting of the Association for Computational Lin-
guistics, pages 129136, Sydney, Australia. Associ-
ation for Computational Linguistics.
Culotta, Aron and Jaffrey Sorensen. 2004. Depen-
dency tree kernels for relation extraction. In Pro-
ceedings of ACL, volume 4.
Doddington, George, Alexis Mitchell, Mark Przy-
bocki, Lance Ramshaw, Stephanie Strassel, and
Ralph Weischedel. 2004. The automatic content
extraction (ACE) programtasks, data, and evalua-
tion. In Proceedings of LREC, volume 4, page
837840.
Finkel, Jenny R., Trond Grenager, and Christopher
Manning. 2005. Incorporating non-local informa-
tion into information extraction systems by gibbs
sampling. In Proceedings of the 43rd Annual Meet-
ing on Association for Computational Linguistics,
volume 43, page 363.
Hwa, Rebecca, Philip Resnik, Amy Weinberg, Clara
Cabezas, and Okan Kolak. 2005. Bootstrapping
parsers via syntactic projection across parallel texts.
Natural Language Engineering, 11(03):311325.
</reference>
<page confidence="0.924847">
570
</page>
<reference confidence="0.956529784090909">
\x0cJoachims, Thorsten. 1998. Text categorization with
support vector machines: Learning with many rele-
vant features. In Proceedings of the European Con-
ference on Machine Learning, pages 137142.
Kambhatla, Nanda. 2004. Combining lexical, syntac-
tic, and semantic features with maximum entropy
models for extracting relations. In Proceedings of
the ACL 2004 on Interactive poster and demonstra-
tion sessions, page 22, Barcelona, Spain. Associa-
tion for Computational Linguistics.
Kim, Hansaem. 2006. Korean national corpus in the
21st century sejong project. In Proceedings of the
13th NIJL International Symposium, page 4954.
Klein, Dan and Christopher D. Manning. 2003. Ac-
curate unlexicalized parsing. In Proceedings of the
41st Annual Meeting on Association for Computa-
tional Linguistics - Volume 1, pages 423430, Sap-
poro, Japan. Association for Computational Lin-
guistics.
Koehn, Philipp, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Pro-
ceedings of the 2003 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics on Human Language Technology, vol-
ume 1, pages 4854.
Lee, Gary Geunbae, Jeongwon Cha, and Jong-Hyeok
Lee. 2002. Syllable pattern-based unknown mor-
pheme segmentation and estimation for hybrid part-
of-speech tagging of korean. Computational Lin-
guistics, 28(1):5370.
Merlo, Paola, Suzanne Stevenson, Vivian Tsang, and
Gianluca Allaria. 2002. A multilingual paradigm
for automatic verb classification. In Proceedings of
the 40th Annual Meeting on Association for Compu-
tational Linguistics, pages 207214, Philadelphia,
Pennsylvania. Association for Computational Lin-
guistics.
Moschitti, Alessandro. 2006. Making tree kernels
practical for natural language learning. In Proceed-
ings of EACL06.
Och, Franz Josef and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignment
models. Computational Linguistics, 29(1):1951,
March.
Pado, Sebastian and Mirella Lapata. 2009.
Cross-lingual annotation projection of semantic
roles. Journal of Artificial Intelligence Research,
36(1):307340.
Yarowsky, David and Grace Ngai. 2001. Inducing
multilingual POS taggers and NP bracketers via ro-
bust projection across aligned corpora. In Second
meeting of the North American Chapter of the Asso-
ciation for Computational Linguistics on Language
technologies 2001, pages 18, Pittsburgh, Pennsyl-
vania. Association for Computational Linguistics.
Yarowsky, David, Grace Ngai, and Richard Wicen-
towski. 2001. Inducing multilingual text analysis
tools via robust projection across aligned corpora.
In Proceedings of the first international conference
on Human language technology research, pages 1
8, San Diego. Association for Computational Lin-
guistics.
Zelenko, Dmitry, Chinatsu Aone, and Anthony
Richardella. 2003. Kernel methods for relation ex-
traction. J. Mach. Learn. Res., 3:10831106.
Zhang, Min, Jie Zhang, Jian Su, and Guodong Zhou.
2006. A composite kernel to extract relations be-
tween entities with both flat and structured features.
In Proceedings of the 21st International Conference
on Computational Linguistics and the 44th annual
meeting of the Association for Computational Lin-
guistics, pages 825832, Sydney, Australia. Associ-
ation for Computational Linguistics.
Zhang, Zhu. 2004. Weakly-supervised relation clas-
sification for information extraction. In Proceed-
ings of the thirteenth ACM international conference
on Information and knowledge management, pages
581588, Washington, D.C., USA. ACM.
Zhou, Guodong, Jian Su, Jie Zhang, and Min Zhang.
2005. Exploring various knowledge in relation ex-
traction. In Proceedings of the 43rd Annual Meeting
on Association for Computational Linguistics, page
434.
Zitouni, Imed and Radu Florian. 2008. Mention detec-
tion crossing the language barrier. In Proceedings
of the Conference on Empirical Methods in Natural
Language Processing, pages 600609, Honolulu,
Hawaii. Association for Computational Linguistics.
</reference>
<page confidence="0.961817">
571
</page>
<figure confidence="0.256817">
\x0c&apos;
</figure>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.066192">
<note confidence="0.6948495">b&apos;Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 564571, Beijing, August 2010</note>
<title confidence="0.9940175">A Cross-lingual Annotation Projection Approach for Relation Detection</title>
<author confidence="0.641665">Jonghoon Lee</author>
<affiliation confidence="0.996972">Department of Computer Science and Engineering, Pohang University of Science and Technology</affiliation>
<email confidence="0.487089">{megaup|jh21983|gblee}@postech.ac.kr</email>
<affiliation confidence="0.999958">Saarland University</affiliation>
<email confidence="0.981157">m.jeong@mmci.uni-saarland.de</email>
<abstract confidence="0.999119235294118">While extensive studies on relation extraction have been conducted in the last decade, statistical systems based on supervised learning are still limited because they require large amounts of training data to achieve high performance. In this paper, we develop a cross-lingual annotation projection method that leverages parallel corpora to bootstrap a relation detector without significant annotation efforts for a resource-poor language. In order to make our method more reliable, we introduce three simple projection noise reduction methods. The merit of our method is demonstrated through a novel Korean relation detection task.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Jinxiu Chen</author>
<author>Donghong Ji</author>
<author>Chew Lim Tan</author>
<author>Zhengyu Niu</author>
</authors>
<title>Relation extraction using label propagation based semi-supervised learning.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics,</booktitle>
<pages>129136</pages>
<institution>Sydney, Australia. Association for Computational Linguistics.</institution>
<contexts>
<context position="2417" citStr="Chen et al., 2006" startWordPosition="354" endWordPosition="357">ead a weakly-supervised learning technique in order to learn the relation extractor without significant annotation efforts. To do this, we propose to leverage parallel corpora to project the relation annotation on the source language (e.g. English) to the target (e.g. Korean). While many supervised machine learning approaches have been successfully applied to the RDC task (Kambhatla, 2004; Zhou et al., 2005; Zelenko et al., 2003; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005; Zhang et al., 2006), few have focused on weakly-supervised relation extraction. For example, (Zhang, 2004) and (Chen et al., 2006) utilized weakly-supervised learning techniques for relation extraction, but they did not consider weak supervision in the context of cross-lingual relation extraction. Our key hypothesis on the use of parallel corpora for learning the relation extraction system is referred to as cross-lingual annotation projection. Early studies of cross-lingual annotation projection were accomplished for lexically-based tasks; for example part-of-speech tagging (Yarowsky and Ngai, 2001), named-entity tagging (Yarowsky et al., 2001), and verb classification (Merlo et al., 2002). Recently, there has been incre</context>
</contexts>
<marker>Chen, Ji, Tan, Niu, 2006</marker>
<rawString>Chen, Jinxiu, Donghong Ji, Chew Lim Tan, and Zhengyu Niu. 2006. Relation extraction using label propagation based semi-supervised learning. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, pages 129136, Sydney, Australia. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aron Culotta</author>
<author>Jaffrey Sorensen</author>
</authors>
<title>Dependency tree kernels for relation extraction.</title>
<date>2004</date>
<booktitle>In Proceedings of ACL,</booktitle>
<volume>4</volume>
<contexts>
<context position="2259" citStr="Culotta and Sorensen, 2004" startWordPosition="330" endWordPosition="333">er language such as Korean. Since manual annotation of entities and their relations for such resource-poor languages is very expensive, we would like to consider instead a weakly-supervised learning technique in order to learn the relation extractor without significant annotation efforts. To do this, we propose to leverage parallel corpora to project the relation annotation on the source language (e.g. English) to the target (e.g. Korean). While many supervised machine learning approaches have been successfully applied to the RDC task (Kambhatla, 2004; Zhou et al., 2005; Zelenko et al., 2003; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005; Zhang et al., 2006), few have focused on weakly-supervised relation extraction. For example, (Zhang, 2004) and (Chen et al., 2006) utilized weakly-supervised learning techniques for relation extraction, but they did not consider weak supervision in the context of cross-lingual relation extraction. Our key hypothesis on the use of parallel corpora for learning the relation extraction system is referred to as cross-lingual annotation projection. Early studies of cross-lingual annotation projection were accomplished for lexically-based tasks; for example part-of-speech</context>
</contexts>
<marker>Culotta, Sorensen, 2004</marker>
<rawString>Culotta, Aron and Jaffrey Sorensen. 2004. Dependency tree kernels for relation extraction. In Proceedings of ACL, volume 4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Doddington</author>
<author>Alexis Mitchell</author>
<author>Mark Przybocki</author>
<author>Lance Ramshaw</author>
<author>Stephanie Strassel</author>
<author>Ralph Weischedel</author>
</authors>
<title>The automatic content extraction (ACE) programtasks, data, and evaluation.</title>
<date>2004</date>
<booktitle>In Proceedings of LREC,</booktitle>
<volume>4</volume>
<pages>837840</pages>
<contexts>
<context position="1361" citStr="Doddington et al., 2004" startWordPosition="190" endWordPosition="193">projection method that leverages parallel corpora to bootstrap a relation detector without significant annotation efforts for a resource-poor language. In order to make our method more reliable, we introduce three simple projection noise reduction methods. The merit of our method is demonstrated through a novel Korean relation detection task. 1 Introduction Relation extraction aims to identify semantic relations of entities in a document. Many relation extraction studies have followed the Relation Detection and Characterization (RDC) task organized by the Automatic Content Extraction project (Doddington et al., 2004) to make multilingual corpora of English, Chinese and Arabic. Although these datasets encourage the development and evaluation of statistical relation extractors for such languages, there would be a scarcity of labeled training samples when learning a new system for another language such as Korean. Since manual annotation of entities and their relations for such resource-poor languages is very expensive, we would like to consider instead a weakly-supervised learning technique in order to learn the relation extractor without significant annotation efforts. To do this, we propose to leverage par</context>
</contexts>
<marker>Doddington, Mitchell, Przybocki, Ramshaw, Strassel, Weischedel, 2004</marker>
<rawString>Doddington, George, Alexis Mitchell, Mark Przybocki, Lance Ramshaw, Stephanie Strassel, and Ralph Weischedel. 2004. The automatic content extraction (ACE) programtasks, data, and evaluation. In Proceedings of LREC, volume 4, page 837840.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny R Finkel</author>
<author>Trond Grenager</author>
<author>Christopher Manning</author>
</authors>
<title>Incorporating non-local information into information extraction systems by gibbs sampling.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics,</booktitle>
<volume>43</volume>
<pages>363</pages>
<contexts>
<context position="15411" citStr="Finkel et al., 2005" startWordPosition="2402" endWordPosition="2405"> 2. The English sentences in the parallel corpus were prepro2 The parallel corpus collected and other resources are all available in our website http://isoft.postech.ac.kr/megaup/research/resources/ 567 \x0ccessed by the Stanford Parser 3 (Klein and Manning, 2003) which provides a set of analyzed results including part-of-speech tag sequences, a dependency tree, and a constituent parse tree for a sentence. The annotation for English sentences is divided into two subtasks: entity mention recognition and relation detection. We utilized an offthe-shelf system, Stanford Named Entity Recognizer 4 (Finkel et al., 2005) for detecting entity mentions on the English sentences. The total number of English entities detected was 285,566. Each pair of recognized entities within a sentence was considered as an instance for relation detection. A classification model learned with the training set of the ACE 2003 corpus which consists of 674 documents and 9,683 relation instances was built for relation detection in English. In our implementation, we built a tree kernelbased SVM model using SVM-Light 5 (Joachims, 1998) and Tree Kernel Tools 6 (Moschitti, 2006). The subtree kernel method (Moschitti, 2006) for shortest p</context>
</contexts>
<marker>Finkel, Grenager, Manning, 2005</marker>
<rawString>Finkel, Jenny R., Trond Grenager, and Christopher Manning. 2005. Incorporating non-local information into information extraction systems by gibbs sampling. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, volume 43, page 363.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca Hwa</author>
<author>Philip Resnik</author>
<author>Amy Weinberg</author>
<author>Clara Cabezas</author>
<author>Okan Kolak</author>
</authors>
<title>Bootstrapping parsers via syntactic projection across parallel texts.</title>
<date>2005</date>
<journal>Natural Language Engineering,</journal>
<volume>11</volume>
<issue>03</issue>
<contexts>
<context position="3118" citStr="Hwa et al., 2005" startWordPosition="454" endWordPosition="457">d not consider weak supervision in the context of cross-lingual relation extraction. Our key hypothesis on the use of parallel corpora for learning the relation extraction system is referred to as cross-lingual annotation projection. Early studies of cross-lingual annotation projection were accomplished for lexically-based tasks; for example part-of-speech tagging (Yarowsky and Ngai, 2001), named-entity tagging (Yarowsky et al., 2001), and verb classification (Merlo et al., 2002). Recently, there has been increasing interest in applications of annotation projection such as dependency parsing (Hwa et al., 2005), mention detection (Zitouni and Florian, 2008), and semantic role labeling (Pado and Lapata, 2009). However, to the best of our knowledge, no work has reported on the RDC task. In this paper, we apply a cross-lingual annotation projection approach to binary relation detection, a task of identifying the relation between two entities. A simple projection method propagates the relations in source language sentences to 564 \x0cword-aligned target sentences, and a target relation detector can bootstrap from projected annotation. However, this automatic annotation is unreliable because of mis-class</context>
</contexts>
<marker>Hwa, Resnik, Weinberg, Cabezas, Kolak, 2005</marker>
<rawString>Hwa, Rebecca, Philip Resnik, Amy Weinberg, Clara Cabezas, and Okan Kolak. 2005. Bootstrapping parsers via syntactic projection across parallel texts. Natural Language Engineering, 11(03):311325.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten \x0cJoachims</author>
</authors>
<title>Text categorization with support vector machines: Learning with many relevant features.</title>
<date>1998</date>
<booktitle>In Proceedings of the European Conference on Machine Learning,</booktitle>
<pages>137142</pages>
<marker>\x0cJoachims, 1998</marker>
<rawString>\x0cJoachims, Thorsten. 1998. Text categorization with support vector machines: Learning with many relevant features. In Proceedings of the European Conference on Machine Learning, pages 137142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nanda Kambhatla</author>
</authors>
<title>Combining lexical, syntactic, and semantic features with maximum entropy models for extracting relations.</title>
<date>2004</date>
<booktitle>In Proceedings of the ACL</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Barcelona,</location>
<contexts>
<context position="2190" citStr="Kambhatla, 2004" startWordPosition="320" endWordPosition="321">eled training samples when learning a new system for another language such as Korean. Since manual annotation of entities and their relations for such resource-poor languages is very expensive, we would like to consider instead a weakly-supervised learning technique in order to learn the relation extractor without significant annotation efforts. To do this, we propose to leverage parallel corpora to project the relation annotation on the source language (e.g. English) to the target (e.g. Korean). While many supervised machine learning approaches have been successfully applied to the RDC task (Kambhatla, 2004; Zhou et al., 2005; Zelenko et al., 2003; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005; Zhang et al., 2006), few have focused on weakly-supervised relation extraction. For example, (Zhang, 2004) and (Chen et al., 2006) utilized weakly-supervised learning techniques for relation extraction, but they did not consider weak supervision in the context of cross-lingual relation extraction. Our key hypothesis on the use of parallel corpora for learning the relation extraction system is referred to as cross-lingual annotation projection. Early studies of cross-lingual annotation projection we</context>
</contexts>
<marker>Kambhatla, 2004</marker>
<rawString>Kambhatla, Nanda. 2004. Combining lexical, syntactic, and semantic features with maximum entropy models for extracting relations. In Proceedings of the ACL 2004 on Interactive poster and demonstration sessions, page 22, Barcelona, Spain. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hansaem Kim</author>
</authors>
<title>Korean national corpus in the 21st century sejong project.</title>
<date>2006</date>
<booktitle>In Proceedings of the 13th NIJL International Symposium,</booktitle>
<pages>4954</pages>
<contexts>
<context position="17256" citStr="Kim, 2006" startWordPosition="2666" endWordPosition="2667">responding sentences in Korean. The Korean sentences were preprocessed by our part-of-speech tagger 7 (Lee et al., 2002) and a dependency parser implemented by MSTParser with 3 http://nlp.stanford.edu/software/lex-parser.shtml 4 http://nlp.stanford.edu/software/CRF-NER.shtml 5 http://svmlight.joachims.org/ 6 http://disi.unitn.it/moschitt/Tree-Kernel.htm 7 http://isoft.postech.ac.kr/megaup/research/postag/ Filter Without assessing With assessing none 97,239 39,203 + heuristics 31,652 12,775 + dictionary 39,891 17,381 Table 1: Numbers of projected instances a model trained on the Sejong corpus (Kim, 2006). The annotation projections were performed on the bi-sentences of the parallel corpus followed by descriptions mentioned in Section 2.2. The bi-sentences were processed by the GIZA++ software (Och and Ney, 2003) in the standard configuration in both English-Korean and KoreanEnglish directions. The bi-direcional alignments were joined by the grow-diag-final algorithm, which is widely used in bilingual phrase extraction (Koehn et al., 2003) for statistical machine translation. This system achieved 65.1/41.6/50.8 in Precision/Recall/F-measure in our evaluation of 201 randomly sampled English-Kor</context>
</contexts>
<marker>Kim, 2006</marker>
<rawString>Kim, Hansaem. 2006. Korean national corpus in the 21st century sejong project. In Proceedings of the 13th NIJL International Symposium, page 4954.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics -</booktitle>
<volume>1</volume>
<pages>423430</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sapporo, Japan.</location>
<contexts>
<context position="15055" citStr="Klein and Manning, 2003" startWordPosition="2343" endWordPosition="2347">n in Korean text with propagated annotations from English resources. 4.1 Annotation The first step to evaluate our method was annotating the English sentences in a given parallel corpus. We use an English-Korean parallel corpus crawled from an English-Korean dictionary on the web. The parallel corpus consists of 454,315 bisentence pairs in English and Korean 2. The English sentences in the parallel corpus were prepro2 The parallel corpus collected and other resources are all available in our website http://isoft.postech.ac.kr/megaup/research/resources/ 567 \x0ccessed by the Stanford Parser 3 (Klein and Manning, 2003) which provides a set of analyzed results including part-of-speech tag sequences, a dependency tree, and a constituent parse tree for a sentence. The annotation for English sentences is divided into two subtasks: entity mention recognition and relation detection. We utilized an offthe-shelf system, Stanford Named Entity Recognizer 4 (Finkel et al., 2005) for detecting entity mentions on the English sentences. The total number of English entities detected was 285,566. Each pair of recognized entities within a sentence was considered as an instance for relation detection. A classification model </context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Klein, Dan and Christopher D. Manning. 2003. Accurate unlexicalized parsing. In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics - Volume 1, pages 423430, Sapporo, Japan. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Josef Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology,</booktitle>
<volume>1</volume>
<pages>4854</pages>
<contexts>
<context position="17699" citStr="Koehn et al., 2003" startWordPosition="2730" endWordPosition="2733">With assessing none 97,239 39,203 + heuristics 31,652 12,775 + dictionary 39,891 17,381 Table 1: Numbers of projected instances a model trained on the Sejong corpus (Kim, 2006). The annotation projections were performed on the bi-sentences of the parallel corpus followed by descriptions mentioned in Section 2.2. The bi-sentences were processed by the GIZA++ software (Och and Ney, 2003) in the standard configuration in both English-Korean and KoreanEnglish directions. The bi-direcional alignments were joined by the grow-diag-final algorithm, which is widely used in bilingual phrase extraction (Koehn et al., 2003) for statistical machine translation. This system achieved 65.1/41.6/50.8 in Precision/Recall/F-measure in our evaluation of 201 randomly sampled English-Korean bisentences with manually annotated alignments. The number of projected instances varied with the applied strategies for reducing noise as shown in Table 1. Many projected instances were filtered out by heuristics, and only 32.6% of the instances were left. However, several instances were rescued by dictionary-based alignment correction and the number of projected instances increased from 31,652 to 39,891. For all cases of noise reduct</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Koehn, Philipp, Franz Josef Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology, volume 1, pages 4854.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gary Geunbae Lee</author>
<author>Jeongwon Cha</author>
<author>Jong-Hyeok Lee</author>
</authors>
<title>Syllable pattern-based unknown morpheme segmentation and estimation for hybrid partof-speech tagging of korean.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<volume>28</volume>
<issue>1</issue>
<contexts>
<context position="16766" citStr="Lee et al., 2002" startWordPosition="2614" endWordPosition="2617">all/F-measure on the test set of the ACE 2003 corpus, which consists of 97 documents and 1,386 relation instances. The annotation of relations was performed by determining the existence of semantic relations for all 115,452 instances with the trained model for relation detection. The annotation detected 22,162 instances as positive which have semantic relations. 4.2 Projection The labels about entities and relations in the English sentences of the parallel corpora were propagated into the corresponding sentences in Korean. The Korean sentences were preprocessed by our part-of-speech tagger 7 (Lee et al., 2002) and a dependency parser implemented by MSTParser with 3 http://nlp.stanford.edu/software/lex-parser.shtml 4 http://nlp.stanford.edu/software/CRF-NER.shtml 5 http://svmlight.joachims.org/ 6 http://disi.unitn.it/moschitt/Tree-Kernel.htm 7 http://isoft.postech.ac.kr/megaup/research/postag/ Filter Without assessing With assessing none 97,239 39,203 + heuristics 31,652 12,775 + dictionary 39,891 17,381 Table 1: Numbers of projected instances a model trained on the Sejong corpus (Kim, 2006). The annotation projections were performed on the bi-sentences of the parallel corpus followed by description</context>
</contexts>
<marker>Lee, Cha, Lee, 2002</marker>
<rawString>Lee, Gary Geunbae, Jeongwon Cha, and Jong-Hyeok Lee. 2002. Syllable pattern-based unknown morpheme segmentation and estimation for hybrid partof-speech tagging of korean. Computational Linguistics, 28(1):5370.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paola Merlo</author>
<author>Suzanne Stevenson</author>
<author>Vivian Tsang</author>
<author>Gianluca Allaria</author>
</authors>
<title>A multilingual paradigm for automatic verb classification.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>207214</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Philadelphia, Pennsylvania.</location>
<contexts>
<context position="2985" citStr="Merlo et al., 2002" startWordPosition="433" endWordPosition="436"> For example, (Zhang, 2004) and (Chen et al., 2006) utilized weakly-supervised learning techniques for relation extraction, but they did not consider weak supervision in the context of cross-lingual relation extraction. Our key hypothesis on the use of parallel corpora for learning the relation extraction system is referred to as cross-lingual annotation projection. Early studies of cross-lingual annotation projection were accomplished for lexically-based tasks; for example part-of-speech tagging (Yarowsky and Ngai, 2001), named-entity tagging (Yarowsky et al., 2001), and verb classification (Merlo et al., 2002). Recently, there has been increasing interest in applications of annotation projection such as dependency parsing (Hwa et al., 2005), mention detection (Zitouni and Florian, 2008), and semantic role labeling (Pado and Lapata, 2009). However, to the best of our knowledge, no work has reported on the RDC task. In this paper, we apply a cross-lingual annotation projection approach to binary relation detection, a task of identifying the relation between two entities. A simple projection method propagates the relations in source language sentences to 564 \x0cword-aligned target sentences, and a ta</context>
</contexts>
<marker>Merlo, Stevenson, Tsang, Allaria, 2002</marker>
<rawString>Merlo, Paola, Suzanne Stevenson, Vivian Tsang, and Gianluca Allaria. 2002. A multilingual paradigm for automatic verb classification. In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, pages 207214, Philadelphia, Pennsylvania. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
</authors>
<title>Making tree kernels practical for natural language learning.</title>
<date>2006</date>
<booktitle>In Proceedings of EACL06.</booktitle>
<contexts>
<context position="15951" citStr="Moschitti, 2006" startWordPosition="2493" endWordPosition="2494">ffthe-shelf system, Stanford Named Entity Recognizer 4 (Finkel et al., 2005) for detecting entity mentions on the English sentences. The total number of English entities detected was 285,566. Each pair of recognized entities within a sentence was considered as an instance for relation detection. A classification model learned with the training set of the ACE 2003 corpus which consists of 674 documents and 9,683 relation instances was built for relation detection in English. In our implementation, we built a tree kernelbased SVM model using SVM-Light 5 (Joachims, 1998) and Tree Kernel Tools 6 (Moschitti, 2006). The subtree kernel method (Moschitti, 2006) for shortest path enclosed subtrees (Zhang et al., 2006) was adopted in our model. Our relation detection model achieved 81.2/69.8/75.1 in Precision/Recall/F-measure on the test set of the ACE 2003 corpus, which consists of 97 documents and 1,386 relation instances. The annotation of relations was performed by determining the existence of semantic relations for all 115,452 instances with the trained model for relation detection. The annotation detected 22,162 instances as positive which have semantic relations. 4.2 Projection The labels about entit</context>
<context position="20787" citStr="Moschitti, 2006" startWordPosition="3215" endWordPosition="3216">isted of the results of a series of heuristic-based filtering and dictionary-based correction. For each training set with projected instances, an additional set was derived by performing assessment-based instance selection. We built the relation detection models for all seven training sets (a baseline set, three projected sets without assessing, and three projected sets with assessing). Our implementations are based on the SVM-Light and Tree Kernel Tools described in the former subsection. The shortest path dependency kernel (Bunescu and Mooney, 2005) implemented by the subtree kernel method (Moschitti, 2006) was adopted to learn all models. The performance for each model was evaluated with the predictions of the model on the test set, which was the other half of Korean RDC corpus. We measured the performances of the models on true entity mentions with true chaining of coreference. Precision, Recall and F-measure were adopted for our evaluation. 5 Experimental Results Table 2 compares the performances of the different models which are distinguished by the applied strategies for noise reduction. It shows that: The model with non-filtered projections achieves extremely poor performance due to a larg</context>
</contexts>
<marker>Moschitti, 2006</marker>
<rawString>Moschitti, Alessandro. 2006. Making tree kernels practical for natural language learning. In Proceedings of EACL06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="17468" citStr="Och and Ney, 2003" startWordPosition="2696" endWordPosition="2699">tware/lex-parser.shtml 4 http://nlp.stanford.edu/software/CRF-NER.shtml 5 http://svmlight.joachims.org/ 6 http://disi.unitn.it/moschitt/Tree-Kernel.htm 7 http://isoft.postech.ac.kr/megaup/research/postag/ Filter Without assessing With assessing none 97,239 39,203 + heuristics 31,652 12,775 + dictionary 39,891 17,381 Table 1: Numbers of projected instances a model trained on the Sejong corpus (Kim, 2006). The annotation projections were performed on the bi-sentences of the parallel corpus followed by descriptions mentioned in Section 2.2. The bi-sentences were processed by the GIZA++ software (Och and Ney, 2003) in the standard configuration in both English-Korean and KoreanEnglish directions. The bi-direcional alignments were joined by the grow-diag-final algorithm, which is widely used in bilingual phrase extraction (Koehn et al., 2003) for statistical machine translation. This system achieved 65.1/41.6/50.8 in Precision/Recall/F-measure in our evaluation of 201 randomly sampled English-Korean bisentences with manually annotated alignments. The number of projected instances varied with the applied strategies for reducing noise as shown in Table 1. Many projected instances were filtered out by heuri</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Och, Franz Josef and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):1951, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Pado</author>
<author>Mirella Lapata</author>
</authors>
<title>Cross-lingual annotation projection of semantic roles.</title>
<date>2009</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<volume>36</volume>
<issue>1</issue>
<contexts>
<context position="3217" citStr="Pado and Lapata, 2009" startWordPosition="469" endWordPosition="472">ypothesis on the use of parallel corpora for learning the relation extraction system is referred to as cross-lingual annotation projection. Early studies of cross-lingual annotation projection were accomplished for lexically-based tasks; for example part-of-speech tagging (Yarowsky and Ngai, 2001), named-entity tagging (Yarowsky et al., 2001), and verb classification (Merlo et al., 2002). Recently, there has been increasing interest in applications of annotation projection such as dependency parsing (Hwa et al., 2005), mention detection (Zitouni and Florian, 2008), and semantic role labeling (Pado and Lapata, 2009). However, to the best of our knowledge, no work has reported on the RDC task. In this paper, we apply a cross-lingual annotation projection approach to binary relation detection, a task of identifying the relation between two entities. A simple projection method propagates the relations in source language sentences to 564 \x0cword-aligned target sentences, and a target relation detector can bootstrap from projected annotation. However, this automatic annotation is unreliable because of mis-classification of source text and word alignment errors, so it causes a critical falling-off in annotati</context>
</contexts>
<marker>Pado, Lapata, 2009</marker>
<rawString>Pado, Sebastian and Mirella Lapata. 2009. Cross-lingual annotation projection of semantic roles. Journal of Artificial Intelligence Research, 36(1):307340.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
<author>Grace Ngai</author>
</authors>
<title>Inducing multilingual POS taggers and NP bracketers via robust projection across aligned corpora. In</title>
<date>2001</date>
<booktitle>Second meeting of the North American Chapter of the Association for Computational Linguistics on Language technologies</booktitle>
<pages>18</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Pittsburgh, Pennsylvania.</location>
<contexts>
<context position="2893" citStr="Yarowsky and Ngai, 2001" startWordPosition="420" endWordPosition="423">and Mooney, 2005; Zhang et al., 2006), few have focused on weakly-supervised relation extraction. For example, (Zhang, 2004) and (Chen et al., 2006) utilized weakly-supervised learning techniques for relation extraction, but they did not consider weak supervision in the context of cross-lingual relation extraction. Our key hypothesis on the use of parallel corpora for learning the relation extraction system is referred to as cross-lingual annotation projection. Early studies of cross-lingual annotation projection were accomplished for lexically-based tasks; for example part-of-speech tagging (Yarowsky and Ngai, 2001), named-entity tagging (Yarowsky et al., 2001), and verb classification (Merlo et al., 2002). Recently, there has been increasing interest in applications of annotation projection such as dependency parsing (Hwa et al., 2005), mention detection (Zitouni and Florian, 2008), and semantic role labeling (Pado and Lapata, 2009). However, to the best of our knowledge, no work has reported on the RDC task. In this paper, we apply a cross-lingual annotation projection approach to binary relation detection, a task of identifying the relation between two entities. A simple projection method propagates t</context>
</contexts>
<marker>Yarowsky, Ngai, 2001</marker>
<rawString>Yarowsky, David and Grace Ngai. 2001. Inducing multilingual POS taggers and NP bracketers via robust projection across aligned corpora. In Second meeting of the North American Chapter of the Association for Computational Linguistics on Language technologies 2001, pages 18, Pittsburgh, Pennsylvania. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
<author>Grace Ngai</author>
<author>Richard Wicentowski</author>
</authors>
<title>Inducing multilingual text analysis tools via robust projection across aligned corpora.</title>
<date>2001</date>
<booktitle>In Proceedings of the first international conference on Human language technology research,</booktitle>
<volume>1</volume>
<pages>pages</pages>
<location>San</location>
<contexts>
<context position="2939" citStr="Yarowsky et al., 2001" startWordPosition="426" endWordPosition="429">focused on weakly-supervised relation extraction. For example, (Zhang, 2004) and (Chen et al., 2006) utilized weakly-supervised learning techniques for relation extraction, but they did not consider weak supervision in the context of cross-lingual relation extraction. Our key hypothesis on the use of parallel corpora for learning the relation extraction system is referred to as cross-lingual annotation projection. Early studies of cross-lingual annotation projection were accomplished for lexically-based tasks; for example part-of-speech tagging (Yarowsky and Ngai, 2001), named-entity tagging (Yarowsky et al., 2001), and verb classification (Merlo et al., 2002). Recently, there has been increasing interest in applications of annotation projection such as dependency parsing (Hwa et al., 2005), mention detection (Zitouni and Florian, 2008), and semantic role labeling (Pado and Lapata, 2009). However, to the best of our knowledge, no work has reported on the RDC task. In this paper, we apply a cross-lingual annotation projection approach to binary relation detection, a task of identifying the relation between two entities. A simple projection method propagates the relations in source language sentences to 5</context>
</contexts>
<marker>Yarowsky, Ngai, Wicentowski, 2001</marker>
<rawString>Yarowsky, David, Grace Ngai, and Richard Wicentowski. 2001. Inducing multilingual text analysis tools via robust projection across aligned corpora. In Proceedings of the first international conference on Human language technology research, pages 1 8, San Diego. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dmitry Zelenko</author>
<author>Chinatsu Aone</author>
<author>Anthony Richardella</author>
</authors>
<title>Kernel methods for relation extraction.</title>
<date>2003</date>
<journal>J. Mach. Learn. Res.,</journal>
<pages>3--10831106</pages>
<contexts>
<context position="2231" citStr="Zelenko et al., 2003" startWordPosition="326" endWordPosition="329">a new system for another language such as Korean. Since manual annotation of entities and their relations for such resource-poor languages is very expensive, we would like to consider instead a weakly-supervised learning technique in order to learn the relation extractor without significant annotation efforts. To do this, we propose to leverage parallel corpora to project the relation annotation on the source language (e.g. English) to the target (e.g. Korean). While many supervised machine learning approaches have been successfully applied to the RDC task (Kambhatla, 2004; Zhou et al., 2005; Zelenko et al., 2003; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005; Zhang et al., 2006), few have focused on weakly-supervised relation extraction. For example, (Zhang, 2004) and (Chen et al., 2006) utilized weakly-supervised learning techniques for relation extraction, but they did not consider weak supervision in the context of cross-lingual relation extraction. Our key hypothesis on the use of parallel corpora for learning the relation extraction system is referred to as cross-lingual annotation projection. Early studies of cross-lingual annotation projection were accomplished for lexically-based tasks</context>
</contexts>
<marker>Zelenko, Aone, Richardella, 2003</marker>
<rawString>Zelenko, Dmitry, Chinatsu Aone, and Anthony Richardella. 2003. Kernel methods for relation extraction. J. Mach. Learn. Res., 3:10831106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Min Zhang</author>
<author>Jie Zhang</author>
<author>Jian Su</author>
<author>Guodong Zhou</author>
</authors>
<title>A composite kernel to extract relations between entities with both flat and structured features.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics,</booktitle>
<pages>825832</pages>
<institution>Sydney, Australia. Association for Computational Linguistics.</institution>
<contexts>
<context position="2306" citStr="Zhang et al., 2006" startWordPosition="338" endWordPosition="341"> entities and their relations for such resource-poor languages is very expensive, we would like to consider instead a weakly-supervised learning technique in order to learn the relation extractor without significant annotation efforts. To do this, we propose to leverage parallel corpora to project the relation annotation on the source language (e.g. English) to the target (e.g. Korean). While many supervised machine learning approaches have been successfully applied to the RDC task (Kambhatla, 2004; Zhou et al., 2005; Zelenko et al., 2003; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005; Zhang et al., 2006), few have focused on weakly-supervised relation extraction. For example, (Zhang, 2004) and (Chen et al., 2006) utilized weakly-supervised learning techniques for relation extraction, but they did not consider weak supervision in the context of cross-lingual relation extraction. Our key hypothesis on the use of parallel corpora for learning the relation extraction system is referred to as cross-lingual annotation projection. Early studies of cross-lingual annotation projection were accomplished for lexically-based tasks; for example part-of-speech tagging (Yarowsky and Ngai, 2001), named-entit</context>
<context position="16053" citStr="Zhang et al., 2006" startWordPosition="2506" endWordPosition="2509">entions on the English sentences. The total number of English entities detected was 285,566. Each pair of recognized entities within a sentence was considered as an instance for relation detection. A classification model learned with the training set of the ACE 2003 corpus which consists of 674 documents and 9,683 relation instances was built for relation detection in English. In our implementation, we built a tree kernelbased SVM model using SVM-Light 5 (Joachims, 1998) and Tree Kernel Tools 6 (Moschitti, 2006). The subtree kernel method (Moschitti, 2006) for shortest path enclosed subtrees (Zhang et al., 2006) was adopted in our model. Our relation detection model achieved 81.2/69.8/75.1 in Precision/Recall/F-measure on the test set of the ACE 2003 corpus, which consists of 97 documents and 1,386 relation instances. The annotation of relations was performed by determining the existence of semantic relations for all 115,452 instances with the trained model for relation detection. The annotation detected 22,162 instances as positive which have semantic relations. 4.2 Projection The labels about entities and relations in the English sentences of the parallel corpora were propagated into the correspond</context>
</contexts>
<marker>Zhang, Zhang, Su, Zhou, 2006</marker>
<rawString>Zhang, Min, Jie Zhang, Jian Su, and Guodong Zhou. 2006. A composite kernel to extract relations between entities with both flat and structured features. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, pages 825832, Sydney, Australia. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhu Zhang</author>
</authors>
<title>Weakly-supervised relation classification for information extraction.</title>
<date>2004</date>
<booktitle>In Proceedings of the thirteenth ACM international conference on Information and knowledge management,</booktitle>
<pages>581588</pages>
<publisher>ACM.</publisher>
<location>Washington, D.C., USA.</location>
<contexts>
<context position="2393" citStr="Zhang, 2004" startWordPosition="351" endWordPosition="352">e to consider instead a weakly-supervised learning technique in order to learn the relation extractor without significant annotation efforts. To do this, we propose to leverage parallel corpora to project the relation annotation on the source language (e.g. English) to the target (e.g. Korean). While many supervised machine learning approaches have been successfully applied to the RDC task (Kambhatla, 2004; Zhou et al., 2005; Zelenko et al., 2003; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005; Zhang et al., 2006), few have focused on weakly-supervised relation extraction. For example, (Zhang, 2004) and (Chen et al., 2006) utilized weakly-supervised learning techniques for relation extraction, but they did not consider weak supervision in the context of cross-lingual relation extraction. Our key hypothesis on the use of parallel corpora for learning the relation extraction system is referred to as cross-lingual annotation projection. Early studies of cross-lingual annotation projection were accomplished for lexically-based tasks; for example part-of-speech tagging (Yarowsky and Ngai, 2001), named-entity tagging (Yarowsky et al., 2001), and verb classification (Merlo et al., 2002). Recent</context>
</contexts>
<marker>Zhang, 2004</marker>
<rawString>Zhang, Zhu. 2004. Weakly-supervised relation classification for information extraction. In Proceedings of the thirteenth ACM international conference on Information and knowledge management, pages 581588, Washington, D.C., USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guodong Zhou</author>
<author>Jian Su</author>
<author>Jie Zhang</author>
<author>Min Zhang</author>
</authors>
<title>Exploring various knowledge in relation extraction.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>434</pages>
<contexts>
<context position="2209" citStr="Zhou et al., 2005" startWordPosition="322" endWordPosition="325">ples when learning a new system for another language such as Korean. Since manual annotation of entities and their relations for such resource-poor languages is very expensive, we would like to consider instead a weakly-supervised learning technique in order to learn the relation extractor without significant annotation efforts. To do this, we propose to leverage parallel corpora to project the relation annotation on the source language (e.g. English) to the target (e.g. Korean). While many supervised machine learning approaches have been successfully applied to the RDC task (Kambhatla, 2004; Zhou et al., 2005; Zelenko et al., 2003; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005; Zhang et al., 2006), few have focused on weakly-supervised relation extraction. For example, (Zhang, 2004) and (Chen et al., 2006) utilized weakly-supervised learning techniques for relation extraction, but they did not consider weak supervision in the context of cross-lingual relation extraction. Our key hypothesis on the use of parallel corpora for learning the relation extraction system is referred to as cross-lingual annotation projection. Early studies of cross-lingual annotation projection were accomplished for</context>
</contexts>
<marker>Zhou, Su, Zhang, Zhang, 2005</marker>
<rawString>Zhou, Guodong, Jian Su, Jie Zhang, and Min Zhang. 2005. Exploring various knowledge in relation extraction. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, page 434.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Imed Zitouni</author>
<author>Radu Florian</author>
</authors>
<title>Mention detection crossing the language barrier.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>600609</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Honolulu, Hawaii.</location>
<contexts>
<context position="3165" citStr="Zitouni and Florian, 2008" startWordPosition="461" endWordPosition="464"> context of cross-lingual relation extraction. Our key hypothesis on the use of parallel corpora for learning the relation extraction system is referred to as cross-lingual annotation projection. Early studies of cross-lingual annotation projection were accomplished for lexically-based tasks; for example part-of-speech tagging (Yarowsky and Ngai, 2001), named-entity tagging (Yarowsky et al., 2001), and verb classification (Merlo et al., 2002). Recently, there has been increasing interest in applications of annotation projection such as dependency parsing (Hwa et al., 2005), mention detection (Zitouni and Florian, 2008), and semantic role labeling (Pado and Lapata, 2009). However, to the best of our knowledge, no work has reported on the RDC task. In this paper, we apply a cross-lingual annotation projection approach to binary relation detection, a task of identifying the relation between two entities. A simple projection method propagates the relations in source language sentences to 564 \x0cword-aligned target sentences, and a target relation detector can bootstrap from projected annotation. However, this automatic annotation is unreliable because of mis-classification of source text and word alignment err</context>
</contexts>
<marker>Zitouni, Florian, 2008</marker>
<rawString>Zitouni, Imed and Radu Florian. 2008. Mention detection crossing the language barrier. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 600609, Honolulu, Hawaii. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>