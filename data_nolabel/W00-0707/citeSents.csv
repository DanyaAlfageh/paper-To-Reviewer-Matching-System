After sentence alignment using the method described in CITATION, the corpus was split into disjoint segments as shown in table 1,,
However, this appears to be a weak technique (Langlais and CITATION), even when A is allowed to depend on various features of the context (hi, s),,
In previous work CITATION, I described a Maximum Entropy/Minimum Divergence (MEMD) model CITATION for p(w[hi, s) which incorporates a trigram language model and a translation component which is an analog of the well-known IBM translation model 1 CITATION,,
Complex and expensive search strategies are required to find the best target text in this approach (CITATION; CITATION; Ochet al., 1999; CITATION),,
In previous work CITATION, I described a Maximum En,,
However, this appears to be a weak technique (Langlais and CITATION), even when A is allowed to depend on various features of the context (hi,,
This is very important for applications such as TransType (CITATION; Langlais et al., 2000), where the task is to make real-time predictions of the text a human translator will type next, based on the source text under translation and some prefix of the target text that has already been typed,,
In CITATION I describe an 38 \x0ceffective technique for selecting MEMD wordpair features,,
Maximum likelihood estimates for these parameters can be obtained with the EM algorithm over a bilingual training corpus, as described in CITATION,,
For all MEMD models, I used 20,000 word-pair features selected using the method described in CITATION; this is suboptimal but gives reasonably good performance and facilitates experimentation,,
For a given choice of q and f, the IIS algorithm CITATION can be used to find maximum likelihood values for the parameters ~,,
 are required to find the best target text in this approach (CITATION; CITATION; Ochet al., 1999; CITATION),,
ch strategies are required to find the best target text in this approach (CITATION; CITATION; Ochet al., 1999; CITATION),,
It can be shown (Della CITATION) that these are the also the values which minimize the Kullback-Liebler divergence D(p[[q) between the model and the reference distribution under the constraint that the expectations of the features (ie, the components of f) with respect to the model must equal their expectations with respect to the empirical distribution derived from the training corpus,,
