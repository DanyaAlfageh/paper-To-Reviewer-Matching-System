<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.241179">
b&quot;Coling 2010: Poster Volume, pages 14891497,
</note>
<address confidence="0.405569">
Beijing, August 2010
</address>
<title confidence="0.669518">
Sentence Ordering with Event-Enriched Semantics and Two-
Layered Clustering for Multi-Document News Summarization
</title>
<author confidence="0.929184">
Renxian Zhang Wenjie Li Qin Lu
</author>
<affiliation confidence="0.994927">
Department of Computing, the Hong Kong Polytechnic University
</affiliation>
<email confidence="0.995443">
{csrzhang,cswjli,csluqin}@comp.polyu.edu.hk
</email>
<sectionHeader confidence="0.990727" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.996356307692308">
We propose an event-enriched model to
alleviate the semantic deficiency
problem in the IR-style text processing
and apply it to sentence ordering for
multi-document news summarization.
The ordering algorithm is built on event
and entity coherence, both locally and
globally. To accommodate the event-
enriched model, a novel LSA-integrated
two-layered clustering approach is
adopted. The experimental result shows
clear advantage of our model over
event-agonistic models.
</bodyText>
<sectionHeader confidence="0.997849" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998849113636364">
One of the crucial steps in multi-document
summarization (MDS) is information ordering,
right after content selection and before sentence
realization (Jurafsky and Martin, 2009:832
834). Problems with this step are the culprit for
much of the dissatisfaction with automatic
summaries. While textual order may guide the
ordering in single-document summarization, no
such guidance is available for MDS ordering.
A sensible solution is ordering sentences by
enhancing coherence since incoherence is the
source of disorder. Recent researches in this
direction mostly focus on local coherence by
studying lexical cohesion (Conroy et al., 2006)
or entity overlap and transition (Barzilay and
Lapata, 2008). But global coherence, i.e.,
coherence between sentence groups with the
whole text in view, is largely unaccounted for
and few efforts are made at levels higher than
entity or word in measuring sentence coherence.
On the other hand, event as a high-level
construct has proved useful in MDS content
selection (Filatova and Hatzivassiloglou, 2004;
Li et al., 2006). But the potential of event in
summarization has not been fully gauged and
few publications report using event in MDS
information ordering. We will argue that event
is instrumental for MDS information ordering,
especially multi-document news summarization
(MDNS). Ordering algorithms based on event
and entity information outperform those based
only on entity information.
After related works are surveyed in section 2,
we will discuss in section 3 the problem of
semantic deficiency in IR-based text processing,
which motivates building event information into
sentence representation. The details of such
representation are provided in section 4. In
section 5, we will explicate the ordering
algorithms, including layered clustering and
cluster-based ordering. The performance of the
event-enriched model will be extensively
evaluated in section 6. Section 7 will conclude
the work with directions to future work.
</bodyText>
<sectionHeader confidence="0.999637" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.998922529411765">
In MDS, information ordering is often realized
on the sentence level and treated as a coherence
enhancement task. A simple ordering criterion
is the chronological order of the events
represented in the sentences, which is often
augmented with other ordering criteria such as
lexical overlap (Conroy et al., 2006), lexical
cohesion (Barzilay et al., 2002) or syntactic
features (Lapata 2003).
A different way to capture local coherence in
sentence ordering is the Centering Theory (CT,
Grosz et al. 1995)-inspired entity-transition
approach, advocated by Barzilay and Lapata
(2005, 2008). In their entity grid model,
syntactic roles played by entities and transitions
between these syntactic roles underlie the
coherence patterns between sentences and in the
</bodyText>
<page confidence="0.958913">
1489
</page>
<bodyText confidence="0.999149028571429">
\x0cwhole text. An entity-parsed corpus can be used
to train a model that prefers the sentence
orderings that comply with the optimal entity
transition patterns.
Another important clue to sentence ordering
is the sentence positional information in a
source document, or precedence relation,
which is utilized by Okazaki et al. (2004) in
combination with topical clustering.
Those works are all relevant to the current
work because we seek ordering clues from
chronological order, lexical cohesion, entity
transition, and sentence precedence. But we also
add an important member to the panoply event.
Despite its intuitive and conceptual appeal,
event is not as extensively used in
summarization as term or entity. Filatova and
Hatzivassiloglou (2004) use atomic events as
conceptual representations in MDS content
selection, followed by Li et al. (2006) who treat
event terms and named entities as graph nodes
in their PageRank algorithm. Yoshioka and
Haraguchi (2004) report an event reference-
based approach to MDS content selection for
Japanese articles. Although sentence
reordering is a component of their model, it
relies merely on textual and chronological order.
Few published works report using event
information in MDS sentence ordering.
Our work will represent text content at two
levels: event vectors and sentence vectors. This
is close in spirit to Brombergs (2006) enriched
LSA-coherence model, where both sentence and
word vectors are used to compute a centroid as
the topic of the text.
</bodyText>
<sectionHeader confidence="0.963543" genericHeader="method">
3 Semantic Deficiency in IR-Style Text
</sectionHeader>
<subsectionHeader confidence="0.446876">
Processing
</subsectionHeader>
<bodyText confidence="0.962192714285714">
As automatic summarization traces its root to
Information Retrieval (IR), it inherits the vector
space model (VSM) of text representation,
according to which a sentence is treated as a bag
of words or stoplist-filtered terms. The order or
relation among the terms is ignored. For
example,
</bodyText>
<listItem confidence="0.8509972">
1a) The storm killed 120,000 people in Jamaica
and five in the Dominican Republic before moving
west to Mexico.
1b) [Dominican, Mexico, Jamaica, Republic, five,
kill, move, people, storm, west]
1c) [Dominican Republic, Mexico, Jamaica,
people, storm]
1b) and 1c) are the term-based and entity-
based representations of 1a) respectively. They
only indicate what the sentence is about (i.e.,
</listItem>
<bodyText confidence="0.9853585625">
some happening, probably a storm, in some
place that affects people), but aboutness is a
far cry from informativeness. For instance, no
message about people in which place, Mexico
or Jamaica, are affected or what moves to
where can be gleaned from 1b) although such
message is clearly conveyed in 1a). In other
words, the IR-style text representation is
semantically deficient.
We argue that a natural text, especially a
news article, is not only about somebody or
something. It also tells what happened to
somebody or something in a temporal-spatial
manner. A natural approach to meeting the
what happened requirement is to introduce
event.
</bodyText>
<sectionHeader confidence="0.829475" genericHeader="method">
4 Event-EnrichedSentenceRepresentation
</sectionHeader>
<bodyText confidence="0.999318">
In summarization, an event is an activity or
episode associated with participants, time, place,
and manner. Conceptually, event bridges
sentence and term/entity and partially fills the
semantic gap in the sentence representation.
</bodyText>
<subsectionHeader confidence="0.999674">
4.1 Event Structure and Extraction
</subsectionHeader>
<bodyText confidence="0.986078272727273">
Following (Li et al. 2006), we define an event E
as a structured semantic unit consisting of one
event term Term(E) and a set of event entities
Entity(E). In the news domain, event terms are
typically action verbs or deverbal nouns. Light
verbs such as take, give, etc. (Tan et al.,
2006) are removed.
Event entities include named entities and
high-frequency entities. Named entities denote
people, locations, organizations, dates, etc.
High-frequency entities are common nouns or
NPs that frequently participate in news events.
Filatova and Hatzivassiloglou (2004) take the
top 10 most frequent entities and Li et al. (2006)
take the entities with frequency &gt; 10. Rather
than using a fixed threshold, we reformulate
high-frequency as relative statistics based on
(assumed) Gaussian distribution of the entities
and consider those with z-score &gt; 1 as candidate
event entities.
Event extraction begins with shallow parsing
and named entity recognition, analyzing each
</bodyText>
<page confidence="0.949784">
1490
</page>
<bodyText confidence="0.914972083333333">
\x0csentence S into ordered lists of event terms {t1,
t2, ...}. Low-frequency common entities are
removed. If a noun is decided to be an event
term, it cannot be (the head noun of) an entity.
The next step is to identify events with event
terms and entities. Filatova and
Hatzivassiloglou (2003) treat events as triplets
with two event entities sandwiching one
connector (event term). But the number
restriction on entities is counterintuitive and is
dropped in our method. We first identify n + 1
Segi segmented by n event terms tj.
</bodyText>
<figureCaption confidence="0.6206728">
... t1 ... ... tj-1 ... tj ... tj+1 ... ... tn ...
Figure 1. Segments among Event Terms
For each tj, the corresponding event Ej are
extracted by taking tj and the event entities in its
nearest entity-containing Segp and Segq.
</figureCaption>
<equation confidence="0.926538">
Ej = [tj, Entity(Segp)Entity(Segq)] (Eq. 1)
</equation>
<bodyText confidence="0.990086727272727">
where p = argmax() and q
= argmin() if such p and q
exist. 1d) is the event-extracted result of 1a).
1d) {[killed, [storm, people, Jamaica, Dominican
Republic]], [moving, [people, Jamaica, Dominican
Republic, west, Mexico]]}
From this representation, it is easy to identify
the two events in sentence 1a) led by the event
terms killed and moving. Unlike the triplets
(two named entities and one connector) in
(Filatova and Hatzivassiloglou 2003), an event
in our model can have an unlimited number of
event entities, as is often the real case.
Moreover, we can tell that the killing involves
people, storm, Jamaica, etc. and the
moving involves Jamaica, Dominique
Republic, etc.
The shallow parsing-based approach is
admittedly coarse-grade (e.g., storm is
missing from the moving event), but the
extracted event-enriched representations help to
alleviate the semantic deficiency problem in IR.
</bodyText>
<subsectionHeader confidence="0.989672">
4.2 Event Relations
</subsectionHeader>
<bodyText confidence="0.997788272727273">
The relations between two events include event
term relation and event entity relation. Two
events are similar if their event terms are similar
and/or their event entities are similar. Such
similarities are in turn defined on the word level.
For event terms, we first find the root verbs of
deverbal nouns and then measure verb similarity
by using the fine-grained relations provided by
VerbOcean (Chklovski and Pantel, 2004),
which has proved useful in summarization (Liu
et al., 2007). But unlike (Liu et al., 2007), we
count in all the verb relations except antonymy
because considering two antonymous verbs as
similar is counterintuitive. The other four
relations similarity, strength, enablement,
before are all considered in our measurement
of verb similarity. If we denote the normalized
score of two verbs on relation i as VOi(V1, V2)
with i = 1, 2, 3, 4 corresponding to the above
four relations, the term similarity of two events
t(E1, E2) is defined as in Eq. 2, where I is a
small number to suppress zeroes. I = 0.01 if
</bodyText>
<equation confidence="0.94064425">
VOi(V1, V2) = 1 and otherwise I = 0.
t(E1, E2) = t(Term(E1), Term(E2)) = 1
(1 ((), ()) +
) (Eq. 2)
</equation>
<bodyText confidence="0.992163625">
Entity similarity is measured by the shared
entities between two events. Li et al. (2006)
define entity similarity as the number of shared
entities, which may unfairly assign high scores
to events with many entities in our model. So
we decide to use the normalized result as shown
in Eq. 3, where e(E1, E2) denotes the event
entity-based similarity between events E1 and E2.
</bodyText>
<equation confidence="0.97041375">
e(E1, E2) =
|()()|
|()()|
(Eq. 3)
</equation>
<bodyText confidence="0.7122785">
(E1, E2), the score of event similarity, is a
linear combination of t(E1, E2) and e(E1, E2).
</bodyText>
<equation confidence="0.869271">
(E1, E2) = I1 t(E1, E2) + (1 I1) e(E1, E2) (Eq. 4)
</equation>
<subsectionHeader confidence="0.991005">
4.3 Statistical Evidence for News Events
</subsectionHeader>
<bodyText confidence="0.997478357142857">
In this work, we introduce events as a middle-
layer representation between words and
sentences under the assumptions that 1) events
are widely distributed in a text and that 2) they
are natural clusters of salient information in a
text. They guarantee the relevance of event to
our task summaries are condensed collections
of salient information in source documents.
In order to confirm them, we scan the whole
dataset in our experiment, which consists of 42
200w human extracts and 39 400w human
extracts for the DUC 02 multi-document extract
task. Detailed information about the dataset can
be found in Section 6. Table 1 lists the statistics.
</bodyText>
<figure confidence="0.695791125">
200w 400w
200w +
400w
Source
Docs
Entity/Sent 8.78 8.48 8.47 6.01
Entity/Word 0.34 0.33 0.33 0.30
Event/Sent 2.43 2.26 2.28 1.42
Segn
Segj-1 Segj
Seg0
1491
\x0cEvent/Word 0.09 0.09 0.09 0.07
Sents with
events/Sents
86.9% 85.1% 84.6% 71.3%
</figure>
<tableCaption confidence="0.968078">
Table 1. Statistics from DUC 02 Dataset
</tableCaption>
<bodyText confidence="0.99965475">
There are on average 1.42 events per sentence
in the source documents, and more than 70% of
all the sentences contain events. The high event
density confirms our first assumption about the
distribution of events. For the 200w+400w
category consisting of all the human-selected
sentences, there are on average 2.28 events per
sentence, a 60% increase from the same ratio in
the source documents. The proportion of event-
containing sentences reaches 84.6%, 13%
higher than that in the source documents. Such
is evidence that events count into the extract-
worthiness of sentences, which confirms our
second assumption about the relevance of
events to summarization. The data also show
higher entity density in the extracts than in the
source documents. As entities are still reliable
and domain-independent clues of salient content,
we will consider both event and entity in the
following ordering algorithm.
</bodyText>
<sectionHeader confidence="0.839611" genericHeader="method">
5 MDS Sentence Ordering with Event
</sectionHeader>
<bodyText confidence="0.967227">
and Entity Coherence
In this section, we discuss how event can
facilitate MDS sentence ordering with layered
clustering on the event and sentence levels and
then how event and entity information can be
integrated in a coherence-based algorithm to
order sentences based on sentence clusters.
</bodyText>
<subsectionHeader confidence="0.931367">
5.1 Two-layered Clustering
</subsectionHeader>
<bodyText confidence="0.982778384615385">
After sentences are represented as collections of
events, we need to vectorize events and
sentences to facilitate clustering and cluster-
based sentence ordering.
For a document set, event vectorization
begins with aggregating all the event terms and
entities in a set of event units (eu). Given m
distinct event terms, n distinct named entities,
and p distinct high-frequency common entities,
the m + n + p eus are a concatenation of the
event terms and entities such that eui is an event
term for 1 i m, a named entity for m + 1 i
m + n, and a high-frequency entity for m + n +
</bodyText>
<figure confidence="0.519097">
1 i m + n + p. The eus define the m + n + p
dimensions of an event vector in an eu-by-event
matrix E = [eij], as shown in Figure 2.
, ,
, ,
</figure>
<figureCaption confidence="0.977074">
Figure 2. eu-by-Event Matrix
</figureCaption>
<bodyText confidence="0.997935666666667">
We further define EntityN(Ej) and EntityH(Ej)
to be the set of named entities and set of high-
frequency entities of Ej. Then,
</bodyText>
<equation confidence="0.970262461538461">
(, ()) 1 i m
eij =
(,)
()
()
m + 1 i m + n
(,)
()
()
m + n + 1 i
m + n + p (Eq. 5)
2 w1 is identical to w2
Hn(w1, w2) = 1 w1 (w2) is a part of w2 (w1) or they
</equation>
<bodyText confidence="0.92257">
are in a hypernymy / holonymy
</bodyText>
<equation confidence="0.9870138">
relationship
0 otherwise (Eq. 6)
1 w1 is identical to w2
Hh(w1, w2) = 0.5 w1 are w2 are synonyms
0 otherwise (Eq. 7)
</equation>
<bodyText confidence="0.994991954545455">
In Eq. 5, t(w1, w2) is defined as in Eq. 2.
Both the entity-based Hn(w1, w2) and Hh(w1, w2)
are measured in terms of total equivalence
(identity) and partial equivalence. For named
entities, partial equivalence applies to structural
subsumption (e.g., Britain and Great Britain)
and hypernymy/holonymy (e.g., South Africa
and Zambia). For common entities, it applies
to synonymy (e.g., security and safety).
Partial equivalence is considered because of the
lexical variations frequently employed in
journalist writing. The named entity scores are
doubled because they represent the essential
elements of a news story.
Since the events are represented as vectors,
sentence vectorization based on events is not as
straightforward as on entities or terms. In this
work we propose a novel approach of two-
layered clustering for the purpose. The basic
idea is clustering events at the first layer and
then using event clusters as a feature to
vectorize and cluster sentences at the second
</bodyText>
<figure confidence="0.905146625">
E1, E2, ... Eq
eu1
...
eum
...
eum+n
...
eum+n+p
</figure>
<page confidence="0.937015">
1492
</page>
<bodyText confidence="0.989745095238095">
\x0clayer. Hard clustering of events, such as K-
means, not only results in binary values in event
vectors and data sparseness but also is
inappropriate. For example, if EC1 clusters
events all with event terms similar to t* and EC2
clusters events all with event entity sets similar
to e* (a set), what about event {t*, e*}?
Assigning it to either EC1 or EC2 is problematic
as it is partially similar to both. So we decide to
do soft clustering at the first layer.
A well-studied soft clustering technique is the
Expectation-Maximization (EM) algorithm
which iteratively estimates the unknown
parameters in a probability mixture model. We
assume a Gaussian mixture model for the q
event vectors V1, V2, ..., Vq, with hidden
variables Hi, initial means Mi, priors i, and
covariance matrix Ci. The E-step is to calculate
the hidden variables
for each Vt and the M-
step re-estimates the new priors i
</bodyText>
<equation confidence="0.6838975">
, means Mi
,
</equation>
<bodyText confidence="0.936945652173913">
and covariance matrix Ci
. We iterate the two
steps until the log-likelihood converges within a
threshold = 10-6
. The performance of the EM
algorithm is sensitive to the initial means, which
are pre-computed by a conventional K-means.
In a preliminary study, we found that the
event vectors display pronounced sparseness. A
solution to this problem in an effort to leverage
the latent event topics among eus is the
Latent Semantic Analysis (LSA, Landauer and
Dumais, 1997) approach. We apply LSA-style
dimensionality reduction to the eu-by-event
matrix E by doing Singular Value
Decomposition (SVD). A problem is with the
number h of the largest singular values, which
affects the performance of dimensionality
reduction. In this work, we adopt a utility-based
metric to find the best h* by maximizing intra-
cluster similarity (ih) and minimizing inter-
cluster similarity (Oh) corresponding to the h-
dimensionality reduction
</bodyText>
<equation confidence="0.9899815">
h* = argmax
(Eq. 8)
</equation>
<bodyText confidence="0.976051">
ih is defined as the mean of average cluster
similarities measured by cosine distance and Oh
is the mean of cluster centroid similarities.
Because the EM clustering assigns a probability
to every event vector, we also take those
probabilities into account when calculating ih
and Oh.
Based on the EM clustering of events, we
vectorize a sentence by summing up the
probabilities of its constituent event vectors
over all event clusters (ECs) and obtaining an
</bodyText>
<figureCaption confidence="0.760559">
EC-by-sentence (Sn) matrix S = [sij].
Figure 3. EC-by-Sentence Matrix
</figureCaption>
<equation confidence="0.942012">
sij = P(
)
</equation>
<bodyText confidence="0.960329666666667">
where
is Ers vector.
At the sentence layer, hard clustering is
sufficient because we need definitive, not
probabilistic, membership information for the
next step sentence ordering. We use K-means
for the purpose. The LSA-style dimensionality
reduction is still in order as possible
performance gain is expected from the
discovery of latent EC topics. The decision of
the best dimensionality is the same as before,
except that no probabilities are included.
</bodyText>
<subsectionHeader confidence="0.999332">
5.2 Coherence-Based Sentence Ordering
</subsectionHeader>
<bodyText confidence="0.99966175">
Our ordering algorithm is based on sentence
clusters, which is designed on the observation
that human writers and summarizers organize
sentences by blocks (paragraphs). Sentences
within a block are conceptually close to each
other and adjacent sentences cohere with each
other. Local coherence is thus realized within
blocks. On the other hand, blocks are not
randomly ordered. Two blocks are put next to
each other if their contents are close enough to
ensure text-level coherence. So text-level, or
global coherence is realized among blocks.
We believe in MDNS, the block-style
organization is a sensible strategy taken by
human extractors to sort sentences from
different sources. Sentence clusters are
simulations of such blocks and our ordering
algorithm will be based on local coherence and
global coherence described above.
First we have to pinpoint the leading sentence
for an extract. Using the heuristic of time and
textual precedence, we first generate a set of
possible leading sentences L = {Li} as the
intersection of the document-leading extract
sentence set LDoc and the time-leading sentence
set LTime. Note that |LDoc |= the number of
documents, LTime is in fact a sentence collection
of time-leading documents, and LDoc l LTime .
</bodyText>
<equation confidence="0.746603833333333">
S1, S2, ... Sn
EC1
...
ECm
1493
\x0cIf L is a singleton, finding the leading
</equation>
<bodyText confidence="0.940881">
sentence SL is trivial. If not, SL is decided to be
the sentence in L most similar to all the other
sentences in the extract sentence set P so that it
qualifies as a good topic sentence.
</bodyText>
<equation confidence="0.8840615">
SL = argmax (, )
\\{} (Eq. 9)
</equation>
<bodyText confidence="0.8964876">
where (, ) is the similarity between S1
and S2 in terms of their event similarity (S1, S2)
and entity similarity H(S1, S2). (S1, S2) is an
extended version of (E1, E2) (Eq. 4) by
averaging the t(Ei, Ej) and e(Ei, Ej) for all (Ei,
</bodyText>
<equation confidence="0.994999181818182">
Ej) pairs in S1 S2.
(S1, S2) = I2
(,)
,
|()()|
+
(1 I2)
(,)
,
|()()|
(Eq. 10)
</equation>
<bodyText confidence="0.948919093023256">
where Event(S) is the set of all events in S. Next,
H(S1, S2) is the cosine similarity between their
entity vectors
and
with entity weights
constructed according to Eq. 6 and 7. Then,
(, ) = I3 (S1, S2) +(1 I3)H(S1, S2) (Eq. 11)
After the leading sentence is determined, we
identify the leading cluster it belongs to and our
local coherence-based ordering starts with this
cluster. We adopt a greedy algorithm, which
selects each time from the unordered sentence
set a sentence that best coheres with the
sentence just selected, called anchor sentence.
Matching each candidate sentence with the
anchor sentence only in terms of would
assume that the sentences are isolated and
decontextualized. But the anchor sentence did
not come from nowhere and in order to find its
best successor, we should also seek clues from
its source context, which is inspired by the
sentence precedence by Okazaki et al. (2004).
More formally, given an anchor sentence Si at
the end of the ordered sentence list, we select
the next best sentence Si+1 according to their
associative similarity and substitutive
similarity, two crucial measures invented by us.
Associative similarity SimASS(Si, Sj) measures
how Si and Sj associate with each other in terms
of their event and entity coherence, which
almost is , . But to better capture the
transition between entities and the flow of topic,
we also consider a topic-continuity score tc(Si,
Sj) according to the Centering Theory. If the
topic continuity is measured in terms of entity
change, local coherence can be captured by the
centering transitions (CB and CP) in adjacent
sentences. Based on (Taboada and Wiesemann,
2009), we assign 0.2 to the Establish and
Continue transitions, 0.1 to Smooth Shift and
Retain, and 0 to other centering transitions.
Since tc(Si, Sj) only applies to entities, it is
treated as a bonus affiliated to H(Si, Sj).
</bodyText>
<equation confidence="0.9962625">
, = I4 (Si, Sj) + (1 I4) H(Si, Sj)
(1 + tc(Si, Sj)) (Eq. 12)
</equation>
<bodyText confidence="0.9880055">
Substitutive similarity accommodates what
we earlier emphasized about the source context
of the extracted sentences by measuring to what
degree Si and Sj resemble each others relevant
source context. More formally, let LC(Si) and
RC(Si) be the left and right source contexts of Si
respectively, and the substitutive similarity
SimSUB(Si, Sj) is defined as follows.
</bodyText>
<equation confidence="0.561406">
, S = , () +
(), S (Eq. 13)
</equation>
<bodyText confidence="0.9991311">
In this work, we simply take LC(Si) and RC(Si)
to be the left adjacent sentence and right
adjacent sentence of Si in the source document.
Note that tc(Si, Sj) does not apply here. In view
of the chronological order widely accepted in
MDS ordering, a time penalty, tp(Si, Sj), is used
to discount the score by 0.8 if Sis document
date is later than Sjs document date. Finally, Eq.
14 summarizes our intra-cluster ordering
method in a sentence cluster SCk.
</bodyText>
<equation confidence="0.9968675">
Si+1 = argmax\\{} , +
(1 ) , (, ) (Eq. 14)
</equation>
<bodyText confidence="0.99981055">
After all the sentences in the current sentence
cluster are ordered, we move on by considering
the similarity of sentence clusters. Given a
processed sentence cluster SCi, the next best
sentence cluster SCi+1 is the one that maximizes
the cluster similarity SimCLU(SCi, SCj) among
the set of all clusters U. Since clusters are
collections of sentences, their similarity is the
mean of cross-cluster pairwise sentence
similarities, each calculated according to Eq. 14.
Eq. 15 shows how SCi+1 is computed.
SCi+1=argmax\\{}(, ) (Eq. 15)
This is how we incorporate (block-style)
global coherence into MDS sentence ordering.
Starting from the second chosen sentence
cluster, we choose the first sentence in the
current cluster with reference to the last
sentence in the previous processed cluster and
apply Eq. 14. We continue the whole process
until all the extract sentences are ordered.
</bodyText>
<page confidence="0.959826">
1494
</page>
<sectionHeader confidence="0.729376" genericHeader="evaluation">
\x0c6 Evaluation
</sectionHeader>
<bodyText confidence="0.9227375">
In this section, we report the experimental result
on the DUC 02 dataset.
</bodyText>
<subsectionHeader confidence="0.996093">
6.1 Data
</subsectionHeader>
<bodyText confidence="0.999919277777778">
We use the dataset of the DUC 02
summarization track for MDS because it
includes an extraction task for which model
extracts are provided. For every document set, 2
model extracts are provided each for the 200w
and 400w length categories. We use 1 randomly
chosen model extract per document set per
length category as the gold standard.
We intended to use all the 59 document sets
on DUC 02 but found that for some categories,
both model extracts contain material from
sections such as the title, lead, or even byline.
Those extracts are incompatible with our design
tailored for news body extracts. Therefore we
have to filter them and retain only those extracts
with all units selected from the news body. As a
result, we collect 42 200w extracts and 39 400w
extracts as our experimental dataset.
</bodyText>
<subsectionHeader confidence="0.998927">
6.2 Peer Orderings
</subsectionHeader>
<bodyText confidence="0.9995395">
We evaluate the role played by various key
elements in our approach, including event, topic
continuity, time penalty, and LSA-style
dimensionality reduction. In addition, we
produce a random ordering and a baseline
ordering according to chronological and textual
order only. Table 2 lists the 9 peer orderings to
be evaluated, with their codes.
</bodyText>
<figure confidence="0.994229">
A Random
B Baseline (time order + textual order)
C Entity only (no LSA)
D Event only (no LSA)
E Entity + Event topic continuity (no LSA)
F Entity + Event time penalty (no LSA)
G Entity + Event (no LSA)
H Entity + Event (event clustering LSA)
I Entity + Event (event + sentence clustering LSA)
</figure>
<tableCaption confidence="0.928061">
Table 2. Peer Orderings
</tableCaption>
<subsectionHeader confidence="0.994687">
6.3 Metrics
</subsectionHeader>
<bodyText confidence="0.988309">
A popular metric used in sequence evaluation
is Kendalls IJ (Lapata, 2006), which measures
ordering differences in terms of the number of
adjacent sentence inversions necessary to
convert a test ordering to the reference ordering.
</bodyText>
<equation confidence="0.812922">
IJ = 4m/(n(n 1)) (Eq. 16)
</equation>
<bodyText confidence="0.998944142857143">
where m is the number of inversions described
above and n is the total number of sentences.
The second metric we use is the Average
Continuity (AC) developed by Bollegala et al.
(2006), which captures the intuition that the
ordering quality can be estimated by the number
of correctly arranged continuous sentences.
</bodyText>
<equation confidence="0.923078">
= exp(
log( + )
(Eq. 17)
</equation>
<bodyText confidence="0.999565625">
where k is the maximum number of continuous
sentences, is a small value in case Pn = 1. Pn,
the proportion of continuous sentences of length
n in an ordering, is defined as m/(N n + 1)
where m is the number of continuous sentences
of length n in both the test and reference
orderings and N is the total number of sentences.
We set k = 4 and = 0.01.
</bodyText>
<subsectionHeader confidence="0.721545">
6.4 Result
</subsectionHeader>
<bodyText confidence="0.957075333333333">
We empirically determine all the parameters (i)
and produce all the peer orderings. Table 3 lists
the result, where we also show the statistical
significance between the full model peer
ordering I and all other versions, marked by *
(p &lt; .05) and ** (p &lt; .01) on a two-tailed t-test.
</bodyText>
<table confidence="0.908682307692308">
Peer
Code
200w 400w
Kendalls IJ AC Kendalls IJ AC
A 0.014** 0.009** -0.019** 0.004**
B 0.387 0.151* 0.259** 0.151*
C 0.369* 0.128* 0.264* 0.156*
D 0.380 0.163 0.270* 0.158*
E 0.375* 0.156* 0.267* 0.157*
F 0.388 0.159* 0.264* 0.157*
G 0.385 0.158* 0.269* 0.162
H 0.384 0.164 0.292* 0.170
I 0.395 0.170 0.350 0.176
</table>
<tableCaption confidence="0.998792">
Table 3. Evaluation Result
</tableCaption>
<bodyText confidence="0.940071066666667">
Almost all versions with entity and event
information outperform the baseline. The LSA-
style dimensionality reduction proves effective
for our task, as the full model (Peer I) ranks first
and significantly beats versions without event
information, topic continuity, or LSA. Applying
LSA to both event and sentence clustering is
better than applying it only to event clustering
(Peer H), which produces unstable results and is
sometimes outperformed by no-LSA versions
(Peer G).
Event (Peer D) proves to be more valuable
than entity (Peer C) as the event-only versions
outperform the entity-only version in all
categories, which is predicable because events
</bodyText>
<page confidence="0.79857">
1495
</page>
<bodyText confidence="0.988743047619048">
\x0care high-level constructs that incorporate most
of the document-level important entities.
When entity is used, extra bonus can be
gained from topic continuity concerns from CT
(Peer E vs. Peer G) because the centering
transition effectively captures the coherence
pattern between adjacent sentences. The effect
of the chronological order seems less clear (Peer
F vs. P) as removing it hurts longer extracts
rather than short extracts. Therefore
chronological clues are more valuable for
arranging more sentences from the same source
document.
Our ordering algorithm achieves even better
result with long extracts because the importance
of order and coherence grows with text length.
Measured by Kendalls IJ, the full model
ordering in the 400w category is significantly
better than all other orderings.
For a qualitative evaluation, we select the
200w extract d080ae and list all the sentences in
</bodyText>
<figureCaption confidence="0.9350315">
Figure 4. The event terms are boldfaced and the
event entities are underlined.
</figureCaption>
<bodyText confidence="0.963330857142857">
Limited by space, lets focus on the baseline
(1 2 3 4 5 6), entity-only (3 5 2 4 6 1), and full-
model versions (3 5 4 2 1 6). The news extract
is about the acquitting of child molesters. Both
the acquitting and molesting events are
found in 1) and 3) but only the latter qualifies as
the topic sentence because it contains important
event entities. Choosing 3) instead of 1) as the
leading sentence shows the advantage of our
event-enriched model over the baseline. The
same choice is made by the entity-only version
because 3) happens to be also entity-intensive.
In order to see the advantage of the full model
over the entity-only model, lets consider 2) and
4). 2) is chosen by the entity-only model after 5)
because of the heavy entity overlap between 5)
a
because of the heavy entity overlap between 5)
and 2). But semantically, 2) is not as close to 5)
as 4) because only 4) contains entities for both
the acquitting (juror) and molesting
(children) events and intuitively, 4) continues
the main trial-acquittal event topic but 2)
supplies only secondary information. We
examined the sentence clusters before the
ordering and found that 3), 5), and 4) are
clustered together only by the full model,
leading to better coherence, locally and globally.
</bodyText>
<sectionHeader confidence="0.984682" genericHeader="conclusions">
7 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.9997644">
We set out by realizing the semantic deficiency
of IR and propose a low-cost approach of
building event semantics into sentence
representation. Event extraction relies on
shallow parsing and external knowledge sources.
Then we propose a novel approach of two-
layered clustering to use event information,
coupled with LSA-style dimensionality
reduction. MDS sentence ordering is guided by
local and global coherence to simulate the
block-style writing and is realized by a greedy
algorithm. The evaluation shows clear
advantage of our event-enriched model over
baseline and event-agonistic models,
quantitatively and qualitatively.
The extraction approach can be refined by
deep parsing and rich verb (frame) semantics. In
a follow-up project, we will expand our dataset
and experiment with more data and incorporate
human evaluation in comparative tasks.
</bodyText>
<sectionHeader confidence="0.847193" genericHeader="references">
Acknowledgment
</sectionHeader>
<bodyText confidence="0.924571">
The work described in this paper was partially
supported by a grant from the HK RGC (Project
Number: PolyU5217/07E).
1) Thursday&apos;s acquittals in the McMartin Pre-School molestation case outraged parents who said prosecutors botched it,
while those on the defense side proclaimed a triumph of justice over hysteria and hype.
2) Originally, there were seven defendants, including Raymond Buckey&apos;s sister, Peggy Ann Buckey, and Virginia McMartin,
the founder of the school, mother of Mrs. Buckey and grandmother of Raymond Buckey.
</bodyText>
<reference confidence="0.897507333333333">
3) Seven jurors who spoke with reporters in a joint news conference after acquitting Raymond Buckey and his mother,
Peggy McMartin Buckey, on 52 molestation charges Thursday said they felt some children who testified may have been
molested _ but not at the family-run McMartin Pre-School.
4) ``The children were never allowed to say in their own words what happened to them,&apos;&apos; said juror John Breese.
5) Ray Buckey and his mother, Peggy McMartin Buckey, were found not guilty Thursday of molesting children at the
family-run McMartin Pre-School in Manhattan Beach, a verdict which brought to a close the longest and costliest criminal
trial in history .
6) As it becomes apparent that McMartin cases will stretch out for years to come, parents and the former criminal defendants
alike are trying to resign themselves to the inevitability that the matter may be one they can never leave behind.
</reference>
<figureCaption confidence="0.624109">
Figure 4. Extract sentences of d80ae, 200w
</figureCaption>
<page confidence="0.665344">
1496
</page>
<reference confidence="0.97928219047619">
\x0cReferences
Barzilay, R., Elhadad, N., and McKeown, K. 2002.
Inferring Strategies for Sentence Ordering in
Multidocument News Summarization. Journal of
Artificial Intelligence Research, 17:3555.
Barzilay, R., and Lapata, M. 2005. Modeling Local
Coherence: An Entity-based Approach. In
Proceedings of the 43rd Annual Meeting of the
ACL, 141-148. Ann Arbor.
Barzilay, R., and Lapata, M. 2008. Modeling Local
Coherence: An Entity-Based Approach.
Computational Linguistics, 34:134.
Bollegala, D, Okazaki, N., and Ishizuka, M. 2006. A
Bottom-up Approach to Sentence Ordering for
Multi-document Summarization. In Proceedings
of the 21st International Conference on
Computational Linguistics and 44th Annual
Meeting of the ACL, 385392. Sydney, Australia.
Bromberg, I. 2006. Ordering Sentences According to
Topicality. Presented at the Midwest
Computational Linguistics Colloquium.
Chklovski, T., and Pantel, P. 2004. VerbOcean:
Mining the Web for Fine-Grained Semantic Verb
Relations. In Proceedings of Conference on
Empirical Methods in Natural Language
Processing (EMNLP-04). 1113. Barcelona,
Spain.
Conroy, J. M., Schlesinger, J. D., and Goldstein, J.
2006. CLASSY Tasked Based Summarization:
Back to Basics. In proceedings of the Document
Understanding Conference (DUC-06).
Filatova, E., and Hatzivassiloglou, V. 2003. Domain-
independent detection, extraction, and labeling of
atomic events. In Proceedings of RANLP, 145
152, Borovetz, Bulgaria.
Filatova, E., and Hatzivassiloglou, V. 2004. Event-
Based Extractive Summarization. In Proceedings
of the ACL-04, 104111.
Grosz, B. J., Aravind K. J., and Scott W. 1995.
Centering: A framework for Modeling the Local
Coherence of Discourse. Computational
Linguistics, 21(2):203225.
Jurafsky D., and Martin, J. H. 2009. Speech and
Language Processing, Second Edition. Upper
Saddle River, NJ: Pearson Education International.
Landauer, T., and Dumais, S. 1997. A solution to
Platos problem: The latent semantic analysis
theory of the acquisition, induction, and
representation of knowledge. Psychological
Review, 104.
Lapata, M. 2003. Probabilistic Text Structuring:
Experiments with Sentence Ordering. In
Proceedings of the Annual Meeting of ACL, 545-
552. Sapporo, Japan.
Li, W., Wu, M., Lu, Q., Xu, W., and Yuan, C. 2006.
Extractive Summarization Using Inter- and Intra-
Event Relevance. In Proceedings of the 21st
International Conference on Computational
Linguistics and 44th Annual Meeting of the ACL,
369376. Sydney.
Liu, M., Li, W., Wu, M., and Lu, Q. 2007. Extractive
Summarization Based on Event Term Clustering.
In Proceedings of the ACL 2007 Demo and Poster
Sessions, 185188. Prague.
Okazaki, N., Matsuo, Y., and Ishizuka, M. 2004.
Improving Chronological Ordering by Precedence
Relation. In Proceedings of 20th International
Conference on Computational Linguistics
(COLING 04), 750756.
Taboada, M., and Wiesemann, L., Subjects and
topics in conversation. Journal of Pragmatics
(2009), doi:10.1016/j.pragma.2009.04.009.
Tan, Y. F., Kan, M., and Cui, H. 2006. Extending
corpus-based identification of light verb
constructions using a supervised learning
framework. In Proceedings of the EACL 2006
Workshop on Multi-word-expressions in a
multilingual context, 4956, Trento, Italy.
Yoshioka, M., and Haraguchi, M. 2004. Multiple
News Articles Summarization Based on Event
Reference Information. In Working Notes of
NTCIR-4, Tokyo.
1497
\x0c&quot;
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.751060">
<note confidence="0.89105">b&quot;Coling 2010: Poster Volume, pages 14891497, Beijing, August 2010</note>
<title confidence="0.99571">Sentence Ordering with Event-Enriched Semantics and Two- Layered Clustering for Multi-Document News Summarization</title>
<author confidence="0.999527">Renxian Zhang Wenjie Li Qin Lu</author>
<affiliation confidence="0.999988">Department of Computing, the Hong Kong Polytechnic University</affiliation>
<email confidence="0.964557">csrzhang@comp.polyu.edu.hk</email>
<email confidence="0.964557">cswjli@comp.polyu.edu.hk</email>
<email confidence="0.964557">csluqin@comp.polyu.edu.hk</email>
<abstract confidence="0.998617357142857">We propose an event-enriched model to alleviate the semantic deficiency problem in the IR-style text processing and apply it to sentence ordering for multi-document news summarization. The ordering algorithm is built on event and entity coherence, both locally and globally. To accommodate the eventenriched model, a novel LSA-integrated two-layered clustering approach is adopted. The experimental result shows clear advantage of our model over event-agonistic models.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>\x0cReferences Barzilay</author>
<author>R Elhadad</author>
<author>N</author>
<author>K McKeown</author>
</authors>
<title>Inferring Strategies for Sentence Ordering in Multidocument News Summarization.</title>
<date>2002</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>17--3555</pages>
<contexts>
<context position="3157" citStr="Barzilay et al., 2002" startWordPosition="452" endWordPosition="455">we will explicate the ordering algorithms, including layered clustering and cluster-based ordering. The performance of the event-enriched model will be extensively evaluated in section 6. Section 7 will conclude the work with directions to future work. 2 Related Work In MDS, information ordering is often realized on the sentence level and treated as a coherence enhancement task. A simple ordering criterion is the chronological order of the events represented in the sentences, which is often augmented with other ordering criteria such as lexical overlap (Conroy et al., 2006), lexical cohesion (Barzilay et al., 2002) or syntactic features (Lapata 2003). A different way to capture local coherence in sentence ordering is the Centering Theory (CT, Grosz et al. 1995)-inspired entity-transition approach, advocated by Barzilay and Lapata (2005, 2008). In their entity grid model, syntactic roles played by entities and transitions between these syntactic roles underlie the coherence patterns between sentences and in the 1489 \x0cwhole text. An entity-parsed corpus can be used to train a model that prefers the sentence orderings that comply with the optimal entity transition patterns. Another important clue to sen</context>
</contexts>
<marker>Barzilay, Elhadad, N, McKeown, 2002</marker>
<rawString>\x0cReferences Barzilay, R., Elhadad, N., and McKeown, K. 2002. Inferring Strategies for Sentence Ordering in Multidocument News Summarization. Journal of Artificial Intelligence Research, 17:3555.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Barzilay</author>
<author>M Lapata</author>
</authors>
<title>Modeling Local Coherence: An Entity-based Approach.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the ACL,</booktitle>
<pages>141--148</pages>
<location>Ann Arbor.</location>
<contexts>
<context position="3382" citStr="Barzilay and Lapata (2005" startWordPosition="484" endWordPosition="487">ith directions to future work. 2 Related Work In MDS, information ordering is often realized on the sentence level and treated as a coherence enhancement task. A simple ordering criterion is the chronological order of the events represented in the sentences, which is often augmented with other ordering criteria such as lexical overlap (Conroy et al., 2006), lexical cohesion (Barzilay et al., 2002) or syntactic features (Lapata 2003). A different way to capture local coherence in sentence ordering is the Centering Theory (CT, Grosz et al. 1995)-inspired entity-transition approach, advocated by Barzilay and Lapata (2005, 2008). In their entity grid model, syntactic roles played by entities and transitions between these syntactic roles underlie the coherence patterns between sentences and in the 1489 \x0cwhole text. An entity-parsed corpus can be used to train a model that prefers the sentence orderings that comply with the optimal entity transition patterns. Another important clue to sentence ordering is the sentence positional information in a source document, or precedence relation, which is utilized by Okazaki et al. (2004) in combination with topical clustering. Those works are all relevant to the curren</context>
</contexts>
<marker>Barzilay, Lapata, 2005</marker>
<rawString>Barzilay, R., and Lapata, M. 2005. Modeling Local Coherence: An Entity-based Approach. In Proceedings of the 43rd Annual Meeting of the ACL, 141-148. Ann Arbor.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Barzilay</author>
<author>M Lapata</author>
</authors>
<title>Modeling Local Coherence: An Entity-Based Approach. Computational Linguistics,</title>
<date>2008</date>
<pages>34--134</pages>
<contexts>
<context position="1509" citStr="Barzilay and Lapata, 2008" startWordPosition="203" endWordPosition="206">tion ordering, right after content selection and before sentence realization (Jurafsky and Martin, 2009:832 834). Problems with this step are the culprit for much of the dissatisfaction with automatic summaries. While textual order may guide the ordering in single-document summarization, no such guidance is available for MDS ordering. A sensible solution is ordering sentences by enhancing coherence since incoherence is the source of disorder. Recent researches in this direction mostly focus on local coherence by studying lexical cohesion (Conroy et al., 2006) or entity overlap and transition (Barzilay and Lapata, 2008). But global coherence, i.e., coherence between sentence groups with the whole text in view, is largely unaccounted for and few efforts are made at levels higher than entity or word in measuring sentence coherence. On the other hand, event as a high-level construct has proved useful in MDS content selection (Filatova and Hatzivassiloglou, 2004; Li et al., 2006). But the potential of event in summarization has not been fully gauged and few publications report using event in MDS information ordering. We will argue that event is instrumental for MDS information ordering, especially multi-document</context>
</contexts>
<marker>Barzilay, Lapata, 2008</marker>
<rawString>Barzilay, R., and Lapata, M. 2008. Modeling Local Coherence: An Entity-Based Approach. Computational Linguistics, 34:134.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Bollegala</author>
<author>N Okazaki</author>
<author>M Ishizuka</author>
</authors>
<title>A Bottom-up Approach to Sentence Ordering for Multi-document Summarization.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL,</booktitle>
<pages>385392</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="26040" citStr="Bollegala et al. (2006)" startWordPosition="4264" endWordPosition="4267"> Event time penalty (no LSA) G Entity + Event (no LSA) H Entity + Event (event clustering LSA) I Entity + Event (event + sentence clustering LSA) Table 2. Peer Orderings 6.3 Metrics A popular metric used in sequence evaluation is Kendalls IJ (Lapata, 2006), which measures ordering differences in terms of the number of adjacent sentence inversions necessary to convert a test ordering to the reference ordering. IJ = 4m/(n(n 1)) (Eq. 16) where m is the number of inversions described above and n is the total number of sentences. The second metric we use is the Average Continuity (AC) developed by Bollegala et al. (2006), which captures the intuition that the ordering quality can be estimated by the number of correctly arranged continuous sentences. = exp( log( + ) (Eq. 17) where k is the maximum number of continuous sentences, is a small value in case Pn = 1. Pn, the proportion of continuous sentences of length n in an ordering, is defined as m/(N n + 1) where m is the number of continuous sentences of length n in both the test and reference orderings and N is the total number of sentences. We set k = 4 and = 0.01. 6.4 Result We empirically determine all the parameters (i) and produce all the peer orderings.</context>
</contexts>
<marker>Bollegala, Okazaki, Ishizuka, 2006</marker>
<rawString>Bollegala, D, Okazaki, N., and Ishizuka, M. 2006. A Bottom-up Approach to Sentence Ordering for Multi-document Summarization. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, 385392. Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Bromberg</author>
</authors>
<title>Ordering Sentences According to Topicality. Presented at the Midwest Computational Linguistics Colloquium.</title>
<date>2006</date>
<marker>Bromberg, 2006</marker>
<rawString>Bromberg, I. 2006. Ordering Sentences According to Topicality. Presented at the Midwest Computational Linguistics Colloquium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Chklovski</author>
<author>P Pantel</author>
</authors>
<title>VerbOcean: Mining the Web for Fine-Grained Semantic Verb Relations.</title>
<date>2004</date>
<booktitle>In Proceedings of Conference on Empirical Methods in Natural Language Processing (EMNLP-04). 1113.</booktitle>
<location>Barcelona,</location>
<contexts>
<context position="9858" citStr="Chklovski and Pantel, 2004" startWordPosition="1496" endWordPosition="1499"> is admittedly coarse-grade (e.g., storm is missing from the moving event), but the extracted event-enriched representations help to alleviate the semantic deficiency problem in IR. 4.2 Event Relations The relations between two events include event term relation and event entity relation. Two events are similar if their event terms are similar and/or their event entities are similar. Such similarities are in turn defined on the word level. For event terms, we first find the root verbs of deverbal nouns and then measure verb similarity by using the fine-grained relations provided by VerbOcean (Chklovski and Pantel, 2004), which has proved useful in summarization (Liu et al., 2007). But unlike (Liu et al., 2007), we count in all the verb relations except antonymy because considering two antonymous verbs as similar is counterintuitive. The other four relations similarity, strength, enablement, before are all considered in our measurement of verb similarity. If we denote the normalized score of two verbs on relation i as VOi(V1, V2) with i = 1, 2, 3, 4 corresponding to the above four relations, the term similarity of two events t(E1, E2) is defined as in Eq. 2, where I is a small number to suppress zeroes. I = 0</context>
</contexts>
<marker>Chklovski, Pantel, 2004</marker>
<rawString>Chklovski, T., and Pantel, P. 2004. VerbOcean: Mining the Web for Fine-Grained Semantic Verb Relations. In Proceedings of Conference on Empirical Methods in Natural Language Processing (EMNLP-04). 1113. Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J M Conroy</author>
<author>J D Schlesinger</author>
<author>J Goldstein</author>
</authors>
<title>CLASSY Tasked Based Summarization: Back to Basics.</title>
<date>2006</date>
<booktitle>In proceedings of the Document Understanding Conference (DUC-06).</booktitle>
<contexts>
<context position="1448" citStr="Conroy et al., 2006" startWordPosition="194" endWordPosition="197"> steps in multi-document summarization (MDS) is information ordering, right after content selection and before sentence realization (Jurafsky and Martin, 2009:832 834). Problems with this step are the culprit for much of the dissatisfaction with automatic summaries. While textual order may guide the ordering in single-document summarization, no such guidance is available for MDS ordering. A sensible solution is ordering sentences by enhancing coherence since incoherence is the source of disorder. Recent researches in this direction mostly focus on local coherence by studying lexical cohesion (Conroy et al., 2006) or entity overlap and transition (Barzilay and Lapata, 2008). But global coherence, i.e., coherence between sentence groups with the whole text in view, is largely unaccounted for and few efforts are made at levels higher than entity or word in measuring sentence coherence. On the other hand, event as a high-level construct has proved useful in MDS content selection (Filatova and Hatzivassiloglou, 2004; Li et al., 2006). But the potential of event in summarization has not been fully gauged and few publications report using event in MDS information ordering. We will argue that event is instrum</context>
<context position="3115" citStr="Conroy et al., 2006" startWordPosition="446" endWordPosition="449">re provided in section 4. In section 5, we will explicate the ordering algorithms, including layered clustering and cluster-based ordering. The performance of the event-enriched model will be extensively evaluated in section 6. Section 7 will conclude the work with directions to future work. 2 Related Work In MDS, information ordering is often realized on the sentence level and treated as a coherence enhancement task. A simple ordering criterion is the chronological order of the events represented in the sentences, which is often augmented with other ordering criteria such as lexical overlap (Conroy et al., 2006), lexical cohesion (Barzilay et al., 2002) or syntactic features (Lapata 2003). A different way to capture local coherence in sentence ordering is the Centering Theory (CT, Grosz et al. 1995)-inspired entity-transition approach, advocated by Barzilay and Lapata (2005, 2008). In their entity grid model, syntactic roles played by entities and transitions between these syntactic roles underlie the coherence patterns between sentences and in the 1489 \x0cwhole text. An entity-parsed corpus can be used to train a model that prefers the sentence orderings that comply with the optimal entity transiti</context>
</contexts>
<marker>Conroy, Schlesinger, Goldstein, 2006</marker>
<rawString>Conroy, J. M., Schlesinger, J. D., and Goldstein, J. 2006. CLASSY Tasked Based Summarization: Back to Basics. In proceedings of the Document Understanding Conference (DUC-06).</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Filatova</author>
<author>V Hatzivassiloglou</author>
</authors>
<title>Domainindependent detection, extraction, and labeling of atomic events.</title>
<date>2003</date>
<booktitle>In Proceedings of RANLP, 145 152,</booktitle>
<location>Borovetz, Bulgaria.</location>
<contexts>
<context position="8009" citStr="Filatova and Hatzivassiloglou (2003)" startWordPosition="1198" endWordPosition="1201">the entities with frequency &gt; 10. Rather than using a fixed threshold, we reformulate high-frequency as relative statistics based on (assumed) Gaussian distribution of the entities and consider those with z-score &gt; 1 as candidate event entities. Event extraction begins with shallow parsing and named entity recognition, analyzing each 1490 \x0csentence S into ordered lists of event terms {t1, t2, ...}. Low-frequency common entities are removed. If a noun is decided to be an event term, it cannot be (the head noun of) an entity. The next step is to identify events with event terms and entities. Filatova and Hatzivassiloglou (2003) treat events as triplets with two event entities sandwiching one connector (event term). But the number restriction on entities is counterintuitive and is dropped in our method. We first identify n + 1 Segi segmented by n event terms tj. ... t1 ... ... tj-1 ... tj ... tj+1 ... ... tn ... Figure 1. Segments among Event Terms For each tj, the corresponding event Ej are extracted by taking tj and the event entities in its nearest entity-containing Segp and Segq. Ej = [tj, Entity(Segp)Entity(Segq)] (Eq. 1) where p = argmax() and q = argmin() if such p and q exist. 1d) is the event-extracted resul</context>
</contexts>
<marker>Filatova, Hatzivassiloglou, 2003</marker>
<rawString>Filatova, E., and Hatzivassiloglou, V. 2003. Domainindependent detection, extraction, and labeling of atomic events. In Proceedings of RANLP, 145 152, Borovetz, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Filatova</author>
<author>V Hatzivassiloglou</author>
</authors>
<title>EventBased Extractive Summarization.</title>
<date>2004</date>
<booktitle>In Proceedings of the ACL-04,</booktitle>
<pages>104111</pages>
<contexts>
<context position="1854" citStr="Filatova and Hatzivassiloglou, 2004" startWordPosition="257" endWordPosition="260"> A sensible solution is ordering sentences by enhancing coherence since incoherence is the source of disorder. Recent researches in this direction mostly focus on local coherence by studying lexical cohesion (Conroy et al., 2006) or entity overlap and transition (Barzilay and Lapata, 2008). But global coherence, i.e., coherence between sentence groups with the whole text in view, is largely unaccounted for and few efforts are made at levels higher than entity or word in measuring sentence coherence. On the other hand, event as a high-level construct has proved useful in MDS content selection (Filatova and Hatzivassiloglou, 2004; Li et al., 2006). But the potential of event in summarization has not been fully gauged and few publications report using event in MDS information ordering. We will argue that event is instrumental for MDS information ordering, especially multi-document news summarization (MDNS). Ordering algorithms based on event and entity information outperform those based only on entity information. After related works are surveyed in section 2, we will discuss in section 3 the problem of semantic deficiency in IR-based text processing, which motivates building event information into sentence representat</context>
<context position="4316" citStr="Filatova and Hatzivassiloglou (2004)" startWordPosition="624" endWordPosition="627">ly with the optimal entity transition patterns. Another important clue to sentence ordering is the sentence positional information in a source document, or precedence relation, which is utilized by Okazaki et al. (2004) in combination with topical clustering. Those works are all relevant to the current work because we seek ordering clues from chronological order, lexical cohesion, entity transition, and sentence precedence. But we also add an important member to the panoply event. Despite its intuitive and conceptual appeal, event is not as extensively used in summarization as term or entity. Filatova and Hatzivassiloglou (2004) use atomic events as conceptual representations in MDS content selection, followed by Li et al. (2006) who treat event terms and named entities as graph nodes in their PageRank algorithm. Yoshioka and Haraguchi (2004) report an event referencebased approach to MDS content selection for Japanese articles. Although sentence reordering is a component of their model, it relies merely on textual and chronological order. Few published works report using event information in MDS sentence ordering. Our work will represent text content at two levels: event vectors and sentence vectors. This is close i</context>
<context position="7307" citStr="Filatova and Hatzivassiloglou (2004)" startWordPosition="1084" endWordPosition="1087">gap in the sentence representation. 4.1 Event Structure and Extraction Following (Li et al. 2006), we define an event E as a structured semantic unit consisting of one event term Term(E) and a set of event entities Entity(E). In the news domain, event terms are typically action verbs or deverbal nouns. Light verbs such as take, give, etc. (Tan et al., 2006) are removed. Event entities include named entities and high-frequency entities. Named entities denote people, locations, organizations, dates, etc. High-frequency entities are common nouns or NPs that frequently participate in news events. Filatova and Hatzivassiloglou (2004) take the top 10 most frequent entities and Li et al. (2006) take the entities with frequency &gt; 10. Rather than using a fixed threshold, we reformulate high-frequency as relative statistics based on (assumed) Gaussian distribution of the entities and consider those with z-score &gt; 1 as candidate event entities. Event extraction begins with shallow parsing and named entity recognition, analyzing each 1490 \x0csentence S into ordered lists of event terms {t1, t2, ...}. Low-frequency common entities are removed. If a noun is decided to be an event term, it cannot be (the head noun of) an entity. T</context>
</contexts>
<marker>Filatova, Hatzivassiloglou, 2004</marker>
<rawString>Filatova, E., and Hatzivassiloglou, V. 2004. EventBased Extractive Summarization. In Proceedings of the ACL-04, 104111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B J Grosz</author>
<author>K J Aravind</author>
<author>W Scott</author>
</authors>
<title>Centering: A framework for Modeling the Local Coherence of Discourse.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<volume>21</volume>
<issue>2</issue>
<contexts>
<context position="3306" citStr="Grosz et al. 1995" startWordPosition="476" endWordPosition="479">xtensively evaluated in section 6. Section 7 will conclude the work with directions to future work. 2 Related Work In MDS, information ordering is often realized on the sentence level and treated as a coherence enhancement task. A simple ordering criterion is the chronological order of the events represented in the sentences, which is often augmented with other ordering criteria such as lexical overlap (Conroy et al., 2006), lexical cohesion (Barzilay et al., 2002) or syntactic features (Lapata 2003). A different way to capture local coherence in sentence ordering is the Centering Theory (CT, Grosz et al. 1995)-inspired entity-transition approach, advocated by Barzilay and Lapata (2005, 2008). In their entity grid model, syntactic roles played by entities and transitions between these syntactic roles underlie the coherence patterns between sentences and in the 1489 \x0cwhole text. An entity-parsed corpus can be used to train a model that prefers the sentence orderings that comply with the optimal entity transition patterns. Another important clue to sentence ordering is the sentence positional information in a source document, or precedence relation, which is utilized by Okazaki et al. (2004) in com</context>
</contexts>
<marker>Grosz, Aravind, Scott, 1995</marker>
<rawString>Grosz, B. J., Aravind K. J., and Scott W. 1995. Centering: A framework for Modeling the Local Coherence of Discourse. Computational Linguistics, 21(2):203225.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Jurafsky</author>
<author>J H Martin</author>
</authors>
<title>Speech and Language Processing, Second Edition. Upper Saddle River,</title>
<date>2009</date>
<publisher>Pearson Education International.</publisher>
<location>NJ:</location>
<contexts>
<context position="986" citStr="Jurafsky and Martin, 2009" startWordPosition="126" endWordPosition="129">o alleviate the semantic deficiency problem in the IR-style text processing and apply it to sentence ordering for multi-document news summarization. The ordering algorithm is built on event and entity coherence, both locally and globally. To accommodate the eventenriched model, a novel LSA-integrated two-layered clustering approach is adopted. The experimental result shows clear advantage of our model over event-agonistic models. 1 Introduction One of the crucial steps in multi-document summarization (MDS) is information ordering, right after content selection and before sentence realization (Jurafsky and Martin, 2009:832 834). Problems with this step are the culprit for much of the dissatisfaction with automatic summaries. While textual order may guide the ordering in single-document summarization, no such guidance is available for MDS ordering. A sensible solution is ordering sentences by enhancing coherence since incoherence is the source of disorder. Recent researches in this direction mostly focus on local coherence by studying lexical cohesion (Conroy et al., 2006) or entity overlap and transition (Barzilay and Lapata, 2008). But global coherence, i.e., coherence between sentence groups with the whol</context>
</contexts>
<marker>Jurafsky, Martin, 2009</marker>
<rawString>Jurafsky D., and Martin, J. H. 2009. Speech and Language Processing, Second Edition. Upper Saddle River, NJ: Pearson Education International.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Landauer</author>
<author>S Dumais</author>
</authors>
<title>A solution to Platos problem: The latent semantic analysis theory of the acquisition, induction, and representation of knowledge.</title>
<date>1997</date>
<journal>Psychological Review,</journal>
<volume>104</volume>
<contexts>
<context position="16935" citStr="Landauer and Dumais, 1997" startWordPosition="2735" endWordPosition="2738">priors i, and covariance matrix Ci. The E-step is to calculate the hidden variables for each Vt and the Mstep re-estimates the new priors i , means Mi , and covariance matrix Ci . We iterate the two steps until the log-likelihood converges within a threshold = 10-6 . The performance of the EM algorithm is sensitive to the initial means, which are pre-computed by a conventional K-means. In a preliminary study, we found that the event vectors display pronounced sparseness. A solution to this problem in an effort to leverage the latent event topics among eus is the Latent Semantic Analysis (LSA, Landauer and Dumais, 1997) approach. We apply LSA-style dimensionality reduction to the eu-by-event matrix E by doing Singular Value Decomposition (SVD). A problem is with the number h of the largest singular values, which affects the performance of dimensionality reduction. In this work, we adopt a utility-based metric to find the best h* by maximizing intracluster similarity (ih) and minimizing intercluster similarity (Oh) corresponding to the hdimensionality reduction h* = argmax (Eq. 8) ih is defined as the mean of average cluster similarities measured by cosine distance and Oh is the mean of cluster centroid simil</context>
</contexts>
<marker>Landauer, Dumais, 1997</marker>
<rawString>Landauer, T., and Dumais, S. 1997. A solution to Platos problem: The latent semantic analysis theory of the acquisition, induction, and representation of knowledge. Psychological Review, 104.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Lapata</author>
</authors>
<title>Probabilistic Text Structuring: Experiments with Sentence Ordering.</title>
<date>2003</date>
<booktitle>In Proceedings of the Annual Meeting of ACL,</booktitle>
<pages>545--552</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="3193" citStr="Lapata 2003" startWordPosition="459" endWordPosition="460">luding layered clustering and cluster-based ordering. The performance of the event-enriched model will be extensively evaluated in section 6. Section 7 will conclude the work with directions to future work. 2 Related Work In MDS, information ordering is often realized on the sentence level and treated as a coherence enhancement task. A simple ordering criterion is the chronological order of the events represented in the sentences, which is often augmented with other ordering criteria such as lexical overlap (Conroy et al., 2006), lexical cohesion (Barzilay et al., 2002) or syntactic features (Lapata 2003). A different way to capture local coherence in sentence ordering is the Centering Theory (CT, Grosz et al. 1995)-inspired entity-transition approach, advocated by Barzilay and Lapata (2005, 2008). In their entity grid model, syntactic roles played by entities and transitions between these syntactic roles underlie the coherence patterns between sentences and in the 1489 \x0cwhole text. An entity-parsed corpus can be used to train a model that prefers the sentence orderings that comply with the optimal entity transition patterns. Another important clue to sentence ordering is the sentence posit</context>
</contexts>
<marker>Lapata, 2003</marker>
<rawString>Lapata, M. 2003. Probabilistic Text Structuring: Experiments with Sentence Ordering. In Proceedings of the Annual Meeting of ACL, 545-552. Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Li</author>
<author>M Wu</author>
<author>Q Lu</author>
<author>W Xu</author>
<author>C Yuan</author>
</authors>
<title>Extractive Summarization Using Inter- and IntraEvent Relevance.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL,</booktitle>
<pages>369376</pages>
<location>Sydney.</location>
<contexts>
<context position="1872" citStr="Li et al., 2006" startWordPosition="261" endWordPosition="264">ences by enhancing coherence since incoherence is the source of disorder. Recent researches in this direction mostly focus on local coherence by studying lexical cohesion (Conroy et al., 2006) or entity overlap and transition (Barzilay and Lapata, 2008). But global coherence, i.e., coherence between sentence groups with the whole text in view, is largely unaccounted for and few efforts are made at levels higher than entity or word in measuring sentence coherence. On the other hand, event as a high-level construct has proved useful in MDS content selection (Filatova and Hatzivassiloglou, 2004; Li et al., 2006). But the potential of event in summarization has not been fully gauged and few publications report using event in MDS information ordering. We will argue that event is instrumental for MDS information ordering, especially multi-document news summarization (MDNS). Ordering algorithms based on event and entity information outperform those based only on entity information. After related works are surveyed in section 2, we will discuss in section 3 the problem of semantic deficiency in IR-based text processing, which motivates building event information into sentence representation. The details o</context>
<context position="4419" citStr="Li et al. (2006)" startWordPosition="640" endWordPosition="643">rmation in a source document, or precedence relation, which is utilized by Okazaki et al. (2004) in combination with topical clustering. Those works are all relevant to the current work because we seek ordering clues from chronological order, lexical cohesion, entity transition, and sentence precedence. But we also add an important member to the panoply event. Despite its intuitive and conceptual appeal, event is not as extensively used in summarization as term or entity. Filatova and Hatzivassiloglou (2004) use atomic events as conceptual representations in MDS content selection, followed by Li et al. (2006) who treat event terms and named entities as graph nodes in their PageRank algorithm. Yoshioka and Haraguchi (2004) report an event referencebased approach to MDS content selection for Japanese articles. Although sentence reordering is a component of their model, it relies merely on textual and chronological order. Few published works report using event information in MDS sentence ordering. Our work will represent text content at two levels: event vectors and sentence vectors. This is close in spirit to Brombergs (2006) enriched LSA-coherence model, where both sentence and word vectors are use</context>
<context position="6768" citStr="Li et al. 2006" startWordPosition="1002" endWordPosition="1005">antically deficient. We argue that a natural text, especially a news article, is not only about somebody or something. It also tells what happened to somebody or something in a temporal-spatial manner. A natural approach to meeting the what happened requirement is to introduce event. 4 Event-EnrichedSentenceRepresentation In summarization, an event is an activity or episode associated with participants, time, place, and manner. Conceptually, event bridges sentence and term/entity and partially fills the semantic gap in the sentence representation. 4.1 Event Structure and Extraction Following (Li et al. 2006), we define an event E as a structured semantic unit consisting of one event term Term(E) and a set of event entities Entity(E). In the news domain, event terms are typically action verbs or deverbal nouns. Light verbs such as take, give, etc. (Tan et al., 2006) are removed. Event entities include named entities and high-frequency entities. Named entities denote people, locations, organizations, dates, etc. High-frequency entities are common nouns or NPs that frequently participate in news events. Filatova and Hatzivassiloglou (2004) take the top 10 most frequent entities and Li et al. (2006) </context>
<context position="10653" citStr="Li et al. (2006)" startWordPosition="1640" endWordPosition="1643"> verbs as similar is counterintuitive. The other four relations similarity, strength, enablement, before are all considered in our measurement of verb similarity. If we denote the normalized score of two verbs on relation i as VOi(V1, V2) with i = 1, 2, 3, 4 corresponding to the above four relations, the term similarity of two events t(E1, E2) is defined as in Eq. 2, where I is a small number to suppress zeroes. I = 0.01 if VOi(V1, V2) = 1 and otherwise I = 0. t(E1, E2) = t(Term(E1), Term(E2)) = 1 (1 ((), ()) + ) (Eq. 2) Entity similarity is measured by the shared entities between two events. Li et al. (2006) define entity similarity as the number of shared entities, which may unfairly assign high scores to events with many entities in our model. So we decide to use the normalized result as shown in Eq. 3, where e(E1, E2) denotes the event entity-based similarity between events E1 and E2. e(E1, E2) = |()()| |()()| (Eq. 3) (E1, E2), the score of event similarity, is a linear combination of t(E1, E2) and e(E1, E2). (E1, E2) = I1 t(E1, E2) + (1 I1) e(E1, E2) (Eq. 4) 4.3 Statistical Evidence for News Events In this work, we introduce events as a middlelayer representation between words and sentences u</context>
</contexts>
<marker>Li, Wu, Lu, Xu, Yuan, 2006</marker>
<rawString>Li, W., Wu, M., Lu, Q., Xu, W., and Yuan, C. 2006. Extractive Summarization Using Inter- and IntraEvent Relevance. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, 369376. Sydney.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Liu</author>
<author>W Li</author>
<author>M Wu</author>
<author>Q Lu</author>
</authors>
<title>Extractive Summarization Based on Event Term Clustering.</title>
<date>2007</date>
<contexts>
<context position="9919" citStr="Liu et al., 2007" startWordPosition="1506" endWordPosition="1509">nt), but the extracted event-enriched representations help to alleviate the semantic deficiency problem in IR. 4.2 Event Relations The relations between two events include event term relation and event entity relation. Two events are similar if their event terms are similar and/or their event entities are similar. Such similarities are in turn defined on the word level. For event terms, we first find the root verbs of deverbal nouns and then measure verb similarity by using the fine-grained relations provided by VerbOcean (Chklovski and Pantel, 2004), which has proved useful in summarization (Liu et al., 2007). But unlike (Liu et al., 2007), we count in all the verb relations except antonymy because considering two antonymous verbs as similar is counterintuitive. The other four relations similarity, strength, enablement, before are all considered in our measurement of verb similarity. If we denote the normalized score of two verbs on relation i as VOi(V1, V2) with i = 1, 2, 3, 4 corresponding to the above four relations, the term similarity of two events t(E1, E2) is defined as in Eq. 2, where I is a small number to suppress zeroes. I = 0.01 if VOi(V1, V2) = 1 and otherwise I = 0. t(E1, E2) = t(Ter</context>
</contexts>
<marker>Liu, Li, Wu, Lu, 2007</marker>
<rawString>Liu, M., Li, W., Wu, M., and Lu, Q. 2007. Extractive Summarization Based on Event Term Clustering.</rawString>
</citation>
<citation valid="false">
<booktitle>In Proceedings of the ACL 2007 Demo and Poster Sessions,</booktitle>
<pages>185188</pages>
<location>Prague.</location>
<marker></marker>
<rawString>In Proceedings of the ACL 2007 Demo and Poster Sessions, 185188. Prague.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Okazaki</author>
<author>Y Matsuo</author>
<author>M Ishizuka</author>
</authors>
<title>Improving Chronological Ordering by Precedence Relation.</title>
<date>2004</date>
<booktitle>In Proceedings of 20th International Conference on Computational Linguistics (COLING 04),</booktitle>
<pages>750756</pages>
<contexts>
<context position="3899" citStr="Okazaki et al. (2004)" startWordPosition="562" endWordPosition="565">eory (CT, Grosz et al. 1995)-inspired entity-transition approach, advocated by Barzilay and Lapata (2005, 2008). In their entity grid model, syntactic roles played by entities and transitions between these syntactic roles underlie the coherence patterns between sentences and in the 1489 \x0cwhole text. An entity-parsed corpus can be used to train a model that prefers the sentence orderings that comply with the optimal entity transition patterns. Another important clue to sentence ordering is the sentence positional information in a source document, or precedence relation, which is utilized by Okazaki et al. (2004) in combination with topical clustering. Those works are all relevant to the current work because we seek ordering clues from chronological order, lexical cohesion, entity transition, and sentence precedence. But we also add an important member to the panoply event. Despite its intuitive and conceptual appeal, event is not as extensively used in summarization as term or entity. Filatova and Hatzivassiloglou (2004) use atomic events as conceptual representations in MDS content selection, followed by Li et al. (2006) who treat event terms and named entities as graph nodes in their PageRank algor</context>
<context position="21196" citStr="Okazaki et al. (2004)" startWordPosition="3446" endWordPosition="3449">e leading cluster it belongs to and our local coherence-based ordering starts with this cluster. We adopt a greedy algorithm, which selects each time from the unordered sentence set a sentence that best coheres with the sentence just selected, called anchor sentence. Matching each candidate sentence with the anchor sentence only in terms of would assume that the sentences are isolated and decontextualized. But the anchor sentence did not come from nowhere and in order to find its best successor, we should also seek clues from its source context, which is inspired by the sentence precedence by Okazaki et al. (2004). More formally, given an anchor sentence Si at the end of the ordered sentence list, we select the next best sentence Si+1 according to their associative similarity and substitutive similarity, two crucial measures invented by us. Associative similarity SimASS(Si, Sj) measures how Si and Sj associate with each other in terms of their event and entity coherence, which almost is , . But to better capture the transition between entities and the flow of topic, we also consider a topic-continuity score tc(Si, Sj) according to the Centering Theory. If the topic continuity is measured in terms of en</context>
</contexts>
<marker>Okazaki, Matsuo, Ishizuka, 2004</marker>
<rawString>Okazaki, N., Matsuo, Y., and Ishizuka, M. 2004. Improving Chronological Ordering by Precedence Relation. In Proceedings of 20th International Conference on Computational Linguistics (COLING 04), 750756.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Taboada</author>
<author>L Wiesemann</author>
</authors>
<title>Subjects and topics in conversation.</title>
<date>2009</date>
<journal>Journal of Pragmatics</journal>
<pages>10--1016</pages>
<contexts>
<context position="21943" citStr="Taboada and Wiesemann, 2009" startWordPosition="3566" endWordPosition="3569">Si+1 according to their associative similarity and substitutive similarity, two crucial measures invented by us. Associative similarity SimASS(Si, Sj) measures how Si and Sj associate with each other in terms of their event and entity coherence, which almost is , . But to better capture the transition between entities and the flow of topic, we also consider a topic-continuity score tc(Si, Sj) according to the Centering Theory. If the topic continuity is measured in terms of entity change, local coherence can be captured by the centering transitions (CB and CP) in adjacent sentences. Based on (Taboada and Wiesemann, 2009), we assign 0.2 to the Establish and Continue transitions, 0.1 to Smooth Shift and Retain, and 0 to other centering transitions. Since tc(Si, Sj) only applies to entities, it is treated as a bonus affiliated to H(Si, Sj). , = I4 (Si, Sj) + (1 I4) H(Si, Sj) (1 + tc(Si, Sj)) (Eq. 12) Substitutive similarity accommodates what we earlier emphasized about the source context of the extracted sentences by measuring to what degree Si and Sj resemble each others relevant source context. More formally, let LC(Si) and RC(Si) be the left and right source contexts of Si respectively, and the substitutive s</context>
</contexts>
<marker>Taboada, Wiesemann, 2009</marker>
<rawString>Taboada, M., and Wiesemann, L., Subjects and topics in conversation. Journal of Pragmatics (2009), doi:10.1016/j.pragma.2009.04.009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y F Tan</author>
<author>M Kan</author>
<author>H Cui</author>
</authors>
<title>Extending corpus-based identification of light verb constructions using a supervised learning framework.</title>
<date>2006</date>
<booktitle>In Proceedings of the EACL</booktitle>
<location>Trento, Italy.</location>
<contexts>
<context position="7030" citStr="Tan et al., 2006" startWordPosition="1049" endWordPosition="1052">t is to introduce event. 4 Event-EnrichedSentenceRepresentation In summarization, an event is an activity or episode associated with participants, time, place, and manner. Conceptually, event bridges sentence and term/entity and partially fills the semantic gap in the sentence representation. 4.1 Event Structure and Extraction Following (Li et al. 2006), we define an event E as a structured semantic unit consisting of one event term Term(E) and a set of event entities Entity(E). In the news domain, event terms are typically action verbs or deverbal nouns. Light verbs such as take, give, etc. (Tan et al., 2006) are removed. Event entities include named entities and high-frequency entities. Named entities denote people, locations, organizations, dates, etc. High-frequency entities are common nouns or NPs that frequently participate in news events. Filatova and Hatzivassiloglou (2004) take the top 10 most frequent entities and Li et al. (2006) take the entities with frequency &gt; 10. Rather than using a fixed threshold, we reformulate high-frequency as relative statistics based on (assumed) Gaussian distribution of the entities and consider those with z-score &gt; 1 as candidate event entities. Event extra</context>
</contexts>
<marker>Tan, Kan, Cui, 2006</marker>
<rawString>Tan, Y. F., Kan, M., and Cui, H. 2006. Extending corpus-based identification of light verb constructions using a supervised learning framework. In Proceedings of the EACL 2006 Workshop on Multi-word-expressions in a multilingual context, 4956, Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Yoshioka</author>
<author>M Haraguchi</author>
</authors>
<title>Multiple News Articles Summarization Based on Event Reference Information.</title>
<date>2004</date>
<booktitle>In Working Notes of NTCIR-4,</booktitle>
<location>Tokyo. \x0c&quot;</location>
<contexts>
<context position="4534" citStr="Yoshioka and Haraguchi (2004)" startWordPosition="658" endWordPosition="661">mbination with topical clustering. Those works are all relevant to the current work because we seek ordering clues from chronological order, lexical cohesion, entity transition, and sentence precedence. But we also add an important member to the panoply event. Despite its intuitive and conceptual appeal, event is not as extensively used in summarization as term or entity. Filatova and Hatzivassiloglou (2004) use atomic events as conceptual representations in MDS content selection, followed by Li et al. (2006) who treat event terms and named entities as graph nodes in their PageRank algorithm. Yoshioka and Haraguchi (2004) report an event referencebased approach to MDS content selection for Japanese articles. Although sentence reordering is a component of their model, it relies merely on textual and chronological order. Few published works report using event information in MDS sentence ordering. Our work will represent text content at two levels: event vectors and sentence vectors. This is close in spirit to Brombergs (2006) enriched LSA-coherence model, where both sentence and word vectors are used to compute a centroid as the topic of the text. 3 Semantic Deficiency in IR-Style Text Processing As automatic su</context>
</contexts>
<marker>Yoshioka, Haraguchi, 2004</marker>
<rawString>Yoshioka, M., and Haraguchi, M. 2004. Multiple News Articles Summarization Based on Event Reference Information. In Working Notes of NTCIR-4, Tokyo. \x0c&quot;</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>