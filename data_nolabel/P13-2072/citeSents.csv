This is a variant of BLEU CITATION with strict brevity penalty, where a long translation for one sentence can not be used to counteract the brevity penalty for another sentence with a short translation,,
Overall, even though the method shows some promise, we do not see the dramatic gains that have been seen for the web search ranking task CITATION,,
We achieve this by applying gradient boosting machines CITATION to learn new weak learners (features) in the form of regression trees, using a differentiable loss function related to BLEU,,
In the related field of web search ranking, automatically learned non-linear features have brought dramatic improvements in quality (CITATION; Wu This resea,,
In the related field of web search ranking, automatically learned non-linear features have brought dramatic improvements in quality (CITATION; Wu This research was conducted during the authors internship at,,
The initial scores have the form F0(x) = l=1...L lfl(x).This is equivalent to using the CITATION method of parameter tuning for a fixed input feature set and a linear model,,
e loss function is the pairwise ranking log-loss from the PRO method for parameter tuning CITATION,,
ying gradient boosting machines CITATION to learn new weak learners (features) in the form of regression trees, using a differentiable loss function related to BLEU,,
We build on the work by CITATION which shows how to induce features to minimize any differentiable loss function,,
When a linear model does not fit well, researchers are careful to manually add important feature conjunctions, as for example, (Daume III and Jagarlamudi, 2011; CITATION),,
We apply the framework of gradient boosting for decision tree weak learners CITATION,,
Some recent works have attempted to relax the linearity assumption on MT features CITATION, by defining non-parametric models on complete translation hypotheses, for use in an nbest re-ranking setting,,
We report performance using the BLEU-SBP metric proposed in (CITATIONa),,
When a linear model does not fit well, researchers are careful to manually add important feature conjunctions, as for example, (Daume III and Jagarlamudi, 2011; CITATION,,
1 Introduction The linear model for machine translation CITATION has become the de-facto standard in the field,,
CITATION) has become the de-facto standard in the field,,
2.3 Loss function We use a pair-wise ranking log-loss as in the PRO parameter tuning method CITATION,,
In the related field of web search ranking, automatically learned non-linear features have brought dramatic improvements in quality (CITATION; Wu This research was conducted during the authors internship at Microsoft Research et al., 2010),,
The minimization is done approximately by a standard greedy tree-growing algorithm CITATION,,
Recently, researchers have proposed a large number of additional features (CITATION; CITATION) and parameter tuning method,,
et al., 2007; CITATION) and parameter tuning methods (CITATIONb; CITATION; CITATION) which are better able to scale to the larger parameter space,,
In the related field of web search ranking, automatically learned non-linear features have brought dramatic improvements in quality (CITATION; Wu This research was conducted during the authors internship at Microsoft Research et a,,
In our application the features are regression decision trees, and the loss function is the pairwise ranking log-loss from the PRO method for parameter tuning CITATION,,
 researchers are careful to manually add important feature conjunctions, as for example, (Daume III and Jagarlamudi, 2011; CITATION),,
Recently, researchers have proposed a large number of additional features (CITATION; CITATION) and parameter tuning methods (CITATIONb; CITATION; CITATION) which are better able to scale to the larger parameter space,,
