A real advantage of these models comes from the freedom in de\x0cning these features: for example, (Ratnaparkhi 96; CITATION) both describe feature sets which would be dicult to incorporate in a generative model,,
In maximum-entropy taggers (Ratnaparkhi 96; CITATION), the tagging problem is decomposed into sequence of decisions in tagging the problem in left-to-right fashion,,
See (Collinsand Du\x0by 2001; Collins and Du\x0by 2002; CITATION) for other applications of the voted perceptronto NLP problems.1 2 Parameter Estimation 2.1 HMM Taggers In this section, as a motivating example, we describe a special case of the algorithm in this paper: the algorithm applied to a trigram tagger,,
1 Introduction Maximum-entropy (ME) models are justi\x0cably a very popular choice for tagging problems in Natural Language Processing: for example see (Ratnaparkhi 96) for their use on part-of-speech tagging, and CITATION for their use on a FAQ segmentation task,,
