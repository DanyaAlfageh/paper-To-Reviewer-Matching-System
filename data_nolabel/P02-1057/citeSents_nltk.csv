1 Introduction Single document summarization systems proposed to date fall within one of the following three classes: Extractive summarizers simply select and present to the user the most important sentences in a text see (Mani and Maybury, 1999; CITATION; CITATION) for comprehensive overviews of the methods and algorithms used to accomplish this.,,
Headline generators are noisy-channel probabilistic systems that are trained on large corpora of \x02Headline, Text\x03 pairs (CITATION; CITATION).,,
Sentence simplification systems (CITATION; CITATION; CITATION; CITATION; CITATION; CITATION) are capable of compressing long sentences by deleting unimportant words and phrases.,,
1 Introduction Single document summarization systems proposed to date fall within one of the following three classes: Extractive summarizers simply select and present to the user the most important sentences in a text see (Mani and Maybury, 1999; CITATION; CITATION) for comprehensive overviews of the methods and algorithms used to accomplish this.,,
Headline generators are noisy-channel probabilistic systems that are trained on large corpora of \x02Headline, Text\x03 pairs (CITATION; CITATION).,,
Sentence simplification systems (CITATION; CITATION; CITATION; CITATION; CITATION; CITATION) are capable of compressing long sentences by deleting unimportant words and phrases.,,
(See CITATION for details concerning the corpus and the annotation process.),,
The additionall two systems were: PD-EDU: Same as EDU except using the perfect discourse trees, available from the RST corpus CITATION.,,
sses: Extractive summarizers simply select and present to the user the most important sentences in a text see (Mani and Maybury, 1999; CITATION; CITATION) for comprehensive overviews of the methods and algorithms used to accomplish this.,,
Headline generators are noisy-channel probabilistic systems that are trained on large corpora of \x02Headline, Text\x03 pairs (CITATION; CITATION).,,
Sentence simplification systems (CITATION; CITATION; CITATION; CITATION; CITATION; CITATION) are capable of compressing long sentences by deleting unimportant words and phrases.,,
all within one of the following three classes: Extractive summarizers simply select and present to the user the most important sentences in a text see (Mani and Maybury, 1999; CITATION; CITATION) for comprehensive overviews of the methods and algorithms used to accomplish this.,,
Headline generators are noisy-channel probabilistic systems that are trained on large corpora of \x02Headline, Text\x03 pairs (CITATION; CITATION).,,
Sentence simplification systems (CITATION; CITATION; CITATION; CITATION; CITATION; CITATION) are capable of compressing long sentences by deleting unimportant words and phrases.,,
To do this, we use the decision-based discourse parser described by CITATION2.,,
tactic parser CITATION.,,
This forest is then passed on to the forest ranking system which is used as decoder CITATION.,,
rizers simply select and present to the user the most important sentences in a text see (Mani and Maybury, 1999; CITATION; CITATION) for comprehensive overviews of the methods and algorithms used to accomplish this.,,
Headline generators are noisy-channel probabilistic systems that are trained on large corpora of \x02Headline, Text\x03 pairs (CITATION; CITATION).,,
Sentence simplification systems (CITATION; CITATION; CITATION; CITATION; CITATION; CITATION) are capable of compressing long sentences by deleting unimportant words and phrases.,,
We call this set the MITRE corpus CITATION.,,
 and present to the user the most important sentences in a text see (Mani and Maybury, 1999; CITATION; CITATION) for comprehensive overviews of the methods and algorithms used to accomplish this.,,
Headline generators are noisy-channel probabilistic systems that are trained on large corpora of \x02Headline, Text\x03 pairs (CITATION; CITATION).,,
Sentence simplification systems (CITATION; CITATION; CITATION; CITATION; CITATION; CITATION) are capable of compressing long sentences by deleting unimportant words and phrases.,,
 to the user the most important sentences in a text see (Mani and Maybury, 1999; CITATION; CITATION) for comprehensive overviews of the methods and algorithms used to accomplish this.,,
Headline generators are noisy-channel probabilistic systems that are trained on large corpora of \x02Headline, Text\x03 pairs (CITATION; CITATION).,,
Sentence simplification systems (CITATION; CITATION; CITATION; CITATION; CITATION; CITATION) are capable of compressing long sentences by deleting unimportant words and phrases.,,
CITATION describe in detail a noisy-channel model that explains how short sentences can be expanded into longer ones by inserting and expanding syntactic constituents (and words).,,
We refer the reader to CITATION for the details.,,
extent the noisy-channel model proposed by CITATION.,,
Rhetorical Structure Theory (RST) CITATION provides us this glue.,,
These are both examples of sentence expansion as used previously by CITATION.,,
There are a vast number of potential compressions of a large DS-tree, but we can efficiently pack them into a shared-forest structure, as described in detail by CITATION.,,
& CITATION.,,
Thankfully, such a generic extractor has already been built CITATION.,,
To do this, we use the decision-based discourse parser described by CITATION2.,,
tactic parser CITATION.,,
This forest is then passed on to the forest ranking system which is used as decoder CITATION.,,
wing three classes: Extractive summarizers simply select and present to the user the most important sentences in a text see (Mani and Maybury, 1999; CITATION; CITATION) for comprehensive overviews of the methods and algorithms used to accomplish this.,,
Headline generators are noisy-channel probabilistic systems that are trained on large corpora of \x02Headline, Text\x03 pairs (CITATION; CITATION).,,
Sentence simplification systems (CITATION; CITATION; CITATION; CITATION; CITATION; CITATION) are capable of compressing long sentences by deleting unimportant words and phrases.,,
1 Introduction Single document summarization systems proposed to date fall within one of the following three classes: Extractive summarizers simply select and present to the user the most important sentences in a text see (Mani and Maybury, 1999; CITATION; CITATION) for comprehensive overviews of the methods and algorithms used to accomplish this.,,
Headline generators are noisy-channel probabilistic systems that are trained on large corpora of \x02Headline, Text\x03 pairs (CITATION; CITATION).,,
Sentence simplification systems (CITATION; CITATION; CITATION; CITATION; CITATION; CITATION) are capable of compressing long sentences by deleting unimportant words and phras,,
extent the noisy-channel model proposed by CITATION.,,
Rhetorical Structure Theory (RST) CITATION provides us this glue.,,
1 Introduction Single document summarization systems proposed to date fall within one of the following three classes: Extractive summarizers simply select and present to the user the most important sentences in a text see (Mani and Maybury, 1999; CITATION; CITATION) for comprehensive overviews of the methods and algorithms used to accomplish this.,,
Headline generators are noisy-channel probabilistic systems that are trained on large corpora of \x02Headline, Text\x03 pairs (CITATION; CITATION).,,
Sentence simplification systems (CITATION; CITATION; CITATION; CITATION; CITATION; CITATION) are capable of compressing long sentences by deleting unimportant wo,,
extent the noisy-channel model proposed by CITATION.,,
Rhetorical Structure Theory (RST) CITATION provides us this glue.,,
These are both examples of sentence expansion as used previously by CITATION.,,
CITATION describe in detail a noisy-channel model that explains how short sentences can be expanded into longer ones by inserting and expanding syntactic constituents (and words).,,
We refer the reader to CITATION for the details.,,
There are a vast number of potential compressions of a large DS-tree, but we can efficiently pack them into a shared-forest structure, as described in detail by CITATION.,,
