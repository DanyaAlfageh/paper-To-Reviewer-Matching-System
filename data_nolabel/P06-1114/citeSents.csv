Recently, the task of automatically recognizing one form of semantic inference textual entailment has received much attention from groups participating in the 2005 and 2006 PASCAL Recognizing Textual Entailment (RTE) Challenges CITATION,,
Under these approaches (referred to as licensing by CITATION and aboutness by CITATION), p is considered to be an answer to a question ?q iff ?q logically entails the set of worlds in which p is true(i.e,,
As in CITATION, we used a twostep approach to obtain sufficient training data for the Alignment Classifier,,
CITATION); (3) a noisy-channel model which selects the most likely answer to a question (cf,,
CITATION),,
While probabilistic or web-based methods for answer validation have been previously explored in the literature CITATION, these approaches have modeled the relationship between a question and a (correct) answer in terms of relevance and have not tried to approximate the deeper semantic phenomena that are involved in determining answerhood,,
In order to provide a baseline for our experiments, we ran a version of our Q/A system, known as FERRET (CITATIONa), that does not make use of textual entailment information when identifying answers to questions,,
In previous work (CITATIONb), we have described techniques that can be used to automatically generate well-formed natural language questions from the text of paragraphs retrieved by a PR module,,
Following an idea proposed in CITATION, we created a corpus of approximately 101,000 textual entailment examples by pairing the headline and first sentence from newswire documents,,
In order increase the likelihood that 909 \x0conly true paraphrases were considered as phraselevel alternations for an example, extracted sentences were clustered using complete-link clustering using a technique proposed in CITATION,,
Training Data Development Set Additional Corpora Number of Examples 800 201,000 Task QA-test 0.5750 0.6950 IE-test 0.6450 0.7300 IR-test 0.6200 0.7450 SUM-test 0.7700 0.8450 Overall Accuracy 0.6525 0.7538 Table 8: Accuracy on the 2006 RTE Test Set In previous work CITATION, we have found that the type and amount of training data available to our TE system significantly (p < 0.05) impacted its performance on the 2006 RTE Test Set,,
\x052\x05 UNALIGNED CHUNK: This feature represents the number of chunks in one text that are not aligned with a chunk from the other \x053\x05 LEXICAL ENTAILMENT PROBABILITY: This feature is defined in CITATION,,
As described in CITATION, the Preprocessing module is used to syntactically parse texts, identify the semantic dependencies of predicates, label named entities, normalize temporal and spatial expressions, resolve instances of coreference, and annotate predicates with polarity, tense, and modality information,,
CITATION); or (4) a constraint satisfaction problem, where sets of auxiliary questions are used to provide more information and better constrain the answers to individual questions (cf,,
Features derived from the entailment confidence were then combined with the keyword- and relation-based features described in (CITATIONa) in order to produce a final ranking of candidate answers,,
Work on the semantics of questions (CITATION; CITATION) has argued that the formal answerhood relation found between a question and a set of (correct) answers can be cast in terms of logical entailment,,
Following CITATION, we expect that if a question ?q logically entails another question ?q0, then some subset of the answers entailed by ?q0 should also be interpreted as valid answers to ?q,,
Classifier Training Set Precision Recall F-Measure Linear 10K pairs 0.837 0.774 0.804 Maximum Entropy 10K pairs 0.881 0.851 0.866 Maximum Entropy 450K pairs 0.902 0.944 0.922 Table 4: Performance of Alignment Classifier 3.2 Paraphrase Acquisition Much recent work on automatic paraphrasing CITATION has used relatively simple statistical techniques to identify text passages that contain the same information from parallel corpora,,
cosine similarity), (2) a set of lexicosemantic features (including WordNet Similarity CITATION, named entity class equality, and part-of-speech equality), and (3) a set of string-based features (such as Levenshtein edit distance and morphological stem equality),,
(CITATION; CITATION)); (2) a combination of language processes that transform questions and candidate answers in logic representations such that reasoning systems can select the correct answer based on their proofs (cf,,
