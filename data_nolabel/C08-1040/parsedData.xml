<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<bodyText confidence="0.557752">
b&apos;Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 313320
</bodyText>
<address confidence="0.73187">
Manchester, August 2008
</address>
<title confidence="0.926407">
Tracking the Dynamic Evolution of Participant Salience in a Discussion
</title>
<author confidence="0.990576">
Ahmed Hassan
</author>
<affiliation confidence="0.999327">
University of Michigan
</affiliation>
<email confidence="0.995865">
hassanam@umich.edu
</email>
<author confidence="0.991139">
Anthony Fader
</author>
<affiliation confidence="0.999416">
University of Michigan
</affiliation>
<email confidence="0.995948">
afader@umich.edu
</email>
<author confidence="0.991696">
Michael H. Crespin
</author>
<affiliation confidence="0.999373">
University of Georgia
</affiliation>
<email confidence="0.995741">
crespin@uga.edu
</email>
<author confidence="0.999232">
Kevin M. Quinn
</author>
<affiliation confidence="0.998159">
Harvard University
</affiliation>
<email confidence="0.99585">
kquinn@fsa.harvard.edu
</email>
<author confidence="0.994626">
Burt L. Monroe
</author>
<affiliation confidence="0.999881">
Pennsylvania State University
</affiliation>
<email confidence="0.994991">
burtmonroe@psu.edu
</email>
<author confidence="0.948145">
Michael Colaresi
</author>
<affiliation confidence="0.998437">
Michigan State University
</affiliation>
<email confidence="0.994931">
colaresi@msu.edu
</email>
<author confidence="0.959968">
Dragomir R. Radev
</author>
<affiliation confidence="0.998956">
University of Michigan
</affiliation>
<email confidence="0.996558">
radev@umich.edu
</email>
<sectionHeader confidence="0.990803" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999108565217391">
We introduce a technique for analyzing the
temporal evolution of the salience of par-
ticipants in a discussion. Our method can
dynamically track how the relative impor-
tance of speakers evolve over time using
graph based techniques. Speaker salience
is computed based on the eigenvector cen-
trality in a graph representation of partici-
pants in a discussion. Two participants in a
discussion are linked with an edge if they
use similar rhetoric. The method is dy-
namic in the sense that the graph evolves
over time to capture the evolution inher-
ent to the participants salience. We used
our method to track the salience of mem-
bers of the US Senate using data from the
US Congressional Record. Our analysis
investigated how the salience of speakers
changes over time. Our results show that
the scores can capture speaker centrality
in topics as well as events that result in
change of salience or influence among dif-
ferent participants.
</bodyText>
<sectionHeader confidence="0.998272" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.994952549019608">
There are several sources of data that record
speeches or participations in debates or discus-
sions among a group of speakers or participants.
Those include parliamentary records, blogs, and
news groups. This data represents a very important
and unexploited source of information that con-
tains several trends and ideas. In any debate or
discussion, there are certain types of persons who
c
2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
influence other people and pass information or ad-
vice to them. Those persons are often regarded
as experts in the field or simply influential peo-
ple and they tend to affect the ideas and rhetoric
of other participants. This effect can be tracked
down by tracking the similarity between different
speeches. We can then imagine a debate with many
people arguing about many different things as a
network of speeches or participations interacting
with each other. We can then try to identify the
most salient or important participants by identify-
ing the most central speeches in this network and
associating them with their speakers. When we
have a large dataset of debates and conversations
that expand over a long period of time, the salience
of participants becomes a dynamic property that
changes over time. To capture this dynamic nature
of the process, the graph of speeches must evolve
over time such that we have a different graph at
each instance of time that reflects the interaction
of speeches at this instant.
We apply our method to the US Congressional
Record. The US Congressional Record documents
everything said and done in the US Congress
House and Senate. The speeches in this data set
are made by a large number of people over a long
period of time. Using political speeches as test
data for the proposed method adds an extra layer
of meaning onto the measure of speakers salience.
Speaker salience of the Congress members can re-
flect the importance or influence in the US leg-
islative process. The way salience scores evolve
over time can answer several interesting issues like
how the influence of the speakers vary with major-
ity status and change of party control. It can also
study the dynamics of the relative distribution of
attention to each topic area in different time peri-
ods.
</bodyText>
<page confidence="0.999309">
313
</page>
<bodyText confidence="0.998303222222222">
\x0cThe rest of this paper will proceed as follows.
Section 2 reviews some related work. In Section 3,
we describe how the data can be clustered into dif-
ferent topic clusters. In Section 4, we describe
our method for computing the salience of different
participant in a discussion, we also describe how
to the network of speakers varies over time. Sec-
tion 5 describes the experimental setup. Finally,
we present the conclusions in Section 6.
</bodyText>
<sectionHeader confidence="0.999615" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999434511111111">
Several methods have been proposed for identify-
ing the most central nodes in a network. Degree
centrality, closeness, and betweenness (Newman,
2003) are among the most known methods for
measuring centrality of nodes in a network. Eigen-
vector centrality is another powerful method that
that has been applied to several types of networks.
For example it has been used to measure cen-
trality in hyperlinked web pages networks (Brin
and Page, 1998; Kleinberg, 1998), lexical net-
works (Erkan and Radev, 2004; Mihalcea and Ta-
rau, 2004; Kurland and Lee, 2005; Kurland and
Lee, 2006), and semantic networks (Mihalcea et
al., 2004).
The interest of applying natural language pro-
cessing techniques in the area of political science
has been recently increasing.
(Quinn et al., 2006) introduce a multinomial
mixture model to cluster political speeches into
topics or related categories. In (Porter et al., 2005),
a network analysis of the members and committees
of the US House of Representatives is performed.
The authors prove that there are connections link-
ing some political positions to certain committees.
This suggests that there are factors affecting com-
mittee membership and that they are not deter-
mined at random. In (Thomas et al., 2006), the au-
thors try to automatically classify speeches, from
the US Congress debates, as supporting or oppos-
ing a given topic by taking advantage of the voting
records of the speakers. (Fader et al., 2007) in-
troduce MavenRank , which is a method based on
lexical centrality that identifies the most influen-
tial members of the US Senate. It computes a sin-
gle salience score for each speaker that is constant
over time.
In this paper, we introduce a new method for
tracking the evolution of the salience of partici-
pants in a discussion over time. Our method is
based on the ones described in (Erkan and Radev,
2004; Mihalcea and Tarau, 2004; Fader et al.,
2007), The objective of this paper is to dynami-
cally rank speakers or participants in a discussion.
The proposed method is dynamic in the sense that
the computed importance varies over time.
</bodyText>
<sectionHeader confidence="0.997478" genericHeader="method">
3 Topic Clusters
</sectionHeader>
<bodyText confidence="0.999693">
Before applying the proposed method to a data
set with speeches in multiple topics, we first need
to divide the speech documents into topic clus-
ters. We used the model described in (Quinn et al.,
2006) for this purpose. The model presented in this
paper assumes that the probabilities of a document
belonging to a certain topic varies smoothly over
time and the words within a given document have
exactly the same probability of being drawn from
a particular topic (Quinn et al., 2006). These two
properties make the model different than standard
mixture models (McLachlan and Peel, 2000) and
the latent Dirichlet allocation model of (Blei et al.,
2003). The model of (Quinn et al., 2006) is most
closely related to the model of (Blei and Lafferty,
2006), who present a generalization of the model
used by (Quinn et al., 2006).
The output from the topic model is a D K
matrix Z where D is the number of speeches , K
is the number of topics and the element zdk repre-
sents the probability of the dth speech being gen-
erated by topic k. We then assign each speech d
to the kth cluster where k = arg maxj zdj. If the
maximum value is not unique, one of the clusters
having the maximum value is arbitrary selected.
</bodyText>
<sectionHeader confidence="0.984371" genericHeader="method">
4 Speaker Centrality
</sectionHeader>
<bodyText confidence="0.998789166666667">
In this section we describe how to build a network
of speeches and use it to identify speaker centrality.
We also describe how to generate different projec-
tions of the network at different times, and how
to use those projection to get dynamic salience
scores.
</bodyText>
<subsectionHeader confidence="0.999906">
4.1 Computing Speaker Salience
</subsectionHeader>
<bodyText confidence="0.998286222222222">
The method we used is similar to the methods de-
scribed in (Erkan and Radev, 2004; Mihalcea and
Tarau, 2004; Kurland and Lee, 2005), which were
originally used for ranking sentences and docu-
ments in extractive summarization and information
retrieval systems.
A collection of speeches can be represented as
a network where similar speeches are linked to
each other. The proposed method is based on
</bodyText>
<page confidence="0.999178">
314
</page>
<bodyText confidence="0.983439814814815">
\x0cthe premise that important speeches tend to be
lexically similar to other important speeches, and
important speeches tend to belong to important
speakers. Hence given a collection of speeches and
a similarity measure, we can build a network and
define the centrality score of a speech recursively
in terms of the scores of other similar speeches.
Later, we can compute the salience of a speaker
as the sum of the centrality measure of all his
speeches.
To measure the similarity between two
speeches, we use the bag-of-words model to repre-
sent each sentence as an N-dimensional vector of
tf-idf scores, where N is the number of all possible
words in the target language. The similarity
between two speeches is then computed using the
cosine similarity between the two vectors.
A vector of term frequencies is used to represent
each speech. Those term frequencies are weighted
according to the relative importance of the given
term in the cluster.
The vectors representing speeches contain term
frequencies (or tf), which are weighted according
to their inverse document frequencies to account
for the relative importance of the given term in the
cluster. The inverse document frequency of a term
w is given by (Sparck-Jones, 1972)
</bodyText>
<equation confidence="0.999446333333333">
idf(w) = log
\x12
N
nw
\x13
(1)
</equation>
<bodyText confidence="0.9985945">
where nw is the number of speeches in the clus-
ter containing the term w, and N is the number of
documents in the cluster. We calculated idf values
specific to each topic, rather than to all speeches.
We preferred to use topic-specific idf values be-
cause the relative importance of words may vary
from one topic to the other.
The tf-idf cosine similarity measure is computed
as the cosine of the angle between the tf-idf vec-
tors. It is defined as follows:
</bodyText>
<equation confidence="0.999414285714286">
P
wu,v tfu(w) tfv(w) idf(w)2
P
wu(tfu(w) idf(w))2
P
wv(tfv(w) idf(w))2
, (2)
</equation>
<bodyText confidence="0.994888857142857">
The choice of tf-idf scores to measure speech
similarity is an arbitrary choice. Some other possi-
ble similarity measures are edit distance, language
models (Kurland and Lee, 2005), or generation
probabilities (Erkan, 2006).
The recursive definition of the score of any
speech s in the speeches network is given by
</bodyText>
<equation confidence="0.996625">
p(s) =
X
tadj[s]
p(t)
deg(t)
(3)
</equation>
<bodyText confidence="0.996214333333333">
where deg(t) is the degree of node t, and adj[s] is
the set of all speeches adjacent to s in the network.
This can be rewritten in matrix notation as:
</bodyText>
<equation confidence="0.795868555555556">
p = pB (4)
where p = (p(s1), p(s2), . . . , p(sN )) and the ma-
trix B is the row normalized similarity matrix of
the graph
B(i, j) =
S(i, j)
P
k S(i, k)
(5)
</equation>
<bodyText confidence="0.977294789473684">
where S(i, j) = sim(si, sj). Equation (4) shows
that the vector of salience scores p is the left eigen-
vector of B with eigenvalue 1.
The matrix B can be thought of as a stochastic
matrix that acts as transition matrix of a Markov
chain. An element X(i, j) of a stochastic matrix
specifies the transition probability from state i to
state j in the corresponding Markov chain. And
the whole process can be seen as a Markovian ran-
dom walk on the speeches graph. To help the ran-
dom walker escape from periodic or disconnected
components, (Brin and Page, 1998) suggests re-
serving a small escape probability at each node
that represents a chance of jumping to any node
in the graph, making the Markov chain irreducible
and aperiodic, which guarantees the existence of
the eigenvector.
Equation (4) can then be rewritten, assuming a
uniform escape probability, as:
</bodyText>
<equation confidence="0.975395">
p = p[dU + (1 d)B] (6)
</equation>
<bodyText confidence="0.9930175">
where N is the total number of nodes, U is a
square matrix with U(i, j) = 1/N for all i, j, and
d is the escape probability chosen in the interval
[0.1, 0.2] (Brin and Page, 1998).
</bodyText>
<subsectionHeader confidence="0.995974">
4.2 Dynamic Salience Scores
</subsectionHeader>
<bodyText confidence="0.927579818181818">
We use the time stamps associated with the data to
compute dynamic salience scores pT (u) that iden-
tify central speakers at some time T. To do this,
we create a speech graph that evolves over time.
Let T be the current date and let u and v be two
speech documents that occur on days tu and tv.
Our goal is to discount the lexical similarity of u
and v based on how far apart they are. One way
to do this is by defining a new similarity measure
s(u, v; T) as:
s(u, v; T) = tf-idf-cosine(u, v) f(u, v; T) (7)
</bodyText>
<page confidence="0.989106">
315
</page>
<bodyText confidence="0.9921856">
\x0cwhere f(u, v; T) is a function taking values in
[0, 1].
If f(u, v; T) = 1 for all u, v, and T, then time is
ignored when calculating similarity and pT (u) =
p(u). On the other hand, suppose we let
</bodyText>
<equation confidence="0.9944102">
f(u, v; T) =
(
1 if tu = tv = T,
0 else.
(8)
</equation>
<bodyText confidence="0.98404419047619">
This removes all edges that link a speech, occur-
ring at some time T, to all other speeches occur-
ring at some time other than T and the ranking al-
gorithm will be run on what is essentially the sub-
graph of documents restricted to time T (although
the isolated speech documents will receive small
non-zero scores because of the escape probability
from Section 4.1). These two cases act as the ex-
treme boundaries of possible functions f: in the
first case time difference has no effect on document
similarity, while in the second case two documents
must occur on the same day to be similar.
We use the following time weight functions in
our experiments. In each case, we assume that the
speeches represented by speech documents u and v
have already occurred, that is, tu, tv T. We will
use the convention that f(u, v; T) = 0 if tu &gt; T
or tv &gt; T for all time weight functions, which
captures the idea that speeches that have not yet
occurred have no influence on the graph at time T.
Also define
</bodyText>
<equation confidence="0.695689">
age(u, v; T) = T min{tu, tv} (9)
</equation>
<bodyText confidence="0.997604333333333">
which gives the age of the oldest speech document
from the pair u, v at time T.
Exponential: Given a parameter a &gt; 0, define
</bodyText>
<equation confidence="0.9888715">
fexp,a(u, v; T) = ea age(u,v;T)
. (10)
</equation>
<bodyText confidence="0.971196222222222">
This function will decrease the impact of sim-
ilarity as time increases in an exponential
fashion. a is a parameter that controls how
fast this happens, where a larger value of a
makes earlier speeches have a small impact
on current scores and a smaller value of a
means that earlier speeches will have a larger
impact on current scores.
Linear: Given b &gt; 0, define
</bodyText>
<equation confidence="0.991813833333333">
flin,d(u, v; T) =
1 1
b age(u, v; T)
if age(u, v; T) b
0 if age(u, v; T) &gt; b
(11)
</equation>
<figureCaption confidence="0.9121545">
Figure 1: The Dynamic boundary cases for Sena-
tor Santorum.
</figureCaption>
<bodyText confidence="0.99353">
This function gives speech documents that
occur at time T full weight and then decreases
their weight linearly towards time T + b,
where it becomes 0.
Boundary: Given d 0, define
</bodyText>
<equation confidence="0.9978772">
fbnd,d(u, v; T) =
(
1 if age(u, v; T) d
0 if age(u, v; T) &gt; d
(12)
</equation>
<bodyText confidence="0.983434789473684">
This function gives speech documents occur-
ring within d days of T the regular tf-idf sim-
ilarity score, but sets the similarity of speech
documents occurring outside of d days to 0.
The case when d = 0 is one of the boundary
cases explained above.
Figure 1 gives an example of different time
weighting functions for Senator Rick Santorum
(R - Pennsylvania) on topic 22 (Abortion) during
1997, the first session of the 105th Congress. The
dashed line shows the case when time has no ef-
fect on similarity (his score is constant over time),
while the solid line shows the case where only
speeches on the current day are considered simi-
lar (his score spikes only on days where he speaks
and is near zero otherwise). The dotted line shows
the case when the influence of older speeches de-
creases exponentially, which is more dynamic than
the first case but smoother than the second case.
</bodyText>
<sectionHeader confidence="0.984183" genericHeader="method">
5 Experiments and Results
</sectionHeader>
<subsectionHeader confidence="0.789721">
5.1 Data
</subsectionHeader>
<bodyText confidence="0.9855695">
We used the United States Congressional Speech
corpus (Monroe et al., 2006) in our experiment.
</bodyText>
<page confidence="0.998588">
316
</page>
<bodyText confidence="0.902713125">
\x0cThis corpus is in XML formatted version of the
electronic United States Congressional Record
from the Library of Congress1. The Congressional
Record is a verbatim transcript of the speeches
made in the US House of Representatives and Sen-
ate and includes tens of thousands of speeches per
year (Monroe et al., 2006). The data we used cover
the period from January 2001 to January 2003.
</bodyText>
<subsectionHeader confidence="0.997817">
5.2 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.998104052631579">
We used results from (Quinn et al., 2006) to get
topic clusters from the data, as described in Sec-
tion 3. The total number of topics was 42. The
average sized topic cluster had several hundred
speech documents (Quinn et al., 2006).
We set up a pipeline using a Perl implementa-
tion of the proposed method We ran it on the topic
clusters and ranked the speakers based on the cen-
trality scores of their speeches. The graph nodes
were speech documents. A speakers score was
determined by the average of the scores of the
speeches given by that speaker. After comparing
the different time weighting function as shown in
Figure 1, we decided to use the exponential time
weight function for all the experiments discussed
below. Exponential time weighting function de-
creases the impact of similarity as time increases
in an exponential fashion. It also allows us to con-
trol the rate of decay using the parameter a.
</bodyText>
<subsectionHeader confidence="0.943983">
5.3 Baseline
</subsectionHeader>
<bodyText confidence="0.999686142857143">
We compare the performance of our system to
a simple baseline that calculates the salience of
a speaker as a weighted count of the number of
times he has spoken. The baseline gives high
weight to recent speeches . The weight decreases
as the speeches gets older. The salience score of a
speaker is calculate as follows:
</bodyText>
<equation confidence="0.994358833333333">
BS(i) =
X
d
d0d
Si
d (13)
</equation>
<bodyText confidence="0.828869833333333">
Where BS(i) is the baseline score of speaker i,
is the discounting factor, d0 is the current date,
and Si
d is the number of speeches made by speaker
i at date d. We used = 0.9 for all our experi-
ments.
</bodyText>
<sectionHeader confidence="0.673434" genericHeader="evaluation">
5.4 Results
</sectionHeader>
<bodyText confidence="0.981326">
One way to evaluate the dynamic salience scores,
is to look at changes when party control of the
</bodyText>
<equation confidence="0.685404">
1
http://thomas.loc.gov
</equation>
<bodyText confidence="0.987171568627451">
chamber switches. Similar to (Hartog and Mon-
roe, 2004), we exploit the party switch made by
Senator Jim Jeffords of Vermont and the result-
ing change in majority control of the Senate dur-
ing the 107th Congress as a quasi-experimental
design. In short, Jeffords announced his switch
on May 24, 2001 from Republican to Independent
status, effective June 6, 2001. Jeffords stated that
he would vote with the Democrats to organize the
Senate, giving the Democrats a one-seat advantage
and change control of the Senate from the Repub-
licans back to the Democrats. This change of ma-
jority status during the 107th Congress allows us
to ignore many of the factors that could potentially
influence dynamic salience scores at the start of a
new congress.
On average, we expect committee chairs or a
member of the majority party to be the most im-
portant speaker on each topic followed by ranking
members or a member of the minority party. If
our measure is capturing dynamics in the central-
ity of Senators, we expect Republicans to be more
central before the Jeffords switch and Democrats
becoming central soon afterwards, assuming the
topic is being discussed on the Senate floor. We
show that the proposed technique captures several
interesting events in the data and also show that the
baseline explained above fails to capture the same
set of events.
Figure 2(a) shows the dynamic salience scores
over time for Senator John McCain (R - Arizona)
and Senator Carl Levin (D - Michigan) on topic
5 (Armed Forces 2) for the 107th Senate. Mc-
Cain was the most salient speaker for this topic
until June 2001. Soon after the change in major-
ity status a switch happened and Levin, the new
chair of Senate Armed Services, replaced McCain
as the most salient speaker. On the other hand,
Figure 2(b) shows the baseline scores for the same
topic and same speakers. We notice here that the
baseline failed to capture the switch of salience
near June 2001.
We can also observe similar behavior in Fig-
ure 3(a). This figure shows how Senate Majority
Leader Trent Lott (R - Mississippi) was the most
salient speaker on topic 35 (Procedural Legisla-
tion) until July 2001. Topic 35 does not map to
a specific committee but rather is related to ma-
neuvering bills through the legislative process on
the floor, a job generally delegated to members in
the Senate leadership. Just after his party gained
</bodyText>
<page confidence="0.996345">
317
</page>
<figure confidence="0.991124551724138">
\x0c0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
Jan01 Mar01 May01 Jul01 Sep01 Nov01 Jan02 Mar02 May02 Jul02 Sep02 Nov02 Jan03
LexRank
Time
Dynamic Lexrank, Senate 107 Armed Forces 2 (Infrastructure), Exponential, a=0.02, th=
MCCAIN
LEVINCARL
(a) Dynamic Lexrank
0
2
4
6
8
10
Jan01 Mar01 May01 Jul01 Sep01 Nov01 Jan02 Mar02 May02 Jul02 Sep02 Nov02 Jan03
LexRank
Time
Baseline, Senate 107 Armed Forces 2 (Infrastructure)
MCCAIN
LEVINCARL
(b) Baseline
</figure>
<figureCaption confidence="0.963936">
Figure 2: The Switch of Speakers Salience near Jun 2001 for Topic 5(Armed Forces 2).
</figureCaption>
<figure confidence="0.994081857142857">
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
Jan01 Mar01 May01 Jul01 Sep01 Nov01 Jan02 Mar02 May02 Jul02 Sep02 Nov02 Jan03
LexRank
Time
Dynamic Lexrank, Senate 107 Procedural 4 (Legislaton 2), Exponential, a=0.02, th=
REID
LOTT
(a) Dynamic Lexrank
0
5
10
15
20
Jan01 Mar01 May01 Jul01 Sep01 Nov01 Jan02 Mar02 May02 Jul02 Sep02 Nov02 Jan03
LexRank
Time
Baseline, Senate 107 Procedural 4 (Legislaton 2)
REID
LOTT
(b) Baseline
</figure>
<figureCaption confidence="0.79645">
Figure 3: The Switch of Speakers Salience near Jun 2001 for Topic 35(Procedural Legislation).
majority status, Senator Harry Reid (D - Nevada)
</figureCaption>
<bodyText confidence="0.989229378378378">
became the most salient speaker for this topic. This
is consistent with Reids switch from Assistant mi-
nority Leader to Assistant majority Leader. Again
the baseline scores for the same topic and speakers
in Figure 3(b) fails to capture the switch.
An even more interesting test would be to check
whether the Democrats in general become more
central than Republicans after the Jeffords switch.
Figure 4(a) shows the normalized sum of the
scores of all the Democrats and all the Republicans
on topic 5 (Armed Forces 2) for the 107th Senate.
The figure shows how the Republicans were most
salient until soon after the Jeffords switch when the
Democrats regained the majority and became more
salient. We even discovered similar behavior when
we studied how the average salience of Democrats
and Republicans change across all topics. This is
shown in Figure 5(a) where we can see that the
Republicans were more salient on average for all
topics until June 2001. Soon after the change in
majority status, Democrats became more central.
Figures 4(b) and 5(b) show the same results using
the baseline system. We notice that the number of
speeches made by the Democrats and the Repub-
licans is very similar in most of the times. Even
when one of the parties has more speeches than
the other, it does not quite reflect the salience of
the speakers or the parties in general.
An alternative approach to evaluate the dynamic
scores is to exploit the cyclical nature of the leg-
islative process as some bills are re-authorized on
a fairly regular time schedule. For example, the
farm bill comes due about every five years. As a
new topic is coming up for debate, we expect the
saliency scores for relevant legislators to increase.
Figure 6 shows the dynamic scores of Senator
Thomas Harkin (D - Iowa), and Senator Richard
</bodyText>
<page confidence="0.973233">
318
</page>
<figure confidence="0.996440666666667">
\x0c0
0.2
0.4
0.6
0.8
1
Jan01 Mar01 May01 Jul01 Sep01 Nov01 Jan02 Mar02 May02 Jul02 Sep02 Nov02 Jan03
LexRank
Time
Dynamic Lexrank, Senate 107 Armed Forces 2
Republicans
Democrats
(a) Dynamic Lexrank
0
5
10
15
20
25
30
Jan01 Mar01 May01 Jul01 Sep01 Nov01 Jan02 Mar02 May02 Jul02 Sep02 Nov02 Jan03
LexRank
Time
Baseline, Senate 107 Armed Forces 2 (Infrastructure)
Democrates
Republicans
(b) Baseline
</figure>
<figureCaption confidence="0.998503">
Figure 4: The Switch of Speakers Salience near Jun 2001 for Topic 5(Armed Forces 2), Republicans vs
</figureCaption>
<figure confidence="0.986258793103449">
Democrats.
10
12
14
16
18
20
Jan01 Mar01 May01 Jul01 Sep01 Nov01 Jan02 Mar02 May02 Jul02 Sep02 Nov02 Jan03
LexRank
Time
Dynamic Lexrank, Senate 107
Republicans
Democrats
(a) Dynamic Lexrank
0
100
200
300
400
500
600
700
Jan01 Mar01 May01 Jul01 Sep01 Nov01 Jan02 Mar02 May02 Jul02 Sep02 Nov02 Jan03
LexRank
Time
Baseline, Senate 107
Democrates
Republicans
(b) Baseline
</figure>
<figureCaption confidence="0.999562">
Figure 5: The Switch of Speakers Salience near Jun 2001 for All Topics, Republicans vs Democrats.
</figureCaption>
<bodyText confidence="0.919500071428571">
Lugar (R - Indiana) during the 107th senate on
topic 24 (Agriculture). The two senators were
identified, by the proposed method, as the most
salient speakers for this topic, as expected, since
they both served as chairmen of the Senate Com-
mittee on Agriculture, Nutrition, and Forestry
when their party was in the majority during the
107th Senate. This committee was in charge of
shepherding the Farm Bill through the Senate. The
scores of both senators on the agriculture topic sig-
nificantly increased starting late 2001 until June
2002. The debate began on the bill starting in
September of 2001 and it was not passed until May
2002.
</bodyText>
<sectionHeader confidence="0.997776" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.997945235294118">
We presented a graph based method for analyz-
ing the temporal evolution of the salience of par-
ticipants in a discussion. We used this method to
track the evolution of salience of speakers in the
US Congressional Record. We showed that the
way salience scores evolve over time can answer
several interesting issues. We tracked how the in-
fluence of the speakers vary with majority status
and change of party control. We also show how
a baseline system that depends on the number of
speeches fails to capture the interesting events cap-
tured by the proposed system. We also studied the
dynamics of the relative distribution of attention to
each topic area in different time periods and cap-
tured the cyclical nature of the legislative process
as some bills are re-authorized on a fairly regular
time schedule.
</bodyText>
<page confidence="0.994313">
319
</page>
<figure confidence="0.997351666666667">
\x0c0
0.1
0.2
0.3
0.4
0.5
Jan01 Mar01 May01 Jul01 Sep01 Nov01 Jan02 Mar02 May02 Jul02 Sep02 Nov02 Jan03
LexRank
Time
Dynamic Lexrank, Senate 107 Agriculture, Exponential, a=0.02, th=
LUGAR
HARKIN
</figure>
<figureCaption confidence="0.675192">
Figure 6: The Farm Bill Discussions on the Rela-
tive Distribution of Attention to Topic 24 (Agricul-
ture).
</figureCaption>
<sectionHeader confidence="0.973368" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9656745">
This paper is based upon work supported by
the National Science Foundation under Grant No.
0527513, DHB: The dynamics of Political Rep-
resentation and Political Rhetoric. Any opinions,
findings, and conclusions or recommendations ex-
pressed in this paper are those of the authors and
do not necessarily reflect the views of the National
Science Foundation.
</bodyText>
<sectionHeader confidence="0.980494" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999531550724638">
Blei, David and John Lafferty. 2006. Dynamic topic
models. In ICML 2006.
Blei, David, Andrew Ng, and Michael Jordan. 2003.
Latent dirichlet allocation. Journal of Machine
Learning Research, 3:9931022.
Brin, Sergey and Lawrence Page. 1998. The anatomy
of a large-scale hypertextual Web search engine.
CNIS, 30(17):107117.
Erkan, Gunes and Dragomir Radev. 2004. Lexrank:
Graph-based centrality as salience in text summa-
rization. Journal of Artificial Intelligence Research
(JAIR).
Erkan, Gunes. 2006. Language model-based document
clustering using random walks. In HLT/NAACL
2006, pages 479486. Association for Computa-
tional Linguistics.
Fader, Anthony, Dragomir Radev, Michael Crespin,
Burt Monroe, Kevin Quinn, and Michael Colaresi.
2007. Mavenrank: Identifying influential members
of the us senate using lexical centrality. In EMNLP
2007.
Hartog, Chris Den and Nathan Monroe. 2004. The
value of majority status: The effect of jeffordss
switch on asset prices of republican and democratic
firms. Legislative Studies Quarterly, 33:6384.
Kleinberg, Jon. 1998. Authoritative sources in a hyper-
linked environment. In the ACM-SIAM Symposium
on Discrete Algorithms, pages 668677.
Kurland, Oren and Lillian Lee. 2005. PageRank with-
out hyperlinks: Structural re-ranking using links in-
duced by language models. In SIGIR 2005, pages
306313.
Kurland, Oren and Lillian Lee. 2006. Respect my au-
thority! HITS without hyperlinks, utilizing cluster-
based language models. In SIGIR 2006, pages 83
90.
McLachlan, Geoffrey and David Peel. 2000. Finite
Mixture Models. New York: Wiley.
Mihalcea, Rada and Paul Tarau. 2004. TextRank:
Bringing order into texts. In EMNLP 2004.
Mihalcea, Rada, Paul Tarau, and Elizabeth Figa. 2004.
Pagerank on semantic networks, with application
to word sense disambiguation. In COLING 2004,
pages 11261132.
Monroe, Burt, Cheryl Monroe, Kevin Quinn, Dragomir
Radev, Michael Crespin, Michael Colaresi, Anthony
Fader, Jacob Balazer, and Steven Abney. 2006.
United states congressional speech corpus. Depart-
ment of Political Science, The Pennsylvania State
University.
Newman, Mark. 2003. A measure of betweenness
centrality based on random walks. Technical Report
cond-mat/0309045, Arxiv.org.
Porter, Mason, Peter Mucha, Miark Newman, and
Casey Warmbrand. 2005. A network analysis of
committees in the U.S. House of Representatives.
PNAS, 102(20).
Quinn, Kevin, Burt Monroe, Michael Colaresi, Michael
Crespin, and Dragomir Radev. 2006. An automated
method of topic-coding legislative speech over time
with application to the 105th-108th U.S. senate. In
Midwest Political Science Association Meeting.
Sparck-Jones, Karen. 1972. A statistical interpretation
of term specificity and its application in retrieval.
Journal of Documentation, 28(1):1120.
Thomas, Matt, Bo Pang, and Lillian Lee. 2006. Get
out the vote: Determining support or opposition from
Congressional floor-debate transcripts. In EMNLP
2006, pages 327335.
</reference>
<page confidence="0.887273">
320
</page>
<figure confidence="0.303252">
\x0c&apos;
</figure>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.614593">
<note confidence="0.7972125">b&apos;Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 313320 Manchester, August 2008</note>
<title confidence="0.99846">Tracking the Dynamic Evolution of Participant Salience in a Discussion</title>
<author confidence="0.999777">Ahmed Hassan</author>
<affiliation confidence="0.999901">University of Michigan</affiliation>
<email confidence="0.999381">hassanam@umich.edu</email>
<author confidence="0.999692">Anthony Fader</author>
<affiliation confidence="0.999916">University of Michigan</affiliation>
<email confidence="0.99941">afader@umich.edu</email>
<author confidence="0.999883">Michael H Crespin</author>
<affiliation confidence="0.99989">University of Georgia</affiliation>
<email confidence="0.999538">crespin@uga.edu</email>
<author confidence="0.99993">Kevin M Quinn</author>
<affiliation confidence="0.999986">Harvard University</affiliation>
<email confidence="0.997957">kquinn@fsa.harvard.edu</email>
<author confidence="0.998918">Burt L Monroe</author>
<affiliation confidence="0.999194">Pennsylvania State University</affiliation>
<email confidence="0.99897">burtmonroe@psu.edu</email>
<author confidence="0.997469">Michael Colaresi</author>
<affiliation confidence="0.99942">Michigan State University</affiliation>
<email confidence="0.998129">colaresi@msu.edu</email>
<author confidence="0.999002">Dragomir R Radev</author>
<affiliation confidence="0.999922">University of Michigan</affiliation>
<email confidence="0.999785">radev@umich.edu</email>
<abstract confidence="0.99712325">We introduce a technique for analyzing the temporal evolution of the salience of participants in a discussion. Our method can dynamically track how the relative importance of speakers evolve over time using graph based techniques. Speaker salience is computed based on the eigenvector centrality in a graph representation of participants in a discussion. Two participants in a discussion are linked with an edge if they use similar rhetoric. The method is dynamic in the sense that the graph evolves over time to capture the evolution inherent to the participants salience. We used our method to track the salience of members of the US Senate using data from the US Congressional Record. Our analysis investigated how the salience of speakers changes over time. Our results show that the scores can capture speaker centrality in topics as well as events that result in change of salience or influence among different participants.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>David Blei</author>
<author>John Lafferty</author>
</authors>
<title>Dynamic topic models.</title>
<date>2006</date>
<booktitle>In ICML</booktitle>
<contexts>
<context position="7239" citStr="Blei and Lafferty, 2006" startWordPosition="1169" endWordPosition="1172">nto topic clusters. We used the model described in (Quinn et al., 2006) for this purpose. The model presented in this paper assumes that the probabilities of a document belonging to a certain topic varies smoothly over time and the words within a given document have exactly the same probability of being drawn from a particular topic (Quinn et al., 2006). These two properties make the model different than standard mixture models (McLachlan and Peel, 2000) and the latent Dirichlet allocation model of (Blei et al., 2003). The model of (Quinn et al., 2006) is most closely related to the model of (Blei and Lafferty, 2006), who present a generalization of the model used by (Quinn et al., 2006). The output from the topic model is a D K matrix Z where D is the number of speeches , K is the number of topics and the element zdk represents the probability of the dth speech being generated by topic k. We then assign each speech d to the kth cluster where k = arg maxj zdj. If the maximum value is not unique, one of the clusters having the maximum value is arbitrary selected. 4 Speaker Centrality In this section we describe how to build a network of speeches and use it to identify speaker centrality. We also describe h</context>
</contexts>
<marker>Blei, Lafferty, 2006</marker>
<rawString>Blei, David and John Lafferty. 2006. Dynamic topic models. In ICML 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Blei</author>
<author>Andrew Ng</author>
<author>Michael Jordan</author>
</authors>
<title>Latent dirichlet allocation.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>3--9931022</pages>
<contexts>
<context position="7138" citStr="Blei et al., 2003" startWordPosition="1150" endWordPosition="1153"> to a data set with speeches in multiple topics, we first need to divide the speech documents into topic clusters. We used the model described in (Quinn et al., 2006) for this purpose. The model presented in this paper assumes that the probabilities of a document belonging to a certain topic varies smoothly over time and the words within a given document have exactly the same probability of being drawn from a particular topic (Quinn et al., 2006). These two properties make the model different than standard mixture models (McLachlan and Peel, 2000) and the latent Dirichlet allocation model of (Blei et al., 2003). The model of (Quinn et al., 2006) is most closely related to the model of (Blei and Lafferty, 2006), who present a generalization of the model used by (Quinn et al., 2006). The output from the topic model is a D K matrix Z where D is the number of speeches , K is the number of topics and the element zdk represents the probability of the dth speech being generated by topic k. We then assign each speech d to the kth cluster where k = arg maxj zdj. If the maximum value is not unique, one of the clusters having the maximum value is arbitrary selected. 4 Speaker Centrality In this section we desc</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>Blei, David, Andrew Ng, and Michael Jordan. 2003. Latent dirichlet allocation. Journal of Machine Learning Research, 3:9931022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergey Brin</author>
<author>Lawrence Page</author>
</authors>
<title>The anatomy of a large-scale hypertextual Web search engine.</title>
<date>1998</date>
<journal>CNIS,</journal>
<volume>30</volume>
<issue>17</issue>
<contexts>
<context position="4832" citStr="Brin and Page, 1998" startWordPosition="763" endWordPosition="766">, we also describe how to the network of speakers varies over time. Section 5 describes the experimental setup. Finally, we present the conclusions in Section 6. 2 Related Work Several methods have been proposed for identifying the most central nodes in a network. Degree centrality, closeness, and betweenness (Newman, 2003) are among the most known methods for measuring centrality of nodes in a network. Eigenvector centrality is another powerful method that that has been applied to several types of networks. For example it has been used to measure centrality in hyperlinked web pages networks (Brin and Page, 1998; Kleinberg, 1998), lexical networks (Erkan and Radev, 2004; Mihalcea and Tarau, 2004; Kurland and Lee, 2005; Kurland and Lee, 2006), and semantic networks (Mihalcea et al., 2004). The interest of applying natural language processing techniques in the area of political science has been recently increasing. (Quinn et al., 2006) introduce a multinomial mixture model to cluster political speeches into topics or related categories. In (Porter et al., 2005), a network analysis of the members and committees of the US House of Representatives is performed. The authors prove that there are connections</context>
<context position="11414" citStr="Brin and Page, 1998" startWordPosition="1911" endWordPosition="1914">similarity matrix of the graph B(i, j) = S(i, j) P k S(i, k) (5) where S(i, j) = sim(si, sj). Equation (4) shows that the vector of salience scores p is the left eigenvector of B with eigenvalue 1. The matrix B can be thought of as a stochastic matrix that acts as transition matrix of a Markov chain. An element X(i, j) of a stochastic matrix specifies the transition probability from state i to state j in the corresponding Markov chain. And the whole process can be seen as a Markovian random walk on the speeches graph. To help the random walker escape from periodic or disconnected components, (Brin and Page, 1998) suggests reserving a small escape probability at each node that represents a chance of jumping to any node in the graph, making the Markov chain irreducible and aperiodic, which guarantees the existence of the eigenvector. Equation (4) can then be rewritten, assuming a uniform escape probability, as: p = p[dU + (1 d)B] (6) where N is the total number of nodes, U is a square matrix with U(i, j) = 1/N for all i, j, and d is the escape probability chosen in the interval [0.1, 0.2] (Brin and Page, 1998). 4.2 Dynamic Salience Scores We use the time stamps associated with the data to compute dynami</context>
</contexts>
<marker>Brin, Page, 1998</marker>
<rawString>Brin, Sergey and Lawrence Page. 1998. The anatomy of a large-scale hypertextual Web search engine. CNIS, 30(17):107117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gunes Erkan</author>
<author>Dragomir Radev</author>
</authors>
<title>Lexrank: Graph-based centrality as salience in text summarization.</title>
<date>2004</date>
<journal>Journal of Artificial Intelligence Research (JAIR).</journal>
<contexts>
<context position="4891" citStr="Erkan and Radev, 2004" startWordPosition="772" endWordPosition="775">over time. Section 5 describes the experimental setup. Finally, we present the conclusions in Section 6. 2 Related Work Several methods have been proposed for identifying the most central nodes in a network. Degree centrality, closeness, and betweenness (Newman, 2003) are among the most known methods for measuring centrality of nodes in a network. Eigenvector centrality is another powerful method that that has been applied to several types of networks. For example it has been used to measure centrality in hyperlinked web pages networks (Brin and Page, 1998; Kleinberg, 1998), lexical networks (Erkan and Radev, 2004; Mihalcea and Tarau, 2004; Kurland and Lee, 2005; Kurland and Lee, 2006), and semantic networks (Mihalcea et al., 2004). The interest of applying natural language processing techniques in the area of political science has been recently increasing. (Quinn et al., 2006) introduce a multinomial mixture model to cluster political speeches into topics or related categories. In (Porter et al., 2005), a network analysis of the members and committees of the US House of Representatives is performed. The authors prove that there are connections linking some political positions to certain committees. Th</context>
<context position="6235" citStr="Erkan and Radev, 2004" startWordPosition="998" endWordPosition="1001"> al., 2006), the authors try to automatically classify speeches, from the US Congress debates, as supporting or opposing a given topic by taking advantage of the voting records of the speakers. (Fader et al., 2007) introduce MavenRank , which is a method based on lexical centrality that identifies the most influential members of the US Senate. It computes a single salience score for each speaker that is constant over time. In this paper, we introduce a new method for tracking the evolution of the salience of participants in a discussion over time. Our method is based on the ones described in (Erkan and Radev, 2004; Mihalcea and Tarau, 2004; Fader et al., 2007), The objective of this paper is to dynamically rank speakers or participants in a discussion. The proposed method is dynamic in the sense that the computed importance varies over time. 3 Topic Clusters Before applying the proposed method to a data set with speeches in multiple topics, we first need to divide the speech documents into topic clusters. We used the model described in (Quinn et al., 2006) for this purpose. The model presented in this paper assumes that the probabilities of a document belonging to a certain topic varies smoothly over t</context>
<context position="8086" citStr="Erkan and Radev, 2004" startWordPosition="1328" endWordPosition="1331">bility of the dth speech being generated by topic k. We then assign each speech d to the kth cluster where k = arg maxj zdj. If the maximum value is not unique, one of the clusters having the maximum value is arbitrary selected. 4 Speaker Centrality In this section we describe how to build a network of speeches and use it to identify speaker centrality. We also describe how to generate different projections of the network at different times, and how to use those projection to get dynamic salience scores. 4.1 Computing Speaker Salience The method we used is similar to the methods described in (Erkan and Radev, 2004; Mihalcea and Tarau, 2004; Kurland and Lee, 2005), which were originally used for ranking sentences and documents in extractive summarization and information retrieval systems. A collection of speeches can be represented as a network where similar speeches are linked to each other. The proposed method is based on 314 \x0cthe premise that important speeches tend to be lexically similar to other important speeches, and important speeches tend to belong to important speakers. Hence given a collection of speeches and a similarity measure, we can build a network and define the centrality score of </context>
</contexts>
<marker>Erkan, Radev, 2004</marker>
<rawString>Erkan, Gunes and Dragomir Radev. 2004. Lexrank: Graph-based centrality as salience in text summarization. Journal of Artificial Intelligence Research (JAIR).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gunes Erkan</author>
</authors>
<title>Language model-based document clustering using random walks.</title>
<date>2006</date>
<booktitle>In HLT/NAACL</booktitle>
<pages>479486</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="10427" citStr="Erkan, 2006" startWordPosition="1718" endWordPosition="1719">lues specific to each topic, rather than to all speeches. We preferred to use topic-specific idf values because the relative importance of words may vary from one topic to the other. The tf-idf cosine similarity measure is computed as the cosine of the angle between the tf-idf vectors. It is defined as follows: P wu,v tfu(w) tfv(w) idf(w)2 P wu(tfu(w) idf(w))2 P wv(tfv(w) idf(w))2 , (2) The choice of tf-idf scores to measure speech similarity is an arbitrary choice. Some other possible similarity measures are edit distance, language models (Kurland and Lee, 2005), or generation probabilities (Erkan, 2006). The recursive definition of the score of any speech s in the speeches network is given by p(s) = X tadj[s] p(t) deg(t) (3) where deg(t) is the degree of node t, and adj[s] is the set of all speeches adjacent to s in the network. This can be rewritten in matrix notation as: p = pB (4) where p = (p(s1), p(s2), . . . , p(sN )) and the matrix B is the row normalized similarity matrix of the graph B(i, j) = S(i, j) P k S(i, k) (5) where S(i, j) = sim(si, sj). Equation (4) shows that the vector of salience scores p is the left eigenvector of B with eigenvalue 1. The matrix B can be thought of as a</context>
</contexts>
<marker>Erkan, 2006</marker>
<rawString>Erkan, Gunes. 2006. Language model-based document clustering using random walks. In HLT/NAACL 2006, pages 479486. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anthony Fader</author>
<author>Dragomir Radev</author>
<author>Michael Crespin</author>
<author>Burt Monroe</author>
<author>Kevin Quinn</author>
<author>Michael Colaresi</author>
</authors>
<title>Mavenrank: Identifying influential members of the us senate using lexical centrality.</title>
<date>2007</date>
<booktitle>In EMNLP</booktitle>
<contexts>
<context position="5828" citStr="Fader et al., 2007" startWordPosition="924" endWordPosition="927"> political speeches into topics or related categories. In (Porter et al., 2005), a network analysis of the members and committees of the US House of Representatives is performed. The authors prove that there are connections linking some political positions to certain committees. This suggests that there are factors affecting committee membership and that they are not determined at random. In (Thomas et al., 2006), the authors try to automatically classify speeches, from the US Congress debates, as supporting or opposing a given topic by taking advantage of the voting records of the speakers. (Fader et al., 2007) introduce MavenRank , which is a method based on lexical centrality that identifies the most influential members of the US Senate. It computes a single salience score for each speaker that is constant over time. In this paper, we introduce a new method for tracking the evolution of the salience of participants in a discussion over time. Our method is based on the ones described in (Erkan and Radev, 2004; Mihalcea and Tarau, 2004; Fader et al., 2007), The objective of this paper is to dynamically rank speakers or participants in a discussion. The proposed method is dynamic in the sense that th</context>
</contexts>
<marker>Fader, Radev, Crespin, Monroe, Quinn, Colaresi, 2007</marker>
<rawString>Fader, Anthony, Dragomir Radev, Michael Crespin, Burt Monroe, Kevin Quinn, and Michael Colaresi. 2007. Mavenrank: Identifying influential members of the us senate using lexical centrality. In EMNLP 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Den and Nathan Monroe Hartog</author>
</authors>
<title>The value of majority status: The effect of jeffordss switch on asset prices of republican and democratic firms. Legislative Studies Quarterly,</title>
<date>2004</date>
<pages>33--6384</pages>
<marker>Hartog, 2004</marker>
<rawString>Hartog, Chris Den and Nathan Monroe. 2004. The value of majority status: The effect of jeffordss switch on asset prices of republican and democratic firms. Legislative Studies Quarterly, 33:6384.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jon Kleinberg</author>
</authors>
<title>Authoritative sources in a hyperlinked environment.</title>
<date>1998</date>
<booktitle>In the ACM-SIAM Symposium on Discrete Algorithms,</booktitle>
<pages>668677</pages>
<contexts>
<context position="4850" citStr="Kleinberg, 1998" startWordPosition="767" endWordPosition="768">w to the network of speakers varies over time. Section 5 describes the experimental setup. Finally, we present the conclusions in Section 6. 2 Related Work Several methods have been proposed for identifying the most central nodes in a network. Degree centrality, closeness, and betweenness (Newman, 2003) are among the most known methods for measuring centrality of nodes in a network. Eigenvector centrality is another powerful method that that has been applied to several types of networks. For example it has been used to measure centrality in hyperlinked web pages networks (Brin and Page, 1998; Kleinberg, 1998), lexical networks (Erkan and Radev, 2004; Mihalcea and Tarau, 2004; Kurland and Lee, 2005; Kurland and Lee, 2006), and semantic networks (Mihalcea et al., 2004). The interest of applying natural language processing techniques in the area of political science has been recently increasing. (Quinn et al., 2006) introduce a multinomial mixture model to cluster political speeches into topics or related categories. In (Porter et al., 2005), a network analysis of the members and committees of the US House of Representatives is performed. The authors prove that there are connections linking some poli</context>
</contexts>
<marker>Kleinberg, 1998</marker>
<rawString>Kleinberg, Jon. 1998. Authoritative sources in a hyperlinked environment. In the ACM-SIAM Symposium on Discrete Algorithms, pages 668677.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oren Kurland</author>
<author>Lillian Lee</author>
</authors>
<title>PageRank without hyperlinks: Structural re-ranking using links induced by language models.</title>
<date>2005</date>
<booktitle>In SIGIR</booktitle>
<pages>306313</pages>
<contexts>
<context position="4940" citStr="Kurland and Lee, 2005" startWordPosition="781" endWordPosition="784">etup. Finally, we present the conclusions in Section 6. 2 Related Work Several methods have been proposed for identifying the most central nodes in a network. Degree centrality, closeness, and betweenness (Newman, 2003) are among the most known methods for measuring centrality of nodes in a network. Eigenvector centrality is another powerful method that that has been applied to several types of networks. For example it has been used to measure centrality in hyperlinked web pages networks (Brin and Page, 1998; Kleinberg, 1998), lexical networks (Erkan and Radev, 2004; Mihalcea and Tarau, 2004; Kurland and Lee, 2005; Kurland and Lee, 2006), and semantic networks (Mihalcea et al., 2004). The interest of applying natural language processing techniques in the area of political science has been recently increasing. (Quinn et al., 2006) introduce a multinomial mixture model to cluster political speeches into topics or related categories. In (Porter et al., 2005), a network analysis of the members and committees of the US House of Representatives is performed. The authors prove that there are connections linking some political positions to certain committees. This suggests that there are factors affecting comm</context>
<context position="8136" citStr="Kurland and Lee, 2005" startWordPosition="1336" endWordPosition="1339"> k. We then assign each speech d to the kth cluster where k = arg maxj zdj. If the maximum value is not unique, one of the clusters having the maximum value is arbitrary selected. 4 Speaker Centrality In this section we describe how to build a network of speeches and use it to identify speaker centrality. We also describe how to generate different projections of the network at different times, and how to use those projection to get dynamic salience scores. 4.1 Computing Speaker Salience The method we used is similar to the methods described in (Erkan and Radev, 2004; Mihalcea and Tarau, 2004; Kurland and Lee, 2005), which were originally used for ranking sentences and documents in extractive summarization and information retrieval systems. A collection of speeches can be represented as a network where similar speeches are linked to each other. The proposed method is based on 314 \x0cthe premise that important speeches tend to be lexically similar to other important speeches, and important speeches tend to belong to important speakers. Hence given a collection of speeches and a similarity measure, we can build a network and define the centrality score of a speech recursively in terms of the scores of oth</context>
<context position="10384" citStr="Kurland and Lee, 2005" startWordPosition="1711" endWordPosition="1714">ber of documents in the cluster. We calculated idf values specific to each topic, rather than to all speeches. We preferred to use topic-specific idf values because the relative importance of words may vary from one topic to the other. The tf-idf cosine similarity measure is computed as the cosine of the angle between the tf-idf vectors. It is defined as follows: P wu,v tfu(w) tfv(w) idf(w)2 P wu(tfu(w) idf(w))2 P wv(tfv(w) idf(w))2 , (2) The choice of tf-idf scores to measure speech similarity is an arbitrary choice. Some other possible similarity measures are edit distance, language models (Kurland and Lee, 2005), or generation probabilities (Erkan, 2006). The recursive definition of the score of any speech s in the speeches network is given by p(s) = X tadj[s] p(t) deg(t) (3) where deg(t) is the degree of node t, and adj[s] is the set of all speeches adjacent to s in the network. This can be rewritten in matrix notation as: p = pB (4) where p = (p(s1), p(s2), . . . , p(sN )) and the matrix B is the row normalized similarity matrix of the graph B(i, j) = S(i, j) P k S(i, k) (5) where S(i, j) = sim(si, sj). Equation (4) shows that the vector of salience scores p is the left eigenvector of B with eigenv</context>
</contexts>
<marker>Kurland, Lee, 2005</marker>
<rawString>Kurland, Oren and Lillian Lee. 2005. PageRank without hyperlinks: Structural re-ranking using links induced by language models. In SIGIR 2005, pages 306313.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oren Kurland</author>
<author>Lillian Lee</author>
</authors>
<title>Respect my authority! HITS without hyperlinks, utilizing clusterbased language models.</title>
<date>2006</date>
<booktitle>In SIGIR</booktitle>
<pages>83--90</pages>
<contexts>
<context position="4964" citStr="Kurland and Lee, 2006" startWordPosition="785" endWordPosition="788">nt the conclusions in Section 6. 2 Related Work Several methods have been proposed for identifying the most central nodes in a network. Degree centrality, closeness, and betweenness (Newman, 2003) are among the most known methods for measuring centrality of nodes in a network. Eigenvector centrality is another powerful method that that has been applied to several types of networks. For example it has been used to measure centrality in hyperlinked web pages networks (Brin and Page, 1998; Kleinberg, 1998), lexical networks (Erkan and Radev, 2004; Mihalcea and Tarau, 2004; Kurland and Lee, 2005; Kurland and Lee, 2006), and semantic networks (Mihalcea et al., 2004). The interest of applying natural language processing techniques in the area of political science has been recently increasing. (Quinn et al., 2006) introduce a multinomial mixture model to cluster political speeches into topics or related categories. In (Porter et al., 2005), a network analysis of the members and committees of the US House of Representatives is performed. The authors prove that there are connections linking some political positions to certain committees. This suggests that there are factors affecting committee membership and tha</context>
</contexts>
<marker>Kurland, Lee, 2006</marker>
<rawString>Kurland, Oren and Lillian Lee. 2006. Respect my authority! HITS without hyperlinks, utilizing clusterbased language models. In SIGIR 2006, pages 83 90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geoffrey McLachlan</author>
<author>David Peel</author>
</authors>
<title>Finite Mixture Models.</title>
<date>2000</date>
<publisher>Wiley.</publisher>
<location>New York:</location>
<contexts>
<context position="7073" citStr="McLachlan and Peel, 2000" startWordPosition="1139" endWordPosition="1142">e varies over time. 3 Topic Clusters Before applying the proposed method to a data set with speeches in multiple topics, we first need to divide the speech documents into topic clusters. We used the model described in (Quinn et al., 2006) for this purpose. The model presented in this paper assumes that the probabilities of a document belonging to a certain topic varies smoothly over time and the words within a given document have exactly the same probability of being drawn from a particular topic (Quinn et al., 2006). These two properties make the model different than standard mixture models (McLachlan and Peel, 2000) and the latent Dirichlet allocation model of (Blei et al., 2003). The model of (Quinn et al., 2006) is most closely related to the model of (Blei and Lafferty, 2006), who present a generalization of the model used by (Quinn et al., 2006). The output from the topic model is a D K matrix Z where D is the number of speeches , K is the number of topics and the element zdk represents the probability of the dth speech being generated by topic k. We then assign each speech d to the kth cluster where k = arg maxj zdj. If the maximum value is not unique, one of the clusters having the maximum value is</context>
</contexts>
<marker>McLachlan, Peel, 2000</marker>
<rawString>McLachlan, Geoffrey and David Peel. 2000. Finite Mixture Models. New York: Wiley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Paul Tarau</author>
</authors>
<title>TextRank: Bringing order into texts.</title>
<date>2004</date>
<booktitle>In EMNLP</booktitle>
<contexts>
<context position="4917" citStr="Mihalcea and Tarau, 2004" startWordPosition="776" endWordPosition="780">scribes the experimental setup. Finally, we present the conclusions in Section 6. 2 Related Work Several methods have been proposed for identifying the most central nodes in a network. Degree centrality, closeness, and betweenness (Newman, 2003) are among the most known methods for measuring centrality of nodes in a network. Eigenvector centrality is another powerful method that that has been applied to several types of networks. For example it has been used to measure centrality in hyperlinked web pages networks (Brin and Page, 1998; Kleinberg, 1998), lexical networks (Erkan and Radev, 2004; Mihalcea and Tarau, 2004; Kurland and Lee, 2005; Kurland and Lee, 2006), and semantic networks (Mihalcea et al., 2004). The interest of applying natural language processing techniques in the area of political science has been recently increasing. (Quinn et al., 2006) introduce a multinomial mixture model to cluster political speeches into topics or related categories. In (Porter et al., 2005), a network analysis of the members and committees of the US House of Representatives is performed. The authors prove that there are connections linking some political positions to certain committees. This suggests that there are</context>
<context position="6261" citStr="Mihalcea and Tarau, 2004" startWordPosition="1002" endWordPosition="1005">s try to automatically classify speeches, from the US Congress debates, as supporting or opposing a given topic by taking advantage of the voting records of the speakers. (Fader et al., 2007) introduce MavenRank , which is a method based on lexical centrality that identifies the most influential members of the US Senate. It computes a single salience score for each speaker that is constant over time. In this paper, we introduce a new method for tracking the evolution of the salience of participants in a discussion over time. Our method is based on the ones described in (Erkan and Radev, 2004; Mihalcea and Tarau, 2004; Fader et al., 2007), The objective of this paper is to dynamically rank speakers or participants in a discussion. The proposed method is dynamic in the sense that the computed importance varies over time. 3 Topic Clusters Before applying the proposed method to a data set with speeches in multiple topics, we first need to divide the speech documents into topic clusters. We used the model described in (Quinn et al., 2006) for this purpose. The model presented in this paper assumes that the probabilities of a document belonging to a certain topic varies smoothly over time and the words within a</context>
<context position="8112" citStr="Mihalcea and Tarau, 2004" startWordPosition="1332" endWordPosition="1335">h being generated by topic k. We then assign each speech d to the kth cluster where k = arg maxj zdj. If the maximum value is not unique, one of the clusters having the maximum value is arbitrary selected. 4 Speaker Centrality In this section we describe how to build a network of speeches and use it to identify speaker centrality. We also describe how to generate different projections of the network at different times, and how to use those projection to get dynamic salience scores. 4.1 Computing Speaker Salience The method we used is similar to the methods described in (Erkan and Radev, 2004; Mihalcea and Tarau, 2004; Kurland and Lee, 2005), which were originally used for ranking sentences and documents in extractive summarization and information retrieval systems. A collection of speeches can be represented as a network where similar speeches are linked to each other. The proposed method is based on 314 \x0cthe premise that important speeches tend to be lexically similar to other important speeches, and important speeches tend to belong to important speakers. Hence given a collection of speeches and a similarity measure, we can build a network and define the centrality score of a speech recursively in te</context>
</contexts>
<marker>Mihalcea, Tarau, 2004</marker>
<rawString>Mihalcea, Rada and Paul Tarau. 2004. TextRank: Bringing order into texts. In EMNLP 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Paul Tarau</author>
<author>Elizabeth Figa</author>
</authors>
<date>2004</date>
<contexts>
<context position="5011" citStr="Mihalcea et al., 2004" startWordPosition="792" endWordPosition="795"> Several methods have been proposed for identifying the most central nodes in a network. Degree centrality, closeness, and betweenness (Newman, 2003) are among the most known methods for measuring centrality of nodes in a network. Eigenvector centrality is another powerful method that that has been applied to several types of networks. For example it has been used to measure centrality in hyperlinked web pages networks (Brin and Page, 1998; Kleinberg, 1998), lexical networks (Erkan and Radev, 2004; Mihalcea and Tarau, 2004; Kurland and Lee, 2005; Kurland and Lee, 2006), and semantic networks (Mihalcea et al., 2004). The interest of applying natural language processing techniques in the area of political science has been recently increasing. (Quinn et al., 2006) introduce a multinomial mixture model to cluster political speeches into topics or related categories. In (Porter et al., 2005), a network analysis of the members and committees of the US House of Representatives is performed. The authors prove that there are connections linking some political positions to certain committees. This suggests that there are factors affecting committee membership and that they are not determined at random. In (Thomas</context>
</contexts>
<marker>Mihalcea, Tarau, Figa, 2004</marker>
<rawString>Mihalcea, Rada, Paul Tarau, and Elizabeth Figa. 2004.</rawString>
</citation>
<citation valid="true">
<title>Pagerank on semantic networks, with application to word sense disambiguation.</title>
<date>2004</date>
<booktitle>In COLING</booktitle>
<pages>11261132</pages>
<marker>2004</marker>
<rawString>Pagerank on semantic networks, with application to word sense disambiguation. In COLING 2004, pages 11261132.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Burt Monroe</author>
<author>Cheryl Monroe</author>
<author>Kevin Quinn</author>
<author>Dragomir Radev</author>
<author>Michael Crespin</author>
<author>Michael Colaresi</author>
<author>Anthony Fader</author>
<author>Jacob Balazer</author>
<author>Steven Abney</author>
</authors>
<title>United states congressional speech corpus.</title>
<date>2006</date>
<institution>Department of Political Science, The Pennsylvania State University.</institution>
<contexts>
<context position="15637" citStr="Monroe et al., 2006" startWordPosition="2722" endWordPosition="2725">ortion) during 1997, the first session of the 105th Congress. The dashed line shows the case when time has no effect on similarity (his score is constant over time), while the solid line shows the case where only speeches on the current day are considered similar (his score spikes only on days where he speaks and is near zero otherwise). The dotted line shows the case when the influence of older speeches decreases exponentially, which is more dynamic than the first case but smoother than the second case. 5 Experiments and Results 5.1 Data We used the United States Congressional Speech corpus (Monroe et al., 2006) in our experiment. 316 \x0cThis corpus is in XML formatted version of the electronic United States Congressional Record from the Library of Congress1. The Congressional Record is a verbatim transcript of the speeches made in the US House of Representatives and Senate and includes tens of thousands of speeches per year (Monroe et al., 2006). The data we used cover the period from January 2001 to January 2003. 5.2 Experimental Setup We used results from (Quinn et al., 2006) to get topic clusters from the data, as described in Section 3. The total number of topics was 42. The average sized topic</context>
</contexts>
<marker>Monroe, Monroe, Quinn, Radev, Crespin, Colaresi, Fader, Balazer, Abney, 2006</marker>
<rawString>Monroe, Burt, Cheryl Monroe, Kevin Quinn, Dragomir Radev, Michael Crespin, Michael Colaresi, Anthony Fader, Jacob Balazer, and Steven Abney. 2006. United states congressional speech corpus. Department of Political Science, The Pennsylvania State University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Newman</author>
</authors>
<title>A measure of betweenness centrality based on random walks.</title>
<date>2003</date>
<tech>Technical Report cond-mat/0309045, Arxiv.org.</tech>
<contexts>
<context position="4538" citStr="Newman, 2003" startWordPosition="715" endWordPosition="716">ds. 313 \x0cThe rest of this paper will proceed as follows. Section 2 reviews some related work. In Section 3, we describe how the data can be clustered into different topic clusters. In Section 4, we describe our method for computing the salience of different participant in a discussion, we also describe how to the network of speakers varies over time. Section 5 describes the experimental setup. Finally, we present the conclusions in Section 6. 2 Related Work Several methods have been proposed for identifying the most central nodes in a network. Degree centrality, closeness, and betweenness (Newman, 2003) are among the most known methods for measuring centrality of nodes in a network. Eigenvector centrality is another powerful method that that has been applied to several types of networks. For example it has been used to measure centrality in hyperlinked web pages networks (Brin and Page, 1998; Kleinberg, 1998), lexical networks (Erkan and Radev, 2004; Mihalcea and Tarau, 2004; Kurland and Lee, 2005; Kurland and Lee, 2006), and semantic networks (Mihalcea et al., 2004). The interest of applying natural language processing techniques in the area of political science has been recently increasing</context>
</contexts>
<marker>Newman, 2003</marker>
<rawString>Newman, Mark. 2003. A measure of betweenness centrality based on random walks. Technical Report cond-mat/0309045, Arxiv.org.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mason Porter</author>
<author>Peter Mucha</author>
<author>Miark Newman</author>
<author>Casey Warmbrand</author>
</authors>
<title>A network analysis of committees in the U.S. House of Representatives.</title>
<date>2005</date>
<journal>PNAS,</journal>
<volume>102</volume>
<issue>20</issue>
<contexts>
<context position="5288" citStr="Porter et al., 2005" startWordPosition="834" endWordPosition="837">d that that has been applied to several types of networks. For example it has been used to measure centrality in hyperlinked web pages networks (Brin and Page, 1998; Kleinberg, 1998), lexical networks (Erkan and Radev, 2004; Mihalcea and Tarau, 2004; Kurland and Lee, 2005; Kurland and Lee, 2006), and semantic networks (Mihalcea et al., 2004). The interest of applying natural language processing techniques in the area of political science has been recently increasing. (Quinn et al., 2006) introduce a multinomial mixture model to cluster political speeches into topics or related categories. In (Porter et al., 2005), a network analysis of the members and committees of the US House of Representatives is performed. The authors prove that there are connections linking some political positions to certain committees. This suggests that there are factors affecting committee membership and that they are not determined at random. In (Thomas et al., 2006), the authors try to automatically classify speeches, from the US Congress debates, as supporting or opposing a given topic by taking advantage of the voting records of the speakers. (Fader et al., 2007) introduce MavenRank , which is a method based on lexical ce</context>
</contexts>
<marker>Porter, Mucha, Newman, Warmbrand, 2005</marker>
<rawString>Porter, Mason, Peter Mucha, Miark Newman, and Casey Warmbrand. 2005. A network analysis of committees in the U.S. House of Representatives. PNAS, 102(20).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Quinn</author>
<author>Burt Monroe</author>
<author>Michael Colaresi</author>
<author>Michael Crespin</author>
<author>Dragomir Radev</author>
</authors>
<title>An automated method of topic-coding legislative speech over time with application to the 105th-108th U.S. senate.</title>
<date>2006</date>
<booktitle>In Midwest Political Science Association Meeting.</booktitle>
<contexts>
<context position="5160" citStr="Quinn et al., 2006" startWordPosition="815" endWordPosition="818">e among the most known methods for measuring centrality of nodes in a network. Eigenvector centrality is another powerful method that that has been applied to several types of networks. For example it has been used to measure centrality in hyperlinked web pages networks (Brin and Page, 1998; Kleinberg, 1998), lexical networks (Erkan and Radev, 2004; Mihalcea and Tarau, 2004; Kurland and Lee, 2005; Kurland and Lee, 2006), and semantic networks (Mihalcea et al., 2004). The interest of applying natural language processing techniques in the area of political science has been recently increasing. (Quinn et al., 2006) introduce a multinomial mixture model to cluster political speeches into topics or related categories. In (Porter et al., 2005), a network analysis of the members and committees of the US House of Representatives is performed. The authors prove that there are connections linking some political positions to certain committees. This suggests that there are factors affecting committee membership and that they are not determined at random. In (Thomas et al., 2006), the authors try to automatically classify speeches, from the US Congress debates, as supporting or opposing a given topic by taking a</context>
<context position="6686" citStr="Quinn et al., 2006" startWordPosition="1076" endWordPosition="1079">e a new method for tracking the evolution of the salience of participants in a discussion over time. Our method is based on the ones described in (Erkan and Radev, 2004; Mihalcea and Tarau, 2004; Fader et al., 2007), The objective of this paper is to dynamically rank speakers or participants in a discussion. The proposed method is dynamic in the sense that the computed importance varies over time. 3 Topic Clusters Before applying the proposed method to a data set with speeches in multiple topics, we first need to divide the speech documents into topic clusters. We used the model described in (Quinn et al., 2006) for this purpose. The model presented in this paper assumes that the probabilities of a document belonging to a certain topic varies smoothly over time and the words within a given document have exactly the same probability of being drawn from a particular topic (Quinn et al., 2006). These two properties make the model different than standard mixture models (McLachlan and Peel, 2000) and the latent Dirichlet allocation model of (Blei et al., 2003). The model of (Quinn et al., 2006) is most closely related to the model of (Blei and Lafferty, 2006), who present a generalization of the model use</context>
<context position="16114" citStr="Quinn et al., 2006" startWordPosition="2802" endWordPosition="2805"> smoother than the second case. 5 Experiments and Results 5.1 Data We used the United States Congressional Speech corpus (Monroe et al., 2006) in our experiment. 316 \x0cThis corpus is in XML formatted version of the electronic United States Congressional Record from the Library of Congress1. The Congressional Record is a verbatim transcript of the speeches made in the US House of Representatives and Senate and includes tens of thousands of speeches per year (Monroe et al., 2006). The data we used cover the period from January 2001 to January 2003. 5.2 Experimental Setup We used results from (Quinn et al., 2006) to get topic clusters from the data, as described in Section 3. The total number of topics was 42. The average sized topic cluster had several hundred speech documents (Quinn et al., 2006). We set up a pipeline using a Perl implementation of the proposed method We ran it on the topic clusters and ranked the speakers based on the centrality scores of their speeches. The graph nodes were speech documents. A speakers score was determined by the average of the scores of the speeches given by that speaker. After comparing the different time weighting function as shown in Figure 1, we decided to us</context>
</contexts>
<marker>Quinn, Monroe, Colaresi, Crespin, Radev, 2006</marker>
<rawString>Quinn, Kevin, Burt Monroe, Michael Colaresi, Michael Crespin, and Dragomir Radev. 2006. An automated method of topic-coding legislative speech over time with application to the 105th-108th U.S. senate. In Midwest Political Science Association Meeting.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karen Sparck-Jones</author>
</authors>
<title>A statistical interpretation of term specificity and its application in retrieval.</title>
<date>1972</date>
<contexts>
<context position="9640" citStr="Sparck-Jones, 1972" startWordPosition="1581" endWordPosition="1582">is the number of all possible words in the target language. The similarity between two speeches is then computed using the cosine similarity between the two vectors. A vector of term frequencies is used to represent each speech. Those term frequencies are weighted according to the relative importance of the given term in the cluster. The vectors representing speeches contain term frequencies (or tf), which are weighted according to their inverse document frequencies to account for the relative importance of the given term in the cluster. The inverse document frequency of a term w is given by (Sparck-Jones, 1972) idf(w) = log \x12 N nw \x13 (1) where nw is the number of speeches in the cluster containing the term w, and N is the number of documents in the cluster. We calculated idf values specific to each topic, rather than to all speeches. We preferred to use topic-specific idf values because the relative importance of words may vary from one topic to the other. The tf-idf cosine similarity measure is computed as the cosine of the angle between the tf-idf vectors. It is defined as follows: P wu,v tfu(w) tfv(w) idf(w)2 P wu(tfu(w) idf(w))2 P wv(tfv(w) idf(w))2 , (2) The choice of tf-idf scores to meas</context>
</contexts>
<marker>Sparck-Jones, 1972</marker>
<rawString>Sparck-Jones, Karen. 1972. A statistical interpretation of term specificity and its application in retrieval.</rawString>
</citation>
<citation valid="false">
<journal>Journal of Documentation,</journal>
<volume>28</volume>
<issue>1</issue>
<marker></marker>
<rawString>Journal of Documentation, 28(1):1120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matt Thomas</author>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Get out the vote: Determining support or opposition from Congressional floor-debate transcripts. In EMNLP</title>
<date>2006</date>
<pages>327335</pages>
<contexts>
<context position="5625" citStr="Thomas et al., 2006" startWordPosition="889" endWordPosition="892"> 2004). The interest of applying natural language processing techniques in the area of political science has been recently increasing. (Quinn et al., 2006) introduce a multinomial mixture model to cluster political speeches into topics or related categories. In (Porter et al., 2005), a network analysis of the members and committees of the US House of Representatives is performed. The authors prove that there are connections linking some political positions to certain committees. This suggests that there are factors affecting committee membership and that they are not determined at random. In (Thomas et al., 2006), the authors try to automatically classify speeches, from the US Congress debates, as supporting or opposing a given topic by taking advantage of the voting records of the speakers. (Fader et al., 2007) introduce MavenRank , which is a method based on lexical centrality that identifies the most influential members of the US Senate. It computes a single salience score for each speaker that is constant over time. In this paper, we introduce a new method for tracking the evolution of the salience of participants in a discussion over time. Our method is based on the ones described in (Erkan and R</context>
</contexts>
<marker>Thomas, Pang, Lee, 2006</marker>
<rawString>Thomas, Matt, Bo Pang, and Lillian Lee. 2006. Get out the vote: Determining support or opposition from Congressional floor-debate transcripts. In EMNLP 2006, pages 327335.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>