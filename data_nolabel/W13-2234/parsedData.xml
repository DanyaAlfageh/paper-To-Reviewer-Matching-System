<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<affiliation confidence="0.155965">
b&amp;apos;Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 271280,
</affiliation>
<address confidence="0.459037">
Sofia, Bulgaria, August 8-9, 2013 c
</address>
<title confidence="0.733825333333333">
2013 Association for Computational Linguistics
Generating English Determiners in Phrase-Based Translation with
Synthetic Translation Options
</title>
<author confidence="0.917495">
Yulia Tsvetkov Chris Dyer Lori Levin Archna Bhatia
</author>
<affiliation confidence="0.956134">
Language Technologies Institute
Carnegie Mellon University
</affiliation>
<address confidence="0.931798">
Pittspurgh, PA, 15213, USA
</address>
<email confidence="0.984449">
{ytsvetko, cdyer, lsl, archna}@cs.cmu.edu
</email>
<sectionHeader confidence="0.990696" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9987786">
We propose a technique for improving
the quality of phrase-based translation
systems by creating synthetic translation
optionsphrasal translations that are gen-
erated by auxiliary translation and post-
editing processesto augment the de-
fault phrase inventory learned from par-
allel data. We apply our technique to
the problem of producing English deter-
miners when translating from Russian and
Czech, languages that lack definiteness
morphemes. Our approach augments the
English side of the phrase table using a
classifier to predict where English arti-
cles might plausibly be added or removed,
and then we decode as usual. Doing
so, we obtain significant improvements in
quality relative to a standard phrase-based
baseline and to a to post-editing complete
translations with the classifier.
</bodyText>
<sectionHeader confidence="0.998014" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998813979166667">
Phrase-based translation works as follows. A set
of candidate translations for an input sentence is
created by matching contiguous spans of the in-
put against an inventory of phrasal translations,
reordering them into a target-language appropri-
ate order, and choosing the best one according to a
discriminative model that combines features of the
phrases used, reordering patterns, and target lan-
guage model (Koehn et al., 2003). This relatively
simple approach to translation can be remarkably
effective, and, since its introduction, it has been
the basis for further innovations, including devel-
oping better models for distinguishing the good
translations from bad ones (Chiang, 2012; Gim-
pel and Smith, 2012; Cherry and Foster, 2012;
Eidelman et al., 2013), improving the identifica-
tion of phrase pairs in parallel data (DeNero et al.,
2008; DeNero and Klein, 2010), and formal gen-
eralizations to gapped rules and rich nonterminal
types (Chiang, 2007; Galley et al., 2006). This
paper proposes a different mechanism for improv-
ing phrase-based translation: the use of synthetic
translation options to supplement the standard
phrasal inventory used in phrase-based translation
systems.
In the following, we argue that phrase tables ac-
quired in usual way will be expected to have gaps
in their coverage in certain language pairs and
that supplementing these with synthetic translation
options is a priori preferable to alternative tech-
niques, such as post processing, for generalizing
beyond the translation pairs observable in training
data (2). As a case study, we consider the prob-
lem of producing English definite/indefinite arti-
cles (the, a, and an) when translating from Russian
and Czech, two languages that lack overt definite-
ness morphemes (3). We develop a classifier that
predicts the presence and absence of English arti-
cles (4). This classifier is used to generate syn-
thetic translation options that are used to augment
phrase tables used the usual way (5). We eval-
uate their performance relative to post-processing
approach and to a baseline phrase-based system,
finding that synthetic translation options reliably
outperform the other approaches (6). We then
discuss how our approach relates to previous work
(7) and conclude by discussing further applica-
tions of our technique (8).
</bodyText>
<sectionHeader confidence="0.963976" genericHeader="method">
2 Why Synthetic Translation Options?
</sectionHeader>
<bodyText confidence="0.995992333333333">
Before turning to the problem of generating En-
glish articles, we give arguments for why syn-
thetic translation options are a useful extension of
</bodyText>
<page confidence="0.991655">
271
</page>
<bodyText confidence="0.9980415">
\x0cstandard phrase-based translation approaches, and
why this technique might be better than some al-
ternative proposals that been made for generaliz-
ing beyond translation examples directly observ-
able in the training data.
In language pairs that are typologically sim-
ilar (i.e., when both languages lexicalize the
same kinds of semantic and syntactic informa-
tion), words and phrases map relatively directly
from source to target languages, and the standard
approach to learning phrase pairs is quite effec-
tive.1 However, in language pairs in which in-
dividual source language words have many dif-
ferent possible translations (e.g., when the target
language word could have many different inflec-
tions or could be surrounded by different func-
tion words that have no direct correspondence in
the source language), we can expect the standard
phrasal inventory to be incomplete, except when
very large quantities of parallel data are available
or for very frequent words. There simply will not
be enough examples from which to learn the ideal
set of translation options. Therefore, since phrase
based translation can only generate input/output
word pairs that were directly observed in the train-
ing corpus, the decoders only hope for produc-
ing a good output is to find a fluent, meaning-
preserving translation using incomplete transla-
tion lexicons. Synthetic translation option genera-
tion seeks to fill these gaps using secondary gener-
ation processes that produce possible phrase trans-
lation alternatives that are not directly extractable
from the training data. We hypothesize that by
filling in gaps in the translation options, discrim-
inative translation models will be more effective
(leading to better translation quality).
The creation of synthetic translation options can
be understood as a kind of translation or post-
editing of phrasal units/translations. This raises
a question: if we have the ability to post-edit a
phrasal translation or retranslate a source phrase
so as to fill in gaps in the phrasal inventory, we
should be able to use the same technique to trans-
late the sentence; why not do this? While the ef-
fectiveness of this approach will ultimately be as-
sessed empirically, translation option generation is
appealing because the translation option synthe-
sizer need not produce only single-best guesses
</bodyText>
<page confidence="0.937395">
1
</page>
<bodyText confidence="0.96207525">
When translating from a language with a richer lexical
inventory to a simpler one, approximate matching or backing
off to (e.g.) morphologically simpler forms likewise reliably
produces good translations.
</bodyText>
<figure confidence="0.972098785714286">
saw +1SG +PST cat+ACC
1SG+NOM
I saw
saw a
saw the
cat
a
the cat
cat
saw the cat
saw a cat
I saw
I saw a
I saw the
</figure>
<figureCaption confidence="0.99995">
Figure 1: Russian-English phrase-based transla-
</figureCaption>
<bodyText confidence="0.9477178125">
tion example. Since Russian lacks a definiteness
morpheme the determiners a, the must be part of
a translation option containing oaeaae or eieo
in order to be present in the right place in the En-
glish output. Translation options that are in dashed
boxes should exist but were not observed in the
training data. This work seeks to produce such
missing translation options synthetically.
if multiple possibilities appear to be equally good
(say, multiple inflections of a translated lemma),
then multiple translation options may be synthe-
sized. Ultimately, of course, the global translation
model must select one translation for every phrase
it uses, but the decoder will have access to global
information that it can use to pick better transla-
tion options.
</bodyText>
<sectionHeader confidence="0.935104" genericHeader="method">
3 Case Study: English Definite Articles
</sectionHeader>
<bodyText confidence="0.9996201875">
We now turn to a translation problem that we will
use to assess the value of synthetic translation op-
tions: generating English in/definite articles when
translating from Russian.
Definiteness is a semantic property of noun
phrases that expresses information such as iden-
tifiability, specificity, familiarity and unique-
ness (Lyons, 1999). In English, it is expressed
through the use of article determiners and non-
article determiners. Although languages may ex-
press definiteness through such morphemes, many
languages use alternative mechanisms. For exam-
ple they may use noncanonical word orders (Mo-
hanan, 1994)2 or different constructions such as
existentials, differential object marking (Aissen,
2003), and the ba () construction in Chinese
</bodyText>
<page confidence="0.979335">
2
</page>
<bodyText confidence="0.9661465">
See pp. 1112 for an example in Hindi, a language with-
out articles.
</bodyText>
<page confidence="0.995683">
272
</page>
<bodyText confidence="0.999163411764706">
\x0c(Chen, 2004). While these languages lack arti-
cles, they may use demonstratives and the quan-
tifier one to emphasize definiteness and indefinite-
ness, respectively.
Russian and Czech are examples of languages
that use non-lexical means to express definiteness.
As such, in Russian to English translation systems,
we expect that most Russian nouns should have at
least three translation optionsthe bare noun, the
noun preceded by the, and the noun preceded a/an.
Fig. 1 illustrates how the definiteness mismatch
between Russian and English can result in gaps
in the phrasal inventory learned from a relatively
large parallel corpus. The Russian input should
translate (depending on context) as either I saw a
cat or I saw the cat; however, the phrase table we
learned is only able to generate the former.3
</bodyText>
<sectionHeader confidence="0.976524" genericHeader="method">
4 Predicting English Definite Articles
</sectionHeader>
<bodyText confidence="0.9997725">
Although English articles express semantic con-
tent, their use is largely predictable in context,
both for native English speakers and for automated
systems (Knight and Chander, 1994).4 In this sec-
tion we describe a classifier that uses local contex-
tual features to predict whether an article belongs
in a particular position in a sequence of words, and
if so, whether it is definite or indefinite (the form
of the indefinite article is deterministic given the
pronunciation of the following word).
</bodyText>
<subsectionHeader confidence="0.992301">
4.1 Model
</subsectionHeader>
<bodyText confidence="0.9986712">
The classifier takes an English word sequence w =
hw1, w2, . . . , w|w|i with missing articles and an in-
dex i and predicts whether no article, a definite ar-
ticle, or an indefinite article should appear before
wi. We parameterize the classifier as a multiclass
</bodyText>
<page confidence="0.990941">
3
</page>
<bodyText confidence="0.986451666666667">
The phrase table for this example was extracted from the
WMT 2013 shared task training data consisting of 1.2M sen-
tence pairs.
</bodyText>
<page confidence="0.988216">
4
</page>
<bodyText confidence="0.997886571428571">
An interesting contribution of this work is a discussion
on lower and upper bounds that can be achieved by native
English speakers in predicting determiners. 67% is a lower
bound, obtained by guessing the for every instance. The up-
per bound was obtained experimentally, and was measured on
noun phrases (NP) without context, in a context of 4 words
(2 before and 2 after NP), and given full context. Human
subjects achieved an accuracy of 94-96% given full context,
83-88% for NPs in a context of 4 words, and 79-80% for NPs
without context. Since in the current state-of-the-art building
an automated determiners prediction in a full context (repre-
senting meaning computationally) is not a feasible task, we
view 83-88% accuracy as our goal, and 88% as an upper
bound for our method.
</bodyText>
<equation confidence="0.92103225">
logistic regression:
p(y  |w, i) exp
X
j
</equation>
<bodyText confidence="0.9362522">
jhj(y, w, i),
where hj() are feature functions, j are the corre-
sponding weights, and y {D, I, N} refer, respec-
tively, to the outputs: definite article, indefinite ar-
ticle, and no article.5
</bodyText>
<subsectionHeader confidence="0.616049">
4.2 Features
</subsectionHeader>
<bodyText confidence="0.993716">
The English article system is extremely com-
plex (as non-native English speakers will surely
know!): in addition to a general placement rule
that articles must precede a noun or its modifiers
in an NP, multiple other factors can also affect ar-
ticle selection, including countability of the head
noun, syntactic properties of an adjective modi-
fying a noun (superlative, ordinal), discourse fac-
tors, general knowledge, etc. In this section, we
define morphosyntactic features aimed at reflect-
ing basic grammatical rules, we define statistical,
semantic and shallow lexical features to capture
additional regular and idiosyncratic usages of def-
inite and indefinite articles in English. Below we
provide brief details of the features and their mo-
tivation.
Lexical. Because training data can be con-
structed inexpensively (from any unannotated En-
glish corpus), n-gram indicator features, such as
[[wi1ywiwi+1 = with y lot of]], can be es-
timated reliably and capture construction-specific
article use.
Morphosyntactic. We used part-of-speech
(POS) tags produced by the Stanford POS tagger
(Toutanova and Manning, 2000) to capture gen-
eral article patterns. These are relevant features
in the prediction of articles as we observe certain
constraints regarding the use of articles in the
neighborhood of certain POS tags. For example,
we do not expect to predict an article following an
adjective (JJ).
Semantic. We extract further information indi-
cating whether a named entity, as identified by the
Stanford NE Recognizer (Finkel et al., 2005) be-
gins at wi. These features are relevant as there
</bodyText>
<page confidence="0.97439">
5
</page>
<bodyText confidence="0.9883044">
Realization of the classes D and N as lexical items is
straightforward. To convert I into a or an, we use the
CMU pronouncing dictionary (http://www.speech.
cs.cmu.edu/cgi-bin/cmudict) and select an if wi
starts with a phonetic vowel.
</bodyText>
<page confidence="0.994293">
273
</page>
<bodyText confidence="0.999026357142857">
\x0cis, in general, a constraint on the co-occurrence
of articles with named entities which can help us
predict the use of articles in such constructions.
For example, proper nouns do not tend to co-
occur with articles in English. Although there are
some proper nouns that have an article included in
them, such as the Netherlands, the United States
of America, but these are fixed expressions and the
model is easily able to capture such cases with lex-
ical features.
Statistical. Statistical features capture probabil-
ity of co-occurrences of a sample with each of
the determiner classes, e.g., for wi1ywi we
collect probabilities of wi1Iwi, wi1Dwi, and
</bodyText>
<page confidence="0.350065">
wi1Nwi.6
</page>
<subsectionHeader confidence="0.984232">
4.3 Training and evaluation
</subsectionHeader>
<bodyText confidence="0.981041038461539">
We employ the creg regression modeling frame-
work to train a ternary logistic regression classi-
fier.7 All features were computed for the target-
side of the Russian-English TED corpus (Cettolo
et al., 2012); from 117,527 sentences we removed
5K sentences used as tuning and test sets in the
MT system. We extract statistical features from
monolingual English corpora released for WMT-
11 (Callison-Burch et al., 2011).
In the training corpus there are 65,075 I in-
stances, 114,571 D instances, and 2,435,287 N in-
stances. To create a balanced training set we
randomly sample 65K instances from each set of
collected instances.8 This training set of feature
vectors has 142,604 features and 285,210 param-
eters. To minimize the number of free parame-
ters in our model we use `1 regularization. We
perform 10-fold cross validation experiments with
various feature combinations, evaluating the clas-
sifier accuracy for all classes and for each class
independently. The performance of the classifier
on individual classes and consolidated results for
all classes are listed in Table 1.
We observe that morphosyntactic and lexical
features are highly significant, reducing the er-
ror rate of statistical features by 25%. A combi-
</bodyText>
<page confidence="0.993186">
6
</page>
<bodyText confidence="0.990618571428571">
Although statistical features are de rigeur in NLP, they
are arguably justified for this problem on linguistic grounds
since human subjects use frequency-based in addition to their
grammatical knowledge. For example, we say He is at school
rather than He is at the school, but Americans say He is in
the hospital while UK English speakers might prefer He is in
hospital.
</bodyText>
<page confidence="0.979372">
7
</page>
<footnote confidence="0.338025">
https://github.com/redpony/creg
</footnote>
<page confidence="0.958293">
8
</page>
<table confidence="0.9777167">
Preliminary experiments indicated that the excess of N
labels resulted in poor performance.
Feature combination All I D N
Statistical 0.80 0.76 0.79 0.87
Lexical 0.82 0.79 0.80 0.87
Morphosyntactic 0.75 0.71 0.64 0.86
Semantic 0.35 0.99 0.02 0.04
Statistical+Lexical 0.85 0.83 0.82 0.89
+ Morphosyntactic 0.87 0.86 0.83 0.92
+ Semantic 0.87 0.86 0.83 0.92
</table>
<tableCaption confidence="0.66464">
Table 1: 10-fold cross validation accuracy of the
classifier over all and by class.
</tableCaption>
<bodyText confidence="0.9393352">
nation of morphosyntactic, lexical, and statistical
features is also helpful, reducing 13% more errors.
Semantic features do not contribute to the classi-
fier accuracy (we believe, mainly due to the feature
sparsity).
</bodyText>
<sectionHeader confidence="0.995989" genericHeader="method">
5 Experimental Setup
</sectionHeader>
<bodyText confidence="0.998556">
Our experimental workflow includes the follow-
ing steps. First, we select a phrase table PTsource
from which we generate synthetic phrases. For
each phrase pair hf, ei in PTsource we generate n
synthetic variants of the target side phrase e which
we then append to PTbaseline. We annotate both
the original and synthetic phrases with additional
translation features in PTbaseline.
For this language pair, we have several options
for how to construct PTsource. The most straight-
forward way is to extract the phrasal inventory as
usual; a second option is to extract phrases from
training data from which definite articles have
been removed (since we will rely on the classifier
to reinsert them where they belong).
To synthesize phrases, we employ two differ-
ent techniques: LM-based and classifier-based.
We use a LM for one- or two-word phrases or
an auxiliary classifier for longer phrases and cre-
ate a new phrase in which we insert, remove or
substitute an article between each adjacent pair of
words in the original phrase. Such distinction be-
tween short and longer phrases has clear motiva-
tion: phrases without context may allow alterna-
tive, equally plausible options for article selection,
therefore we can just rely on a LM, trained on
large monolingual corpora, to identify phrases un-
observed in MT training corpus. Longer context
restricts determiners usage and statistical model
decisions are less prone to generating ungrammat-
ical synthetic phrases.
LM-based method is applied to phrases shorter
than three words. These phrases are numerous,
roughly 20% of a phrase table, and extracted from
</bodyText>
<page confidence="0.992563">
274
</page>
<bodyText confidence="0.997377869565217">
\x0cmany sites in the training data. For each short (tar-
get) phrase we add all possible alternative entries
observed in the LM and not observed in the orig-
inal translation model. For example, for a short
target phrase a cat we extract the cat.
We apply an auxiliary classifier to longer
phrases, containing three or more words. Based
on the classifier prediction, we use the maximally
probable class to insert, remove or substitute an
article between each adjacent pair of words in
the original phrase. Synthetic phrases are gener-
ated by linguistically-informed features and can
introduce alternative grammatically-correct trans-
lations of source phrases by adding or removing
existing articles (since the English article selection
in a local context is often ambiguous and not cat-
egorical). We add a synthetic phrase only if the
phrase pair not observed in the original model.
We compare two possible applications of a clas-
sifier: one-pass and iterative prediction. With
one-pass prediction we decide on the prediction
for each position independently of other deci-
sions. With iterative update we adopt the best
first (greedy) strategy, selecting in each iteration
the update-location in which the classifier obtains
highest confidence score. In each iteration we in-
corporate a prediction in a target phrase, and in the
next iteration the best first decision is made on an
updated phrase. Iterative prediction stops when no
updates are introduced.
Synthetic phrases are added to a phrase table
with the five standard phrasal translation features
that were found in the source phrase, and with sev-
eral new features. First, we add a boolean fea-
ture indicating the origin of a phrase: synthetic or
original. Second, we experiment with a posterior
probability of a classifier averaged over all loca-
tions where it could be extracted from the training
data. The next feature is derived from this score:
it is a boolean feature indicating a confidence of
the classifier: the feature value is 1 iff the average
classifier score is higher than some threshold.
Consider again a phrase I saw a cat discussed
in Section 1. Synthetic entry generation from the
original phrase table entry is illustrated in Fig-
ure 2.
</bodyText>
<sectionHeader confidence="0.979811" genericHeader="method">
6 Translation Results
</sectionHeader>
<bodyText confidence="0.995896294117647">
We now review the results of experiments using
synthetic translation options in a machine trans-
lation system. We use the Moses toolkit (Koehn
et al., 2007) to train a baseline phrase-based SMT
system. Each configuration we compare has a dif-
ferent phrase table, with synthetic phrases gen-
erated with best-first or iterative strategies, from
a phrase table with- or without-determiners, with
variable number of translation features. To verify
that system improvement is consistent, and is not a
result of optimizer instability (Clark et al., 2011),
we replicate each experimental setup three times,
and then estimate the translation quality of the me-
dian MT system using the MultEval toolkit.9
The corpus is the same as in Section 4.3:
the training part contains 112,527 sentences from
Russian-English TED corpus, randomly sampled
3K sentences are used for tuning and a disjoint set
of 2K sentences is used for test. We lowercase
both sides, and use Stanford CoreNLP10 tools to
tokenize the corpora. We employ SRILM toolkit
(Stolcke, 2002) to linearly interpolate the target
side of the training corpus with the WMT En-
glish corpus, optimizing towards the MT tuning
set. This LM is used in all experiments.
The rest of this section is organized as follows.
First, we compare two approaches to the deter-
miners classifier application. Then, we provide
detailed description of experiments with synthetic
phrases. We evaluate various aspects of synthetic
phrases generation and summarize all the results
in Table 3. In Table 5 we show examples of im-
proved translations.
Classifier application: one-pass vs. iterative.
First, as an intrinsic evaluation of the prediction
strategy we remove definite and indefinite articles
from the reference translations (2K test sentences)
and then employ the determiners classifier to re-
produce the original sentences. In Table 2 we re-
port on the word error rate (WER) derived from
the Levenshtein distance between the original sen-
tences and the sentences (1) without articles, (2)
with articles recovered using one-pass prediction,
and (3) articles recovered using iterative predic-
tion. The WER is averaged over all test sentences.
Both one-pass and iterative approaches are effec-
tive in the task of determiners prediction, reducing
the number of errors by 44%. The iterative ap-
proach yields slightly lower WER, hence we em-
ploy the iterative prediction in the future experi-
ments with synthetic phrases.
</bodyText>
<figure confidence="0.951393142857143">
9
https://github.com/jhclark/multeval
10
http://nlp.stanford.edu/software/corenlp.shtml
275
\x0cthe
&amp;lt;s&amp;gt; I saw a cat &amp;lt;/s&amp;gt;
None
None
original phrase
post-processing
synthetic phrase
is synthetic
is no-context
</figure>
<figureCaption confidence="0.999375">
Figure 2: Synthetic entry generation example. The original parallel phrase has two additional boolean
</figureCaption>
<bodyText confidence="0.86257875">
features (set to false) indicating that this is not a synthetic phrase and not a short phrase. We apply
our determiners classifier to predict an article at each location marked with a dashed box. Based on a
classifier prediction we derive a new phrase I saw the cat. Since corresponding parallel entry is not in
the original phrase table, we set the synthetic indicator feature to 1.
</bodyText>
<table confidence="0.730429">
Post-processing WER
None 5.6%
One-pass 3.2%
Iterative 3.1%
</table>
<tableCaption confidence="0.859421">
Table 2: WER (lower is better) of reference trans-
</tableCaption>
<bodyText confidence="0.967697196428571">
lations without articles and of post-processed ref-
erence translations. Both one-pass and iterative
approaches are effective in the task of determin-
ers prediction.
MT output post-processing. We then evaluate
the post-processing strategy directly on the MT
output. We experiment with one-pass and itera-
tive post-processing of two variants of the base-
line system outputs: original output and the out-
put without articles (we remove the articles prior
to post-processing). The results are listed in Ta-
ble 3. Interestingly, we do not obtain any improve-
ments applying the determiners classifier in a con-
ventional way of a MT output post-processing. It
is the combination of linguistically-motivated fea-
tures with synthetic phrases that contribute to the
best performance.
LM-based synthetic phrases. As discussed
above, LM-based (short) phrases are shorter than
3 tokens and their synthetic variants contain same
words with articles inserted or deleted between
each adjacent pair of words. The phrase table
of the baseline system contains 2,441,678 phrase
pairs. There are 518,453 original short phrases,
and our technique yields 842,252 new synthetic
entries which we append to the baseline phrase ta-
ble. Table 3 shows the evaluation of the median
SMT system (derived from three systems) with
short phrases. In these systems the five phrasal
translation features are the same as in the base-
line systems. Improvement in the BLEU score
(Papineni et al., 2002) is statistically significant
(p &amp;lt; .05), compared to the baseline system
Classifier-generated synthetic phrases We ap-
ply classifier with the iterative prediction directly
on the baseline phrase table entries and synthe-
size 944,145 new parallel phrases, increasing the
phrase table size by 38%. The phrasal transla-
tion features in each synthetic phrase are the same
as in the phrase it was derived from. The BLEU
score of the median SMT system with synthetic
phrases is 22.9 .1, the improvement is statisti-
cally significant (p &amp;lt; .01). Post-processing of a
phrase table created from corpora without articles
and adding synthetic phrases to the baseline phrase
table yielded similar results.
Translation features for synthetic phrases In
the following experiments we aim to establish the
optimal set of translation features that should be
used with synthetic phrases. We train several SMT
systems, each containing synthetic phrases derived
from the original phrase table by iterative classifi-
cation, and with LM-based short phrases. Each
synthetic phrase has five translation features as an
original phrase it was derived from. The additional
features that we evaluate are:
</bodyText>
<footnote confidence="0.2511915">
1. Boolean feature for LM-based synthetic
phrases
</footnote>
<page confidence="0.878714">
276
</page>
<table confidence="0.746351666666667">
\x0cMT System BLEU
Baseline 22.6 .1
MT output post-processing
</table>
<listItem confidence="0.76143525">
one-pass, MT output with articles 20.8
one-pass, MT output without articles 19.7
iterative, MT output with articles 22.6
iterative, MT output without articles 21.8
</listItem>
<table confidence="0.973807714285714">
With synthetic phrases
LM-based phrases 22.9 .1
+ classifier-generated phrases 22.9 .1
+ features 1,2 23.0 .1
+ features 1,2,3 22.8 .1
+ features 1,2,3,4 22.8 .1
+ feature 5 22.9 .1
</table>
<tableCaption confidence="0.999344">
Table 3: Summary of experiments with MT out-
</tableCaption>
<bodyText confidence="0.951739">
put post-processing and with synthetic translation
options in a phrase table. Post-processing of the
MT output do not improve translations. Best per-
forming system with synthetic phrases has five
original phrase translation features and two addi-
tional boolean features indicating if the phrase is
LM-based or not, is classifier-generated or not. All
the synthetic systems are significantly better than
the baseline system.
</bodyText>
<listItem confidence="0.803315">
2. Boolean feature for classifier-generated syn-
thetic phrases
3. Classifier confidence: posterior probability of
the classifier averaged over all samples in a tar-
get phrase.
4. Boolean feature indicating a confidence of the
</listItem>
<bodyText confidence="0.98775759375">
classifier: the feature value is 1 iff the Fea-
ture 3 scores higher than some threshold. The
threshold was set to 0.8, we did not experiment
with other values.
5. Boolean feature for a synthetic phrase of any
type: LM-based or classifier-generated
Table 3 details the change in the BLEU score
of each experimental setup. The best perform-
ing system has five original phrase translation fea-
tures and two additional boolean features indicat-
ing if the phrase is LM-based or not, is classifier-
generated or not. Note that all the synthetic sys-
tems are significantly better than the baseline.
Czech-English. Our technique was developed
using Russian-English system in the TED domain,
so we want to see how our method generalizes to a
different domain when translating from a different
language. We therefore applied our most success-
ful configuration to a Czech-English news transla-
tion task.11 For training, we use the WMT Czech-
English parallel corpus CzEng0.7; we tune using
the WMT2011 test set and test on the WMT2012
test set. The LM is trained on the target side of the
training corpus. Determiners classifier, re-trained
on the English side of this corpus, with statistical,
lexical, morphosyntactic and dependency features
obtained an accuracy of 88%.
In Table 4, we report the results of evaluat-
ing the performance of the Russian-to-English
and Czech-to-English MT systems with synthetic
phrases. The results of both systems show a statis-
tically significant (p &amp;lt; .01) improvement in terms
</bodyText>
<table confidence="0.87270175">
of BLEU score.
Russian Czech
Baseline 22.6 .1 16.0 .05
Synthetic 23.0 .1 16.2 .03
</table>
<tableCaption confidence="0.717807">
Table 4: BLEU score of Russian-to-English
and Czech-to-English MT systems with synthetic
</tableCaption>
<bodyText confidence="0.996777111111111">
phrases and features 1 and 2 show a significant im-
provement.
Qualitative analysis. Table 5 shows some ex-
amples from the output of our Russian-to-English
systems. Although both systems produce compre-
hensible translations, the system augmented with
determiner classifier is more fluent. The first ex-
ample represents a case where a singular count
noun (piece) is present which requires an article.
The baseline is not able to identify this require-
ment and hence does not insert the article an be-
fore the phrase extraordinary engineering piece.
Our system, however, correctly identifies the con-
struction requiring an article and thus provides an
appropriate form of the article (an- Indefinite arti-
cle for lexical items beginning with a vowel). Thus
we see that our system is able to capture the lin-
guistic requirement of the singular count nouns to
co-occur with an article. In the second row, the
lexical item poor is used as an adjective. The base-
line has inserted an article in front of it, chang-
ing it to a noun. Our system, however, is able to
maintain the status of poor as an adjective since
it has the option not to insert an article. Thus we
see that besides fluency, our system also does bet-
ter in maintaining the grammatical category of a
lexical item. In the third row, the phrase three
</bodyText>
<page confidence="0.998457">
11
</page>
<bodyText confidence="0.9842575">
Like Russian, Czech is a Slavic language that does not
have definite or indefinite articles.
</bodyText>
<page confidence="0.985517">
277
</page>
<bodyText confidence="0.999698333333333">
\x0cSource: ii oai ia iaiaa , yoi auaauaany iiecaaaaiea eiaiaiiai eneonnoaa .
Reference: but nonetheless , it s an extraordinary piece of engineering .
Baseline: but nevertheless , it s extraordinary engineering piece of art .
Ours: but nevertheless , it s an extraordinary piece of engineering art .
Source: e ii iiiaei aaoeieoeyi iia oa ia aaaiay .
Reference: and by many definitions she is no longer poor .
Baseline: and in a lot definitions , it s not a poor .
Ours: and in a lot definitions she s not poor .
Source: iai ioii iaeiieou oe ieeeeaaa aiianeeo eoaeae .
Reference: we must feed three billion people in cities .
Baseline: we need to feed the three billion urban hundreds of them .
Ours: we need to feed three billion people in the city .
</bodyText>
<tableCaption confidence="0.583246">
Table 5: Examples of translations with improved articles handling.
</tableCaption>
<bodyText confidence="0.996828090909091">
billion people refers to a nonidentifiable referent.
The baseline inserts the definite article the. If a
human subject reads this translation, it would mis-
lead him/her to interpret the object three billion
people as referring to a specific identifiable set.
Our system, on the other hand, correctly selects
the determiner class N and hence does not insert an
article. Thus we see that our system does not just
add fluency but it also captures a semantic distinc-
tion, namely identifiability, that a human subject
makes when producing or interpreting a phrase.
</bodyText>
<sectionHeader confidence="0.998907" genericHeader="related work">
7 Related Work
</sectionHeader>
<bodyText confidence="0.993725027777778">
Automated determiner prediction has been found
beneficial in a variety of applications, including
postediting of MT output (Knight and Chander,
1994), text generation (Elhadad, 1993; Minnen
et al., 2000), and more recently identification and
correction of ESL errors (Han et al., 2006; De Fe-
lice and Pulman, 2008; Gamon et al., 2009; Ro-
zovskaya and Roth, 2010). Our work on determin-
ers extends previous studies in several dimensions.
While all previous approaches were tested only on
NP constructions, we evaluate our classifier on any
sequence of tokens.
To the best of our knowledge, the only stud-
ies that directly address generation of synthetic
phrase table entries was conducted by Chen et al.
(2011) and Koehn and Hoang (2007). The former
find semantically similar source phrases and pro-
duce fabricated translations by combining these
source phrases with a set of their target phrases;
however, they do not observe improvements. The
later work integrates the synthesis of translation
options into the decoder. While related in spirit,
their method only supports a limited set of gen-
erative processes for producing the candidate set
(lacking, for instance, the simple and effective
phrase post-editing process we have used), and
their implementation has been plagued by compu-
tational challenges.
Post-processing techniques have been ex-
tremely popular. These can be understood as using
a translation model to generate a translation skele-
ton (or k-best skeletons) and then post-editing
these in various ways. These have been applied
to translation into morphologically rich languages,
such as Japanese, German, Turkish, and Finnish
(de Gispert et al., 2005; Suzuki and Toutanova,
</bodyText>
<reference confidence="0.605720666666667">
2006; Suzuki and Toutanova, 2007; Fraser et al.,
2012; Clifton and Sarkar, 2011; Oflazer and Dur-
gar El-Kahlout, 2007).
</reference>
<sectionHeader confidence="0.946081" genericHeader="conclusions">
8 Conclusions and future work
</sectionHeader>
<bodyText confidence="0.999731470588235">
The contribution of this work is twofold. First, we
propose a new supervised method to predict defi-
nite and indefinite articles. Our log-linear model
trained on a linguistically-motivated set of fea-
tures outperforms previously reported results, and
obtains an upper bound of an accuracy achieved
by human subjects given a context of four words.
However, more important result of this work is the
experimentally verified idea of improving phrase-
based SMT via synthetic phrases. While we have
focused on a limited problem in this paper, there
are numerous alternative applications including
translation into morphologically rich languages, as
a method for incorporating (source) contextual in-
formation in making local translation decisions,
enriching the target language lexicon using lexical
translation resources, and many others.
</bodyText>
<sectionHeader confidence="0.967046" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.880337">
We are grateful to Shuly Wintner for insightful sugges-
tions and support. This work was supported in part by the
</bodyText>
<reference confidence="0.577246">
U. S. Army Research Laboratory and the U. S. Army Re-
search Office under contract/grant number W911NF-10-1-
0533.
</reference>
<page confidence="0.847227">
278
</page>
<reference confidence="0.99038695412844">
\x0cReferences
J. Aissen. 2003. Differential object marking: Iconic-
ity vs. economy. Natural Language and Linguistic
Theory, 21(3):435483.
C. Callison-Burch, P. Koehn, C. Monz, and O. Zaidan.
2011. Findings of the 2011 workshop on statisti-
cal machine translation. In Proceedings of the Sixth
Workshop on Statistical Machine Translation, pages
2264, Edinburgh, Scotland, July. Association for
Computational Linguistics.
M. Cettolo, C. Girardi, and M. Federico. 2012. WIT3
:
Web inventory of transcribed and translated talks. In
Proceedings of the 16th
Conference of the European
Association for Machine Translation (EAMT), pages
261268, Trento, Italy, May.
B. Chen, R. Kuhn, and G. Foster. 2011. Semantic
smoothing and fabrication of phrase pairs for SMT.
In Proceedings of the International Workshop on
Spoken Lanuage Translation (IWSLT-2011).
P. Chen. 2004. Identifiability and definiteness in chi-
nese. Linguistics, 42(6):11291184.
C. Cherry and G. Foster. 2012. Batch tuning strategies
for statistical machine translation. In Proceedings of
HLT-NAACL 2012, volume 12, pages 3435.
D. Chiang. 2007. Hierarchical phrase-based transla-
tion. Computational Linguistics, 33(2):201228.
D. Chiang. 2012. Hope and fear for discriminative
training of statistical translation models. The Jour-
nal of Machine Learning Research, 98888:1159
1187.
J. H. Clark, C. Dyer, A. Lavie, and N. A. Smith.
2011. Better hypothesis testing for statistical ma-
chine translation: Controlling for optimizer instabil-
ity. In In Proc. of ACL.
A. Clifton and A. Sarkar. 2011. Combining
morpheme-based machine translation with post-
processing morpheme prediction. In Proceedings of
ACL.
R. De Felice and S. G. Pulman. 2008. A classifier-
based approach to preposition and determiner error
correction in L2 English. In Proceedings of the
22nd International Conference on Computational
Linguistics-Volume 1, pages 169176. Association
for Computational Linguistics.
A. de Gispert, J. B. Marino, and J. M. Crego. 2005.
Improving statistical machine translation by classi-
fying and generalizing inflected verb forms. In Pro-
ceedings of InterSpeech.
J. DeNero and D. Klein. 2010. Discriminative mod-
eling of extraction sets for machine translation. In
Proceedings of the 48th Annual Meeting of the Asso-
ciation for Computational Linguistics, pages 1453
1463. Association for Computational Linguistics.
J. DeNero, A. Bouchard-Cote, and D. Klein. 2008.
Sampling alignment structure under a Bayesian
translation model. In Proceedings of the Confer-
ence on Empirical Methods in Natural Language
Processing, pages 314323. Association for Com-
putational Linguistics.
V. Eidelman, Y. Marton, and P. Resnik. 2013. Online
relative margin maximization for statistical machine
translation. In Proceedings of ACL.
M. Elhadad. 1993. Generating argumentative judg-
ment determiners. In AAAI, pages 344349.
J. R. Finkel, T. Grenager, and C. Manning. 2005. In-
corporating non-local information into information
extraction systems by gibbs sampling. In ACL 05:
Proceedings of the 43rd Annual Meeting on Asso-
ciation for Computational Linguistics, pages 363
370, Morristown, NJ, USA. Association for Compu-
tational Linguistics.
A. Fraser, M. Weller, A. Cahill, and F. Cap. 2012.
Modeling inflection and word-formation in SMT. In
Proceedings of EACL.
M. Galley, J. Graehl, K. Knight, D. Marcu, S. DeNeefe,
W. Wang, and I. Thayer. 2006. Scalable infer-
ence and training of context-rich syntactic transla-
tion models. In ACL-44: Proceedings of the 21st In-
ternational Conference on Computational Linguis-
tics and the 44th annual meeting of the Associa-
tion for Computational Linguistics, pages 961968,
Morristown, NJ, USA. Association for Computa-
tional Linguistics.
M. Gamon, J. Gao, C. Brockett, A. Klementiev, W. B.
Dolan, D. Belenko, and L. Vanderwende. 2009. Us-
ing contextual speller techniques and language mod-
eling for ESL error correction. Urbana, 51:61801.
K. Gimpel and N. A. Smith. 2012. Structured ramp
loss minimization for machine translation. In Pro-
ceedings of 2012 Conference of the North Ameri-
can Chapter of the Association for Computational
Linguistics: Human Language Technologies HLT-
NAACL 2012, Montreal, Canada.
N.-R. Han, M. Chodorow, and C. Leacock. 2006. De-
tecting errors in English article usage by non-native
speakers.
K. Knight and I. Chander. 1994. Automated poste-
diting of documents. In Proceedings of the Na-
tional Conference on Artificial Intelligence, pages
779779, Seattle, WA.
P. Koehn and H. Hoang. 2007. Factored transla-
tion models. In Proceedings of the 2007 Joint
Conference on Empirical Methods in Natural Lan-
guage Processing and Computational Natural Lan-
guage Learning (EMNLP-CoNLL), pages 868876,
Prague, Czech Republic, June. Association for Com-
putational Linguistics.
</reference>
<page confidence="0.952093">
279
</page>
<reference confidence="0.997427475409836">
\x0cP. Koehn, F. J. Och, and D. Marcu. 2003. Statistical
phrase-based translation. In NAACL 03: Proceed-
ings of the 2003 Conference of the North American
Chapter of the Association for Computational Lin-
guistics on Human Language Technology, pages 48
54. Association for Computational Linguistics.
P. Koehn, H. Hoang, A. Birch, C. Callison-Burch,
M. Federico, N. Bertoldi, B. Cowan, W. Shen,
C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,
and E. Herbst. 2007. Moses: Open source toolkit
for statistical machine translation. In Proceedings of
the 45th Annual Meeting of the Association for Com-
putational Linguistics Companion Volume Proceed-
ings of the Demo and Poster Sessions, pages 177
180, Prague, Czech Republic, June. Association for
Computational Linguistics.
C. Lyons. 1999. Definiteness. Cambridge University
Press.
G. Minnen, F. Bond, and A. Copestake. 2000.
Memory-based learning for article generation. In
Proceedings of the 2nd workshop on Learning lan-
guage in logic and the 4th conference on Compu-
tational natural language learning-Volume 7, pages
4348. Association for Computational Linguistics.
T. Mohanan. 1994. Argument Structure in Hindi.
CSLI Publications.
K. Oflazer and I. Durgar El-Kahlout. 2007. Explor-
ing different representational units in English-to-
Turkish statistical machine translation. In Proceed-
ings of the Second Workshop on Statistical Machine
Translation, pages 2532, Prague, Czech Republic,
June. Association for Computational Linguistics.
K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu. 2002.
BLEU: a method for automatic evaluation of ma-
chine translation. In ACL 02: Proceedings of the
40th Annual Meeting on Association for Computa-
tional Linguistics, pages 311318, Morristown, NJ,
USA. Association for Computational Linguistics.
A. Rozovskaya and D. Roth. 2010. Training
paradigms for correcting errors in grammar and us-
age. Urbana, 51:61801.
A. Stolcke. 2002. SRILMan extensible language
modeling toolkit. In Procedings of International
Conference on Spoken Language Processing, pages
901904.
H. Suzuki and K. Toutanova. 2006. Learning to pre-
dict case markers in Japanese. In Proceedings of
the 21st International Conference on Computational
Linguistics and the 44th annual meeting of the Asso-
ciation for Computational Linguistics, pages 1049
1056. Association for Computational Linguistics.
H. Suzuki and K. Toutanova. 2007. Generating case
markers in machine translation. In Proceedings of
HLT-NAACL 2007, pages 4956.
K. Toutanova and C. D. Manning. 2000. Enriching
the knowledge sources used in a maximum entropy
part-of-speech tagger. In Proceedings of the 2000
Joint SIGDAT conference on Empirical methods in
natural language processing and very large corpora,
pages 6370, Morristown, NJ, USA. Association for
Computational Linguistics.
</reference>
<page confidence="0.785207">
280
</page>
<figure confidence="0.365811">
\x0c&amp;apos;
</figure>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.715306">
<note confidence="0.883086333333333">b&amp;apos;Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 271280, Sofia, Bulgaria, August 8-9, 2013 c 2013 Association for Computational Linguistics</note>
<title confidence="0.981085">Generating English Determiners in Phrase-Based Translation with Synthetic Translation Options</title>
<author confidence="0.996604">Yulia Tsvetkov Chris Dyer Lori Levin Archna Bhatia</author>
<affiliation confidence="0.9964835">Language Technologies Institute Carnegie Mellon University</affiliation>
<address confidence="0.999713">Pittspurgh, PA, 15213, USA</address>
<email confidence="0.999484">ytsvetko@cs.cmu.edu</email>
<email confidence="0.999484">cdyer@cs.cmu.edu</email>
<email confidence="0.999484">lsl@cs.cmu.edu</email>
<email confidence="0.999484">archna@cs.cmu.edu</email>
<abstract confidence="0.998728428571429">We propose a technique for improving the quality of phrase-based translation systems by creating synthetic translation optionsphrasal translations that are generated by auxiliary translation and postediting processesto augment the default phrase inventory learned from parallel data. We apply our technique to the problem of producing English determiners when translating from Russian and Czech, languages that lack definiteness morphemes. Our approach augments the English side of the phrase table using a classifier to predict where English articles might plausibly be added or removed, and then we decode as usual. Doing so, we obtain significant improvements in quality relative to a standard phrase-based baseline and to a to post-editing complete translations with the classifier.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Suzuki</author>
<author>Toutanova</author>
</authors>
<title>Oflazer and Durgar El-Kahlout,</title>
<date>2012</date>
<journal>U. S. Army Research Laboratory and the U. S. Army Research Office under contract/grant</journal>
<volume>number</volume>
<pages>911--10</pages>
<location>Clifton</location>
<marker>Suzuki, Toutanova, 2012</marker>
<rawString>2006; Suzuki and Toutanova, 2007; Fraser et al., 2012; Clifton and Sarkar, 2011; Oflazer and Durgar El-Kahlout, 2007). U. S. Army Research Laboratory and the U. S. Army Research Office under contract/grant number W911NF-10-1-0533.</rawString>
</citation>
<citation valid="true">
<authors>
<author>\x0cReferences J Aissen</author>
</authors>
<title>Differential object marking: Iconicity vs.</title>
<date>2003</date>
<booktitle>economy. Natural Language and Linguistic Theory,</booktitle>
<pages>21--3</pages>
<contexts>
<context position="7914" citStr="Aissen, 2003" startWordPosition="1214" endWordPosition="1215">anslation options: generating English in/definite articles when translating from Russian. Definiteness is a semantic property of noun phrases that expresses information such as identifiability, specificity, familiarity and uniqueness (Lyons, 1999). In English, it is expressed through the use of article determiners and nonarticle determiners. Although languages may express definiteness through such morphemes, many languages use alternative mechanisms. For example they may use noncanonical word orders (Mohanan, 1994)2 or different constructions such as existentials, differential object marking (Aissen, 2003), and the ba () construction in Chinese 2 See pp. 1112 for an example in Hindi, a language without articles. 272 \x0c(Chen, 2004). While these languages lack articles, they may use demonstratives and the quantifier one to emphasize definiteness and indefiniteness, respectively. Russian and Czech are examples of languages that use non-lexical means to express definiteness. As such, in Russian to English translation systems, we expect that most Russian nouns should have at least three translation optionsthe bare noun, the noun preceded by the, and the noun preceded a/an. Fig. 1 illustrates how t</context>
</contexts>
<marker>Aissen, 2003</marker>
<rawString>\x0cReferences J. Aissen. 2003. Differential object marking: Iconicity vs. economy. Natural Language and Linguistic Theory, 21(3):435483.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Callison-Burch</author>
<author>P Koehn</author>
<author>C Monz</author>
<author>O Zaidan</author>
</authors>
<title>Findings of the 2011 workshop on statistical machine translation.</title>
<date>2011</date>
<booktitle>In Proceedings of the Sixth Workshop on Statistical Machine Translation,</booktitle>
<pages>2264</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Edinburgh, Scotland,</location>
<contexts>
<context position="13726" citStr="Callison-Burch et al., 2011" startWordPosition="2160" endWordPosition="2163">ical. Statistical features capture probability of co-occurrences of a sample with each of the determiner classes, e.g., for wi1ywi we collect probabilities of wi1Iwi, wi1Dwi, and wi1Nwi.6 4.3 Training and evaluation We employ the creg regression modeling framework to train a ternary logistic regression classifier.7 All features were computed for the targetside of the Russian-English TED corpus (Cettolo et al., 2012); from 117,527 sentences we removed 5K sentences used as tuning and test sets in the MT system. We extract statistical features from monolingual English corpora released for WMT11 (Callison-Burch et al., 2011). In the training corpus there are 65,075 I instances, 114,571 D instances, and 2,435,287 N instances. To create a balanced training set we randomly sample 65K instances from each set of collected instances.8 This training set of feature vectors has 142,604 features and 285,210 parameters. To minimize the number of free parameters in our model we use `1 regularization. We perform 10-fold cross validation experiments with various feature combinations, evaluating the classifier accuracy for all classes and for each class independently. The performance of the classifier on individual classes and </context>
</contexts>
<marker>Callison-Burch, Koehn, Monz, Zaidan, 2011</marker>
<rawString>C. Callison-Burch, P. Koehn, C. Monz, and O. Zaidan. 2011. Findings of the 2011 workshop on statistical machine translation. In Proceedings of the Sixth Workshop on Statistical Machine Translation, pages 2264, Edinburgh, Scotland, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Cettolo</author>
<author>C Girardi</author>
<author>M Federico</author>
</authors>
<title>WIT3 : Web inventory of transcribed and translated talks.</title>
<date>2012</date>
<booktitle>In Proceedings of the 16th Conference of the European Association for Machine Translation (EAMT),</booktitle>
<pages>261268</pages>
<location>Trento, Italy,</location>
<contexts>
<context position="13517" citStr="Cettolo et al., 2012" startWordPosition="2127" endWordPosition="2130">have an article included in them, such as the Netherlands, the United States of America, but these are fixed expressions and the model is easily able to capture such cases with lexical features. Statistical. Statistical features capture probability of co-occurrences of a sample with each of the determiner classes, e.g., for wi1ywi we collect probabilities of wi1Iwi, wi1Dwi, and wi1Nwi.6 4.3 Training and evaluation We employ the creg regression modeling framework to train a ternary logistic regression classifier.7 All features were computed for the targetside of the Russian-English TED corpus (Cettolo et al., 2012); from 117,527 sentences we removed 5K sentences used as tuning and test sets in the MT system. We extract statistical features from monolingual English corpora released for WMT11 (Callison-Burch et al., 2011). In the training corpus there are 65,075 I instances, 114,571 D instances, and 2,435,287 N instances. To create a balanced training set we randomly sample 65K instances from each set of collected instances.8 This training set of feature vectors has 142,604 features and 285,210 parameters. To minimize the number of free parameters in our model we use `1 regularization. We perform 10-fold </context>
</contexts>
<marker>Cettolo, Girardi, Federico, 2012</marker>
<rawString>M. Cettolo, C. Girardi, and M. Federico. 2012. WIT3 : Web inventory of transcribed and translated talks. In Proceedings of the 16th Conference of the European Association for Machine Translation (EAMT), pages 261268, Trento, Italy, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Chen</author>
<author>R Kuhn</author>
<author>G Foster</author>
</authors>
<title>Semantic smoothing and fabrication of phrase pairs for SMT.</title>
<date>2011</date>
<contexts>
<context position="31602" citStr="Chen et al. (2011)" startWordPosition="5026" endWordPosition="5029"> including postediting of MT output (Knight and Chander, 1994), text generation (Elhadad, 1993; Minnen et al., 2000), and more recently identification and correction of ESL errors (Han et al., 2006; De Felice and Pulman, 2008; Gamon et al., 2009; Rozovskaya and Roth, 2010). Our work on determiners extends previous studies in several dimensions. While all previous approaches were tested only on NP constructions, we evaluate our classifier on any sequence of tokens. To the best of our knowledge, the only studies that directly address generation of synthetic phrase table entries was conducted by Chen et al. (2011) and Koehn and Hoang (2007). The former find semantically similar source phrases and produce fabricated translations by combining these source phrases with a set of their target phrases; however, they do not observe improvements. The later work integrates the synthesis of translation options into the decoder. While related in spirit, their method only supports a limited set of generative processes for producing the candidate set (lacking, for instance, the simple and effective phrase post-editing process we have used), and their implementation has been plagued by computational challenges. Post</context>
</contexts>
<marker>Chen, Kuhn, Foster, 2011</marker>
<rawString>B. Chen, R. Kuhn, and G. Foster. 2011. Semantic smoothing and fabrication of phrase pairs for SMT.</rawString>
</citation>
<citation valid="false">
<booktitle>In Proceedings of the International Workshop on Spoken Lanuage Translation (IWSLT-2011).</booktitle>
<marker></marker>
<rawString>In Proceedings of the International Workshop on Spoken Lanuage Translation (IWSLT-2011).</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Chen</author>
</authors>
<title>Identifiability and definiteness in chinese.</title>
<date>2004</date>
<journal>Linguistics,</journal>
<volume>42</volume>
<issue>6</issue>
<contexts>
<context position="8043" citStr="Chen, 2004" startWordPosition="1238" endWordPosition="1239">un phrases that expresses information such as identifiability, specificity, familiarity and uniqueness (Lyons, 1999). In English, it is expressed through the use of article determiners and nonarticle determiners. Although languages may express definiteness through such morphemes, many languages use alternative mechanisms. For example they may use noncanonical word orders (Mohanan, 1994)2 or different constructions such as existentials, differential object marking (Aissen, 2003), and the ba () construction in Chinese 2 See pp. 1112 for an example in Hindi, a language without articles. 272 \x0c(Chen, 2004). While these languages lack articles, they may use demonstratives and the quantifier one to emphasize definiteness and indefiniteness, respectively. Russian and Czech are examples of languages that use non-lexical means to express definiteness. As such, in Russian to English translation systems, we expect that most Russian nouns should have at least three translation optionsthe bare noun, the noun preceded by the, and the noun preceded a/an. Fig. 1 illustrates how the definiteness mismatch between Russian and English can result in gaps in the phrasal inventory learned from a relatively large </context>
</contexts>
<marker>Chen, 2004</marker>
<rawString>P. Chen. 2004. Identifiability and definiteness in chinese. Linguistics, 42(6):11291184.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Cherry</author>
<author>G Foster</author>
</authors>
<title>Batch tuning strategies for statistical machine translation.</title>
<date>2012</date>
<booktitle>In Proceedings of HLT-NAACL 2012,</booktitle>
<volume>12</volume>
<pages>3435</pages>
<contexts>
<context position="1987" citStr="Cherry and Foster, 2012" startWordPosition="283" endWordPosition="286"> matching contiguous spans of the input against an inventory of phrasal translations, reordering them into a target-language appropriate order, and choosing the best one according to a discriminative model that combines features of the phrases used, reordering patterns, and target language model (Koehn et al., 2003). This relatively simple approach to translation can be remarkably effective, and, since its introduction, it has been the basis for further innovations, including developing better models for distinguishing the good translations from bad ones (Chiang, 2012; Gimpel and Smith, 2012; Cherry and Foster, 2012; Eidelman et al., 2013), improving the identification of phrase pairs in parallel data (DeNero et al., 2008; DeNero and Klein, 2010), and formal generalizations to gapped rules and rich nonterminal types (Chiang, 2007; Galley et al., 2006). This paper proposes a different mechanism for improving phrase-based translation: the use of synthetic translation options to supplement the standard phrasal inventory used in phrase-based translation systems. In the following, we argue that phrase tables acquired in usual way will be expected to have gaps in their coverage in certain language pairs and th</context>
</contexts>
<marker>Cherry, Foster, 2012</marker>
<rawString>C. Cherry and G. Foster. 2012. Batch tuning strategies for statistical machine translation. In Proceedings of HLT-NAACL 2012, volume 12, pages 3435.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Chiang</author>
</authors>
<title>Hierarchical phrase-based translation.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<contexts>
<context position="2205" citStr="Chiang, 2007" startWordPosition="320" endWordPosition="321">of the phrases used, reordering patterns, and target language model (Koehn et al., 2003). This relatively simple approach to translation can be remarkably effective, and, since its introduction, it has been the basis for further innovations, including developing better models for distinguishing the good translations from bad ones (Chiang, 2012; Gimpel and Smith, 2012; Cherry and Foster, 2012; Eidelman et al., 2013), improving the identification of phrase pairs in parallel data (DeNero et al., 2008; DeNero and Klein, 2010), and formal generalizations to gapped rules and rich nonterminal types (Chiang, 2007; Galley et al., 2006). This paper proposes a different mechanism for improving phrase-based translation: the use of synthetic translation options to supplement the standard phrasal inventory used in phrase-based translation systems. In the following, we argue that phrase tables acquired in usual way will be expected to have gaps in their coverage in certain language pairs and that supplementing these with synthetic translation options is a priori preferable to alternative techniques, such as post processing, for generalizing beyond the translation pairs observable in training data (2). As a c</context>
</contexts>
<marker>Chiang, 2007</marker>
<rawString>D. Chiang. 2007. Hierarchical phrase-based translation. Computational Linguistics, 33(2):201228.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Chiang</author>
</authors>
<title>Hope and fear for discriminative training of statistical translation models.</title>
<date>2012</date>
<journal>The Journal of Machine Learning Research,</journal>
<volume>98888</volume>
<pages>1187</pages>
<contexts>
<context position="1938" citStr="Chiang, 2012" startWordPosition="276" endWordPosition="277">ns for an input sentence is created by matching contiguous spans of the input against an inventory of phrasal translations, reordering them into a target-language appropriate order, and choosing the best one according to a discriminative model that combines features of the phrases used, reordering patterns, and target language model (Koehn et al., 2003). This relatively simple approach to translation can be remarkably effective, and, since its introduction, it has been the basis for further innovations, including developing better models for distinguishing the good translations from bad ones (Chiang, 2012; Gimpel and Smith, 2012; Cherry and Foster, 2012; Eidelman et al., 2013), improving the identification of phrase pairs in parallel data (DeNero et al., 2008; DeNero and Klein, 2010), and formal generalizations to gapped rules and rich nonterminal types (Chiang, 2007; Galley et al., 2006). This paper proposes a different mechanism for improving phrase-based translation: the use of synthetic translation options to supplement the standard phrasal inventory used in phrase-based translation systems. In the following, we argue that phrase tables acquired in usual way will be expected to have gaps i</context>
</contexts>
<marker>Chiang, 2012</marker>
<rawString>D. Chiang. 2012. Hope and fear for discriminative training of statistical translation models. The Journal of Machine Learning Research, 98888:1159 1187.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J H Clark</author>
<author>C Dyer</author>
<author>A Lavie</author>
<author>N A Smith</author>
</authors>
<title>Better hypothesis testing for statistical machine translation: Controlling for optimizer instability. In</title>
<date>2011</date>
<booktitle>In Proc. of ACL.</booktitle>
<contexts>
<context position="19987" citStr="Clark et al., 2011" startWordPosition="3162" endWordPosition="3165">inal phrase table entry is illustrated in Figure 2. 6 Translation Results We now review the results of experiments using synthetic translation options in a machine translation system. We use the Moses toolkit (Koehn et al., 2007) to train a baseline phrase-based SMT system. Each configuration we compare has a different phrase table, with synthetic phrases generated with best-first or iterative strategies, from a phrase table with- or without-determiners, with variable number of translation features. To verify that system improvement is consistent, and is not a result of optimizer instability (Clark et al., 2011), we replicate each experimental setup three times, and then estimate the translation quality of the median MT system using the MultEval toolkit.9 The corpus is the same as in Section 4.3: the training part contains 112,527 sentences from Russian-English TED corpus, randomly sampled 3K sentences are used for tuning and a disjoint set of 2K sentences is used for test. We lowercase both sides, and use Stanford CoreNLP10 tools to tokenize the corpora. We employ SRILM toolkit (Stolcke, 2002) to linearly interpolate the target side of the training corpus with the WMT English corpus, optimizing towa</context>
</contexts>
<marker>Clark, Dyer, Lavie, Smith, 2011</marker>
<rawString>J. H. Clark, C. Dyer, A. Lavie, and N. A. Smith. 2011. Better hypothesis testing for statistical machine translation: Controlling for optimizer instability. In In Proc. of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Clifton</author>
<author>A Sarkar</author>
</authors>
<title>Combining morpheme-based machine translation with postprocessing morpheme prediction.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL.</booktitle>
<marker>Clifton, Sarkar, 2011</marker>
<rawString>A. Clifton and A. Sarkar. 2011. Combining morpheme-based machine translation with postprocessing morpheme prediction. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R De Felice</author>
<author>S G Pulman</author>
</authors>
<title>A classifierbased approach to preposition and determiner error correction in L2 English.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics-Volume 1,</booktitle>
<pages>169176</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>De Felice, Pulman, 2008</marker>
<rawString>R. De Felice and S. G. Pulman. 2008. A classifierbased approach to preposition and determiner error correction in L2 English. In Proceedings of the 22nd International Conference on Computational Linguistics-Volume 1, pages 169176. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A de Gispert</author>
<author>J B Marino</author>
<author>J M Crego</author>
</authors>
<title>Improving statistical machine translation by classifying and generalizing inflected verb forms.</title>
<date>2005</date>
<booktitle>In Proceedings of InterSpeech.</booktitle>
<marker>de Gispert, Marino, Crego, 2005</marker>
<rawString>A. de Gispert, J. B. Marino, and J. M. Crego. 2005. Improving statistical machine translation by classifying and generalizing inflected verb forms. In Proceedings of InterSpeech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J DeNero</author>
<author>D Klein</author>
</authors>
<title>Discriminative modeling of extraction sets for machine translation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1453--1463</pages>
<institution>Association for Computational Linguistics.</institution>
<contexts>
<context position="2120" citStr="DeNero and Klein, 2010" startWordPosition="305" endWordPosition="308">ate order, and choosing the best one according to a discriminative model that combines features of the phrases used, reordering patterns, and target language model (Koehn et al., 2003). This relatively simple approach to translation can be remarkably effective, and, since its introduction, it has been the basis for further innovations, including developing better models for distinguishing the good translations from bad ones (Chiang, 2012; Gimpel and Smith, 2012; Cherry and Foster, 2012; Eidelman et al., 2013), improving the identification of phrase pairs in parallel data (DeNero et al., 2008; DeNero and Klein, 2010), and formal generalizations to gapped rules and rich nonterminal types (Chiang, 2007; Galley et al., 2006). This paper proposes a different mechanism for improving phrase-based translation: the use of synthetic translation options to supplement the standard phrasal inventory used in phrase-based translation systems. In the following, we argue that phrase tables acquired in usual way will be expected to have gaps in their coverage in certain language pairs and that supplementing these with synthetic translation options is a priori preferable to alternative techniques, such as post processing, </context>
</contexts>
<marker>DeNero, Klein, 2010</marker>
<rawString>J. DeNero and D. Klein. 2010. Discriminative modeling of extraction sets for machine translation. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1453 1463. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J DeNero</author>
<author>A Bouchard-Cote</author>
<author>D Klein</author>
</authors>
<title>Sampling alignment structure under a Bayesian translation model.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>314323</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2095" citStr="DeNero et al., 2008" startWordPosition="301" endWordPosition="304">get-language appropriate order, and choosing the best one according to a discriminative model that combines features of the phrases used, reordering patterns, and target language model (Koehn et al., 2003). This relatively simple approach to translation can be remarkably effective, and, since its introduction, it has been the basis for further innovations, including developing better models for distinguishing the good translations from bad ones (Chiang, 2012; Gimpel and Smith, 2012; Cherry and Foster, 2012; Eidelman et al., 2013), improving the identification of phrase pairs in parallel data (DeNero et al., 2008; DeNero and Klein, 2010), and formal generalizations to gapped rules and rich nonterminal types (Chiang, 2007; Galley et al., 2006). This paper proposes a different mechanism for improving phrase-based translation: the use of synthetic translation options to supplement the standard phrasal inventory used in phrase-based translation systems. In the following, we argue that phrase tables acquired in usual way will be expected to have gaps in their coverage in certain language pairs and that supplementing these with synthetic translation options is a priori preferable to alternative techniques, </context>
</contexts>
<marker>DeNero, Bouchard-Cote, Klein, 2008</marker>
<rawString>J. DeNero, A. Bouchard-Cote, and D. Klein. 2008. Sampling alignment structure under a Bayesian translation model. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 314323. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Eidelman</author>
<author>Y Marton</author>
<author>P Resnik</author>
</authors>
<title>Online relative margin maximization for statistical machine translation.</title>
<date>2013</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="2011" citStr="Eidelman et al., 2013" startWordPosition="287" endWordPosition="290">s of the input against an inventory of phrasal translations, reordering them into a target-language appropriate order, and choosing the best one according to a discriminative model that combines features of the phrases used, reordering patterns, and target language model (Koehn et al., 2003). This relatively simple approach to translation can be remarkably effective, and, since its introduction, it has been the basis for further innovations, including developing better models for distinguishing the good translations from bad ones (Chiang, 2012; Gimpel and Smith, 2012; Cherry and Foster, 2012; Eidelman et al., 2013), improving the identification of phrase pairs in parallel data (DeNero et al., 2008; DeNero and Klein, 2010), and formal generalizations to gapped rules and rich nonterminal types (Chiang, 2007; Galley et al., 2006). This paper proposes a different mechanism for improving phrase-based translation: the use of synthetic translation options to supplement the standard phrasal inventory used in phrase-based translation systems. In the following, we argue that phrase tables acquired in usual way will be expected to have gaps in their coverage in certain language pairs and that supplementing these w</context>
</contexts>
<marker>Eidelman, Marton, Resnik, 2013</marker>
<rawString>V. Eidelman, Y. Marton, and P. Resnik. 2013. Online relative margin maximization for statistical machine translation. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Elhadad</author>
</authors>
<title>Generating argumentative judgment determiners.</title>
<date>1993</date>
<booktitle>In AAAI,</booktitle>
<pages>344349</pages>
<contexts>
<context position="31078" citStr="Elhadad, 1993" startWordPosition="4940" endWordPosition="4941"> it would mislead him/her to interpret the object three billion people as referring to a specific identifiable set. Our system, on the other hand, correctly selects the determiner class N and hence does not insert an article. Thus we see that our system does not just add fluency but it also captures a semantic distinction, namely identifiability, that a human subject makes when producing or interpreting a phrase. 7 Related Work Automated determiner prediction has been found beneficial in a variety of applications, including postediting of MT output (Knight and Chander, 1994), text generation (Elhadad, 1993; Minnen et al., 2000), and more recently identification and correction of ESL errors (Han et al., 2006; De Felice and Pulman, 2008; Gamon et al., 2009; Rozovskaya and Roth, 2010). Our work on determiners extends previous studies in several dimensions. While all previous approaches were tested only on NP constructions, we evaluate our classifier on any sequence of tokens. To the best of our knowledge, the only studies that directly address generation of synthetic phrase table entries was conducted by Chen et al. (2011) and Koehn and Hoang (2007). The former find semantically similar source phr</context>
</contexts>
<marker>Elhadad, 1993</marker>
<rawString>M. Elhadad. 1993. Generating argumentative judgment determiners. In AAAI, pages 344349.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Finkel</author>
<author>T Grenager</author>
<author>C Manning</author>
</authors>
<title>Incorporating non-local information into information extraction systems by gibbs sampling.</title>
<date>2005</date>
<booktitle>In ACL 05: Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>363--370</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="12331" citStr="Finkel et al., 2005" startWordPosition="1933" endWordPosition="1936">t of]], can be estimated reliably and capture construction-specific article use. Morphosyntactic. We used part-of-speech (POS) tags produced by the Stanford POS tagger (Toutanova and Manning, 2000) to capture general article patterns. These are relevant features in the prediction of articles as we observe certain constraints regarding the use of articles in the neighborhood of certain POS tags. For example, we do not expect to predict an article following an adjective (JJ). Semantic. We extract further information indicating whether a named entity, as identified by the Stanford NE Recognizer (Finkel et al., 2005) begins at wi. These features are relevant as there 5 Realization of the classes D and N as lexical items is straightforward. To convert I into a or an, we use the CMU pronouncing dictionary (http://www.speech. cs.cmu.edu/cgi-bin/cmudict) and select an if wi starts with a phonetic vowel. 273 \x0cis, in general, a constraint on the co-occurrence of articles with named entities which can help us predict the use of articles in such constructions. For example, proper nouns do not tend to cooccur with articles in English. Although there are some proper nouns that have an article included in them, s</context>
</contexts>
<marker>Finkel, Grenager, Manning, 2005</marker>
<rawString>J. R. Finkel, T. Grenager, and C. Manning. 2005. Incorporating non-local information into information extraction systems by gibbs sampling. In ACL 05: Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, pages 363 370, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Fraser</author>
<author>M Weller</author>
<author>A Cahill</author>
<author>F Cap</author>
</authors>
<title>Modeling inflection and word-formation in SMT.</title>
<date>2012</date>
<booktitle>In Proceedings of EACL.</booktitle>
<marker>Fraser, Weller, Cahill, Cap, 2012</marker>
<rawString>A. Fraser, M. Weller, A. Cahill, and F. Cap. 2012. Modeling inflection and word-formation in SMT. In Proceedings of EACL.</rawString>
</citation>
<citation valid="false">
<authors>
<author>M Galley</author>
<author>J Graehl</author>
<author>K Knight</author>
<author>D Marcu</author>
<author>S DeNeefe</author>
<author>W Wang</author>
<author>I Thayer</author>
</authors>
<title>Scalable inference and training of context-rich syntactic translation models.</title>
<date>2006</date>
<booktitle>In ACL-44: Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics,</booktitle>
<pages>961968</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="2227" citStr="Galley et al., 2006" startWordPosition="322" endWordPosition="325"> used, reordering patterns, and target language model (Koehn et al., 2003). This relatively simple approach to translation can be remarkably effective, and, since its introduction, it has been the basis for further innovations, including developing better models for distinguishing the good translations from bad ones (Chiang, 2012; Gimpel and Smith, 2012; Cherry and Foster, 2012; Eidelman et al., 2013), improving the identification of phrase pairs in parallel data (DeNero et al., 2008; DeNero and Klein, 2010), and formal generalizations to gapped rules and rich nonterminal types (Chiang, 2007; Galley et al., 2006). This paper proposes a different mechanism for improving phrase-based translation: the use of synthetic translation options to supplement the standard phrasal inventory used in phrase-based translation systems. In the following, we argue that phrase tables acquired in usual way will be expected to have gaps in their coverage in certain language pairs and that supplementing these with synthetic translation options is a priori preferable to alternative techniques, such as post processing, for generalizing beyond the translation pairs observable in training data (2). As a case study, we consider</context>
</contexts>
<marker>Galley, Graehl, Knight, Marcu, DeNeefe, Wang, Thayer, 2006</marker>
<rawString>M. Galley, J. Graehl, K. Knight, D. Marcu, S. DeNeefe, W. Wang, and I. Thayer. 2006. Scalable inference and training of context-rich syntactic translation models. In ACL-44: Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, pages 961968, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Gamon</author>
<author>J Gao</author>
<author>C Brockett</author>
<author>A Klementiev</author>
<author>W B Dolan</author>
<author>D Belenko</author>
<author>L Vanderwende</author>
</authors>
<title>Using contextual speller techniques and language modeling for ESL error correction.</title>
<date>2009</date>
<pages>51--61801</pages>
<location>Urbana,</location>
<contexts>
<context position="31229" citStr="Gamon et al., 2009" startWordPosition="4965" endWordPosition="4968"> correctly selects the determiner class N and hence does not insert an article. Thus we see that our system does not just add fluency but it also captures a semantic distinction, namely identifiability, that a human subject makes when producing or interpreting a phrase. 7 Related Work Automated determiner prediction has been found beneficial in a variety of applications, including postediting of MT output (Knight and Chander, 1994), text generation (Elhadad, 1993; Minnen et al., 2000), and more recently identification and correction of ESL errors (Han et al., 2006; De Felice and Pulman, 2008; Gamon et al., 2009; Rozovskaya and Roth, 2010). Our work on determiners extends previous studies in several dimensions. While all previous approaches were tested only on NP constructions, we evaluate our classifier on any sequence of tokens. To the best of our knowledge, the only studies that directly address generation of synthetic phrase table entries was conducted by Chen et al. (2011) and Koehn and Hoang (2007). The former find semantically similar source phrases and produce fabricated translations by combining these source phrases with a set of their target phrases; however, they do not observe improvement</context>
</contexts>
<marker>Gamon, Gao, Brockett, Klementiev, Dolan, Belenko, Vanderwende, 2009</marker>
<rawString>M. Gamon, J. Gao, C. Brockett, A. Klementiev, W. B. Dolan, D. Belenko, and L. Vanderwende. 2009. Using contextual speller techniques and language modeling for ESL error correction. Urbana, 51:61801.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Gimpel</author>
<author>N A Smith</author>
</authors>
<title>Structured ramp loss minimization for machine translation.</title>
<date>2012</date>
<booktitle>In Proceedings of 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies HLTNAACL 2012,</booktitle>
<location>Montreal, Canada.</location>
<contexts>
<context position="1962" citStr="Gimpel and Smith, 2012" startWordPosition="278" endWordPosition="282">t sentence is created by matching contiguous spans of the input against an inventory of phrasal translations, reordering them into a target-language appropriate order, and choosing the best one according to a discriminative model that combines features of the phrases used, reordering patterns, and target language model (Koehn et al., 2003). This relatively simple approach to translation can be remarkably effective, and, since its introduction, it has been the basis for further innovations, including developing better models for distinguishing the good translations from bad ones (Chiang, 2012; Gimpel and Smith, 2012; Cherry and Foster, 2012; Eidelman et al., 2013), improving the identification of phrase pairs in parallel data (DeNero et al., 2008; DeNero and Klein, 2010), and formal generalizations to gapped rules and rich nonterminal types (Chiang, 2007; Galley et al., 2006). This paper proposes a different mechanism for improving phrase-based translation: the use of synthetic translation options to supplement the standard phrasal inventory used in phrase-based translation systems. In the following, we argue that phrase tables acquired in usual way will be expected to have gaps in their coverage in cert</context>
</contexts>
<marker>Gimpel, Smith, 2012</marker>
<rawString>K. Gimpel and N. A. Smith. 2012. Structured ramp loss minimization for machine translation. In Proceedings of 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies HLTNAACL 2012, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N-R Han</author>
<author>M Chodorow</author>
<author>C Leacock</author>
</authors>
<title>Detecting errors in English article usage by non-native speakers.</title>
<date>2006</date>
<contexts>
<context position="31181" citStr="Han et al., 2006" startWordPosition="4955" endWordPosition="4958">entifiable set. Our system, on the other hand, correctly selects the determiner class N and hence does not insert an article. Thus we see that our system does not just add fluency but it also captures a semantic distinction, namely identifiability, that a human subject makes when producing or interpreting a phrase. 7 Related Work Automated determiner prediction has been found beneficial in a variety of applications, including postediting of MT output (Knight and Chander, 1994), text generation (Elhadad, 1993; Minnen et al., 2000), and more recently identification and correction of ESL errors (Han et al., 2006; De Felice and Pulman, 2008; Gamon et al., 2009; Rozovskaya and Roth, 2010). Our work on determiners extends previous studies in several dimensions. While all previous approaches were tested only on NP constructions, we evaluate our classifier on any sequence of tokens. To the best of our knowledge, the only studies that directly address generation of synthetic phrase table entries was conducted by Chen et al. (2011) and Koehn and Hoang (2007). The former find semantically similar source phrases and produce fabricated translations by combining these source phrases with a set of their target p</context>
</contexts>
<marker>Han, Chodorow, Leacock, 2006</marker>
<rawString>N.-R. Han, M. Chodorow, and C. Leacock. 2006. Detecting errors in English article usage by non-native speakers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Knight</author>
<author>I Chander</author>
</authors>
<title>Automated postediting of documents.</title>
<date>1994</date>
<booktitle>In Proceedings of the National Conference on Artificial Intelligence,</booktitle>
<pages>779779</pages>
<location>Seattle, WA.</location>
<contexts>
<context position="9054" citStr="Knight and Chander, 1994" startWordPosition="1395" endWordPosition="1398"> noun, the noun preceded by the, and the noun preceded a/an. Fig. 1 illustrates how the definiteness mismatch between Russian and English can result in gaps in the phrasal inventory learned from a relatively large parallel corpus. The Russian input should translate (depending on context) as either I saw a cat or I saw the cat; however, the phrase table we learned is only able to generate the former.3 4 Predicting English Definite Articles Although English articles express semantic content, their use is largely predictable in context, both for native English speakers and for automated systems (Knight and Chander, 1994).4 In this section we describe a classifier that uses local contextual features to predict whether an article belongs in a particular position in a sequence of words, and if so, whether it is definite or indefinite (the form of the indefinite article is deterministic given the pronunciation of the following word). 4.1 Model The classifier takes an English word sequence w = hw1, w2, . . . , w|w|i with missing articles and an index i and predicts whether no article, a definite article, or an indefinite article should appear before wi. We parameterize the classifier as a multiclass 3 The phrase t</context>
<context position="31046" citStr="Knight and Chander, 1994" startWordPosition="4934" endWordPosition="4937">. If a human subject reads this translation, it would mislead him/her to interpret the object three billion people as referring to a specific identifiable set. Our system, on the other hand, correctly selects the determiner class N and hence does not insert an article. Thus we see that our system does not just add fluency but it also captures a semantic distinction, namely identifiability, that a human subject makes when producing or interpreting a phrase. 7 Related Work Automated determiner prediction has been found beneficial in a variety of applications, including postediting of MT output (Knight and Chander, 1994), text generation (Elhadad, 1993; Minnen et al., 2000), and more recently identification and correction of ESL errors (Han et al., 2006; De Felice and Pulman, 2008; Gamon et al., 2009; Rozovskaya and Roth, 2010). Our work on determiners extends previous studies in several dimensions. While all previous approaches were tested only on NP constructions, we evaluate our classifier on any sequence of tokens. To the best of our knowledge, the only studies that directly address generation of synthetic phrase table entries was conducted by Chen et al. (2011) and Koehn and Hoang (2007). The former find</context>
</contexts>
<marker>Knight, Chander, 1994</marker>
<rawString>K. Knight and I. Chander. 1994. Automated postediting of documents. In Proceedings of the National Conference on Artificial Intelligence, pages 779779, Seattle, WA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>H Hoang</author>
</authors>
<title>Factored translation models.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),</booktitle>
<pages>868876</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="31629" citStr="Koehn and Hoang (2007)" startWordPosition="5031" endWordPosition="5034">of MT output (Knight and Chander, 1994), text generation (Elhadad, 1993; Minnen et al., 2000), and more recently identification and correction of ESL errors (Han et al., 2006; De Felice and Pulman, 2008; Gamon et al., 2009; Rozovskaya and Roth, 2010). Our work on determiners extends previous studies in several dimensions. While all previous approaches were tested only on NP constructions, we evaluate our classifier on any sequence of tokens. To the best of our knowledge, the only studies that directly address generation of synthetic phrase table entries was conducted by Chen et al. (2011) and Koehn and Hoang (2007). The former find semantically similar source phrases and produce fabricated translations by combining these source phrases with a set of their target phrases; however, they do not observe improvements. The later work integrates the synthesis of translation options into the decoder. While related in spirit, their method only supports a limited set of generative processes for producing the candidate set (lacking, for instance, the simple and effective phrase post-editing process we have used), and their implementation has been plagued by computational challenges. Post-processing techniques have</context>
</contexts>
<marker>Koehn, Hoang, 2007</marker>
<rawString>P. Koehn and H. Hoang. 2007. Factored translation models. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 868876, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och Koehn</author>
<author>D Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In NAACL 03: Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology,</booktitle>
<pages>48--54</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Koehn, Marcu, 2003</marker>
<rawString>\x0cP. Koehn, F. J. Och, and D. Marcu. 2003. Statistical phrase-based translation. In NAACL 03: Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology, pages 48 54. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>P Koehn</author>
<author>H Hoang</author>
<author>A Birch</author>
<author>C Callison-Burch</author>
<author>M Federico</author>
<author>N Bertoldi</author>
<author>B Cowan</author>
<author>W Shen</author>
<author>C Moran</author>
<author>R Zens</author>
<author>C Dyer</author>
<author>O Bojar</author>
<author>A Constantin</author>
<author>E Herbst</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions,</booktitle>
<pages>177--180</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="19597" citStr="Koehn et al., 2007" startWordPosition="3103" endWordPosition="3106">classifier averaged over all locations where it could be extracted from the training data. The next feature is derived from this score: it is a boolean feature indicating a confidence of the classifier: the feature value is 1 iff the average classifier score is higher than some threshold. Consider again a phrase I saw a cat discussed in Section 1. Synthetic entry generation from the original phrase table entry is illustrated in Figure 2. 6 Translation Results We now review the results of experiments using synthetic translation options in a machine translation system. We use the Moses toolkit (Koehn et al., 2007) to train a baseline phrase-based SMT system. Each configuration we compare has a different phrase table, with synthetic phrases generated with best-first or iterative strategies, from a phrase table with- or without-determiners, with variable number of translation features. To verify that system improvement is consistent, and is not a result of optimizer instability (Clark et al., 2011), we replicate each experimental setup three times, and then estimate the translation quality of the median MT system using the MultEval toolkit.9 The corpus is the same as in Section 4.3: the training part con</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, Herbst, 2007</marker>
<rawString>P. Koehn, H. Hoang, A. Birch, C. Callison-Burch, M. Federico, N. Bertoldi, B. Cowan, W. Shen, C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin, and E. Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions, pages 177 180, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Lyons</author>
</authors>
<title>Definiteness.</title>
<date>1999</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="7548" citStr="Lyons, 1999" startWordPosition="1162" endWordPosition="1163">ns may be synthesized. Ultimately, of course, the global translation model must select one translation for every phrase it uses, but the decoder will have access to global information that it can use to pick better translation options. 3 Case Study: English Definite Articles We now turn to a translation problem that we will use to assess the value of synthetic translation options: generating English in/definite articles when translating from Russian. Definiteness is a semantic property of noun phrases that expresses information such as identifiability, specificity, familiarity and uniqueness (Lyons, 1999). In English, it is expressed through the use of article determiners and nonarticle determiners. Although languages may express definiteness through such morphemes, many languages use alternative mechanisms. For example they may use noncanonical word orders (Mohanan, 1994)2 or different constructions such as existentials, differential object marking (Aissen, 2003), and the ba () construction in Chinese 2 See pp. 1112 for an example in Hindi, a language without articles. 272 \x0c(Chen, 2004). While these languages lack articles, they may use demonstratives and the quantifier one to emphasize de</context>
</contexts>
<marker>Lyons, 1999</marker>
<rawString>C. Lyons. 1999. Definiteness. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Minnen</author>
<author>F Bond</author>
<author>A Copestake</author>
</authors>
<title>Memory-based learning for article generation.</title>
<date>2000</date>
<booktitle>In Proceedings of the 2nd workshop on Learning language in logic and the 4th conference on Computational natural language learning-Volume 7,</booktitle>
<pages>4348</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="31100" citStr="Minnen et al., 2000" startWordPosition="4942" endWordPosition="4945">ad him/her to interpret the object three billion people as referring to a specific identifiable set. Our system, on the other hand, correctly selects the determiner class N and hence does not insert an article. Thus we see that our system does not just add fluency but it also captures a semantic distinction, namely identifiability, that a human subject makes when producing or interpreting a phrase. 7 Related Work Automated determiner prediction has been found beneficial in a variety of applications, including postediting of MT output (Knight and Chander, 1994), text generation (Elhadad, 1993; Minnen et al., 2000), and more recently identification and correction of ESL errors (Han et al., 2006; De Felice and Pulman, 2008; Gamon et al., 2009; Rozovskaya and Roth, 2010). Our work on determiners extends previous studies in several dimensions. While all previous approaches were tested only on NP constructions, we evaluate our classifier on any sequence of tokens. To the best of our knowledge, the only studies that directly address generation of synthetic phrase table entries was conducted by Chen et al. (2011) and Koehn and Hoang (2007). The former find semantically similar source phrases and produce fabri</context>
</contexts>
<marker>Minnen, Bond, Copestake, 2000</marker>
<rawString>G. Minnen, F. Bond, and A. Copestake. 2000. Memory-based learning for article generation. In Proceedings of the 2nd workshop on Learning language in logic and the 4th conference on Computational natural language learning-Volume 7, pages 4348. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Mohanan</author>
</authors>
<title>Argument Structure in Hindi.</title>
<date>1994</date>
<publisher>CSLI Publications.</publisher>
<contexts>
<context position="7821" citStr="Mohanan, 1994" startWordPosition="1202" endWordPosition="1204">cles We now turn to a translation problem that we will use to assess the value of synthetic translation options: generating English in/definite articles when translating from Russian. Definiteness is a semantic property of noun phrases that expresses information such as identifiability, specificity, familiarity and uniqueness (Lyons, 1999). In English, it is expressed through the use of article determiners and nonarticle determiners. Although languages may express definiteness through such morphemes, many languages use alternative mechanisms. For example they may use noncanonical word orders (Mohanan, 1994)2 or different constructions such as existentials, differential object marking (Aissen, 2003), and the ba () construction in Chinese 2 See pp. 1112 for an example in Hindi, a language without articles. 272 \x0c(Chen, 2004). While these languages lack articles, they may use demonstratives and the quantifier one to emphasize definiteness and indefiniteness, respectively. Russian and Czech are examples of languages that use non-lexical means to express definiteness. As such, in Russian to English translation systems, we expect that most Russian nouns should have at least three translation options</context>
</contexts>
<marker>Mohanan, 1994</marker>
<rawString>T. Mohanan. 1994. Argument Structure in Hindi. CSLI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Oflazer</author>
<author>I Durgar El-Kahlout</author>
</authors>
<title>Exploring different representational units in English-toTurkish statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the Second Workshop on Statistical Machine Translation,</booktitle>
<pages>2532</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<marker>Oflazer, El-Kahlout, 2007</marker>
<rawString>K. Oflazer and I. Durgar El-Kahlout. 2007. Exploring different representational units in English-toTurkish statistical machine translation. In Proceedings of the Second Workshop on Statistical Machine Translation, pages 2532, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Papineni</author>
<author>S Roukos</author>
<author>T Ward</author>
<author>W-J Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In ACL 02: Proceedings of the 40th Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>311318</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="24126" citStr="Papineni et al., 2002" startWordPosition="3807" endWordPosition="3810"> phrases are shorter than 3 tokens and their synthetic variants contain same words with articles inserted or deleted between each adjacent pair of words. The phrase table of the baseline system contains 2,441,678 phrase pairs. There are 518,453 original short phrases, and our technique yields 842,252 new synthetic entries which we append to the baseline phrase table. Table 3 shows the evaluation of the median SMT system (derived from three systems) with short phrases. In these systems the five phrasal translation features are the same as in the baseline systems. Improvement in the BLEU score (Papineni et al., 2002) is statistically significant (p &amp;lt; .05), compared to the baseline system Classifier-generated synthetic phrases We apply classifier with the iterative prediction directly on the baseline phrase table entries and synthesize 944,145 new parallel phrases, increasing the phrase table size by 38%. The phrasal translation features in each synthetic phrase are the same as in the phrase it was derived from. The BLEU score of the median SMT system with synthetic phrases is 22.9 .1, the improvement is statistically significant (p &amp;lt; .01). Post-processing of a phrase table created from corpora without art</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In ACL 02: Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, pages 311318, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Rozovskaya</author>
<author>D Roth</author>
</authors>
<title>Training paradigms for correcting errors in grammar and usage.</title>
<date>2010</date>
<pages>51--61801</pages>
<location>Urbana,</location>
<contexts>
<context position="31257" citStr="Rozovskaya and Roth, 2010" startWordPosition="4969" endWordPosition="4973">he determiner class N and hence does not insert an article. Thus we see that our system does not just add fluency but it also captures a semantic distinction, namely identifiability, that a human subject makes when producing or interpreting a phrase. 7 Related Work Automated determiner prediction has been found beneficial in a variety of applications, including postediting of MT output (Knight and Chander, 1994), text generation (Elhadad, 1993; Minnen et al., 2000), and more recently identification and correction of ESL errors (Han et al., 2006; De Felice and Pulman, 2008; Gamon et al., 2009; Rozovskaya and Roth, 2010). Our work on determiners extends previous studies in several dimensions. While all previous approaches were tested only on NP constructions, we evaluate our classifier on any sequence of tokens. To the best of our knowledge, the only studies that directly address generation of synthetic phrase table entries was conducted by Chen et al. (2011) and Koehn and Hoang (2007). The former find semantically similar source phrases and produce fabricated translations by combining these source phrases with a set of their target phrases; however, they do not observe improvements. The later work integrates</context>
</contexts>
<marker>Rozovskaya, Roth, 2010</marker>
<rawString>A. Rozovskaya and D. Roth. 2010. Training paradigms for correcting errors in grammar and usage. Urbana, 51:61801.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stolcke</author>
</authors>
<title>SRILMan extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In Procedings of International Conference on Spoken Language Processing,</booktitle>
<pages>901904</pages>
<contexts>
<context position="20479" citStr="Stolcke, 2002" startWordPosition="3244" endWordPosition="3245">atures. To verify that system improvement is consistent, and is not a result of optimizer instability (Clark et al., 2011), we replicate each experimental setup three times, and then estimate the translation quality of the median MT system using the MultEval toolkit.9 The corpus is the same as in Section 4.3: the training part contains 112,527 sentences from Russian-English TED corpus, randomly sampled 3K sentences are used for tuning and a disjoint set of 2K sentences is used for test. We lowercase both sides, and use Stanford CoreNLP10 tools to tokenize the corpora. We employ SRILM toolkit (Stolcke, 2002) to linearly interpolate the target side of the training corpus with the WMT English corpus, optimizing towards the MT tuning set. This LM is used in all experiments. The rest of this section is organized as follows. First, we compare two approaches to the determiners classifier application. Then, we provide detailed description of experiments with synthetic phrases. We evaluate various aspects of synthetic phrases generation and summarize all the results in Table 3. In Table 5 we show examples of improved translations. Classifier application: one-pass vs. iterative. First, as an intrinsic eva</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>A. Stolcke. 2002. SRILMan extensible language modeling toolkit. In Procedings of International Conference on Spoken Language Processing, pages 901904.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Suzuki</author>
<author>K Toutanova</author>
</authors>
<title>Learning to predict case markers in Japanese.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics,</booktitle>
<pages>1049--1056</pages>
<institution>Association for Computational Linguistics.</institution>
<marker>Suzuki, Toutanova, 2006</marker>
<rawString>H. Suzuki and K. Toutanova. 2006. Learning to predict case markers in Japanese. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, pages 1049 1056. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Suzuki</author>
<author>K Toutanova</author>
</authors>
<title>Generating case markers in machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of HLT-NAACL</booktitle>
<pages>4956</pages>
<marker>Suzuki, Toutanova, 2007</marker>
<rawString>H. Suzuki and K. Toutanova. 2007. Generating case markers in machine translation. In Proceedings of HLT-NAACL 2007, pages 4956.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Toutanova</author>
<author>C D Manning</author>
</authors>
<title>Enriching the knowledge sources used in a maximum entropy part-of-speech tagger.</title>
<date>2000</date>
<booktitle>In Proceedings of the 2000 Joint SIGDAT conference on Empirical methods in natural language processing and very large corpora,</booktitle>
<pages>6370</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="11908" citStr="Toutanova and Manning, 2000" startWordPosition="1865" endWordPosition="1868">reflecting basic grammatical rules, we define statistical, semantic and shallow lexical features to capture additional regular and idiosyncratic usages of definite and indefinite articles in English. Below we provide brief details of the features and their motivation. Lexical. Because training data can be constructed inexpensively (from any unannotated English corpus), n-gram indicator features, such as [[wi1ywiwi+1 = with y lot of]], can be estimated reliably and capture construction-specific article use. Morphosyntactic. We used part-of-speech (POS) tags produced by the Stanford POS tagger (Toutanova and Manning, 2000) to capture general article patterns. These are relevant features in the prediction of articles as we observe certain constraints regarding the use of articles in the neighborhood of certain POS tags. For example, we do not expect to predict an article following an adjective (JJ). Semantic. We extract further information indicating whether a named entity, as identified by the Stanford NE Recognizer (Finkel et al., 2005) begins at wi. These features are relevant as there 5 Realization of the classes D and N as lexical items is straightforward. To convert I into a or an, we use the CMU pronounci</context>
</contexts>
<marker>Toutanova, Manning, 2000</marker>
<rawString>K. Toutanova and C. D. Manning. 2000. Enriching the knowledge sources used in a maximum entropy part-of-speech tagger. In Proceedings of the 2000 Joint SIGDAT conference on Empirical methods in natural language processing and very large corpora, pages 6370, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>