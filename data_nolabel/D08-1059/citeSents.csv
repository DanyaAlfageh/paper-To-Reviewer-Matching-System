Rows MSTParser 1/2 show the first-order (using feature templates 1 5 from Table 1) CITATION and secondorder (using all feature templates from Table 1) CITATION MSTParsers, as reported by the corresponding papers,,
Row Duan 2007 represents the transition-based model from CITATION, which applies beamsearch to the deterministic model from CITATION, and achieved the previous best accuracy on the data,,
An existing method to combine multiple parsing algorithms is the ensemble approach (CITATIONa), which was reported to be useful in,,
Table 1 shows the feature templates from the MSTParser CITATION, which are defined in terms of the context of a word, its parent and its sibling,,
The terms graph-based and transition-based were used by CITATION to describe the difference between MSTParser CITATION, which is a graph-based parser with a,,
newitem = item // duplicate item newitem.link(prev, index) // modify output.append(newitem) // record // if prev does not have a parent word, // add link making index parent of prev if item.parent(prev) == 0: item.link(index, prev) // modify output.append(item) // record prev = the index of the first word before prev whose parent does not exist or is on its left; 0 if no match clear agenda put the best items from output to agenda Output: the best item in agenda Figure 2: A beam-search decoder for graph-based parsing, developed from the deterministic Covington algorithm for projective parsing CITATION,,
This is done by extending the deterministic Covington algorithm for projective dependency parsing CITATION,,
The terms graph-based and transition-based were used by CITATION to describe the difference between MSTParser (McDonald and ,,
1 Introduction Graph-based (CITATION; CITATION; CITATION) and transition-based (CITATION; CITATION) parsing algorithms offer two different approaches to data-driven dependency parsing,,
The terms graph-based and transition-based were used by CITATION to describe the difference between MSTParser CITATION, which is a graph-based parser with an exhaustive search decoder, and MaltParser CITATION, whic,,
During training, the early update strategy of CITATION is used: when the correct state item falls out of the beam at any stage, parsing is stopped immediately, and the model is updated using the current best partial item,,
The terms graph-based and transition-based were used by CITATION to describe the difference between MSTParser CITATION, which is a g,,
The English data is prepared by following CITATION,,
Beam-search has been successful in many NLP tasks (CITATION; 562 \x0cInputs: training examples (xi, yi) Initialization: set ~ w = 0 Algorithm: // R training iterations; N examples for t = 1..R, i = 1..N: zi = arg maxyGEN(xi) (y) ~ w if zi 6= yi: ~ w = ~ w + (yi) (zi) Outputs: ~ w Figure 1: The perceptron learning algorithm CITATION), and can achieve accuracy that is close to exact inference,,
Bracketed sentences from the Penn Treebank (PTB) 3 are split into training, development and test sets 567 \x0cFigure 6: The influence of beam size on the transitionbased parser, using the development data X-axis: number of training iterations Y-axis: word precision as shown in Table 4, and then translated into dependency structures using the head-finding rules from CITATION,,
6 Related work Our graph-based parser is derived from the work of CITATION,,
Our transition-based parser is derived from the deterministic parser of CITATION,,
We use the discriminative perceptron learning algorithm (CITATION; CITATION) to train the values of ~ w,,
Based on the work of CITATION, CITATION studied global training with an approximated large-margin algorithm,,
While the MSTParser uses exact-inference CITATION, we apply beam-search to decoding,,
Existing efforts to add search to deterministic parsing include Sagae 569 \x0cand Lavie (2006b), which applied best-first search to constituent parsing, and CITATION and CITATION, which applied beamsearch to dependency parsing,,
to deterministic parsing include Sagae 569 \x0cand Lavie (2006b), which applied best-first search to constituent parsing, and CITATION and CITATION, which applied beamsearch to dependency parsing,,
As with the graph-based parser, we use the discriminative perceptron CITATION to train the transition-based model (see Figure 5),,
Before parsing, POS tags are assigned to the input sentence using our reimplementation of the POStagger from CITATION,,
Averaging parameters is a way to reduce overfitting for perceptron training CITATION, and is applied to all our experiments,,
Like CITATION, we evaluate the parsing accuracy by the precision of lexical heads (the percentage of input words, excluding punctuation, that have been assigned the correct parent) and by the percentage of complete matches, in which all words excluding punctuation have been assigned the correct parent,,
A more recent approach CITATION combined MSTParser and MaltParser by using the output of one parser for features in the other,,
CITATION showed that the MSTParser and MaltParser produce different errors,,
Instead of performing exact inference by dynamic programming, we incorporated the linear model and feature templates from CITATION into our beam-search framework, while adding new g,,
Following CITATION, we 1 A recent paper, CITATION reported parent-prediction accuracy of 92.0% using a graph-based parser with a different (larger) set of features (Carreras, 2007),,
An existing method to combine multiple parsing algorithms is the ensemble approach (CITATIONa), which was reported to be useful in improving dependency parsing CITATION,,
Representative of each method, MSTParser and MaltParser gave comparable accuracies in the CoNLL-X shared task CITATION,,
Like CITATION, we use gold-standard POS-tags for the input,,
Like CITATION, we evaluate the parsing accuracy by the precisi,,
The terms graph-based and transition-based were used by CITATION to describe the difference between MSTParser CITATION, which is a graph-based parser with an exhaustive search decoder, and MaltParser CITATION, which is a transition-based parser with a greedy search decoder,,
CITATION and CITATION also showed the effectiveness of global features in improving the accuracy of graph-based parsing, using the approximate Gibbs sampling method and a reranking approach, respectively,,
Existing efforts to add search to deterministic parsing include Sagae 569 \x0cand Lavie (2006b), which applied best-first search to constituent parsing, and CITATION and Dua,,
2 The graph-based parser Following MSTParser (CITATION; CITATION), we define the graphVariables: agenda the beam for state items item partial parse tree output a set of output items index, prev word indexes Input: x POS-tagged input sentence,,
By applying separate word cluster information, CITATION improved the accuracy to 93.2%, which is the best known accuracy on the PTB data,,
of CITATION, CITATION studied global training with an approximated large-margin algorithm,,
The terms graph-based and transition-based were used by CITATION to describe the difference between MSTParser CITATION, which is a graph-based parser with an exhaustive search decoder, and MaltParser (Nivr,,
Instead of performing exact inference by dynamic programming, we incorporated the linear model and feature templates from CITATION into our beam-search framework, while adding new global features,,
Most of the head-finding rules are from CITATION, while we added rules to handle NN and FRAG, and a default rule to use the rightmost node as the head for the constituent that are not listed,,
564 \x0cFigure 3: Feature context for the transition-based algorithm 3 The transition-based parser We develop our transition-based parser using the transition model of the MaltParser CITATION, which is characterized by the use of a stack and four transition actions: Shift, ArcRight, ArcLeft and Reduce,,
