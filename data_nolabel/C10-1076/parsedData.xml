<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<bodyText confidence="0.5331">
b&apos;Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 671679,
</bodyText>
<address confidence="0.518742">
Beijing, August 2010
</address>
<title confidence="0.7465475">
Learning the Scope of Negation via Shallow Semantic Parsing
Junhui Li Guodong Zhou
</title>
<author confidence="0.732438">
Hongling Wang Qiaoming Zhu
</author>
<affiliation confidence="0.9838105">
School of Computer Science and Technology
Soochow University at Suzhou
</affiliation>
<email confidence="0.926219">
{lijunhui, gdzhou, redleaf, qmzhu}@suda.edu.cn
</email>
<sectionHeader confidence="0.563555" genericHeader="abstract">
Corresponding author
Abstract
</sectionHeader>
<bodyText confidence="0.995190909090909">
In this paper we present a simplified shallow
semantic parsing approach to learning the
scope of negation (SoN). This is done by
formulating it as a shallow semantic parsing
problem with the negation signal as the
predicate and the negation scope as its ar-
guments. Our parsing approach to SoN
learning differs from the state-of-the-art
chunking ones in two aspects. First, we ex-
tend SoN learning from the chunking level
to the parse tree level, where structured syn-
tactic information is available. Second, we
focus on determining whether a constituent,
rather than a word, is negated or not, via a
simplified shallow semantic parsing frame-
work. Evaluation on the BioScope corpus
shows that structured syntactic information
is effective in capturing the domination rela-
tionship between a negation signal and its
dominated arguments. It also shows that our
parsing approach much outperforms the
state-of-the-art chunking ones.
</bodyText>
<sectionHeader confidence="0.998271" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999627421052631">
Whereas negation in predicate logic is
well-defined and syntactically simple, negation
in natural language is much complex. Gener-
ally, learning the scope of negation involves
two subtasks: negation signal finding and nega-
tion scope finding. The former decides whether
the words in a sentence are negation signals
(i.e., words indicating negation, e.g., no, not,
fail, rather than), where the semantic informa-
tion of the words, rather than the syntactic in-
formation, plays a critical role. The latter de-
termines the sequences of words in the sen-
tence which are negated by the given negation
signal. Compared with negation scope finding,
negation signal finding is much simpler and has
been well resolved in the literature, e.g. with
the accuracy of 95.8%-98.7% on the three
subcorpora of the Bioscope corpus (Morante
and Daelemans, 2009). In this paper, we focus
on negation scope finding instead. That is, we
assume golden negation signal finding.
Finding negative assertions is essential in
information extraction (IE), where in general,
the aim is to derive factual knowledge from
free text. For example, Vincze et al. (2008)
pointed out that the extracted information
within the scopes of negation signals should
either be discarded or presented separately
from factual information. This is especially
important in the biomedical domain, where
various linguistic forms are used extensively to
express impressions, hypothesized explanations
of experimental results or negative findings.
Szarvas et al. (2008) reported that 13.45% of
the sentences in the abstracts subcorpus of the
BioScope corpus and 12.70% of the sentences
in the full papers subcorpus of the Bioscope
corpus contain negative assertions. In addition
to the IE tasks in the biomedical domain, SoN
learning has attracted more and more attention
in some natural language processing (NLP)
tasks, such as sentiment classification (Turney,
2002). For example, in the sentence The chair
is not comfortable but cheap, although both
the polarities of the words comfortable and
cheap are positive, the polarity of the chair
regarding the attribute cheap keeps positive
while the polarity of the chair regarding the
attribute comfortable is reversed due to the
negation signal not.
Most of the initial research on SoN learning
focused on negated terms finding, using either
some heuristic rules (e.g., regular expression),
or machine learning methods (Chapman et al.,
2001; Huang and Lowe, 2007; Goldin and
Chapman, 2003). Negation scope finding has
been largely ignored until the recent release of
</bodyText>
<page confidence="0.995802">
671
</page>
<bodyText confidence="0.994450039215686">
\x0cthe BioScope corpus (Szarvas et al., 2008;
Vincze et al., 2008). Morante et al. (2008) and
Morante and Daelemans (2009) pioneered the
research on negation scope finding by formu-
lating it as a chunking problem, which classi-
fies the words of a sentence as being inside or
outside the scope of a negation signal. How-
ever, this chunking approach suffers from low
performance, in particular on long sentences,
due to ignoring structured syntactic information.
For example, given golden negation signals on
the Bioscope corpus, Morante and Daelemans
(2009) only got the performance of 50.26% in
PCS (percentage of correct scope) measure on
the full papers subcorpus (22.8 words per sen-
tence on average), compared to 87.27% in PCS
measure on the clinical reports subcorpus (6.6
words per sentence on average).
This paper explores negation scope finding
from a parse tree perspective and formulates it
as a shallow semantic parsing problem, which
has been extensively studied in the past few
years (Carreras and Marquez, 2005). In par-
ticular, the negation signal is recast as the pre-
dicate and the negation scope is recast as its
arguments. The motivation behind is that
structured syntactic information plays a critical
role in negation scope finding and should be
paid much more attention, as indicated by pre-
vious studies in shallow semantic parsing
(Gildea and Palmer, 2002; Punyakanok et al.,
2005). Our parsing approach to negation scope
finding differs from the state-of-the-art chunk-
ing ones in two aspects. First, we extend nega-
tion scope finding from the chunking level into
the parse tree level, where structured syntactic
information is available. Second, we focus on
determining whether a constituent, rather than a
word, is negated or not. Evaluation on the
BioScope corpus shows that our parsing ap-
proach much outperforms the state-of-the-art
chunking ones.
The rest of this paper is organized as follows.
Section 2 reviews related work. Section 3 in-
troduces the Bioscope corpus on which our
approach is evaluated. Section 4 describes our
parsing approach by formulating negation
scope finding as a simplified shallow semantic
parsing problem. Section 5 presents the ex-
perimental results. Finally, Section 6 concludes
the work.
</bodyText>
<sectionHeader confidence="0.999617" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9980358125">
While there is a certain amount of literature
within the NLP community on negated terms
finding (Chapman et al., 2001; Huang and
Lowe, 2007; Goldin and Chapman, 2003),
there are only a few studies on negation scope
finding (Morante et al., 2008; Morante and
Daelemans, 2009).
Negated terms finding
Rule-based methods dominated the initial re-
search on negated terms finding. As a repre-
sentative, Chapman et al. (2001) developed a
simple regular expression-based algorithm to
detect negation signals and identify medical
terms which fall within the negation scope.
They found that their simple regular expres-
sion-based algorithm can effectively identify a
large portion of the pertinent negative state-
ments from discharge summaries on determin-
ing whether a finding or disease is absent. Be-
sides, Huang and Lowe (2007) first proposed
some heuristic rules from a parse tree perspec-
tive to identify negation signals, taking advan-
tage of syntactic parsing, and then located ne-
gated terms in the parse tree using a corre-
sponding negation grammar.
As an alternative to the rule-based methods,
various machine learning methods have been
proposed for finding negated terms. As a rep-
resentative, Goldin and Chapman (2003) a-
dopted both Naive Bayes and decision trees to
distinguish whether an observation is negated
by the negation signal not in hospital reports.
Negation scope finding
Morante et al. (2008) pioneered the research on
negation scope finding, largely due to the
availability of a large-scale annotated corpus,
the Bioscope corpus. They approached the ne-
gation scope finding task as a chunking prob-
lem which predicts whether a word in the sen-
tence is inside or outside of the negation scope,
with proper post-processing to ensure consecu-
tiveness of the negation scope. Morante and
Daelemans (2009) further improved the per-
formance by combing several classifiers.
Similar to SoN learning, there are some ef-
forts in the NLP community on learning the
scope of speculation. As a representative,
Ozgur and Radev (2009) divided speculation
</bodyText>
<page confidence="0.997865">
672
</page>
<bodyText confidence="0.979704605263158">
\x0clearning into two subtasks: speculation signal
finding and speculation scope finding. In par-
ticular, they formulated speculation signal
finding as a classification problem while em-
ploying some heuristic rules from the parse tree
perspective on speculation scope finding.
3 Negation in the BioScope Corpus
This paper employs the BioScope corpus
(Szarvas et al., 2008; Vincze et al., 2008)1
, a
freely downloadable negation resource from
the biomedical domain, as the benchmark cor-
pus. In this corpus, every sentence is annotated
with negation signals and speculation signals
(if it has), as well as their linguistic scopes.
Figure 1 shows a self-explainable example. In
this paper, we only consider negation signals,
rather than speculation ones. Our statistics
shows that 96.57%, 3.23% and 0.20% of nega-
tion signals are represented by one word, two
words and three or more words, respectively.
Additional, adverbs (e.g., not, never) and de-
terminers (e.g., no, neither) occupy 45.66% and
30.99% of negation signals, respectively.
The Bioscope corpus consists of three sub-
corpora: the full papers and the abstracts from
the GENIA corpus (Collier et al., 1999), and
clinical (radiology) reports. Among them, the
full papers subcorpus and the abstracts subcor-
pus come from the same genre, and thus share
some common characteristics in statistics, such
as the number of words in the negation scope to
the right (or left) of the negation signal and the
average scope length. In comparison, the clini-
cal reports subcorpus consists of clinical radi-
ology reports with short sentences. For detailed
statistics about the three subcorpora, please see
Morante and Daelemans (2009).
</bodyText>
<page confidence="0.387853">
1
</page>
<bodyText confidence="0.861377142857143">
http://www.inf.u-szeged.hu/rgai/bioscope
For preprocessing, all the sentences in the
Bioscope corpus are tokenized and then parsed
using the Berkeley parser2
(Petrov and Klein,
2007) trained on the GENIA TreeBank (GTB)
1.0 (Tateisi et al., 2005)3
, which is a bracketed
corpus in (almost) PTB style. 10-fold
cross-validation on GTB1.0 shows that the
parser achieves the performance of 86.57 in
F1-measure. It is worth noting that the GTB1.0
corpus includes all the sentences in the ab-
stracts subcorpus of the Bioscope corpus.
</bodyText>
<sectionHeader confidence="0.738776" genericHeader="method">
4 Negation Scope Finding via Shallow
</sectionHeader>
<subsectionHeader confidence="0.886089">
Semantic Parsing
</subsectionHeader>
<bodyText confidence="0.9966305">
In this section, we first formulate the negation
scope finding task as a shallow semantic pars-
ing problem. Then, we deal with it using a sim-
plified shallow semantic parsing framework.
</bodyText>
<subsectionHeader confidence="0.997782">
4.1 Formulating Negation Scope Finding
</subsectionHeader>
<bodyText confidence="0.987190722222222">
as a Shallow Semantic Parsing Prob-
lem
Given a parse tree and a predicate in it, shallow
semantic parsing recognizes and maps all the
constituents in the sentence into their corre-
sponding semantic arguments (roles) of the
predicate. As far as negation scope finding
considered, the negation signal can be regarded
as the predicate4
, while the scope of the nega-
tion signal can be mapped into several con-
stituents which are negated and thus can be
regarded as the arguments of the negation sig-
nal. In particular, given a negation signal and
its negation scope which covers wordm, ...,
wordn, we adopt the following two heuristic
rules to map the negation scope of the negation
signal into several constituents which can be
</bodyText>
<footnote confidence="0.875710714285714">
deemed as its arguments in the given parse tree.
&lt;sentence id=&quot;S26.8&quot;&gt;These findings &lt;xcope
id=&quot;X26.8.2&quot;&gt;&lt;cue type=&quot;speculation&quot;
ref=&quot;X26.8.2&quot;&gt;indicate that&lt;/cue&gt; &lt;xcope
id=&quot;X26.8.1&quot;&gt;corticosteroid resistance in bron-
chial asthma &lt;cue type=&quot;negation&quot;
ref=&quot;X26.8.1&quot;&gt;can not&lt;/cue&gt; be explained by
</footnote>
<figureCaption confidence="0.7061645">
abnormalities in corticosteroid receptor charac-
teristics&lt;/xcope&gt;&lt;/xcope&gt;.&lt;/sentence&gt;
Figure 1: An annotated sentence in the BioScope
corpus.
</figureCaption>
<listItem confidence="0.804631875">
1) The negation signal itself and all of its an-
cestral constituents are non-arguments.
2) If constituent X is an argument of the given
negation signal, then X should be the high-
est constituent dominated by the scope of
wordm, ..., wordn. That is to say, Xs parent
constituent must cross-bracket or include
the scope of wordm, ..., wordn.
</listItem>
<figure confidence="0.49766975">
2
http://code.google.com/p/berkeleyparser/
3
http://www-tsujii.is.s.u-tokyo.ac.jp/GENIA
</figure>
<page confidence="0.959803">
4
</page>
<bodyText confidence="0.995140666666667">
If a negation signal consists of multiply words
(e.g., rather than), the last word (e.g., than) is cho-
sen to represent the negation signal.
</bodyText>
<page confidence="0.994681">
673
</page>
<figure confidence="0.958033666666667">
\x0cFigure 2: An illustration of a negation signal and its arguments in a parse tree.
These findings
indicates
that
corticosteroid resistance
NP0,1
VBP2,2 SBAR3,11
can not
IN3,3
be
explained by abnormalities
NP4,5
MD6,6 RB7,7
VB8,8 VP9,11
VP8,11
VP6,11
S4,11
VP2,11
S0,11
predicate
arguments
</figure>
<bodyText confidence="0.9989141875">
The first rule ensures that no argument cov-
ers the negation signal while the second rule
ensures no overlap between any two arguments.
For example, in the sentence These findings
indicate that corticosteroid resistance can not
be explained by abnormalities, the negation
signal can not has the negation scope corti-
costeroid resistance can not be explained by
abnormalities. As shown in Figure 2, the node
RB7,7 (i.e., not) represents the negation signal
can not while its arguments include three
constituents {NP4,5, MD6,6, and VP8,11}. It is
worth noting that according to the above rules,
negation scope finding via shallow semantic
parsing, i.e. determining the arguments of a
given negation signal, is robust to some varia-
tions in parse trees. This is also empirically
justified by our later experiments. For example,
if the VP6,11 in Figure 2 is incorrectly expanded
by the rule VP6,11MD6,6+RB7,7+VB8,8+VP9,11,
the negation scope of the negation signal can
not can still be correctly detected as long as
{NP4,5, MD6,6, VB8,8, and VP9,11} are predicted
as the arguments of the negation signal can
not.
Compared with common shallow semantic
parsing which needs to assign an argument
with a semantic label, negation scope finding
does not involve semantic label classification
and thus could be divided into three consequent
phases: argument pruning, argument identifica-
tion and post-processing.
</bodyText>
<subsectionHeader confidence="0.994205">
4.2 Argument Pruning
</subsectionHeader>
<bodyText confidence="0.998234153846154">
Similar to the predicate-argument structures in
common shallow semantic parsing, the nega-
tion signal-scope structures in negation scope
finding can be also classified into several cer-
tain types and argument pruning can be done
by employing several heuristic rules to filter
out constituents, which are most likely
non-arguments of a negation signal. Similar to
the heuristic algorithm as proposed in Xue and
Palmer (2004) for argument pruning in com-
mon shallow semantic parsing, the argument
pruning algorithm adopted here starts from
designating the negation signal as the current
node and collects its siblings. It then iteratively
moves one level up to the parent of the current
node and collects its siblings. The algorithm
ends when it reaches the root of the parse tree.
To sum up, except the negation signal and its
ancestral constituents, any constituent in the
parse tree whose parent covers the given nega-
tion signal will be collected as argument can-
didates. Taking the negation signal node
RB7,7 in Figure 2 as an example, constituents
{MD6,6, VP8,11, NP4,5, IN3,3, VBP2,2, and NP0,1}
are collected as its argument candidates conse-
quently.
</bodyText>
<subsectionHeader confidence="0.996377">
4.3 Argument Identification
</subsectionHeader>
<bodyText confidence="0.998225666666667">
Here, a binary classifier is applied to determine
the argument candidates as either valid argu-
ments or non-arguments. Similar to argument
</bodyText>
<page confidence="0.996615">
674
</page>
<bodyText confidence="0.9275675">
\x0cidentification in common shallow semantic
parsing, the structured syntactic information
plays a critical role in negation scope finding.
Basic Features
Table 1 lists the basic features for argument
identification. These features are also widely
used in common shallow semantic parsing for
both verbal and nominal predicates (Xue, 2008;
</bodyText>
<table confidence="0.3169445">
Li et al., 2009).
Feature Remarks
</table>
<listItem confidence="0.9459935">
b1 Negation: the stem of the negation signal,
e.g., not, rather_than. (can_not)
b2 Phrase Type: the syntactic category of the
argument candidate. (NP)
b3 Path: the syntactic path from the argument
candidate to the negation signal.
(NP&lt;S&gt;VP&gt;RB)
b4 Position: the positional relationship of the
argument candidate with the negation sig-
nal. left or right. (left)
</listItem>
<tableCaption confidence="0.7080755">
Table 1: Basic features and their instantiations for
argument identification in negation scope finding,
</tableCaption>
<bodyText confidence="0.973851464285714">
with NP4,5 as the focus constituent (i.e., the argu-
ment candidate) and can not as the given negation
signal, regarding Figure 2.
Additional Features
To capture more useful information in the ne-
gation signal-scope structures, we also explore
various kinds of additional features. Table 2
shows the features in better capturing the de-
tails regarding the argument candidate and the
negation signal. In particular, we categorize the
additional features into three groups according
to their relationship with the argument candi-
date (AC, in short) and the given negation sig-
nal (NS, in short).
Some features proposed above may not be
effective in argument identification. Therefore,
we adopt the greedy feature selection algorithm
as described in Jiang and Ng (2006) to pick up
positive features incrementally according to
their contributions on the development data.
The algorithm repeatedly selects one feature
each time which contributes most, and stops
when adding any of the remaining features fails
to improve the performance. As far as the ne-
gation scope finding task concerned, the whole
feature selection process could be done by first
running the selection algorithm with the basic
features (b1-b4) and then incrementally picking
</bodyText>
<table confidence="0.681203833333333">
up effective features from (ac1-ac6, AC1-AC2,
ns1-ns4, NS1-NS2, nsac1-nsac2, and NSAC1
-NSAC7).
Feature Remarks
argument candidate (AC) related
ac1 the headword (ac1H) and its POS (ac1P).
(resistance, NN)
ac2 the left word (ac2W) and its POS (ac2P).
(that, IN)
ac3 the right word (ac3W) and its POS (ac3P).
(can, MD)
ac4 the phrase type of its left sibling (ac4L)
and its right sibling (ac4R). (NULL, VP)
ac5 the phrase type of its parent node. (S)
ac6 the subcategory. (S:NP+VP)
combined features (AC1-AC2)
b2&amp;fc1H, b2&amp;fc1P
negation signal (NS) related
ns1 its POS. (RB)
ns2 its left word (ns2L) and right word (ns2R).
(can, be)
ns3 the subcategory. (VP:MD+RB+VP)
ns4 the phrase type of its parent node. (VP)
combined features (NS1-NS2)
b1&amp;ns2L, b1&amp;ns2R
NS-AC-related
nsac1 the compressed path of b3: compressing
sequences of identical labels into one.
(NP&lt;S&gt;VP&gt;RB)
nsac2 whether AC and NS are adjacent in posi-
</table>
<tableCaption confidence="0.519652">
tion. yes or no. (no)
combined features (NSAC1-NSAC7)
b1&amp;b2, b1&amp;b3, b1&amp;nsac1, b3&amp;NS1, b3&amp;NS2,
b4&amp;NS1, b4&amp;NS2
Table 2: Additional features and their instantiations
</tableCaption>
<bodyText confidence="0.98048625">
for argument identification in negation scope find-
ing, with NP4,5 as the focus constituent (i.e., the
argument candidate) and can not as the given
negation signal, regarding Figure 2.
</bodyText>
<subsectionHeader confidence="0.998603">
4.4 Post-Processing
</subsectionHeader>
<bodyText confidence="0.999299571428571">
Although a negation signal in the BioScope
corpus always has only one continuous block
as its negation scope (including the negation
signal itself), the negation scope finder may
result in discontinuous negation scope due to
independent prediction in the argument identi-
fication phase. Given the golden negation sig-
nals, we observed that 6.2% of the negation
scopes predicted by our negation scope finder
are discontinuous.
Figure 3 demonstrates the projection of all
the argument candidates into the word level.
According to our argument pruning algorithm
in Section 4.2, except the words presented by
</bodyText>
<page confidence="0.99574">
675
</page>
<bodyText confidence="0.9026209">
\x0cthe negation signal, the projection covers the
whole sentence and each constituent (LACi or
RACj in Figure 3) receives a probability distri-
bution of being an argument of the given nega-
tion signal in the argument identification phase.
Since a negation signal is deemed inside of its
negation scope in the BioScope corpus, our
post-processing algorithm first includes the
negation signal in its scope and then starts to
identify the left and the right scope boundaries,
respectively.
As shown in Figure 3, the left boundary has
m+1 possibilities, namely the negation signal
itself, the leftmost word of constituent LACi
(1&lt;=i&lt;=m). Supposing LACi receives prob-
ability of Pi being an argument, we use the fol-
lowing formula to determine LACk* whose
leftmost word represents the boundary of the
left scope. If k*=0, then the negation signal
itself represents its left boundary.
</bodyText>
<equation confidence="0.998580909090909">
( )
*
1 1
argmax 1
k m
i i
k i i k
k P
= = +
=
P
</equation>
<bodyText confidence="0.9987605">
Similarly, the right boundary of the given
negation signal can be decided.
</bodyText>
<sectionHeader confidence="0.995371" genericHeader="evaluation">
5 Experimentation
</sectionHeader>
<bodyText confidence="0.988881333333333">
We have evaluated our shallow semantic pars-
ing approach to negation scope finding on the
BioScope corpus.
</bodyText>
<subsectionHeader confidence="0.987838">
5.1 Experimental Settings
</subsectionHeader>
<bodyText confidence="0.997472181818182">
Following the experimental setting in Morante
and Daelemans (2009), the abstracts subcorpus
is randomly divided into 10 folds so as to per-
form 10-fold cross validation, while the per-
formance on both the papers and clinical re-
ports subcorpora is evaluated using the system
trained on the whole abstracts subcorpus. In
addition, SVMLight5
is selected as our classi-
fier. In particular, we adopt the linear kernel
and the training parameter C is fine-tuned to
</bodyText>
<figure confidence="0.6939625">
0.2.
1
5
http://svmlight.joachims.org/
</figure>
<bodyText confidence="0.893692">
The evaluation is made using the accuracy.
We report the accuracy using three measures:
PCLB and PCRB, which indicate the percent-
ages of correct left boundary and right bound-
ary respectively, PCS, which indicates the per-
centage of correct scope as a whole.
</bodyText>
<figure confidence="0.496494">
LACm .... LAC1 RAC1 .... RACn
m n
</figure>
<figureCaption confidence="0.8542505">
Figure 3: Projecting the left and the right argument
candidates into the word level.
</figureCaption>
<subsectionHeader confidence="0.967973">
5.2 Experimental Results on Golden Parse
Trees
</subsectionHeader>
<bodyText confidence="0.977502571428571">
In order to select beneficial features from the
additional features proposed in Section 4.3, we
randomly split the abstracts subcorpus into
training and development datasets with propor-
tion of 4:1. After performing the greedy feature
selection algorithm on the development data,
features {NSAC5, ns2R, NS1, ac1P, ns3,
NSAC7, ac4R} are selected consecutively for
argument identification. Table 3 presents the
effect of selected features in an incremental
way on the development data. It shows that the
additional features significantly improve the
performance by 11.66% in PCS measure from
74.93% to 86.59% ( ).
</bodyText>
<page confidence="0.790494">
2
</page>
<table confidence="0.994384416666667">
; 0.0
p
&lt;
Feature PCLB PCRB PCS
Baseline 84.26 88.92 74.93
+NSAC5 90.96 88.92 81.34
+ns2R 91.55 88.92 81.92
+NS1 92.42 89.50 83.09
+ac1P 93.59 89.50 84.26
+ns3 93.88 90.09 84.84
+NSAC7 94.75 89.80 85.42
+ac4R 95.04 90.67 86.59
</table>
<tableCaption confidence="0.999443">
Table 3: Performance improvement (%) of includ-
</tableCaption>
<bodyText confidence="0.998327473684211">
ing the additional features in an incremental way on
the development data (of the abstracts subcorpus).
However, Table 3 shows that the additional
features behave quite differently in terms of
PCLB and PCRB measures. For example,
PCLB measure benefits more from features
NSAC5, ns2R, NS1, ac1P, and NSAC7 while
PCRB measure benefits more from features
NS1 and ac4R. It also shows that the features
(e.g., NSAC5, ns2R, NS1, NSAC7) related to
neighboring words of the negation signal play a
critical role in recognizing both left and right
boundaries. This may be due to the fact that
neighboring words usually imply sentential
information. For example, can not be indi-
cates a passive clause while did not indicates
an active clause. Table 3 also shows that the
recognition of left boundaries is much easier
than that of right boundaries. This may be due
</bodyText>
<page confidence="0.996842">
676
</page>
<bodyText confidence="0.996396384615384">
\x0cto the fact that 83.6% of negation signals have
themselves as the left boundaries in the ab-
stracts subcorpus.
gument candidate is outside or cross-brackets
with the golden negation scope, then it is a
non-argument. The oracle performance is pre-
sented in the rows of oracle in Table 5 and Ta-
ble 6.
Table 4 presents the performance on the ab-
stracts subcorpus by performing 10-fold
cross-validation. It shows that the additional
features significantly improve the performance
over the three measures ( ).
</bodyText>
<page confidence="0.658006">
2
</page>
<equation confidence="0.646306666666667">
; 0.0
p
&lt;
</equation>
<bodyText confidence="0.971529263157895">
Table 5 and Table 6 show that:
1) Automatic syntactic parsing lowers the per-
formance of negation scope finding on the
abstracts subcorpus in all three measures (e.g.
from 83.10 to 81.84 in PCS). As expected,
the parser trained on the whole GTB1.0
corpus works better than that trained on
6,691 sentences (e.g. 64.02 Vs. 62.70, and
89.79 Vs. 85.21 in PCS measure on the full
papers and the clinical reports subcorpora,
respectively). However, the performance de-
crease shows that negation scope finding is
not as sensitive to automatic syntactic pars-
ing as common shallow semantic parsing,
whose performance might decrease by about
~10 in F1-measure (Toutanova et al., 2005).
This indicates that negation scope finding
via shallow semantic parsing is robust to
some variations in the parse trees.
</bodyText>
<page confidence="0.832595">
1
</page>
<table confidence="0.992414">
Feature PCLB PCRB PCS
Baseline 84.29 87.82 74.05
+selected features 93.06 88.96 83.10
</table>
<tableCaption confidence="0.999022">
Table 4: Performance (%) of negation scope finding
</tableCaption>
<bodyText confidence="0.587878">
on the abstracts subcorpus using 10-fold
cross-validation.
</bodyText>
<subsectionHeader confidence="0.966989">
5.3 Experimental Results on Automatic
Parse Trees
</subsectionHeader>
<bodyText confidence="0.998006360655738">
The GTB1.0 corpus contains 18,541 sentences
in which 11,850 of them (63.91%) overlap with
the sentences in the abstracts subcorpus6
. In
order to get automatic parse trees for the sen-
tences in the abstracts subcorpus, we train the
Berkeley parser with the remaining 6,691 sen-
tences in GTB1.0. The Berkeley parser trained
on 6,691 sentences achieves the performance of
85.22 in F1-measure on the other sentences in
GTB1.0. For both the full papers and clinical
reports subcorpora, we get their automatic
parse trees by using two Berkeley parsers: one
trained on 6,691 sentences in GBT1.0, and the
other trained on all the sentences in GTB1.0.
2) autoparse(test) consistently outperforms
autoparse(t&amp;t) on both the abstracts and the
full papers subcorpora. However, it is sur-
prising to find that autoparse(t&amp;t) achieves
better performance on the clinical reports
subcorpus than autoparse(test). This may be
due to the special characteristics of the
clinical reports subcorpus, which mainly
consists of much shorter sentences with 6.6
words per sentence on average, and better
adaptation of the argument identification
classifier to the variations in the automatic
parse trees.
To test the performance on automatic parse
trees, we employ two different configurations.
First, we train the argument identification clas-
sifier on the abstracts subcorpus using auto-
matic parse trees produced by Berkeley parser
trained on 6,691 sentences. The experimental
results are presented in the rows of auto-
parse(t&amp;t) in Table 5 and Table 6. Then, we
train the argument identification classifier on
the abstracts subcorpus using golden parse
trees. The experimental results are presented in
the rows of autoparse(test) in Table 5 and Ta-
ble 6.
3) The performance on all three subcorpora
indicates that the recognition of right
boundary is much harder than that of left
boundary. This may be due to the longer
right boundary on an average. Our statistics
shows that the average left/right boundaries
are 1.1/6.9, 0.1/3.7, and 1.2/6.5 words on the
abstracts, the full papers and the clinical re-
ports subcorpora, respectively.
We also report an oracle performance to ex-
plore the best possible performance of our sys-
tem by assuming that our negation scope finder
can always correctly determine whether a can-
didate is an argument or not. That is, if an ar-
4) The oracle performance is less sensitive to
automatic syntactic parsing. In addition,
given the performance gap between the per-
formance of our negation scope finder and
the oracle performance, there is still much
room for further performance improvement.
</bodyText>
<page confidence="0.970007">
6
</page>
<bodyText confidence="0.999211">
There are a few cases where two sentences in the
abstracts subcorpus map into one sentence in GTB.
</bodyText>
<page confidence="0.995559">
677
</page>
<table confidence="0.9954238">
\x0cAbstracts Papers Clinical
PCLB PCRB PCS PCLB PCRB PCS PCLB PCRB PCS
autoparse(t&amp;t) 91.97 87.82 80.88 85.45 67.20 59.26 97.48 88.30 85.89
autoparse(test) 92.71 88.33 81.84 87.57 68.78 62.70 97.48 87.73 85.21
oracle 99.72 94.59 94.37 98.94 84.13 83.33 99.89 98.39 98.39
</table>
<tableCaption confidence="0.7515">
Table 5: Performance (%) of negation scope finding on the three subcorpora by using automatic parser trained
</tableCaption>
<table confidence="0.985092666666667">
with 6,691 sentences in GTB1.0.
Papers Clinical
PCLB PCRB PCS PCLB PCRB PCS
autoparse(t&amp;t) 85.98 67.99 60.32 97.48 92.66 90.48
autoparse(test) 87.83 70.11 64.02 97.36 92.20 89.79
oracle 98.94 83.86 83.07 99.77 97.94 97.82
</table>
<tableCaption confidence="0.839159">
Table 6: Performance (%) of negation scope finding on the two subcorpora by using automatic parser trained
with all the sentences in GTB1.0.
</tableCaption>
<table confidence="0.9916114">
Method Abstracts Papers Clinical
M et al. (2008) 57.33 n/a n/a
M &amp; D (2009) 73.36 50.26 87.27
Our baseline 73.42 53.70 88.42
Our final system 81.84 64.02 89.79
</table>
<tableCaption confidence="0.99229625">
Table 7: Performance comparison over the PCS
measure (%) of our system with other
state-of-the-art ones.
Table 7 compares our performance in PCS
</tableCaption>
<bodyText confidence="0.997965217391305">
measure with related work. It shows that even
our baseline system with four basic features as
presented in Table 1 performs better than
Morante et al. (2008) and Morante and Daele-
mans(2009). This indicates the appropriateness
of our simplified shallow semantic parsing ap-
proach and the effectiveness of structured syn-
tactic information on negation scope finding. It
also shows that our final system significantly
outperforms the state-of-the-art ones using a
chunking approach, especially on the abstracts
and full papers subcorpora. However, the im-
provement on the clinical reports subcorpus is
less apparent, partly due to the fact that the
sentences in this subcorpus are much simpler
(with average length of 6.6 words per sentence)
and thus a chunking approach can achieve high
performance. Following are two typical sen-
tences from the clinical reports subcorpus,
where the negation scope covers the whole sen-
tence (except the period punctuation). Such
sentences account for 57% of negation sen-
tences in the clinical reports subcorpus.
</bodyText>
<sectionHeader confidence="0.997307" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.992579038461539">
In this paper we have presented a simplified
shallow semantic parsing approach to negation
scope finding by formulating it as a shallow
semantic parsing problem, which has been ex-
tensively studied in the past few years. In par-
ticular, we regard the negation signal as the
predicate while mapping the negation scope
into several constituents which are deemed as
arguments of the negation signal. Evaluation on
the Bioscope corpus shows the appropriateness
of our shallow semantic parsing approach and
that structured syntactic information plays a
critical role in capturing the domination rela-
tionship between a negation signal and its ne-
gation scope. It also shows that our parsing
approach much outperforms the state-of-the-art
chunking ones. To our best knowledge, this is
the first research on exploring negation scope
finding via shallow semantic parsing.
Future research will focus on joint learning
of negation signal and its negation scope find-
ings. Although Morante and Daelemans (2009)
reported the performance of 95.8%-98.7% on
negation signal finding, it lowers the perform-
ance of negation scope finding by about
7.29%-16.52% in PCS measure.
</bodyText>
<sectionHeader confidence="0.945445" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<reference confidence="0.953298166666667">
This research was supported by Projects
60683150, 60970056, and 90920004 under the
National Natural Science Foundation of China,
Project 20093201110006 under the Specialized
Research Fund for the Doctoral Program of
Higher Education of China.
</reference>
<listItem confidence="0.532986">
(1) No evidence of focal pneumonia .
(2) No findings to account for symptoms .
</listItem>
<page confidence="0.983878">
678
</page>
<reference confidence="0.998200475">
\x0cReferences
Xavier Carreras and Lluis Marquez. 2005. Introduc-
tion to the CoNLL-2005 Shared Task: Semantic
Role Labeling. In Proceedings of CoNLL 2005.
Wendy W. Chapman, Will Bridewell, Paul Hanbury,
Gregory F. Cooper, and Bruce G. Buchanan.
2001. A Simple Algorithm for Identifying Ne-
gated Findings and Diseases in Discharge Sum-
maries. Journal of Biomedical Informatics, 34:
301-310.
Nigel Collier, Hyun Seok Park, Norihiro Ogata, et
al. 1999. The GENIA project: corpus-based
knowledge acquisition and information extrac-
tion from genome research papers. In Proceed-
ings of EACL 1999.
Daniel Gildea and Martha Palmer. 2002. The Ne-
cessity of Parsing for Predicate Argument Rec-
ognition. In Proceedings of ACL 2002.
Ilya M. Goldin and Wendy W. Chapman. 2003.
Learning to Detect Negation with Not in Medi-
cal Texts. In Proceedings of SIGIR 2003.
Yang Huang and Henry Lowe. 2007. A Novel Hy-
brid Approach to Automated Negation Detection
in Clinical Radiology Reports. Journal of the
American Medical Informatics Association, 14(3):
304-311.
Zheng Ping Jiang and Hwee Tou Ng. 2006. Seman-
tic Role Labeling of NomBank: A Maximum En-
tropy Approach. In Proceedings of EMNLP
2006.
Junhui Li, Guodong Zhou, Hai Zhao, Qiaoming Zhu,
and Peide Qian. Improving Nominal SRL in
Chinese Language with Verbal SRL Information
and Automatic Predicate Recognition. In Pro-
ceedings of EMNLP 2009.
Roser Morante, Anthony Liekens, and Walter
Daelemans. 2008. Learning the Scope of Nega-
tion in Biomedical Texts. In Proceedings of
EMNLP 2008.
Roser Morante and Walter Daelemans. 2009. A
Metalearning Approach to Processing the Scope
of Negation. In Proceedings of CoNLL 2009.
Arzucan Ozgur; Dragomir R. Radev. 2009. Detect-
ing Speculations and their Scopes in Scientific
Text. In Proceedings of EMNLP 2009.
Slav Petrov and Dan Klein. 2007. Improved Infer-
ence for Unlexicalized Parsing. In Proceedings of
NAACL 2007.
Vasin Punyakanok, Dan Roth, and Wen-tau Yih.
2005. The Necessity of Syntactic Parsing for
Semantic Role Labeling. In Proceedings of IJCAI
2005.
Gyorgy Szarvas, Veronika Vincze, Richard Farkas,
and Janos Csirik. 2008. The BioScope corpus:
annotation for negation, uncertainty and their
scope in biomedical texts. In Proceedings of
BioNLP 2008.
Yuka Tateisi, Akane Yakushiji, Tomoko Ohta, and
Junichi Tsujii. 2005. Syntax Annotation for the
GENIA Corpus. In Proceedings of IJCNLP 2005,
Companion volume.
Kristina Toutanova, Aria Haghighi, and Christopher
D. Manning. 2005. Joint Learning Improves Se-
mantic Role Labeling. In Proceedings of ACL
2005.
Peter D. Turney. 2002. Thumbs Up or Thumbs
Down? Semantic Orientation Applied to Unsu-
pervised Classification of Reviews. In Proceed-
ings of ACL 2002.
Veronika Vincze, Gyorgy Szarvas, Richard Farkas,
Gyorgy Mora, and Janos Csirik. 2008. The Bio-
Scope corpus: biomedical texts annotated for
uncertainty, negation and their scopes. BMC
Bioinformatics, 9(Suppl 11):S9.
Nianwen Xue and Martha Palmer. 2004. Calibrating
Features for Semantic Role Labeling. In Pro-
ceedings of EMNLP 2004.
Nianwen Xue. 2008. Labeling Chinese Predicates
with Semantic Roles. Computational Linguistics,
34(2):225-255.
</reference>
<page confidence="0.982901">
679
</page>
<figure confidence="0.25269">
\x0c&apos;
</figure>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.596831">
<note confidence="0.8756305">b&apos;Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 671679, Beijing, August 2010</note>
<title confidence="0.999067">Learning the Scope of Negation via Shallow Semantic Parsing</title>
<author confidence="0.945984">Junhui Li Guodong Zhou Hongling Wang Qiaoming Zhu</author>
<affiliation confidence="0.9645675">School of Computer Science and Technology Soochow University at Suzhou</affiliation>
<email confidence="0.934767">lijunhui@suda.edu.cn</email>
<email confidence="0.934767">gdzhou@suda.edu.cn</email>
<email confidence="0.934767">redleaf@suda.edu.cn</email>
<email confidence="0.934767">qmzhu@suda.edu.cn</email>
<note confidence="0.984754">Corresponding author</note>
<abstract confidence="0.999817260869565">In this paper we present a simplified shallow semantic parsing approach to learning the scope of negation (SoN). This is done by formulating it as a shallow semantic parsing problem with the negation signal as the predicate and the negation scope as its arguments. Our parsing approach to SoN learning differs from the state-of-the-art chunking ones in two aspects. First, we extend SoN learning from the chunking level to the parse tree level, where structured syntactic information is available. Second, we focus on determining whether a constituent, rather than a word, is negated or not, via a simplified shallow semantic parsing framework. Evaluation on the BioScope corpus shows that structured syntactic information is effective in capturing the domination relationship between a negation signal and its dominated arguments. It also shows that our parsing approach much outperforms the state-of-the-art chunking ones.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>\x0cReferences Xavier Carreras</author>
<author>Lluis Marquez</author>
</authors>
<title>Introduction to the CoNLL-2005 Shared Task: Semantic Role Labeling.</title>
<date>2005</date>
<booktitle>In Proceedings of CoNLL</booktitle>
<contexts>
<context position="4912" citStr="Carreras and Marquez, 2005" startWordPosition="752" endWordPosition="755">ng sentences, due to ignoring structured syntactic information. For example, given golden negation signals on the Bioscope corpus, Morante and Daelemans (2009) only got the performance of 50.26% in PCS (percentage of correct scope) measure on the full papers subcorpus (22.8 words per sentence on average), compared to 87.27% in PCS measure on the clinical reports subcorpus (6.6 words per sentence on average). This paper explores negation scope finding from a parse tree perspective and formulates it as a shallow semantic parsing problem, which has been extensively studied in the past few years (Carreras and Marquez, 2005). In particular, the negation signal is recast as the predicate and the negation scope is recast as its arguments. The motivation behind is that structured syntactic information plays a critical role in negation scope finding and should be paid much more attention, as indicated by previous studies in shallow semantic parsing (Gildea and Palmer, 2002; Punyakanok et al., 2005). Our parsing approach to negation scope finding differs from the state-of-the-art chunking ones in two aspects. First, we extend negation scope finding from the chunking level into the parse tree level, where structured sy</context>
</contexts>
<marker>Carreras, Marquez, 2005</marker>
<rawString>\x0cReferences Xavier Carreras and Lluis Marquez. 2005. Introduction to the CoNLL-2005 Shared Task: Semantic Role Labeling. In Proceedings of CoNLL 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wendy W Chapman</author>
<author>Will Bridewell</author>
<author>Paul Hanbury</author>
<author>Gregory F Cooper</author>
<author>Bruce G Buchanan</author>
</authors>
<title>A Simple Algorithm for Identifying Negated Findings and Diseases in Discharge Summaries.</title>
<date>2001</date>
<journal>Journal of Biomedical Informatics,</journal>
<volume>34</volume>
<pages>301--310</pages>
<contexts>
<context position="3759" citStr="Chapman et al., 2001" startWordPosition="567" endWordPosition="570">n in some natural language processing (NLP) tasks, such as sentiment classification (Turney, 2002). For example, in the sentence The chair is not comfortable but cheap, although both the polarities of the words comfortable and cheap are positive, the polarity of the chair regarding the attribute cheap keeps positive while the polarity of the chair regarding the attribute comfortable is reversed due to the negation signal not. Most of the initial research on SoN learning focused on negated terms finding, using either some heuristic rules (e.g., regular expression), or machine learning methods (Chapman et al., 2001; Huang and Lowe, 2007; Goldin and Chapman, 2003). Negation scope finding has been largely ignored until the recent release of 671 \x0cthe BioScope corpus (Szarvas et al., 2008; Vincze et al., 2008). Morante et al. (2008) and Morante and Daelemans (2009) pioneered the research on negation scope finding by formulating it as a chunking problem, which classifies the words of a sentence as being inside or outside the scope of a negation signal. However, this chunking approach suffers from low performance, in particular on long sentences, due to ignoring structured syntactic information. For exampl</context>
<context position="6261" citStr="Chapman et al., 2001" startWordPosition="967" endWordPosition="970">valuation on the BioScope corpus shows that our parsing approach much outperforms the state-of-the-art chunking ones. The rest of this paper is organized as follows. Section 2 reviews related work. Section 3 introduces the Bioscope corpus on which our approach is evaluated. Section 4 describes our parsing approach by formulating negation scope finding as a simplified shallow semantic parsing problem. Section 5 presents the experimental results. Finally, Section 6 concludes the work. 2 Related Work While there is a certain amount of literature within the NLP community on negated terms finding (Chapman et al., 2001; Huang and Lowe, 2007; Goldin and Chapman, 2003), there are only a few studies on negation scope finding (Morante et al., 2008; Morante and Daelemans, 2009). Negated terms finding Rule-based methods dominated the initial research on negated terms finding. As a representative, Chapman et al. (2001) developed a simple regular expression-based algorithm to detect negation signals and identify medical terms which fall within the negation scope. They found that their simple regular expression-based algorithm can effectively identify a large portion of the pertinent negative statements from dischar</context>
</contexts>
<marker>Chapman, Bridewell, Hanbury, Cooper, Buchanan, 2001</marker>
<rawString>Wendy W. Chapman, Will Bridewell, Paul Hanbury, Gregory F. Cooper, and Bruce G. Buchanan. 2001. A Simple Algorithm for Identifying Negated Findings and Diseases in Discharge Summaries. Journal of Biomedical Informatics, 34: 301-310.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nigel Collier</author>
<author>Hyun Seok Park</author>
<author>Norihiro Ogata</author>
</authors>
<title>The GENIA project: corpus-based knowledge acquisition and information extraction from genome research papers.</title>
<date>1999</date>
<booktitle>In Proceedings of EACL</booktitle>
<contexts>
<context position="9346" citStr="Collier et al., 1999" startWordPosition="1450" endWordPosition="1453">ation signals and speculation signals (if it has), as well as their linguistic scopes. Figure 1 shows a self-explainable example. In this paper, we only consider negation signals, rather than speculation ones. Our statistics shows that 96.57%, 3.23% and 0.20% of negation signals are represented by one word, two words and three or more words, respectively. Additional, adverbs (e.g., not, never) and determiners (e.g., no, neither) occupy 45.66% and 30.99% of negation signals, respectively. The Bioscope corpus consists of three subcorpora: the full papers and the abstracts from the GENIA corpus (Collier et al., 1999), and clinical (radiology) reports. Among them, the full papers subcorpus and the abstracts subcorpus come from the same genre, and thus share some common characteristics in statistics, such as the number of words in the negation scope to the right (or left) of the negation signal and the average scope length. In comparison, the clinical reports subcorpus consists of clinical radiology reports with short sentences. For detailed statistics about the three subcorpora, please see Morante and Daelemans (2009). 1 http://www.inf.u-szeged.hu/rgai/bioscope For preprocessing, all the sentences in the B</context>
</contexts>
<marker>Collier, Park, Ogata, 1999</marker>
<rawString>Nigel Collier, Hyun Seok Park, Norihiro Ogata, et al. 1999. The GENIA project: corpus-based knowledge acquisition and information extraction from genome research papers. In Proceedings of EACL 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gildea</author>
<author>Martha Palmer</author>
</authors>
<title>The Necessity of Parsing for Predicate Argument Recognition.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL</booktitle>
<contexts>
<context position="5263" citStr="Gildea and Palmer, 2002" startWordPosition="810" endWordPosition="813">l reports subcorpus (6.6 words per sentence on average). This paper explores negation scope finding from a parse tree perspective and formulates it as a shallow semantic parsing problem, which has been extensively studied in the past few years (Carreras and Marquez, 2005). In particular, the negation signal is recast as the predicate and the negation scope is recast as its arguments. The motivation behind is that structured syntactic information plays a critical role in negation scope finding and should be paid much more attention, as indicated by previous studies in shallow semantic parsing (Gildea and Palmer, 2002; Punyakanok et al., 2005). Our parsing approach to negation scope finding differs from the state-of-the-art chunking ones in two aspects. First, we extend negation scope finding from the chunking level into the parse tree level, where structured syntactic information is available. Second, we focus on determining whether a constituent, rather than a word, is negated or not. Evaluation on the BioScope corpus shows that our parsing approach much outperforms the state-of-the-art chunking ones. The rest of this paper is organized as follows. Section 2 reviews related work. Section 3 introduces the</context>
</contexts>
<marker>Gildea, Palmer, 2002</marker>
<rawString>Daniel Gildea and Martha Palmer. 2002. The Necessity of Parsing for Predicate Argument Recognition. In Proceedings of ACL 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ilya M Goldin</author>
<author>Wendy W Chapman</author>
</authors>
<date>2003</date>
<contexts>
<context position="3808" citStr="Goldin and Chapman, 2003" startWordPosition="575" endWordPosition="578">tasks, such as sentiment classification (Turney, 2002). For example, in the sentence The chair is not comfortable but cheap, although both the polarities of the words comfortable and cheap are positive, the polarity of the chair regarding the attribute cheap keeps positive while the polarity of the chair regarding the attribute comfortable is reversed due to the negation signal not. Most of the initial research on SoN learning focused on negated terms finding, using either some heuristic rules (e.g., regular expression), or machine learning methods (Chapman et al., 2001; Huang and Lowe, 2007; Goldin and Chapman, 2003). Negation scope finding has been largely ignored until the recent release of 671 \x0cthe BioScope corpus (Szarvas et al., 2008; Vincze et al., 2008). Morante et al. (2008) and Morante and Daelemans (2009) pioneered the research on negation scope finding by formulating it as a chunking problem, which classifies the words of a sentence as being inside or outside the scope of a negation signal. However, this chunking approach suffers from low performance, in particular on long sentences, due to ignoring structured syntactic information. For example, given golden negation signals on the Bioscope </context>
<context position="6310" citStr="Goldin and Chapman, 2003" startWordPosition="975" endWordPosition="978">our parsing approach much outperforms the state-of-the-art chunking ones. The rest of this paper is organized as follows. Section 2 reviews related work. Section 3 introduces the Bioscope corpus on which our approach is evaluated. Section 4 describes our parsing approach by formulating negation scope finding as a simplified shallow semantic parsing problem. Section 5 presents the experimental results. Finally, Section 6 concludes the work. 2 Related Work While there is a certain amount of literature within the NLP community on negated terms finding (Chapman et al., 2001; Huang and Lowe, 2007; Goldin and Chapman, 2003), there are only a few studies on negation scope finding (Morante et al., 2008; Morante and Daelemans, 2009). Negated terms finding Rule-based methods dominated the initial research on negated terms finding. As a representative, Chapman et al. (2001) developed a simple regular expression-based algorithm to detect negation signals and identify medical terms which fall within the negation scope. They found that their simple regular expression-based algorithm can effectively identify a large portion of the pertinent negative statements from discharge summaries on determining whether a finding or </context>
</contexts>
<marker>Goldin, Chapman, 2003</marker>
<rawString>Ilya M. Goldin and Wendy W. Chapman. 2003.</rawString>
</citation>
<citation valid="true">
<title>Learning to Detect Negation with Not in Medical Texts.</title>
<date>2003</date>
<booktitle>In Proceedings of SIGIR</booktitle>
<contexts>
<context position="7354" citStr="(2003)" startWordPosition="1141" endWordPosition="1141">ession-based algorithm can effectively identify a large portion of the pertinent negative statements from discharge summaries on determining whether a finding or disease is absent. Besides, Huang and Lowe (2007) first proposed some heuristic rules from a parse tree perspective to identify negation signals, taking advantage of syntactic parsing, and then located negated terms in the parse tree using a corresponding negation grammar. As an alternative to the rule-based methods, various machine learning methods have been proposed for finding negated terms. As a representative, Goldin and Chapman (2003) adopted both Naive Bayes and decision trees to distinguish whether an observation is negated by the negation signal not in hospital reports. Negation scope finding Morante et al. (2008) pioneered the research on negation scope finding, largely due to the availability of a large-scale annotated corpus, the Bioscope corpus. They approached the negation scope finding task as a chunking problem which predicts whether a word in the sentence is inside or outside of the negation scope, with proper post-processing to ensure consecutiveness of the negation scope. Morante and Daelemans (2009) further i</context>
</contexts>
<marker>2003</marker>
<rawString>Learning to Detect Negation with Not in Medical Texts. In Proceedings of SIGIR 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Huang</author>
<author>Henry Lowe</author>
</authors>
<title>A Novel Hybrid Approach to Automated Negation Detection in Clinical Radiology Reports.</title>
<date>2007</date>
<journal>Journal of the American Medical Informatics Association,</journal>
<volume>14</volume>
<issue>3</issue>
<pages>304--311</pages>
<contexts>
<context position="3781" citStr="Huang and Lowe, 2007" startWordPosition="571" endWordPosition="574">uage processing (NLP) tasks, such as sentiment classification (Turney, 2002). For example, in the sentence The chair is not comfortable but cheap, although both the polarities of the words comfortable and cheap are positive, the polarity of the chair regarding the attribute cheap keeps positive while the polarity of the chair regarding the attribute comfortable is reversed due to the negation signal not. Most of the initial research on SoN learning focused on negated terms finding, using either some heuristic rules (e.g., regular expression), or machine learning methods (Chapman et al., 2001; Huang and Lowe, 2007; Goldin and Chapman, 2003). Negation scope finding has been largely ignored until the recent release of 671 \x0cthe BioScope corpus (Szarvas et al., 2008; Vincze et al., 2008). Morante et al. (2008) and Morante and Daelemans (2009) pioneered the research on negation scope finding by formulating it as a chunking problem, which classifies the words of a sentence as being inside or outside the scope of a negation signal. However, this chunking approach suffers from low performance, in particular on long sentences, due to ignoring structured syntactic information. For example, given golden negati</context>
<context position="6283" citStr="Huang and Lowe, 2007" startWordPosition="971" endWordPosition="974">ope corpus shows that our parsing approach much outperforms the state-of-the-art chunking ones. The rest of this paper is organized as follows. Section 2 reviews related work. Section 3 introduces the Bioscope corpus on which our approach is evaluated. Section 4 describes our parsing approach by formulating negation scope finding as a simplified shallow semantic parsing problem. Section 5 presents the experimental results. Finally, Section 6 concludes the work. 2 Related Work While there is a certain amount of literature within the NLP community on negated terms finding (Chapman et al., 2001; Huang and Lowe, 2007; Goldin and Chapman, 2003), there are only a few studies on negation scope finding (Morante et al., 2008; Morante and Daelemans, 2009). Negated terms finding Rule-based methods dominated the initial research on negated terms finding. As a representative, Chapman et al. (2001) developed a simple regular expression-based algorithm to detect negation signals and identify medical terms which fall within the negation scope. They found that their simple regular expression-based algorithm can effectively identify a large portion of the pertinent negative statements from discharge summaries on determ</context>
</contexts>
<marker>Huang, Lowe, 2007</marker>
<rawString>Yang Huang and Henry Lowe. 2007. A Novel Hybrid Approach to Automated Negation Detection in Clinical Radiology Reports. Journal of the American Medical Informatics Association, 14(3): 304-311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zheng Ping Jiang</author>
<author>Hwee Tou Ng</author>
</authors>
<title>Semantic Role Labeling of NomBank: A Maximum Entropy Approach.</title>
<date>2006</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<contexts>
<context position="17020" citStr="Jiang and Ng (2006)" startWordPosition="2627" endWordPosition="2630">eatures To capture more useful information in the negation signal-scope structures, we also explore various kinds of additional features. Table 2 shows the features in better capturing the details regarding the argument candidate and the negation signal. In particular, we categorize the additional features into three groups according to their relationship with the argument candidate (AC, in short) and the given negation signal (NS, in short). Some features proposed above may not be effective in argument identification. Therefore, we adopt the greedy feature selection algorithm as described in Jiang and Ng (2006) to pick up positive features incrementally according to their contributions on the development data. The algorithm repeatedly selects one feature each time which contributes most, and stops when adding any of the remaining features fails to improve the performance. As far as the negation scope finding task concerned, the whole feature selection process could be done by first running the selection algorithm with the basic features (b1-b4) and then incrementally picking up effective features from (ac1-ac6, AC1-AC2, ns1-ns4, NS1-NS2, nsac1-nsac2, and NSAC1 -NSAC7). Feature Remarks argument candi</context>
</contexts>
<marker>Jiang, Ng, 2006</marker>
<rawString>Zheng Ping Jiang and Hwee Tou Ng. 2006. Semantic Role Labeling of NomBank: A Maximum Entropy Approach. In Proceedings of EMNLP 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Junhui Li</author>
<author>Guodong Zhou</author>
<author>Hai Zhao</author>
<author>Qiaoming Zhu</author>
<author>Peide Qian</author>
</authors>
<date>2009</date>
<booktitle>Improving Nominal SRL in Chinese Language with Verbal SRL Information and Automatic Predicate Recognition. In Proceedings of EMNLP</booktitle>
<contexts>
<context position="15779" citStr="Li et al., 2009" startWordPosition="2437" endWordPosition="2440">, NP4,5, IN3,3, VBP2,2, and NP0,1} are collected as its argument candidates consequently. 4.3 Argument Identification Here, a binary classifier is applied to determine the argument candidates as either valid arguments or non-arguments. Similar to argument 674 \x0cidentification in common shallow semantic parsing, the structured syntactic information plays a critical role in negation scope finding. Basic Features Table 1 lists the basic features for argument identification. These features are also widely used in common shallow semantic parsing for both verbal and nominal predicates (Xue, 2008; Li et al., 2009). Feature Remarks b1 Negation: the stem of the negation signal, e.g., not, rather_than. (can_not) b2 Phrase Type: the syntactic category of the argument candidate. (NP) b3 Path: the syntactic path from the argument candidate to the negation signal. (NP&lt;S&gt;VP&gt;RB) b4 Position: the positional relationship of the argument candidate with the negation signal. left or right. (left) Table 1: Basic features and their instantiations for argument identification in negation scope finding, with NP4,5 as the focus constituent (i.e., the argument candidate) and can not as the given negation signal, regarding </context>
</contexts>
<marker>Li, Zhou, Zhao, Zhu, Qian, 2009</marker>
<rawString>Junhui Li, Guodong Zhou, Hai Zhao, Qiaoming Zhu, and Peide Qian. Improving Nominal SRL in Chinese Language with Verbal SRL Information and Automatic Predicate Recognition. In Proceedings of EMNLP 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roser Morante</author>
<author>Anthony Liekens</author>
<author>Walter Daelemans</author>
</authors>
<title>Learning the Scope of Negation in Biomedical Texts.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<contexts>
<context position="3980" citStr="Morante et al. (2008)" startWordPosition="603" endWordPosition="606">le and cheap are positive, the polarity of the chair regarding the attribute cheap keeps positive while the polarity of the chair regarding the attribute comfortable is reversed due to the negation signal not. Most of the initial research on SoN learning focused on negated terms finding, using either some heuristic rules (e.g., regular expression), or machine learning methods (Chapman et al., 2001; Huang and Lowe, 2007; Goldin and Chapman, 2003). Negation scope finding has been largely ignored until the recent release of 671 \x0cthe BioScope corpus (Szarvas et al., 2008; Vincze et al., 2008). Morante et al. (2008) and Morante and Daelemans (2009) pioneered the research on negation scope finding by formulating it as a chunking problem, which classifies the words of a sentence as being inside or outside the scope of a negation signal. However, this chunking approach suffers from low performance, in particular on long sentences, due to ignoring structured syntactic information. For example, given golden negation signals on the Bioscope corpus, Morante and Daelemans (2009) only got the performance of 50.26% in PCS (percentage of correct scope) measure on the full papers subcorpus (22.8 words per sentence o</context>
<context position="6388" citStr="Morante et al., 2008" startWordPosition="989" endWordPosition="992">of this paper is organized as follows. Section 2 reviews related work. Section 3 introduces the Bioscope corpus on which our approach is evaluated. Section 4 describes our parsing approach by formulating negation scope finding as a simplified shallow semantic parsing problem. Section 5 presents the experimental results. Finally, Section 6 concludes the work. 2 Related Work While there is a certain amount of literature within the NLP community on negated terms finding (Chapman et al., 2001; Huang and Lowe, 2007; Goldin and Chapman, 2003), there are only a few studies on negation scope finding (Morante et al., 2008; Morante and Daelemans, 2009). Negated terms finding Rule-based methods dominated the initial research on negated terms finding. As a representative, Chapman et al. (2001) developed a simple regular expression-based algorithm to detect negation signals and identify medical terms which fall within the negation scope. They found that their simple regular expression-based algorithm can effectively identify a large portion of the pertinent negative statements from discharge summaries on determining whether a finding or disease is absent. Besides, Huang and Lowe (2007) first proposed some heuristi</context>
<context position="28651" citStr="Morante et al. (2008)" startWordPosition="4498" endWordPosition="4501">99.77 97.94 97.82 Table 6: Performance (%) of negation scope finding on the two subcorpora by using automatic parser trained with all the sentences in GTB1.0. Method Abstracts Papers Clinical M et al. (2008) 57.33 n/a n/a M &amp; D (2009) 73.36 50.26 87.27 Our baseline 73.42 53.70 88.42 Our final system 81.84 64.02 89.79 Table 7: Performance comparison over the PCS measure (%) of our system with other state-of-the-art ones. Table 7 compares our performance in PCS measure with related work. It shows that even our baseline system with four basic features as presented in Table 1 performs better than Morante et al. (2008) and Morante and Daelemans(2009). This indicates the appropriateness of our simplified shallow semantic parsing approach and the effectiveness of structured syntactic information on negation scope finding. It also shows that our final system significantly outperforms the state-of-the-art ones using a chunking approach, especially on the abstracts and full papers subcorpora. However, the improvement on the clinical reports subcorpus is less apparent, partly due to the fact that the sentences in this subcorpus are much simpler (with average length of 6.6 words per sentence) and thus a chunking a</context>
</contexts>
<marker>Morante, Liekens, Daelemans, 2008</marker>
<rawString>Roser Morante, Anthony Liekens, and Walter Daelemans. 2008. Learning the Scope of Negation in Biomedical Texts. In Proceedings of EMNLP 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roser Morante</author>
<author>Walter Daelemans</author>
</authors>
<title>A Metalearning Approach to Processing the Scope of Negation.</title>
<date>2009</date>
<booktitle>In Proceedings of CoNLL</booktitle>
<contexts>
<context position="2164" citStr="Morante and Daelemans, 2009" startWordPosition="325" endWordPosition="328">ding and negation scope finding. The former decides whether the words in a sentence are negation signals (i.e., words indicating negation, e.g., no, not, fail, rather than), where the semantic information of the words, rather than the syntactic information, plays a critical role. The latter determines the sequences of words in the sentence which are negated by the given negation signal. Compared with negation scope finding, negation signal finding is much simpler and has been well resolved in the literature, e.g. with the accuracy of 95.8%-98.7% on the three subcorpora of the Bioscope corpus (Morante and Daelemans, 2009). In this paper, we focus on negation scope finding instead. That is, we assume golden negation signal finding. Finding negative assertions is essential in information extraction (IE), where in general, the aim is to derive factual knowledge from free text. For example, Vincze et al. (2008) pointed out that the extracted information within the scopes of negation signals should either be discarded or presented separately from factual information. This is especially important in the biomedical domain, where various linguistic forms are used extensively to express impressions, hypothesized explan</context>
<context position="4013" citStr="Morante and Daelemans (2009)" startWordPosition="608" endWordPosition="611"> the polarity of the chair regarding the attribute cheap keeps positive while the polarity of the chair regarding the attribute comfortable is reversed due to the negation signal not. Most of the initial research on SoN learning focused on negated terms finding, using either some heuristic rules (e.g., regular expression), or machine learning methods (Chapman et al., 2001; Huang and Lowe, 2007; Goldin and Chapman, 2003). Negation scope finding has been largely ignored until the recent release of 671 \x0cthe BioScope corpus (Szarvas et al., 2008; Vincze et al., 2008). Morante et al. (2008) and Morante and Daelemans (2009) pioneered the research on negation scope finding by formulating it as a chunking problem, which classifies the words of a sentence as being inside or outside the scope of a negation signal. However, this chunking approach suffers from low performance, in particular on long sentences, due to ignoring structured syntactic information. For example, given golden negation signals on the Bioscope corpus, Morante and Daelemans (2009) only got the performance of 50.26% in PCS (percentage of correct scope) measure on the full papers subcorpus (22.8 words per sentence on average), compared to 87.27% in</context>
<context position="6418" citStr="Morante and Daelemans, 2009" startWordPosition="993" endWordPosition="996">ized as follows. Section 2 reviews related work. Section 3 introduces the Bioscope corpus on which our approach is evaluated. Section 4 describes our parsing approach by formulating negation scope finding as a simplified shallow semantic parsing problem. Section 5 presents the experimental results. Finally, Section 6 concludes the work. 2 Related Work While there is a certain amount of literature within the NLP community on negated terms finding (Chapman et al., 2001; Huang and Lowe, 2007; Goldin and Chapman, 2003), there are only a few studies on negation scope finding (Morante et al., 2008; Morante and Daelemans, 2009). Negated terms finding Rule-based methods dominated the initial research on negated terms finding. As a representative, Chapman et al. (2001) developed a simple regular expression-based algorithm to detect negation signals and identify medical terms which fall within the negation scope. They found that their simple regular expression-based algorithm can effectively identify a large portion of the pertinent negative statements from discharge summaries on determining whether a finding or disease is absent. Besides, Huang and Lowe (2007) first proposed some heuristic rules from a parse tree pers</context>
<context position="7944" citStr="Morante and Daelemans (2009)" startWordPosition="1233" endWordPosition="1236">resentative, Goldin and Chapman (2003) adopted both Naive Bayes and decision trees to distinguish whether an observation is negated by the negation signal not in hospital reports. Negation scope finding Morante et al. (2008) pioneered the research on negation scope finding, largely due to the availability of a large-scale annotated corpus, the Bioscope corpus. They approached the negation scope finding task as a chunking problem which predicts whether a word in the sentence is inside or outside of the negation scope, with proper post-processing to ensure consecutiveness of the negation scope. Morante and Daelemans (2009) further improved the performance by combing several classifiers. Similar to SoN learning, there are some efforts in the NLP community on learning the scope of speculation. As a representative, Ozgur and Radev (2009) divided speculation 672 \x0clearning into two subtasks: speculation signal finding and speculation scope finding. In particular, they formulated speculation signal finding as a classification problem while employing some heuristic rules from the parse tree perspective on speculation scope finding. 3 Negation in the BioScope Corpus This paper employs the BioScope corpus (Szarvas et</context>
<context position="9856" citStr="Morante and Daelemans (2009)" startWordPosition="1531" endWordPosition="1534">pe corpus consists of three subcorpora: the full papers and the abstracts from the GENIA corpus (Collier et al., 1999), and clinical (radiology) reports. Among them, the full papers subcorpus and the abstracts subcorpus come from the same genre, and thus share some common characteristics in statistics, such as the number of words in the negation scope to the right (or left) of the negation signal and the average scope length. In comparison, the clinical reports subcorpus consists of clinical radiology reports with short sentences. For detailed statistics about the three subcorpora, please see Morante and Daelemans (2009). 1 http://www.inf.u-szeged.hu/rgai/bioscope For preprocessing, all the sentences in the Bioscope corpus are tokenized and then parsed using the Berkeley parser2 (Petrov and Klein, 2007) trained on the GENIA TreeBank (GTB) 1.0 (Tateisi et al., 2005)3 , which is a bracketed corpus in (almost) PTB style. 10-fold cross-validation on GTB1.0 shows that the parser achieves the performance of 86.57 in F1-measure. It is worth noting that the GTB1.0 corpus includes all the sentences in the abstracts subcorpus of the Bioscope corpus. 4 Negation Scope Finding via Shallow Semantic Parsing In this section,</context>
<context position="20595" citStr="Morante and Daelemans (2009)" startWordPosition="3196" endWordPosition="3199">leftmost word of constituent LACi (1&lt;=i&lt;=m). Supposing LACi receives probability of Pi being an argument, we use the following formula to determine LACk* whose leftmost word represents the boundary of the left scope. If k*=0, then the negation signal itself represents its left boundary. ( ) * 1 1 argmax 1 k m i i k i i k k P = = + = P Similarly, the right boundary of the given negation signal can be decided. 5 Experimentation We have evaluated our shallow semantic parsing approach to negation scope finding on the BioScope corpus. 5.1 Experimental Settings Following the experimental setting in Morante and Daelemans (2009), the abstracts subcorpus is randomly divided into 10 folds so as to perform 10-fold cross validation, while the performance on both the papers and clinical reports subcorpora is evaluated using the system trained on the whole abstracts subcorpus. In addition, SVMLight5 is selected as our classifier. In particular, we adopt the linear kernel and the training parameter C is fine-tuned to 0.2. 1 5 http://svmlight.joachims.org/ The evaluation is made using the accuracy. We report the accuracy using three measures: PCLB and PCRB, which indicate the percentages of correct left boundary and right bo</context>
</contexts>
<marker>Morante, Daelemans, 2009</marker>
<rawString>Roser Morante and Walter Daelemans. 2009. A Metalearning Approach to Processing the Scope of Negation. In Proceedings of CoNLL 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arzucan Ozgur</author>
<author>Dragomir R Radev</author>
</authors>
<title>Detecting Speculations and their Scopes in Scientific Text.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<contexts>
<context position="8160" citStr="Ozgur and Radev (2009)" startWordPosition="1268" endWordPosition="1271">8) pioneered the research on negation scope finding, largely due to the availability of a large-scale annotated corpus, the Bioscope corpus. They approached the negation scope finding task as a chunking problem which predicts whether a word in the sentence is inside or outside of the negation scope, with proper post-processing to ensure consecutiveness of the negation scope. Morante and Daelemans (2009) further improved the performance by combing several classifiers. Similar to SoN learning, there are some efforts in the NLP community on learning the scope of speculation. As a representative, Ozgur and Radev (2009) divided speculation 672 \x0clearning into two subtasks: speculation signal finding and speculation scope finding. In particular, they formulated speculation signal finding as a classification problem while employing some heuristic rules from the parse tree perspective on speculation scope finding. 3 Negation in the BioScope Corpus This paper employs the BioScope corpus (Szarvas et al., 2008; Vincze et al., 2008)1 , a freely downloadable negation resource from the biomedical domain, as the benchmark corpus. In this corpus, every sentence is annotated with negation signals and speculation signa</context>
</contexts>
<marker>Ozgur, Radev, 2009</marker>
<rawString>Arzucan Ozgur; Dragomir R. Radev. 2009. Detecting Speculations and their Scopes in Scientific Text. In Proceedings of EMNLP 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Dan Klein</author>
</authors>
<title>Improved Inference for Unlexicalized Parsing.</title>
<date>2007</date>
<booktitle>In Proceedings of NAACL</booktitle>
<contexts>
<context position="10042" citStr="Petrov and Klein, 2007" startWordPosition="1555" endWordPosition="1558"> and the abstracts subcorpus come from the same genre, and thus share some common characteristics in statistics, such as the number of words in the negation scope to the right (or left) of the negation signal and the average scope length. In comparison, the clinical reports subcorpus consists of clinical radiology reports with short sentences. For detailed statistics about the three subcorpora, please see Morante and Daelemans (2009). 1 http://www.inf.u-szeged.hu/rgai/bioscope For preprocessing, all the sentences in the Bioscope corpus are tokenized and then parsed using the Berkeley parser2 (Petrov and Klein, 2007) trained on the GENIA TreeBank (GTB) 1.0 (Tateisi et al., 2005)3 , which is a bracketed corpus in (almost) PTB style. 10-fold cross-validation on GTB1.0 shows that the parser achieves the performance of 86.57 in F1-measure. It is worth noting that the GTB1.0 corpus includes all the sentences in the abstracts subcorpus of the Bioscope corpus. 4 Negation Scope Finding via Shallow Semantic Parsing In this section, we first formulate the negation scope finding task as a shallow semantic parsing problem. Then, we deal with it using a simplified shallow semantic parsing framework. 4.1 Formulating Ne</context>
</contexts>
<marker>Petrov, Klein, 2007</marker>
<rawString>Slav Petrov and Dan Klein. 2007. Improved Inference for Unlexicalized Parsing. In Proceedings of NAACL 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasin Punyakanok</author>
<author>Dan Roth</author>
<author>Wen-tau Yih</author>
</authors>
<title>The Necessity of Syntactic Parsing for Semantic Role Labeling.</title>
<date>2005</date>
<booktitle>In Proceedings of IJCAI</booktitle>
<contexts>
<context position="5289" citStr="Punyakanok et al., 2005" startWordPosition="814" endWordPosition="817">words per sentence on average). This paper explores negation scope finding from a parse tree perspective and formulates it as a shallow semantic parsing problem, which has been extensively studied in the past few years (Carreras and Marquez, 2005). In particular, the negation signal is recast as the predicate and the negation scope is recast as its arguments. The motivation behind is that structured syntactic information plays a critical role in negation scope finding and should be paid much more attention, as indicated by previous studies in shallow semantic parsing (Gildea and Palmer, 2002; Punyakanok et al., 2005). Our parsing approach to negation scope finding differs from the state-of-the-art chunking ones in two aspects. First, we extend negation scope finding from the chunking level into the parse tree level, where structured syntactic information is available. Second, we focus on determining whether a constituent, rather than a word, is negated or not. Evaluation on the BioScope corpus shows that our parsing approach much outperforms the state-of-the-art chunking ones. The rest of this paper is organized as follows. Section 2 reviews related work. Section 3 introduces the Bioscope corpus on which </context>
</contexts>
<marker>Punyakanok, Roth, Yih, 2005</marker>
<rawString>Vasin Punyakanok, Dan Roth, and Wen-tau Yih. 2005. The Necessity of Syntactic Parsing for Semantic Role Labeling. In Proceedings of IJCAI 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gyorgy Szarvas</author>
<author>Veronika Vincze</author>
<author>Richard Farkas</author>
<author>Janos Csirik</author>
</authors>
<title>The BioScope corpus: annotation for negation, uncertainty and their scope in biomedical texts.</title>
<date>2008</date>
<booktitle>In Proceedings of BioNLP</booktitle>
<contexts>
<context position="2838" citStr="Szarvas et al. (2008)" startWordPosition="423" endWordPosition="426">nstead. That is, we assume golden negation signal finding. Finding negative assertions is essential in information extraction (IE), where in general, the aim is to derive factual knowledge from free text. For example, Vincze et al. (2008) pointed out that the extracted information within the scopes of negation signals should either be discarded or presented separately from factual information. This is especially important in the biomedical domain, where various linguistic forms are used extensively to express impressions, hypothesized explanations of experimental results or negative findings. Szarvas et al. (2008) reported that 13.45% of the sentences in the abstracts subcorpus of the BioScope corpus and 12.70% of the sentences in the full papers subcorpus of the Bioscope corpus contain negative assertions. In addition to the IE tasks in the biomedical domain, SoN learning has attracted more and more attention in some natural language processing (NLP) tasks, such as sentiment classification (Turney, 2002). For example, in the sentence The chair is not comfortable but cheap, although both the polarities of the words comfortable and cheap are positive, the polarity of the chair regarding the attribute ch</context>
<context position="8554" citStr="Szarvas et al., 2008" startWordPosition="1325" endWordPosition="1328">ans (2009) further improved the performance by combing several classifiers. Similar to SoN learning, there are some efforts in the NLP community on learning the scope of speculation. As a representative, Ozgur and Radev (2009) divided speculation 672 \x0clearning into two subtasks: speculation signal finding and speculation scope finding. In particular, they formulated speculation signal finding as a classification problem while employing some heuristic rules from the parse tree perspective on speculation scope finding. 3 Negation in the BioScope Corpus This paper employs the BioScope corpus (Szarvas et al., 2008; Vincze et al., 2008)1 , a freely downloadable negation resource from the biomedical domain, as the benchmark corpus. In this corpus, every sentence is annotated with negation signals and speculation signals (if it has), as well as their linguistic scopes. Figure 1 shows a self-explainable example. In this paper, we only consider negation signals, rather than speculation ones. Our statistics shows that 96.57%, 3.23% and 0.20% of negation signals are represented by one word, two words and three or more words, respectively. Additional, adverbs (e.g., not, never) and determiners (e.g., no, neith</context>
</contexts>
<marker>Szarvas, Vincze, Farkas, Csirik, 2008</marker>
<rawString>Gyorgy Szarvas, Veronika Vincze, Richard Farkas, and Janos Csirik. 2008. The BioScope corpus: annotation for negation, uncertainty and their scope in biomedical texts. In Proceedings of BioNLP 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuka Tateisi</author>
<author>Akane Yakushiji</author>
<author>Tomoko Ohta</author>
<author>Junichi Tsujii</author>
</authors>
<title>Syntax Annotation for the GENIA Corpus.</title>
<date>2005</date>
<booktitle>In Proceedings of IJCNLP 2005, Companion volume.</booktitle>
<contexts>
<context position="10105" citStr="Tateisi et al., 2005" startWordPosition="1566" endWordPosition="1569">hare some common characteristics in statistics, such as the number of words in the negation scope to the right (or left) of the negation signal and the average scope length. In comparison, the clinical reports subcorpus consists of clinical radiology reports with short sentences. For detailed statistics about the three subcorpora, please see Morante and Daelemans (2009). 1 http://www.inf.u-szeged.hu/rgai/bioscope For preprocessing, all the sentences in the Bioscope corpus are tokenized and then parsed using the Berkeley parser2 (Petrov and Klein, 2007) trained on the GENIA TreeBank (GTB) 1.0 (Tateisi et al., 2005)3 , which is a bracketed corpus in (almost) PTB style. 10-fold cross-validation on GTB1.0 shows that the parser achieves the performance of 86.57 in F1-measure. It is worth noting that the GTB1.0 corpus includes all the sentences in the abstracts subcorpus of the Bioscope corpus. 4 Negation Scope Finding via Shallow Semantic Parsing In this section, we first formulate the negation scope finding task as a shallow semantic parsing problem. Then, we deal with it using a simplified shallow semantic parsing framework. 4.1 Formulating Negation Scope Finding as a Shallow Semantic Parsing Problem Give</context>
</contexts>
<marker>Tateisi, Yakushiji, Ohta, Tsujii, 2005</marker>
<rawString>Yuka Tateisi, Akane Yakushiji, Tomoko Ohta, and Junichi Tsujii. 2005. Syntax Annotation for the GENIA Corpus. In Proceedings of IJCNLP 2005, Companion volume.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Aria Haghighi</author>
<author>Christopher D Manning</author>
</authors>
<title>Joint Learning Improves Semantic Role Labeling.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL</booktitle>
<contexts>
<context position="24380" citStr="Toutanova et al., 2005" startWordPosition="3817" endWordPosition="3820">ctic parsing lowers the performance of negation scope finding on the abstracts subcorpus in all three measures (e.g. from 83.10 to 81.84 in PCS). As expected, the parser trained on the whole GTB1.0 corpus works better than that trained on 6,691 sentences (e.g. 64.02 Vs. 62.70, and 89.79 Vs. 85.21 in PCS measure on the full papers and the clinical reports subcorpora, respectively). However, the performance decrease shows that negation scope finding is not as sensitive to automatic syntactic parsing as common shallow semantic parsing, whose performance might decrease by about ~10 in F1-measure (Toutanova et al., 2005). This indicates that negation scope finding via shallow semantic parsing is robust to some variations in the parse trees. 1 Feature PCLB PCRB PCS Baseline 84.29 87.82 74.05 +selected features 93.06 88.96 83.10 Table 4: Performance (%) of negation scope finding on the abstracts subcorpus using 10-fold cross-validation. 5.3 Experimental Results on Automatic Parse Trees The GTB1.0 corpus contains 18,541 sentences in which 11,850 of them (63.91%) overlap with the sentences in the abstracts subcorpus6 . In order to get automatic parse trees for the sentences in the abstracts subcorpus, we train th</context>
</contexts>
<marker>Toutanova, Haghighi, Manning, 2005</marker>
<rawString>Kristina Toutanova, Aria Haghighi, and Christopher D. Manning. 2005. Joint Learning Improves Semantic Role Labeling. In Proceedings of ACL 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
</authors>
<title>Thumbs Up or Thumbs Down? Semantic Orientation Applied to Unsupervised Classification of Reviews.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL</booktitle>
<contexts>
<context position="3237" citStr="Turney, 2002" startWordPosition="487" endWordPosition="488">pecially important in the biomedical domain, where various linguistic forms are used extensively to express impressions, hypothesized explanations of experimental results or negative findings. Szarvas et al. (2008) reported that 13.45% of the sentences in the abstracts subcorpus of the BioScope corpus and 12.70% of the sentences in the full papers subcorpus of the Bioscope corpus contain negative assertions. In addition to the IE tasks in the biomedical domain, SoN learning has attracted more and more attention in some natural language processing (NLP) tasks, such as sentiment classification (Turney, 2002). For example, in the sentence The chair is not comfortable but cheap, although both the polarities of the words comfortable and cheap are positive, the polarity of the chair regarding the attribute cheap keeps positive while the polarity of the chair regarding the attribute comfortable is reversed due to the negation signal not. Most of the initial research on SoN learning focused on negated terms finding, using either some heuristic rules (e.g., regular expression), or machine learning methods (Chapman et al., 2001; Huang and Lowe, 2007; Goldin and Chapman, 2003). Negation scope finding has </context>
</contexts>
<marker>Turney, 2002</marker>
<rawString>Peter D. Turney. 2002. Thumbs Up or Thumbs Down? Semantic Orientation Applied to Unsupervised Classification of Reviews. In Proceedings of ACL 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Veronika Vincze</author>
<author>Gyorgy Szarvas</author>
<author>Richard Farkas</author>
<author>Gyorgy Mora</author>
<author>Janos Csirik</author>
</authors>
<title>The BioScope corpus: biomedical texts annotated for uncertainty, negation and their scopes.</title>
<date>2008</date>
<journal>BMC Bioinformatics,</journal>
<volume>9</volume>
<pages>11--9</pages>
<contexts>
<context position="2455" citStr="Vincze et al. (2008)" startWordPosition="371" endWordPosition="374">nes the sequences of words in the sentence which are negated by the given negation signal. Compared with negation scope finding, negation signal finding is much simpler and has been well resolved in the literature, e.g. with the accuracy of 95.8%-98.7% on the three subcorpora of the Bioscope corpus (Morante and Daelemans, 2009). In this paper, we focus on negation scope finding instead. That is, we assume golden negation signal finding. Finding negative assertions is essential in information extraction (IE), where in general, the aim is to derive factual knowledge from free text. For example, Vincze et al. (2008) pointed out that the extracted information within the scopes of negation signals should either be discarded or presented separately from factual information. This is especially important in the biomedical domain, where various linguistic forms are used extensively to express impressions, hypothesized explanations of experimental results or negative findings. Szarvas et al. (2008) reported that 13.45% of the sentences in the abstracts subcorpus of the BioScope corpus and 12.70% of the sentences in the full papers subcorpus of the Bioscope corpus contain negative assertions. In addition to the </context>
<context position="3957" citStr="Vincze et al., 2008" startWordPosition="599" endWordPosition="602">of the words comfortable and cheap are positive, the polarity of the chair regarding the attribute cheap keeps positive while the polarity of the chair regarding the attribute comfortable is reversed due to the negation signal not. Most of the initial research on SoN learning focused on negated terms finding, using either some heuristic rules (e.g., regular expression), or machine learning methods (Chapman et al., 2001; Huang and Lowe, 2007; Goldin and Chapman, 2003). Negation scope finding has been largely ignored until the recent release of 671 \x0cthe BioScope corpus (Szarvas et al., 2008; Vincze et al., 2008). Morante et al. (2008) and Morante and Daelemans (2009) pioneered the research on negation scope finding by formulating it as a chunking problem, which classifies the words of a sentence as being inside or outside the scope of a negation signal. However, this chunking approach suffers from low performance, in particular on long sentences, due to ignoring structured syntactic information. For example, given golden negation signals on the Bioscope corpus, Morante and Daelemans (2009) only got the performance of 50.26% in PCS (percentage of correct scope) measure on the full papers subcorpus (22</context>
<context position="8576" citStr="Vincze et al., 2008" startWordPosition="1329" endWordPosition="1332">roved the performance by combing several classifiers. Similar to SoN learning, there are some efforts in the NLP community on learning the scope of speculation. As a representative, Ozgur and Radev (2009) divided speculation 672 \x0clearning into two subtasks: speculation signal finding and speculation scope finding. In particular, they formulated speculation signal finding as a classification problem while employing some heuristic rules from the parse tree perspective on speculation scope finding. 3 Negation in the BioScope Corpus This paper employs the BioScope corpus (Szarvas et al., 2008; Vincze et al., 2008)1 , a freely downloadable negation resource from the biomedical domain, as the benchmark corpus. In this corpus, every sentence is annotated with negation signals and speculation signals (if it has), as well as their linguistic scopes. Figure 1 shows a self-explainable example. In this paper, we only consider negation signals, rather than speculation ones. Our statistics shows that 96.57%, 3.23% and 0.20% of negation signals are represented by one word, two words and three or more words, respectively. Additional, adverbs (e.g., not, never) and determiners (e.g., no, neither) occupy 45.66% and </context>
</contexts>
<marker>Vincze, Szarvas, Farkas, Mora, Csirik, 2008</marker>
<rawString>Veronika Vincze, Gyorgy Szarvas, Richard Farkas, Gyorgy Mora, and Janos Csirik. 2008. The BioScope corpus: biomedical texts annotated for uncertainty, negation and their scopes. BMC Bioinformatics, 9(Suppl 11):S9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
<author>Martha Palmer</author>
</authors>
<title>Calibrating Features for Semantic Role Labeling.</title>
<date>2004</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<contexts>
<context position="14523" citStr="Xue and Palmer (2004)" startWordPosition="2241" endWordPosition="2244">cope finding does not involve semantic label classification and thus could be divided into three consequent phases: argument pruning, argument identification and post-processing. 4.2 Argument Pruning Similar to the predicate-argument structures in common shallow semantic parsing, the negation signal-scope structures in negation scope finding can be also classified into several certain types and argument pruning can be done by employing several heuristic rules to filter out constituents, which are most likely non-arguments of a negation signal. Similar to the heuristic algorithm as proposed in Xue and Palmer (2004) for argument pruning in common shallow semantic parsing, the argument pruning algorithm adopted here starts from designating the negation signal as the current node and collects its siblings. It then iteratively moves one level up to the parent of the current node and collects its siblings. The algorithm ends when it reaches the root of the parse tree. To sum up, except the negation signal and its ancestral constituents, any constituent in the parse tree whose parent covers the given negation signal will be collected as argument candidates. Taking the negation signal node RB7,7 in Figure 2 as</context>
</contexts>
<marker>Xue, Palmer, 2004</marker>
<rawString>Nianwen Xue and Martha Palmer. 2004. Calibrating Features for Semantic Role Labeling. In Proceedings of EMNLP 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
</authors>
<title>Labeling Chinese Predicates with Semantic Roles.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<pages>34--2</pages>
<contexts>
<context position="15761" citStr="Xue, 2008" startWordPosition="2435" endWordPosition="2436">6,6, VP8,11, NP4,5, IN3,3, VBP2,2, and NP0,1} are collected as its argument candidates consequently. 4.3 Argument Identification Here, a binary classifier is applied to determine the argument candidates as either valid arguments or non-arguments. Similar to argument 674 \x0cidentification in common shallow semantic parsing, the structured syntactic information plays a critical role in negation scope finding. Basic Features Table 1 lists the basic features for argument identification. These features are also widely used in common shallow semantic parsing for both verbal and nominal predicates (Xue, 2008; Li et al., 2009). Feature Remarks b1 Negation: the stem of the negation signal, e.g., not, rather_than. (can_not) b2 Phrase Type: the syntactic category of the argument candidate. (NP) b3 Path: the syntactic path from the argument candidate to the negation signal. (NP&lt;S&gt;VP&gt;RB) b4 Position: the positional relationship of the argument candidate with the negation signal. left or right. (left) Table 1: Basic features and their instantiations for argument identification in negation scope finding, with NP4,5 as the focus constituent (i.e., the argument candidate) and can not as the given negation </context>
</contexts>
<marker>Xue, 2008</marker>
<rawString>Nianwen Xue. 2008. Labeling Chinese Predicates with Semantic Roles. Computational Linguistics, 34(2):225-255.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>