<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<bodyText confidence="0.3914775">
b&amp;apos;Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL 2007, pp. 957961,
Prague, June 2007. c
</bodyText>
<sectionHeader confidence="0.387224" genericHeader="abstract">
2007 Association for Computational Linguistics
</sectionHeader>
<title confidence="0.754318">
Experiments with a Higher-Order Projective Dependency Parser
</title>
<author confidence="0.975415">
Xavier Carreras
</author>
<affiliation confidence="0.993068">
Massachusetts Institute of Technology (MIT)
Computer Science and Artificial Intelligence Laboratory (CSAIL)
</affiliation>
<address confidence="0.970778">
32 Vassar St., Cambridge, MA 02139
</address>
<email confidence="0.997203">
carreras@csail.mit.edu
</email>
<sectionHeader confidence="0.990819" genericHeader="keywords">
Abstract
</sectionHeader>
<bodyText confidence="0.999649">
We present experiments with a dependency
parsing model defined on rich factors. Our
model represents dependency trees with fac-
tors that include three types of relations be-
tween the tokens of a dependency and their
children. We extend the projective pars-
ing algorithm of Eisner (1996) for our case,
and train models using the averaged percep-
tron. Our experiments show that consider-
ing higher-order information yields signifi-
cant improvements in parsing accuracy, but
comes at a high cost in terms of both time
and memory consumption. In the multi-
lingual exercise of the CoNLL-2007 shared
task (Nivre et al., 2007), our system obtains
the best accuracy for English, and the second
best accuracies for Basque and Czech.
</bodyText>
<sectionHeader confidence="0.99826" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999688682926829">
Structured prediction problems usually involve
models that work with factored representations of
structures. The information included in the factors
determines the type of features that the model can
exploit. However, richer representations translate
into higher complexity of the inference algorithms
associated with the model.
In dependency parsing, the basic first-order model
is defined by a decomposition of a tree into head-
modifier dependencies. Previous work extended this
basic model to include second-order relationsi.e.
dependencies that are adjacent to the main depen-
dency of the factor. Specifically, these approaches
considered sibling relations of the modifier token
(Eisner, 1996; McDonald and Pereira, 2006). In this
paper we extend the parsing model with other types
of second-order relations. In particular, we incorpo-
rate relations between the head and modifier tokens
and the children of the modifier.
One paradigmatic case where the relations we
consider are relevant is PP-attachment. For example,
in They sold 1,210 cars in the U.S., the ambigu-
ity problem is to determine whether the preposition
in (which governs the U.S.) is modifying sold
or cars, the former being correct in this case. It is
generally accepted that to solve the attachment deci-
sion it is necessary to look at the head noun within
the prepositional phrase (i.e., U.S. in the exam-
ple), which has a grand-parental relation with the
two candidate tokens that the phrase may attach
see e.g. (Ratnaparkhi et al., 1994). Other ambigu-
ities in language may also require consideration of
grand-parental relations in the dependency structure.
We present experiments with higher-order models
trained with averaged perceptron. The second-order
relations that we incorporate in the model yield sig-
nificant improvements in accuracy. However, the in-
ference algorithms for our factorization are very ex-
pensive in terms of time and memory consumption,
and become impractical when dealing with many la-
bels or long sentences.
</bodyText>
<sectionHeader confidence="0.994438" genericHeader="method">
2 Higher-Order Projective Models
</sectionHeader>
<bodyText confidence="0.99985075">
A dependency parser receives a sentence x of n to-
kens, and outputs a labeled dependency tree y. In
the tree, a labeled dependency is a triple hh, m, li,
where h [0 . . . n] is the index of the head token,
</bodyText>
<page confidence="0.98089">
957
</page>
<equation confidence="0.78365425">
\x0cl
h m c
c
ch mi mo
</equation>
<figureCaption confidence="0.975399">
Figure 1: A factor in the higher-order parsing model.
</figureCaption>
<bodyText confidence="0.806635">
m [1 . . . n] is the index of the modifier token, and
l [1 . . . L] is the label of the dependency. The
value h = 0 is used for dependencies where the
head is a special root-symbol of the sentence. We
denote by T (x) the set of all possible dependency
structures for a sentence x. In this paper, we restrict
to projective dependency trees. The dependency tree
computed by the parser for a given sentence is:
</bodyText>
<equation confidence="0.978890166666667">
y
(x) = arg max
yT (x)
X
fy
score(w, x, f)
</equation>
<bodyText confidence="0.989805666666667">
The parsing model represents a structure y as a set of
factors, f y, and scores each factor using param-
eters w. In a first-order model a factor corresponds
to a single labeled dependency, i.e. f = hh, m, li.
The features of the model are defined through a fea-
ture function 1(x, h, m) which maps a sentence to-
gether with an unlabeled dependency to a feature
vector in Rd1 . The parameters of the model are a
collection of vectors wl
</bodyText>
<listItem confidence="0.2332225">
1 Rd1 , one for each pos-
sible label. The first-order model scores a factor as
score1(w, x, hh, m, li) = 1(x, h, m) wl
1.
</listItem>
<bodyText confidence="0.972891842105263">
The higher-order model defined in this paper de-
composes a dependency structure into factors that
include children of the head and the modifier. In
particular, a factor in our model is represented by
the signature f = hh, m, l, ch, cmi, cmoi where, as
in the first-order model, h, m and l are respectively
the head, modifier and label of the main dependency
of the factor; ch is the child of h in [h . . . m] that
is closest to m; cmi is child of m inside [h . . . m]
that is furthest from m; cmo is the child of m out-
side [h . . . m] that is furthest from m. Figure 1 de-
picts a factor of the higher-order model, and Table 1
lists the factors of an example sentence. Note that a
factor involves a main labeled dependency and three
adjacent unlabeled dependencies that attach to chil-
dren of h and m. Special values are used when either
of these children are null.
The higher-order model defines additional
m h ch cmi cmo
</bodyText>
<construct confidence="0.982808857142857">
They 1 2 - - -
sold 2 0 - 1 5
1,200 3 4 - - -
cars 4 2 - 3 -
in 5 2 4 - 7
the 6 7 - - -
U.S. 7 5 - 6 -
</construct>
<tableCaption confidence="0.959998">
Table 1: Higher-order factors for an example sentence. For
</tableCaption>
<bodyText confidence="0.955071578947368">
simplicity, labels of the factors have been omitted. A first-order
model considers only hh, mi. The second-order model of Mc-
Donald and Pereira (2006) considers hh, m, chi. For the PP-
attachment decision (factor in row 5), the higher-order model
allows us to define features that relate the verb (sold) with the
content word of the prepositional phrase (U.S.).
second-order features through a function
2(x, h, m, c) which maps a head, a modifier
and a child in a feature vector in Rd2 . The param-
eters of the model are a collection of four vectors
for each dependency label: wl
1 Rd1 as in the
first-order model; and wl
h, wl
mi and wl
mo, all three
in Rd2 and each associated to one of the adjacent
dependencies in the factor. The score of a factor is:
score2(w, x, hh, m, l, ch, cmi, cmoi) =
</bodyText>
<equation confidence="0.9052275">
1(x, h, m) wl
1 + 2(x, h, m, ch) wl
h +
2(x, h, m, cmi) wl
</equation>
<bodyText confidence="0.916988454545454">
mi + 2(x, h, m, cmo) wl
mo
Note that the model uses a common feature func-
tion for second-order relations, but features could
be defined specifically for each type of relation.
Note also that while the higher-order factors include
four dependencies, our modelling choice only ex-
ploits relations between the main dependency and
secondary dependencies. Considering relations be-
tween secondary dependencies would greatly in-
crease the cost of the associated algorithms.
</bodyText>
<subsectionHeader confidence="0.997359">
2.1 Parsing Algorithm
</subsectionHeader>
<bodyText confidence="0.998283454545454">
In this section we sketch an extension of the pro-
jective dynamic programming algorithm of Eis-
ner (1996; 2000) for the higher-order model de-
fined above. The time complexity of the algo-
rithm is O(n4L), and the memory requirements are
O(n2L + n3). As in the Eisner approach, our algo-
rithm visits sentence spans in a bottom up fashion,
and constructs a chart with two types of dynamic
programming structures, namely open and closed
structuressee Figure 2 for a diagram. The dy-
namic programming structures are:
</bodyText>
<page confidence="0.915649">
958
</page>
<equation confidence="0.9179275">
\x0ch m h m e
cmo
l
mi
c
r+1
r
h
c
l
</equation>
<figureCaption confidence="0.9814675">
Figure 2: Dynamic programming structures used in the pars-
ing algorithm. The variables in boldface constitute the index of
</figureCaption>
<bodyText confidence="0.967782333333333">
the chart entry for a structure; the other variables constitute the
back-pointer stored in the chart entry. Left: an open structure
for the chart entry [h, m, l]O ; the algorithm looks for the r, ch
and cmi that yield the optimal score for this structure. Right:
a closed structure for the chart entry [h, e, m]C ; the algorithm
looks for the l and cmo that yield the optimal score.
Open structures: For each span from s to e and
each label l, the algorithm maintains a chart
entry [s, e, l]O associated to the dependency
hs, e, li. For each entry, the algorithm looks
for the optimal splitting point r, sibling ch and
grand-child cmi using parameters wl
</bodyText>
<equation confidence="0.735516">
1, wl
h and
wl
</equation>
<bodyText confidence="0.991804434782609">
mi. This can be done in O(n2) because our
features do not consider interactions between
ch and cmi. Similar entries [e, s, l]O are main-
tained for dependencies headed at e.
Closed structures: For each span from s to e
and each token m [s . . . e], the algorithm
maintains an entry [s, e, m]C associated to a
partial dependency tree rooted at s in which m
is the last modifier of s. The algorithm chooses
the optimal dependency label l and grand-child
cmo in O(nL), using parameters wl
mo. Similar
entries [e, s, m]C are maintained for dependen-
cies headed at e.
We implemented two variants of the algorithm.
The first forces the root token to participate in ex-
actly one dependency. The second allows many de-
pendencies involving the root token. For the single-
root case, it is necessary to treat the root token dif-
ferently than other tokens. In the experiments, we
used the single-root variant if sentences in the train-
ing set satisfy this property. Otherwise we used the
multi-root variant.
</bodyText>
<subsectionHeader confidence="0.969013">
2.2 Features
</subsectionHeader>
<bodyText confidence="0.994083909090909">
The first-order features 1(x, h, m) are the exact
same implementation as in previous CoNLL sys-
tem (Carreras et al., 2006). In turn, those features
were inspired by successful previous work in first-
order dependency parsing (McDonald et al., 2005).
The most basic feature patterns consider the sur-
face form, part-of-speech, lemma and other morpho-
syntactic attributes of the head or the modifier of a
dependency. The representation also considers com-
plex features that exploit a variety of conjunctions
of the forms and part-of-speech tags of the follow-
ing items: the head and modifier; the head, modifier,
and any token in between them; the head, modifier,
and the two tokens following or preceding them.
As for the second-order features, we again
base our features with those of McDonald and
Pereira (2006), who reported successful experiments
with second-order models. We add some patterns to
their features. Let dir be right if h &lt; m, and
left otherwise; let form(xi) and cpos(xi) return
the surface form and coarse part-of-speech of token
xi, respectively. The definition of 2(x, h, m, c) is:
</bodyText>
<table confidence="0.985596777777778">
dir cpos(xh) cpos(xm) cpos(xc)
dir cpos(xh) cpos(xc)
dir cpos(xm) cpos(xc)
dir form(xh) form(xc)
dir form(xm) form(xc)
dir cpos(xh) form(xc)
dir cpos(xm) form(xc)
dir form(xh) cpos(xc)
dir form(xm) cpos(xc)
</table>
<sectionHeader confidence="0.960089" genericHeader="evaluation">
3 Experiments and Results
</sectionHeader>
<bodyText confidence="0.965803777777778">
We report experiments with higher-order models for
the ten languages in the multilingual track of the
CoNLL-2007 shared task (Nivre et al., 2007).1
In all experiments, we trained our models us-
ing the averaged perceptron (Freund and Schapire,
1999), following the extension of Collins (2002) for
structured prediction problems. To train models, we
used projectivized versions of the training depen-
dency trees.2
</bodyText>
<page confidence="0.653194">
1
</page>
<bodyText confidence="0.874955">
We are grateful to the providers of the treebanks that con-
stituted the data for the shared task (Hajic et al., 2004; Aduriz
et al., 2003; Mart et al., 2007; Chen et al., 2003; Bohmova et
al., 2003; Marcus et al., 1993; Johansson and Nugues, 2007;
Prokopidis et al., 2005; Csendes et al., 2005; Montemagni et
al., 2003; Oflazer et al., 2003).
</bodyText>
<page confidence="0.895742">
2
</page>
<bodyText confidence="0.998298666666667">
We obtained projective trees for training sentences by run-
ning the projective parser with an oracle model (that assigns a
score of +1 to correct dependencies and -1 otherwise).
</bodyText>
<page confidence="0.996654">
959
</page>
<table confidence="0.953163166666667">
\x0cCatalan Czech English
First-Order, no averaging 82.07 68.98 83.75
First-Order 86.15 75.96 87.54
Higher-Order, ch 87.50 77.15 88.70
Higher-Order, ch cmo 87.68 77.62 89.28
Higher-Order, ch cmi cmo 88.04 78.09 89.59
</table>
<tableCaption confidence="0.996173">
Table 2: Labeled attachment scores on validation data
</tableCaption>
<bodyText confidence="0.7875685">
(10,000 tokens per language), for different models that ex-
ploit increasing orders of factorizations.
</bodyText>
<subsectionHeader confidence="0.999846">
3.1 Impact of Higher-Order Factorization
</subsectionHeader>
<bodyText confidence="0.999186464285714">
Our first set of experiments looks at the performance
of different factorizations. We selected three lan-
guages with a large number of training sentences,
namely Catalan, Czech and English. To evaluate
models, we held out the training sentences that cover
the first 10,000 tokens; the rest was used for training.
We compared four models at increasing orders of
factorizations. The first is a first-order model. The
second model is similar to that of McDonald and
Pereira (2006): a factor consists of a main labeled
dependency and the head child closest to the mod-
ifier (ch). The third model incorporates the modi-
fier child outside the main dependency in the fac-
torization (cmo). Finally, the last model incorpo-
rates the modifier child inside the dependency span
(cmi), thus corresponding to the complete higher-
order model presented in the previous section.
Table 2 shows the accuracies of the models on
validation data. Each model was trained for up to
10 epochs, and evaluated at the end of each epoch;
we report the best accuracy of these evaluations.
Clearly, the accuracy increases as the factors in-
clude richer information in terms of second-order
relations. The richest model obtains the best accu-
racy in the three languages, being much better than
that of the first-order model. The table also reports
the accuracy of an unaveraged first-order model, il-
lustrating the benefits of parameter averaging.
</bodyText>
<subsectionHeader confidence="0.91769">
3.2 Results on the Multilingual Track
</subsectionHeader>
<bodyText confidence="0.975591444444444">
We trained a higher-order model for each language,
using the averaged perceptron. In the experiments
presented above we observed that the algorithm
does not over-fit, and that after two or three train-
ing epochs only small variations in accuracy occur.
Based on this fact, we designed a criterion to train
models: we ran the training algorithm for up to three
training test
sent./min. mem. UAS LAS
</bodyText>
<table confidence="0.999461454545454">
Arabic 1.21 1.8GB 81.48 70.20
Basque 33.15 1.2GB 81.08 75.73
Catalan 5.50 1.7GB 92.46 87.60
Chinese 1461.66 60MB 86.20 80.86
Czech 18.19 1.8GB 85.16 78.60
English 15.57 1.0GB 90.63 89.61
Greek 8.10 250MB 81.37 73.56
Hungarian 5.65 1.6GB 79.92 75.42
Italian 12.44 900MB 87.19 83.46
Turkish 116.55 600MB 82.41 75.85
Average - - 84.79 79.09
</table>
<tableCaption confidence="0.999661">
Table 3: Performance of the higher-order projective models
</tableCaption>
<bodyText confidence="0.918049571428571">
on the multilingual track of the CoNLL-2007 task. The first two
columns report the speed (in sentences per minute) and mem-
ory requirements of the training algorithmthese evaluations
were made on the first 1,000 training sentences with a Dual-
Core AMD OpteronTM
Processor 256 at 1.8GHz with 4GB of
memory. The last two columns report unlabelled (UAS) and
labelled (LAS) attachment scores on test data.
days of computation, or a maximum of 15 epochs.
For Basque, Chinese and Turkish we could complete
the 15 epochs. For Arabic and Catalan, we could
only complete 2 epochs. Table 3 reports the perfor-
mance of the higher-order projective models on the
ten languages of the multilingual track.
</bodyText>
<sectionHeader confidence="0.998913" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.9995705">
We have presented dependency parsing models that
exploit higher-order factorizations of trees. Such
factorizations allow the definition of second-order
features associated with sibling and grand-parental
relations. For some languages, our models obtain
state-of-the-art results.
One drawback of our approach is that the infer-
ence algorithms for higher-order models are very ex-
pensive. For languages with many dependency la-
bels or long sentences, training and parsing becomes
impractical for current machines. Thus, a promising
line of research is the investigation of methods to
efficiently incorporate higher-order relations in dis-
criminative parsing.
</bodyText>
<sectionHeader confidence="0.96696" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9942125">
I am grateful to Terry Koo, Amir Globerson and Michael
Collins for their helpful comments relating this work, and to the
anonymous reviewers for their suggestions. A significant part
of the system and the code was based on my previous system in
the CoNLL-X task, developed with Mihai Surdeanu and Llus
Marquez at the UPC. The author was supported by the Catalan
</bodyText>
<figure confidence="0.411524333333333">
Ministry of Innovation, Universities and Enterprise.
960
\x0cReferences
</figure>
<reference confidence="0.997756485714286">
A. Abeille, editor. 2003. Treebanks: Building and Using
Parsed Corpora. Kluwer.
I. Aduriz, M. J. Aranzabe, J. M. Arriola, A. Atutxa, A. Diaz
de Ilarraza, A. Garmendia, and M. Oronoz. 2003. Con-
struction of a Basque dependency treebank. In Proc. of the
2nd Workshop on Treebanks and Linguistic Theories (TLT),
pages 201204.
A. Bohmova, J. Hajic, E. Hajicova, and B. Hladka. 2003. The
PDT: a 3-level annotation scenario. In Abeille (Abeille,
2003), chapter 7, pages 103127.
X. Carreras, M. Surdeanu, and L. Marquez. 2006. Projective
dependency parsing with perceptron. In Proc. CoNLL-X.
K. Chen, C. Luo, M. Chang, F. Chen, C. Chen, C. Huang, and
Z. Gao. 2003. Sinica treebank: Design criteria, representa-
tional issues and implementation. In Abeille (Abeille, 2003),
chapter 13, pages 231248.
M. Collins. 2002. Discriminative training methods for hidden
markov models: Theory and experiments with perceptron al-
gorithms. In Proc. of EMNLP-2002.
D. Csendes, J. Csirik, T. Gyimothy, and A. Kocsor. 2005. The
Szeged Treebank. Springer.
J. Eisner. 1996. Three new probabilistic models for depen-
dency parsing: An exploration. In Proc. COLING.
J. Eisner. 2000. Bilexical grammars and their cubic-time pars-
ing algorithms. In H. C. Bunt and A. Nijholt, editors, New
Developments in Natural Language Parsing, pages 2962.
Kluwer Academic Publishers.
Y. Freund and R. E. Schapire. 1999. Large margin classifi-
cation using the perceptron algorithm. Machine Learning,
37(3):277296.
J. Hajic, O. Smrz, P. Zemanek, J. Snaidauf, and E. Beska. 2004.
Prague Arabic dependency treebank: Development in data
and tools. In Proc. of the NEMLAR Intern. Conf. on Arabic
Language Resources and Tools, pages 110117.
R. Johansson and P. Nugues. 2007. Extended constituent-to-
dependency conversion for English. In Proc. of the 16th
Nordic Conference on Computational Linguistics (NODAL-
IDA).
M. Marcus, B. Santorini, and M. Marcinkiewicz. 1993. Build-
ing a large annotated corpus of English: the Penn Treebank.
Computational Linguistics, 19(2):313330.
M. A. Mart, M. Taule, L. Marquez, and M. Bertran.
2007. CESS-ECE: A multilingual and multilevel
annotated corpus. Available for download from:
http://www.lsi.upc.edu/mbertran/cess-ece/.
R. McDonald and F. Pereira. 2006. Online learning of approx-
imate dependency parsing algorithms. In Proc. of EACL-
2006.
R. McDonald, K. Crammer, and F. Pereira. 2005. Online large-
margin training of dependency parsers. In Proc. ACL.
S. Montemagni, F. Barsotti, M. Battista, N. Calzolari, O. Coraz-
zari, A. Lenci, A. Zampolli, F. Fanciulli, M. Massetani,
R. Raffaelli, R. Basili, M. T. Pazienza, D. Saracino, F. Zan-
zotto, N. Nana, F. Pianesi, and R. Delmonte. 2003. Build-
ing the Italian Syntactic-Semantic Treebank. In Abeille
(Abeille, 2003), chapter 11, pages 189210.
J. Nivre, J. Hall, S. Kubler, R. McDonald, J. Nilsson, S. Riedel,
and D. Yuret. 2007. The CoNLL 2007 shared task on de-
pendency parsing. In Proc. of EMNLP-CoNLL.
K. Oflazer, B. Say, D. Zeynep Hakkani-Tur, and G. Tur. 2003.
Building a Turkish treebank. In Abeille (Abeille, 2003),
chapter 15, pages 261277.
P. Prokopidis, E. Desypri, M. Koutsombogera, H. Papageor-
giou, and S. Piperidis. 2005. Theoretical and practical is-
sues in the construction of a Greek dependency treebank. In
Proc. of the 4th Workshop on Treebanks and Linguistic The-
ories (TLT), pages 149160.
A. Ratnaparkhi, J. Reinar, and S. Roukos. 1994. A maximum
entropy model for prepositional phrase attachment. In Proc.
of the ARPA Workshop on Human Language Technology.
</reference>
<page confidence="0.962345">
961
</page>
<figure confidence="0.257945">
\x0c&amp;apos;
</figure>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.557437">
<note confidence="0.889373">b&amp;apos;Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL 2007, pp. 957961, Prague, June 2007. c 2007 Association for Computational Linguistics</note>
<title confidence="0.780248">Experiments with a Higher-Order Projective Dependency Parser</title>
<author confidence="0.969721">Xavier Carreras</author>
<affiliation confidence="0.997242">Massachusetts Institute of Technology (MIT) Computer Science and Artificial Intelligence Laboratory (CSAIL)</affiliation>
<address confidence="0.998697">32 Vassar St., Cambridge, MA 02139</address>
<email confidence="0.999841">carreras@csail.mit.edu</email>
<abstract confidence="0.996485944444444">We present experiments with a dependency parsing model defined on rich factors. Our model represents dependency trees with factors that include three types of relations between the tokens of a dependency and their children. We extend the projective parsing algorithm of Eisner (1996) for our case, and train models using the averaged perceptron. Our experiments show that considering higher-order information yields significant improvements in parsing accuracy, but comes at a high cost in terms of both time and memory consumption. In the multilingual exercise of the CoNLL-2007 shared task (Nivre et al., 2007), our system obtains the best accuracy for English, and the second best accuracies for Basque and Czech.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<title>Treebanks: Building and Using Parsed Corpora.</title>
<date>2003</date>
<editor>A. Abeille, editor.</editor>
<publisher>Kluwer.</publisher>
<marker>2003</marker>
<rawString>A. Abeille, editor. 2003. Treebanks: Building and Using Parsed Corpora. Kluwer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Aduriz</author>
<author>M J Aranzabe</author>
<author>J M Arriola</author>
<author>A Atutxa</author>
<author>A Diaz de Ilarraza</author>
<author>A Garmendia</author>
<author>M Oronoz</author>
</authors>
<title>Construction of a Basque dependency treebank.</title>
<date>2003</date>
<booktitle>In Proc. of the 2nd Workshop on Treebanks and Linguistic Theories (TLT),</booktitle>
<pages>201204</pages>
<marker>Aduriz, Aranzabe, Arriola, Atutxa, de Ilarraza, Garmendia, Oronoz, 2003</marker>
<rawString>I. Aduriz, M. J. Aranzabe, J. M. Arriola, A. Atutxa, A. Diaz de Ilarraza, A. Garmendia, and M. Oronoz. 2003. Construction of a Basque dependency treebank. In Proc. of the 2nd Workshop on Treebanks and Linguistic Theories (TLT), pages 201204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Bohmova</author>
<author>J Hajic</author>
<author>E Hajicova</author>
<author>B Hladka</author>
</authors>
<title>The PDT: a 3-level annotation scenario.</title>
<date>2003</date>
<booktitle>In Abeille (Abeille,</booktitle>
<pages>103127</pages>
<note>chapter 7,</note>
<contexts>
<context position="11150" citStr="Bohmova et al., 2003" startWordPosition="1949" endWordPosition="1952">and Results We report experiments with higher-order models for the ten languages in the multilingual track of the CoNLL-2007 shared task (Nivre et al., 2007).1 In all experiments, we trained our models using the averaged perceptron (Freund and Schapire, 1999), following the extension of Collins (2002) for structured prediction problems. To train models, we used projectivized versions of the training dependency trees.2 1 We are grateful to the providers of the treebanks that constituted the data for the shared task (Hajic et al., 2004; Aduriz et al., 2003; Mart et al., 2007; Chen et al., 2003; Bohmova et al., 2003; Marcus et al., 1993; Johansson and Nugues, 2007; Prokopidis et al., 2005; Csendes et al., 2005; Montemagni et al., 2003; Oflazer et al., 2003). 2 We obtained projective trees for training sentences by running the projective parser with an oracle model (that assigns a score of +1 to correct dependencies and -1 otherwise). 959 \x0cCatalan Czech English First-Order, no averaging 82.07 68.98 83.75 First-Order 86.15 75.96 87.54 Higher-Order, ch 87.50 77.15 88.70 Higher-Order, ch cmo 87.68 77.62 89.28 Higher-Order, ch cmi cmo 88.04 78.09 89.59 Table 2: Labeled attachment scores on validation data </context>
</contexts>
<marker>Bohmova, Hajic, Hajicova, Hladka, 2003</marker>
<rawString>A. Bohmova, J. Hajic, E. Hajicova, and B. Hladka. 2003. The PDT: a 3-level annotation scenario. In Abeille (Abeille, 2003), chapter 7, pages 103127.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Carreras</author>
<author>M Surdeanu</author>
<author>L Marquez</author>
</authors>
<title>Projective dependency parsing with perceptron.</title>
<date>2006</date>
<booktitle>In Proc. CoNLL-X.</booktitle>
<contexts>
<context position="9335" citStr="Carreras et al., 2006" startWordPosition="1658" endWordPosition="1661">ies [e, s, m]C are maintained for dependencies headed at e. We implemented two variants of the algorithm. The first forces the root token to participate in exactly one dependency. The second allows many dependencies involving the root token. For the singleroot case, it is necessary to treat the root token differently than other tokens. In the experiments, we used the single-root variant if sentences in the training set satisfy this property. Otherwise we used the multi-root variant. 2.2 Features The first-order features 1(x, h, m) are the exact same implementation as in previous CoNLL system (Carreras et al., 2006). In turn, those features were inspired by successful previous work in firstorder dependency parsing (McDonald et al., 2005). The most basic feature patterns consider the surface form, part-of-speech, lemma and other morphosyntactic attributes of the head or the modifier of a dependency. The representation also considers complex features that exploit a variety of conjunctions of the forms and part-of-speech tags of the following items: the head and modifier; the head, modifier, and any token in between them; the head, modifier, and the two tokens following or preceding them. As for the second-</context>
</contexts>
<marker>Carreras, Surdeanu, Marquez, 2006</marker>
<rawString>X. Carreras, M. Surdeanu, and L. Marquez. 2006. Projective dependency parsing with perceptron. In Proc. CoNLL-X.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Chen</author>
<author>C Luo</author>
<author>M Chang</author>
<author>F Chen</author>
<author>C Chen</author>
<author>C Huang</author>
<author>Z Gao</author>
</authors>
<title>Sinica treebank: Design criteria, representational issues and implementation.</title>
<date>2003</date>
<booktitle>In Abeille (Abeille,</booktitle>
<pages>231248</pages>
<contexts>
<context position="11128" citStr="Chen et al., 2003" startWordPosition="1945" endWordPosition="1948">(xc) 3 Experiments and Results We report experiments with higher-order models for the ten languages in the multilingual track of the CoNLL-2007 shared task (Nivre et al., 2007).1 In all experiments, we trained our models using the averaged perceptron (Freund and Schapire, 1999), following the extension of Collins (2002) for structured prediction problems. To train models, we used projectivized versions of the training dependency trees.2 1 We are grateful to the providers of the treebanks that constituted the data for the shared task (Hajic et al., 2004; Aduriz et al., 2003; Mart et al., 2007; Chen et al., 2003; Bohmova et al., 2003; Marcus et al., 1993; Johansson and Nugues, 2007; Prokopidis et al., 2005; Csendes et al., 2005; Montemagni et al., 2003; Oflazer et al., 2003). 2 We obtained projective trees for training sentences by running the projective parser with an oracle model (that assigns a score of +1 to correct dependencies and -1 otherwise). 959 \x0cCatalan Czech English First-Order, no averaging 82.07 68.98 83.75 First-Order 86.15 75.96 87.54 Higher-Order, ch 87.50 77.15 88.70 Higher-Order, ch cmo 87.68 77.62 89.28 Higher-Order, ch cmi cmo 88.04 78.09 89.59 Table 2: Labeled attachment scor</context>
</contexts>
<marker>Chen, Luo, Chang, Chen, Chen, Huang, Gao, 2003</marker>
<rawString>K. Chen, C. Luo, M. Chang, F. Chen, C. Chen, C. Huang, and Z. Gao. 2003. Sinica treebank: Design criteria, representational issues and implementation. In Abeille (Abeille, 2003), chapter 13, pages 231248.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
</authors>
<title>Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms.</title>
<date>2002</date>
<booktitle>In Proc. of EMNLP-2002.</booktitle>
<contexts>
<context position="10832" citStr="Collins (2002)" startWordPosition="1895" endWordPosition="1896">m and coarse part-of-speech of token xi, respectively. The definition of 2(x, h, m, c) is: dir cpos(xh) cpos(xm) cpos(xc) dir cpos(xh) cpos(xc) dir cpos(xm) cpos(xc) dir form(xh) form(xc) dir form(xm) form(xc) dir cpos(xh) form(xc) dir cpos(xm) form(xc) dir form(xh) cpos(xc) dir form(xm) cpos(xc) 3 Experiments and Results We report experiments with higher-order models for the ten languages in the multilingual track of the CoNLL-2007 shared task (Nivre et al., 2007).1 In all experiments, we trained our models using the averaged perceptron (Freund and Schapire, 1999), following the extension of Collins (2002) for structured prediction problems. To train models, we used projectivized versions of the training dependency trees.2 1 We are grateful to the providers of the treebanks that constituted the data for the shared task (Hajic et al., 2004; Aduriz et al., 2003; Mart et al., 2007; Chen et al., 2003; Bohmova et al., 2003; Marcus et al., 1993; Johansson and Nugues, 2007; Prokopidis et al., 2005; Csendes et al., 2005; Montemagni et al., 2003; Oflazer et al., 2003). 2 We obtained projective trees for training sentences by running the projective parser with an oracle model (that assigns a score of +1 </context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>M. Collins. 2002. Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms. In Proc. of EMNLP-2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Csendes</author>
<author>J Csirik</author>
<author>T Gyimothy</author>
<author>A Kocsor</author>
</authors>
<title>The Szeged Treebank.</title>
<date>2005</date>
<publisher>Springer.</publisher>
<contexts>
<context position="11246" citStr="Csendes et al., 2005" startWordPosition="1965" endWordPosition="1968">gual track of the CoNLL-2007 shared task (Nivre et al., 2007).1 In all experiments, we trained our models using the averaged perceptron (Freund and Schapire, 1999), following the extension of Collins (2002) for structured prediction problems. To train models, we used projectivized versions of the training dependency trees.2 1 We are grateful to the providers of the treebanks that constituted the data for the shared task (Hajic et al., 2004; Aduriz et al., 2003; Mart et al., 2007; Chen et al., 2003; Bohmova et al., 2003; Marcus et al., 1993; Johansson and Nugues, 2007; Prokopidis et al., 2005; Csendes et al., 2005; Montemagni et al., 2003; Oflazer et al., 2003). 2 We obtained projective trees for training sentences by running the projective parser with an oracle model (that assigns a score of +1 to correct dependencies and -1 otherwise). 959 \x0cCatalan Czech English First-Order, no averaging 82.07 68.98 83.75 First-Order 86.15 75.96 87.54 Higher-Order, ch 87.50 77.15 88.70 Higher-Order, ch cmo 87.68 77.62 89.28 Higher-Order, ch cmi cmo 88.04 78.09 89.59 Table 2: Labeled attachment scores on validation data (10,000 tokens per language), for different models that exploit increasing orders of factorizati</context>
</contexts>
<marker>Csendes, Csirik, Gyimothy, Kocsor, 2005</marker>
<rawString>D. Csendes, J. Csirik, T. Gyimothy, and A. Kocsor. 2005. The Szeged Treebank. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Eisner</author>
</authors>
<title>Three new probabilistic models for dependency parsing: An exploration.</title>
<date>1996</date>
<booktitle>In Proc. COLING.</booktitle>
<contexts>
<context position="683" citStr="Eisner (1996)" startWordPosition="94" endWordPosition="95">. 957961, Prague, June 2007. c 2007 Association for Computational Linguistics Experiments with a Higher-Order Projective Dependency Parser Xavier Carreras Massachusetts Institute of Technology (MIT) Computer Science and Artificial Intelligence Laboratory (CSAIL) 32 Vassar St., Cambridge, MA 02139 carreras@csail.mit.edu Abstract We present experiments with a dependency parsing model defined on rich factors. Our model represents dependency trees with factors that include three types of relations between the tokens of a dependency and their children. We extend the projective parsing algorithm of Eisner (1996) for our case, and train models using the averaged perceptron. Our experiments show that considering higher-order information yields significant improvements in parsing accuracy, but comes at a high cost in terms of both time and memory consumption. In the multilingual exercise of the CoNLL-2007 shared task (Nivre et al., 2007), our system obtains the best accuracy for English, and the second best accuracies for Basque and Czech. 1 Introduction Structured prediction problems usually involve models that work with factored representations of structures. The information included in the factors de</context>
<context position="6976" citStr="Eisner (1996" startWordPosition="1232" endWordPosition="1234">h + 2(x, h, m, cmi) wl mi + 2(x, h, m, cmo) wl mo Note that the model uses a common feature function for second-order relations, but features could be defined specifically for each type of relation. Note also that while the higher-order factors include four dependencies, our modelling choice only exploits relations between the main dependency and secondary dependencies. Considering relations between secondary dependencies would greatly increase the cost of the associated algorithms. 2.1 Parsing Algorithm In this section we sketch an extension of the projective dynamic programming algorithm of Eisner (1996; 2000) for the higher-order model defined above. The time complexity of the algorithm is O(n4L), and the memory requirements are O(n2L + n3). As in the Eisner approach, our algorithm visits sentence spans in a bottom up fashion, and constructs a chart with two types of dynamic programming structures, namely open and closed structuressee Figure 2 for a diagram. The dynamic programming structures are: 958 \x0ch m h m e cmo l mi c r+1 r h c l Figure 2: Dynamic programming structures used in the parsing algorithm. The variables in boldface constitute the index of the chart entry for a structure; </context>
</contexts>
<marker>Eisner, 1996</marker>
<rawString>J. Eisner. 1996. Three new probabilistic models for dependency parsing: An exploration. In Proc. COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Eisner</author>
</authors>
<title>Bilexical grammars and their cubic-time parsing algorithms. In</title>
<date>2000</date>
<booktitle>New Developments in Natural Language Parsing,</booktitle>
<pages>2962</pages>
<editor>H. C. Bunt and A. Nijholt, editors,</editor>
<publisher>Kluwer Academic Publishers.</publisher>
<marker>Eisner, 2000</marker>
<rawString>J. Eisner. 2000. Bilexical grammars and their cubic-time parsing algorithms. In H. C. Bunt and A. Nijholt, editors, New Developments in Natural Language Parsing, pages 2962. Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Freund</author>
<author>R E Schapire</author>
</authors>
<title>Large margin classification using the perceptron algorithm.</title>
<date>1999</date>
<booktitle>Machine Learning,</booktitle>
<volume>37</volume>
<issue>3</issue>
<contexts>
<context position="10789" citStr="Freund and Schapire, 1999" startWordPosition="1887" endWordPosition="1890">rwise; let form(xi) and cpos(xi) return the surface form and coarse part-of-speech of token xi, respectively. The definition of 2(x, h, m, c) is: dir cpos(xh) cpos(xm) cpos(xc) dir cpos(xh) cpos(xc) dir cpos(xm) cpos(xc) dir form(xh) form(xc) dir form(xm) form(xc) dir cpos(xh) form(xc) dir cpos(xm) form(xc) dir form(xh) cpos(xc) dir form(xm) cpos(xc) 3 Experiments and Results We report experiments with higher-order models for the ten languages in the multilingual track of the CoNLL-2007 shared task (Nivre et al., 2007).1 In all experiments, we trained our models using the averaged perceptron (Freund and Schapire, 1999), following the extension of Collins (2002) for structured prediction problems. To train models, we used projectivized versions of the training dependency trees.2 1 We are grateful to the providers of the treebanks that constituted the data for the shared task (Hajic et al., 2004; Aduriz et al., 2003; Mart et al., 2007; Chen et al., 2003; Bohmova et al., 2003; Marcus et al., 1993; Johansson and Nugues, 2007; Prokopidis et al., 2005; Csendes et al., 2005; Montemagni et al., 2003; Oflazer et al., 2003). 2 We obtained projective trees for training sentences by running the projective parser with a</context>
</contexts>
<marker>Freund, Schapire, 1999</marker>
<rawString>Y. Freund and R. E. Schapire. 1999. Large margin classification using the perceptron algorithm. Machine Learning, 37(3):277296.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hajic</author>
<author>O Smrz</author>
<author>P Zemanek</author>
<author>J Snaidauf</author>
<author>E Beska</author>
</authors>
<title>Prague Arabic dependency treebank: Development in data and tools.</title>
<date>2004</date>
<booktitle>In Proc. of the NEMLAR Intern. Conf. on Arabic Language Resources and Tools,</booktitle>
<pages>110117</pages>
<contexts>
<context position="11069" citStr="Hajic et al., 2004" startWordPosition="1933" endWordPosition="1936">ir cpos(xm) form(xc) dir form(xh) cpos(xc) dir form(xm) cpos(xc) 3 Experiments and Results We report experiments with higher-order models for the ten languages in the multilingual track of the CoNLL-2007 shared task (Nivre et al., 2007).1 In all experiments, we trained our models using the averaged perceptron (Freund and Schapire, 1999), following the extension of Collins (2002) for structured prediction problems. To train models, we used projectivized versions of the training dependency trees.2 1 We are grateful to the providers of the treebanks that constituted the data for the shared task (Hajic et al., 2004; Aduriz et al., 2003; Mart et al., 2007; Chen et al., 2003; Bohmova et al., 2003; Marcus et al., 1993; Johansson and Nugues, 2007; Prokopidis et al., 2005; Csendes et al., 2005; Montemagni et al., 2003; Oflazer et al., 2003). 2 We obtained projective trees for training sentences by running the projective parser with an oracle model (that assigns a score of +1 to correct dependencies and -1 otherwise). 959 \x0cCatalan Czech English First-Order, no averaging 82.07 68.98 83.75 First-Order 86.15 75.96 87.54 Higher-Order, ch 87.50 77.15 88.70 Higher-Order, ch cmo 87.68 77.62 89.28 Higher-Order, ch</context>
</contexts>
<marker>Hajic, Smrz, Zemanek, Snaidauf, Beska, 2004</marker>
<rawString>J. Hajic, O. Smrz, P. Zemanek, J. Snaidauf, and E. Beska. 2004. Prague Arabic dependency treebank: Development in data and tools. In Proc. of the NEMLAR Intern. Conf. on Arabic Language Resources and Tools, pages 110117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Johansson</author>
<author>P Nugues</author>
</authors>
<title>Extended constituent-todependency conversion for English.</title>
<date>2007</date>
<booktitle>In Proc. of the 16th Nordic Conference on Computational Linguistics (NODALIDA).</booktitle>
<contexts>
<context position="11199" citStr="Johansson and Nugues, 2007" startWordPosition="1957" endWordPosition="1960">er-order models for the ten languages in the multilingual track of the CoNLL-2007 shared task (Nivre et al., 2007).1 In all experiments, we trained our models using the averaged perceptron (Freund and Schapire, 1999), following the extension of Collins (2002) for structured prediction problems. To train models, we used projectivized versions of the training dependency trees.2 1 We are grateful to the providers of the treebanks that constituted the data for the shared task (Hajic et al., 2004; Aduriz et al., 2003; Mart et al., 2007; Chen et al., 2003; Bohmova et al., 2003; Marcus et al., 1993; Johansson and Nugues, 2007; Prokopidis et al., 2005; Csendes et al., 2005; Montemagni et al., 2003; Oflazer et al., 2003). 2 We obtained projective trees for training sentences by running the projective parser with an oracle model (that assigns a score of +1 to correct dependencies and -1 otherwise). 959 \x0cCatalan Czech English First-Order, no averaging 82.07 68.98 83.75 First-Order 86.15 75.96 87.54 Higher-Order, ch 87.50 77.15 88.70 Higher-Order, ch cmo 87.68 77.62 89.28 Higher-Order, ch cmi cmo 88.04 78.09 89.59 Table 2: Labeled attachment scores on validation data (10,000 tokens per language), for different model</context>
</contexts>
<marker>Johansson, Nugues, 2007</marker>
<rawString>R. Johansson and P. Nugues. 2007. Extended constituent-todependency conversion for English. In Proc. of the 16th Nordic Conference on Computational Linguistics (NODALIDA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Marcus</author>
<author>B Santorini</author>
<author>M Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: the Penn Treebank. Computational Linguistics,</title>
<date>1993</date>
<contexts>
<context position="11171" citStr="Marcus et al., 1993" startWordPosition="1953" endWordPosition="1956">experiments with higher-order models for the ten languages in the multilingual track of the CoNLL-2007 shared task (Nivre et al., 2007).1 In all experiments, we trained our models using the averaged perceptron (Freund and Schapire, 1999), following the extension of Collins (2002) for structured prediction problems. To train models, we used projectivized versions of the training dependency trees.2 1 We are grateful to the providers of the treebanks that constituted the data for the shared task (Hajic et al., 2004; Aduriz et al., 2003; Mart et al., 2007; Chen et al., 2003; Bohmova et al., 2003; Marcus et al., 1993; Johansson and Nugues, 2007; Prokopidis et al., 2005; Csendes et al., 2005; Montemagni et al., 2003; Oflazer et al., 2003). 2 We obtained projective trees for training sentences by running the projective parser with an oracle model (that assigns a score of +1 to correct dependencies and -1 otherwise). 959 \x0cCatalan Czech English First-Order, no averaging 82.07 68.98 83.75 First-Order 86.15 75.96 87.54 Higher-Order, ch 87.50 77.15 88.70 Higher-Order, ch cmo 87.68 77.62 89.28 Higher-Order, ch cmi cmo 88.04 78.09 89.59 Table 2: Labeled attachment scores on validation data (10,000 tokens per la</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>M. Marcus, B. Santorini, and M. Marcinkiewicz. 1993. Building a large annotated corpus of English: the Penn Treebank. Computational Linguistics, 19(2):313330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A Mart</author>
<author>M Taule</author>
<author>L Marquez</author>
<author>M Bertran</author>
</authors>
<title>CESS-ECE: A multilingual and multilevel annotated corpus. Available for download from: http://www.lsi.upc.edu/mbertran/cess-ece/.</title>
<date>2007</date>
<contexts>
<context position="11109" citStr="Mart et al., 2007" startWordPosition="1941" endWordPosition="1944">) dir form(xm) cpos(xc) 3 Experiments and Results We report experiments with higher-order models for the ten languages in the multilingual track of the CoNLL-2007 shared task (Nivre et al., 2007).1 In all experiments, we trained our models using the averaged perceptron (Freund and Schapire, 1999), following the extension of Collins (2002) for structured prediction problems. To train models, we used projectivized versions of the training dependency trees.2 1 We are grateful to the providers of the treebanks that constituted the data for the shared task (Hajic et al., 2004; Aduriz et al., 2003; Mart et al., 2007; Chen et al., 2003; Bohmova et al., 2003; Marcus et al., 1993; Johansson and Nugues, 2007; Prokopidis et al., 2005; Csendes et al., 2005; Montemagni et al., 2003; Oflazer et al., 2003). 2 We obtained projective trees for training sentences by running the projective parser with an oracle model (that assigns a score of +1 to correct dependencies and -1 otherwise). 959 \x0cCatalan Czech English First-Order, no averaging 82.07 68.98 83.75 First-Order 86.15 75.96 87.54 Higher-Order, ch 87.50 77.15 88.70 Higher-Order, ch cmo 87.68 77.62 89.28 Higher-Order, ch cmi cmo 88.04 78.09 89.59 Table 2: Labe</context>
</contexts>
<marker>Mart, Taule, Marquez, Bertran, 2007</marker>
<rawString>M. A. Mart, M. Taule, L. Marquez, and M. Bertran. 2007. CESS-ECE: A multilingual and multilevel annotated corpus. Available for download from: http://www.lsi.upc.edu/mbertran/cess-ece/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>F Pereira</author>
</authors>
<title>Online learning of approximate dependency parsing algorithms.</title>
<date>2006</date>
<booktitle>In Proc. of EACL2006.</booktitle>
<contexts>
<context position="1855" citStr="McDonald and Pereira, 2006" startWordPosition="266" endWordPosition="269"> structures. The information included in the factors determines the type of features that the model can exploit. However, richer representations translate into higher complexity of the inference algorithms associated with the model. In dependency parsing, the basic first-order model is defined by a decomposition of a tree into headmodifier dependencies. Previous work extended this basic model to include second-order relationsi.e. dependencies that are adjacent to the main dependency of the factor. Specifically, these approaches considered sibling relations of the modifier token (Eisner, 1996; McDonald and Pereira, 2006). In this paper we extend the parsing model with other types of second-order relations. In particular, we incorporate relations between the head and modifier tokens and the children of the modifier. One paradigmatic case where the relations we consider are relevant is PP-attachment. For example, in They sold 1,210 cars in the U.S., the ambiguity problem is to determine whether the preposition in (which governs the U.S.) is modifying sold or cars, the former being correct in this case. It is generally accepted that to solve the attachment decision it is necessary to look at the head noun within</context>
<context position="5685" citStr="McDonald and Pereira (2006)" startWordPosition="996" endWordPosition="1000">r model, and Table 1 lists the factors of an example sentence. Note that a factor involves a main labeled dependency and three adjacent unlabeled dependencies that attach to children of h and m. Special values are used when either of these children are null. The higher-order model defines additional m h ch cmi cmo They 1 2 - - - sold 2 0 - 1 5 1,200 3 4 - - - cars 4 2 - 3 - in 5 2 4 - 7 the 6 7 - - - U.S. 7 5 - 6 - Table 1: Higher-order factors for an example sentence. For simplicity, labels of the factors have been omitted. A first-order model considers only hh, mi. The second-order model of McDonald and Pereira (2006) considers hh, m, chi. For the PPattachment decision (factor in row 5), the higher-order model allows us to define features that relate the verb (sold) with the content word of the prepositional phrase (U.S.). second-order features through a function 2(x, h, m, c) which maps a head, a modifier and a child in a feature vector in Rd2 . The parameters of the model are a collection of four vectors for each dependency label: wl 1 Rd1 as in the first-order model; and wl h, wl mi and wl mo, all three in Rd2 and each associated to one of the adjacent dependencies in the factor. The score of a factor i</context>
<context position="10019" citStr="McDonald and Pereira (2006)" startWordPosition="1768" endWordPosition="1771">vious work in firstorder dependency parsing (McDonald et al., 2005). The most basic feature patterns consider the surface form, part-of-speech, lemma and other morphosyntactic attributes of the head or the modifier of a dependency. The representation also considers complex features that exploit a variety of conjunctions of the forms and part-of-speech tags of the following items: the head and modifier; the head, modifier, and any token in between them; the head, modifier, and the two tokens following or preceding them. As for the second-order features, we again base our features with those of McDonald and Pereira (2006), who reported successful experiments with second-order models. We add some patterns to their features. Let dir be right if h &lt; m, and left otherwise; let form(xi) and cpos(xi) return the surface form and coarse part-of-speech of token xi, respectively. The definition of 2(x, h, m, c) is: dir cpos(xh) cpos(xm) cpos(xc) dir cpos(xh) cpos(xc) dir cpos(xm) cpos(xc) dir form(xh) form(xc) dir form(xm) form(xc) dir cpos(xh) form(xc) dir cpos(xm) form(xc) dir form(xh) cpos(xc) dir form(xm) cpos(xc) 3 Experiments and Results We report experiments with higher-order models for the ten languages in the m</context>
<context position="12368" citStr="McDonald and Pereira (2006)" startWordPosition="2139" endWordPosition="2142">ion data (10,000 tokens per language), for different models that exploit increasing orders of factorizations. 3.1 Impact of Higher-Order Factorization Our first set of experiments looks at the performance of different factorizations. We selected three languages with a large number of training sentences, namely Catalan, Czech and English. To evaluate models, we held out the training sentences that cover the first 10,000 tokens; the rest was used for training. We compared four models at increasing orders of factorizations. The first is a first-order model. The second model is similar to that of McDonald and Pereira (2006): a factor consists of a main labeled dependency and the head child closest to the modifier (ch). The third model incorporates the modifier child outside the main dependency in the factorization (cmo). Finally, the last model incorporates the modifier child inside the dependency span (cmi), thus corresponding to the complete higherorder model presented in the previous section. Table 2 shows the accuracies of the models on validation data. Each model was trained for up to 10 epochs, and evaluated at the end of each epoch; we report the best accuracy of these evaluations. Clearly, the accuracy i</context>
</contexts>
<marker>McDonald, Pereira, 2006</marker>
<rawString>R. McDonald and F. Pereira. 2006. Online learning of approximate dependency parsing algorithms. In Proc. of EACL2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>K Crammer</author>
<author>F Pereira</author>
</authors>
<title>Online largemargin training of dependency parsers.</title>
<date>2005</date>
<booktitle>In Proc. ACL.</booktitle>
<contexts>
<context position="9459" citStr="McDonald et al., 2005" startWordPosition="1677" endWordPosition="1680">he root token to participate in exactly one dependency. The second allows many dependencies involving the root token. For the singleroot case, it is necessary to treat the root token differently than other tokens. In the experiments, we used the single-root variant if sentences in the training set satisfy this property. Otherwise we used the multi-root variant. 2.2 Features The first-order features 1(x, h, m) are the exact same implementation as in previous CoNLL system (Carreras et al., 2006). In turn, those features were inspired by successful previous work in firstorder dependency parsing (McDonald et al., 2005). The most basic feature patterns consider the surface form, part-of-speech, lemma and other morphosyntactic attributes of the head or the modifier of a dependency. The representation also considers complex features that exploit a variety of conjunctions of the forms and part-of-speech tags of the following items: the head and modifier; the head, modifier, and any token in between them; the head, modifier, and the two tokens following or preceding them. As for the second-order features, we again base our features with those of McDonald and Pereira (2006), who reported successful experiments wi</context>
</contexts>
<marker>McDonald, Crammer, Pereira, 2005</marker>
<rawString>R. McDonald, K. Crammer, and F. Pereira. 2005. Online largemargin training of dependency parsers. In Proc. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Montemagni</author>
<author>F Barsotti</author>
<author>M Battista</author>
<author>N Calzolari</author>
<author>O Corazzari</author>
<author>A Lenci</author>
<author>A Zampolli</author>
<author>F Fanciulli</author>
<author>M Massetani</author>
<author>R Raffaelli</author>
<author>R Basili</author>
<author>M T Pazienza</author>
<author>D Saracino</author>
<author>F Zanzotto</author>
<author>N Nana</author>
<author>F Pianesi</author>
<author>R Delmonte</author>
</authors>
<title>Building the Italian Syntactic-Semantic Treebank. In Abeille (Abeille,</title>
<date>2003</date>
<pages>189210</pages>
<contexts>
<context position="11271" citStr="Montemagni et al., 2003" startWordPosition="1969" endWordPosition="1972">L-2007 shared task (Nivre et al., 2007).1 In all experiments, we trained our models using the averaged perceptron (Freund and Schapire, 1999), following the extension of Collins (2002) for structured prediction problems. To train models, we used projectivized versions of the training dependency trees.2 1 We are grateful to the providers of the treebanks that constituted the data for the shared task (Hajic et al., 2004; Aduriz et al., 2003; Mart et al., 2007; Chen et al., 2003; Bohmova et al., 2003; Marcus et al., 1993; Johansson and Nugues, 2007; Prokopidis et al., 2005; Csendes et al., 2005; Montemagni et al., 2003; Oflazer et al., 2003). 2 We obtained projective trees for training sentences by running the projective parser with an oracle model (that assigns a score of +1 to correct dependencies and -1 otherwise). 959 \x0cCatalan Czech English First-Order, no averaging 82.07 68.98 83.75 First-Order 86.15 75.96 87.54 Higher-Order, ch 87.50 77.15 88.70 Higher-Order, ch cmo 87.68 77.62 89.28 Higher-Order, ch cmi cmo 88.04 78.09 89.59 Table 2: Labeled attachment scores on validation data (10,000 tokens per language), for different models that exploit increasing orders of factorizations. 3.1 Impact of Higher</context>
</contexts>
<marker>Montemagni, Barsotti, Battista, Calzolari, Corazzari, Lenci, Zampolli, Fanciulli, Massetani, Raffaelli, Basili, Pazienza, Saracino, Zanzotto, Nana, Pianesi, Delmonte, 2003</marker>
<rawString>S. Montemagni, F. Barsotti, M. Battista, N. Calzolari, O. Corazzari, A. Lenci, A. Zampolli, F. Fanciulli, M. Massetani, R. Raffaelli, R. Basili, M. T. Pazienza, D. Saracino, F. Zanzotto, N. Nana, F. Pianesi, and R. Delmonte. 2003. Building the Italian Syntactic-Semantic Treebank. In Abeille (Abeille, 2003), chapter 11, pages 189210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
<author>J Hall</author>
<author>S Kubler</author>
<author>R McDonald</author>
<author>J Nilsson</author>
<author>S Riedel</author>
<author>D Yuret</author>
</authors>
<title>shared task on dependency parsing.</title>
<date>2007</date>
<journal>The CoNLL</journal>
<booktitle>In Proc. of EMNLP-CoNLL.</booktitle>
<contexts>
<context position="1012" citStr="Nivre et al., 2007" startWordPosition="146" endWordPosition="149">stract We present experiments with a dependency parsing model defined on rich factors. Our model represents dependency trees with factors that include three types of relations between the tokens of a dependency and their children. We extend the projective parsing algorithm of Eisner (1996) for our case, and train models using the averaged perceptron. Our experiments show that considering higher-order information yields significant improvements in parsing accuracy, but comes at a high cost in terms of both time and memory consumption. In the multilingual exercise of the CoNLL-2007 shared task (Nivre et al., 2007), our system obtains the best accuracy for English, and the second best accuracies for Basque and Czech. 1 Introduction Structured prediction problems usually involve models that work with factored representations of structures. The information included in the factors determines the type of features that the model can exploit. However, richer representations translate into higher complexity of the inference algorithms associated with the model. In dependency parsing, the basic first-order model is defined by a decomposition of a tree into headmodifier dependencies. Previous work extended this </context>
<context position="10687" citStr="Nivre et al., 2007" startWordPosition="1871" endWordPosition="1874">-order models. We add some patterns to their features. Let dir be right if h &lt; m, and left otherwise; let form(xi) and cpos(xi) return the surface form and coarse part-of-speech of token xi, respectively. The definition of 2(x, h, m, c) is: dir cpos(xh) cpos(xm) cpos(xc) dir cpos(xh) cpos(xc) dir cpos(xm) cpos(xc) dir form(xh) form(xc) dir form(xm) form(xc) dir cpos(xh) form(xc) dir cpos(xm) form(xc) dir form(xh) cpos(xc) dir form(xm) cpos(xc) 3 Experiments and Results We report experiments with higher-order models for the ten languages in the multilingual track of the CoNLL-2007 shared task (Nivre et al., 2007).1 In all experiments, we trained our models using the averaged perceptron (Freund and Schapire, 1999), following the extension of Collins (2002) for structured prediction problems. To train models, we used projectivized versions of the training dependency trees.2 1 We are grateful to the providers of the treebanks that constituted the data for the shared task (Hajic et al., 2004; Aduriz et al., 2003; Mart et al., 2007; Chen et al., 2003; Bohmova et al., 2003; Marcus et al., 1993; Johansson and Nugues, 2007; Prokopidis et al., 2005; Csendes et al., 2005; Montemagni et al., 2003; Oflazer et al.</context>
</contexts>
<marker>Nivre, Hall, Kubler, McDonald, Nilsson, Riedel, Yuret, 2007</marker>
<rawString>J. Nivre, J. Hall, S. Kubler, R. McDonald, J. Nilsson, S. Riedel, and D. Yuret. 2007. The CoNLL 2007 shared task on dependency parsing. In Proc. of EMNLP-CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Oflazer</author>
<author>B Say</author>
<author>D Zeynep Hakkani-Tur</author>
<author>G Tur</author>
</authors>
<date>2003</date>
<contexts>
<context position="11294" citStr="Oflazer et al., 2003" startWordPosition="1973" endWordPosition="1976"> et al., 2007).1 In all experiments, we trained our models using the averaged perceptron (Freund and Schapire, 1999), following the extension of Collins (2002) for structured prediction problems. To train models, we used projectivized versions of the training dependency trees.2 1 We are grateful to the providers of the treebanks that constituted the data for the shared task (Hajic et al., 2004; Aduriz et al., 2003; Mart et al., 2007; Chen et al., 2003; Bohmova et al., 2003; Marcus et al., 1993; Johansson and Nugues, 2007; Prokopidis et al., 2005; Csendes et al., 2005; Montemagni et al., 2003; Oflazer et al., 2003). 2 We obtained projective trees for training sentences by running the projective parser with an oracle model (that assigns a score of +1 to correct dependencies and -1 otherwise). 959 \x0cCatalan Czech English First-Order, no averaging 82.07 68.98 83.75 First-Order 86.15 75.96 87.54 Higher-Order, ch 87.50 77.15 88.70 Higher-Order, ch cmo 87.68 77.62 89.28 Higher-Order, ch cmi cmo 88.04 78.09 89.59 Table 2: Labeled attachment scores on validation data (10,000 tokens per language), for different models that exploit increasing orders of factorizations. 3.1 Impact of Higher-Order Factorization Ou</context>
</contexts>
<marker>Oflazer, Say, Hakkani-Tur, Tur, 2003</marker>
<rawString>K. Oflazer, B. Say, D. Zeynep Hakkani-Tur, and G. Tur. 2003.</rawString>
</citation>
<citation valid="true">
<title>Building a Turkish treebank. In Abeille (Abeille,</title>
<date>2003</date>
<pages>261277</pages>
<note>chapter 15,</note>
<marker>2003</marker>
<rawString>Building a Turkish treebank. In Abeille (Abeille, 2003), chapter 15, pages 261277.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Prokopidis</author>
<author>E Desypri</author>
<author>M Koutsombogera</author>
<author>H Papageorgiou</author>
<author>S Piperidis</author>
</authors>
<title>Theoretical and practical issues in the construction of a Greek dependency treebank.</title>
<date>2005</date>
<booktitle>In Proc. of the 4th Workshop on Treebanks and Linguistic Theories (TLT),</booktitle>
<pages>149160</pages>
<contexts>
<context position="11224" citStr="Prokopidis et al., 2005" startWordPosition="1961" endWordPosition="1964">languages in the multilingual track of the CoNLL-2007 shared task (Nivre et al., 2007).1 In all experiments, we trained our models using the averaged perceptron (Freund and Schapire, 1999), following the extension of Collins (2002) for structured prediction problems. To train models, we used projectivized versions of the training dependency trees.2 1 We are grateful to the providers of the treebanks that constituted the data for the shared task (Hajic et al., 2004; Aduriz et al., 2003; Mart et al., 2007; Chen et al., 2003; Bohmova et al., 2003; Marcus et al., 1993; Johansson and Nugues, 2007; Prokopidis et al., 2005; Csendes et al., 2005; Montemagni et al., 2003; Oflazer et al., 2003). 2 We obtained projective trees for training sentences by running the projective parser with an oracle model (that assigns a score of +1 to correct dependencies and -1 otherwise). 959 \x0cCatalan Czech English First-Order, no averaging 82.07 68.98 83.75 First-Order 86.15 75.96 87.54 Higher-Order, ch 87.50 77.15 88.70 Higher-Order, ch cmo 87.68 77.62 89.28 Higher-Order, ch cmi cmo 88.04 78.09 89.59 Table 2: Labeled attachment scores on validation data (10,000 tokens per language), for different models that exploit increasing</context>
</contexts>
<marker>Prokopidis, Desypri, Koutsombogera, Papageorgiou, Piperidis, 2005</marker>
<rawString>P. Prokopidis, E. Desypri, M. Koutsombogera, H. Papageorgiou, and S. Piperidis. 2005. Theoretical and practical issues in the construction of a Greek dependency treebank. In Proc. of the 4th Workshop on Treebanks and Linguistic Theories (TLT), pages 149160.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ratnaparkhi</author>
<author>J Reinar</author>
<author>S Roukos</author>
</authors>
<title>A maximum entropy model for prepositional phrase attachment.</title>
<date>1994</date>
<booktitle>In Proc. of the ARPA Workshop on Human Language Technology.</booktitle>
<contexts>
<context position="2638" citStr="Ratnaparkhi et al., 1994" startWordPosition="398" endWordPosition="401">tokens and the children of the modifier. One paradigmatic case where the relations we consider are relevant is PP-attachment. For example, in They sold 1,210 cars in the U.S., the ambiguity problem is to determine whether the preposition in (which governs the U.S.) is modifying sold or cars, the former being correct in this case. It is generally accepted that to solve the attachment decision it is necessary to look at the head noun within the prepositional phrase (i.e., U.S. in the example), which has a grand-parental relation with the two candidate tokens that the phrase may attach see e.g. (Ratnaparkhi et al., 1994). Other ambiguities in language may also require consideration of grand-parental relations in the dependency structure. We present experiments with higher-order models trained with averaged perceptron. The second-order relations that we incorporate in the model yield significant improvements in accuracy. However, the inference algorithms for our factorization are very expensive in terms of time and memory consumption, and become impractical when dealing with many labels or long sentences. 2 Higher-Order Projective Models A dependency parser receives a sentence x of n tokens, and outputs a labe</context>
</contexts>
<marker>Ratnaparkhi, Reinar, Roukos, 1994</marker>
<rawString>A. Ratnaparkhi, J. Reinar, and S. Roukos. 1994. A maximum entropy model for prepositional phrase attachment. In Proc. of the ARPA Workshop on Human Language Technology.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>