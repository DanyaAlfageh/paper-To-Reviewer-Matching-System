4.1 Experimental Setup Like several previous work (e.g., CITATION, CITATION, CITATION), we view polarity classification as a supervised learning task,,
n attempts on tackling this so-called document-level subjectivity classification task, with very encouraging results (see CITATION and CITATION for details),,
Next, we learn our polarity classifier using positive and negative reviews taken from two movie 611 \x0creview datasets, one assembled by CITATION and the other by ourselves,,
hen represented as a vector of unigrams with length normalization.7 Following CITATION, we use frequency as presence,,
Admittedly, the high accuracy achieved using such a simple set of features is somewhat surprising, although it is consistent with previous results on document-level subjectivity classification in which accuracies of 94-97% were obtained (CITATION; CITATION),,
Indeed, recent work has shown that benefits can be made by first separating facts from opinions in a document (e.g, CITATION) and classifying the polarity based solely on the subjective portions of the document (e.g., CITATION),,
For instance, instead of representing the polarity of a term using a binary value, CITATION use Turne,,
However, recent research in the related (but arguably simpler) task of text classification shows that a bigrambased text classifier outperforms its unigrambased counterpart CITATION,,
There have been attempts on tackling this so-called document-level subjectivity classification task, with very encouraging results (see CITATION and CITATION for details),,
1 http://www.wjh.harvard.edu/inquirer/ spreadsheet guid.htm 2 CITATION have also manually tagged a list of terms with their polarity, but this list is not publicly available,,
For instance, instead of representing the polarity of a term using a binary value, CITATION use Turneys (2002) method to assign a real value to represent term polarity and introduce a variety of numerical features that are aggregate measures of the polarity values of terms selected from the document under consideration,,
Note that our result on Dataset A is as strong as that obtained by CITATION via their subjectivity summarization algorithm, which retains only the subjective portions of a document,,
The negative results that CITATION obtained when using bigrams as features for their polarity classifier seem to suggest that high-order n-grams are not useful for polarity classification,,
unigrams with length normalization.7 Following CITATION, we use frequency as presence,,
Two notable exceptions are the work of CITATION and CITATION,,
CITATION extract a larger variety of features from dependency parses, but unlike us, their goal is to determine the polarity of a phrase, not a document,,
20 A newly generated feature could be misleading for the learner if the contextual polarity (i.e., polarity in the presence of context) of the adjective involved differs from its prior polarity (see CITATION),,
10 CITATION show that this metric is effective at selecting good features for text classification,,
We perform 10-fold cross-validation (CV) experiments on the above dataset, using CITATION SVMlight package5 to train an SVM classifier for distinguishing reviews and non-reviews,,
Similar results were also obtained by CITATION,,
The negative results that CITATION obtained when using bigrams as features for their polarity classifier see,,
We conjecture that more sophisticated methods would be needed in order to take advantage of objective information in polarity classification (e.g., CITATION),,
For instance, instead of representing the polarity of a term using a binary value, CITATION use Turneys (2002) method to assign a real value to represent,,
There have been several attempts at extracting features for polarity classification from dependency parses, but most focus on extracting specific types of information such as adjective-noun relations (e.g., CITATION, CITATION) or nouns that enjoy a dependency relation with a polarity term (e.g., CITATION),,
All learning parameters are set to their default values.6 Each document is first tokenized and downcased, and then represented as a vector of unigrams with length normalization.7 Following CITATION, we use frequency as presence,,
The task has recently received a lot of attention, with applications ranging from multiperspective question-answering (e.g., CITATION) to opinion-oriented information extraction (e.g., CITATION) and summarization (e.g., CITATION),,
In our experiments, the SV, VO and AN relations are extracted from each document by the MINIPAR dependency parser CITATION,,
Motivated by the work of CITATION, we identify and extract objective material from nonreviews and show how to exploit such information in polarity classification,,
 (2003), CITATION, CITATION), a phrase (e.g., CITATION), and a specific object (such as a product) mentioned in a document (e.g., CITATION, CITATION, CITATION),,
document (e.g., CITATION),,
Two notable exceptions are the work of CITATION and Pang ,,
Other commonly-used feature selection metrics are discussed in CITATION,,
Unlike most previous work on polarity classification, which has largely focused on exploiting adjective-noun (AN) relations (e.g., CITATION, CITATION), we hypothesized that subject-verb (SV) and verb-object (VO) relations would also be useful for the task,,
2.2 Polarity Classification There is a large body of work on classifying the polarity of a document (e.g., CITATION, CITATION), a sentence (e.g., CITATION, CITATION, CITATION, CITATION), a phrase (e.g., CITATION), and a specific object (such as a product) mentioned in a document (e.g., CITATION, CITATION, CITATION),,
Much work has been performed on learning to identify and classify polarity terms (i.e., terms expressing a positive sentiment (e.g., happy) or a negative sentiment (e.g., terrible)) and exploiting them to do polarity classification (e.g., CITATION, CITATION, CITATION, CITATION, CITATION),,
