Table 3: TINE-B: Combination of BLEU and the shallow-semantic component Metric cz-en fr-en de-en es-en avg TINE-B 0.27 0.25 0.30 0.30 0.28 Finally, we improve the tuning of the weights of the components ( and parameters) by using a simple genetic algorithm CITATION to select the weights that maximize the correlation with human scores on a development set (we use the development sets from WMT10 CITATION).,,
urus CITATION .,,
The most well-know metric is probably METEOR (CITATION; CITATION).,,
CITATION measure word choice and word order by the matching of words based on surface forms, stems, senses and semantic similarity.,,
CITATION propose to match bags of unigrams, bigrams and trigrams considering bo,,
The lexical component weight is prioritized because it has shown a good average Kendalls tau correlation (0.23) on a development dataset CITATION.,,
We compare our metric against standard BLEU CITATION, METEOR CITATION and other previous metrics reported in,,
Table 3: TINE-B: Combination of BLEU and the shallow-semantic component Metric cz-en fr-en de-en es-en avg TINE-B 0.27 0.25 0.30 0.30 0.28 Finally, we improve the tuning of the weights of the components ( and parameters) by using a simple genetic algorithm CITATION to select the weights that maximize the correlation with human scores on a development set (we use the development sets from WMT10 CITATION).,,
d measuring the matching of lexical items to incorporate information about the semantic structure of the sentence, as in CITATION.,,
However, the metric should also be flexible to consider inexact matches of semantic components, similar to what is done with lexical metrics like METEOR CITATION.,,
The metric is particularly dependent on semantic role label117 \x0cing systems, which have reached satisfactory performance for English CITATION.,,
Verbs are aligned using VerbNet CITATION and VerbOcean CITATION.,,
VerbOcean was created by a semi-automatic extraction algorithm CITATION with an average accuracy of 65.5%.,,
A number of other metrics have been proposed to address these limitations, for example, by allowing for the matching of synonyms or paraphrases of content words, such as in METEOR CITATION.,,
Other attempts have been made to capture whether the reference translation and hypothesis translations share the same meaning using shallow semantics, i.e., Semantic Role Labeling CITATION.,,
The most well-know metric is probably METEOR (CITATION; CITATION).,,
CITATION measure word choice and word order by the matching of words based on surface forms, stems, senses and semantic similarity.,,
CITATION propose to match bags of unigrams, bigrams and trigrams considering both recall and precision and,,
3 Metric Description The rationale behind TINE is that an adequacyoriented metric should go beyond measuring the matching of lexical items to incorporate information about the semantic structure of the sentence, as in CITATION.,,
However, the metric should also be flexible to consider inexact matches of semantic components, similar to what is done with lexical metrics like METEOR CITATION.,,
The metric is particularly dependent on semantic role label117 \x0cing systems, which have reached satisfactory performance for English CITATION.,,
tion (0.23) on a development dataset CITATION.,,
We compare our metric against standard BLEU CITATION, METEOR CITATION and other previous metrics reported in CITATION which also claim to use some form of semantic information (see Section 2 for their description).,,
A number of other metrics have been proposed to address these limitations, for example, by allowing for the matching of synonyms or paraphrases of content words, such as in METEOR CITATION.,,
Other attempts have been made to capture whether the reference translation and hypothesis translations share the same meaning using shallow semantics, i.e., Semantic Role Labeling CITATION.,,
The metric uses SRLs such as in CITATION.,,
The closest related metric to the one proposed in this paper is that by CITATION and CITATION, which also uses shallow semantic representations.,,
The closest related metric to the one proposed in this paper is that by CITATION and CITATION, which also uses shallow semantic representations.,,
The closest metric to TINE CITATION, which also uses semantic roles as one of its 1 http://ml.nec-labs.com/senna/ 2 http://www.lsi.upc.edu/ srlconll/ 119 \x0cTable 2: Comparison with previous semanticallyoriented metrics using segment-level Kendalls tau correlation with human judgments Metric cz-en fr-en de-en es-en avg CITATION 0.34 0.34 0.38 0.34 0.35 CITATION 0.34 0.33 0.34 0.33 0.33 CITATION 0.33 0.27 0.37 0.32 0.32 METEOR 0.33 0.27 0.36 0.33 0.32 TINE 0.28 0.25 0.30 0.22 0.26 BLEU 0.26 0.22 0.27 0.28 0.26 (He et al., 2010) 0.15 0.14 0.17 0.21 0.17 CITATION 0.05 0.0 0.12 0.0,,
The metric uses SRLs such as in CITATION.,,
The 116 \x0cinexact matching is based on the use of ontologies such as VerbNet CITATION and distributional semantics similarity metrics, such as Dekang Lins thesaurus CITATION .,,
For every mismatch in a segment, we retrieve the 118 \x0c20-most similar words from Dekang Lins distributional thesaurus CITATION, resulting in sets with richer lexical variety.,,
The most well-know metric is probably METEOR (CITATION; CITATION).,,
CITATION measure word choice and word order by the matching of words based on surface forms, stems, senses and semantic similarity.,,
CITATION propose to match bags of unigrams, bigrams and trigrams considering both recall and precision and F-measure giving more importance to recall, but also using WordNet synonyms.,,
CITATION use transformations in order to match short syntactic units defined as Basic Elements (BE).,,
The closest metric to TINE CITATION, which also uses semantic roles as one of its 1 http://ml.nec-labs.com/senna/ 2 http://www.lsi.upc.edu/ srlconll/ 119 \x0cTable 2: Comparison with previous semanticallyoriented metrics using segment-level Kendalls tau correlation with human judgments Metric cz-en fr-en de-en es-en avg CITATION 0.34 0.34 0.38 0.34 0.35 CITATION 0.34 0.33 0.34 0.33 0.33 CITATION 0.33 0.27 0.37 0.32 0.32 METEOR 0.33 0.27 0.36 0.33 0.32 TINE 0.28 0.25 0.30 0.22 0.26 BLEU 0.26 0.22 0.27 0.28 0.26 (He et al., 2010) 0.15 0.14 0.17 0.21 0.17 CITATION 0.05 0.0 0.12 0.05 0.05 components, achieves better performance.,,
CITATION propose to match bags of unigrams, bigrams and trigrams considering both recall and precision and F-measure giving more importance to recall, but also using WordNet synonyms.,,
CITATION use transformations in order to match short syntactic units defined as Basic Elements (BE).,,
CITATION uses Textual Entailment features extracted from the Standford Entailment Recognizer (MacCartney et al., 2006).,,
The most commonly used metrics, BLEU CITATION and alike, perform simple exact matching of n-grams between hypothesis and reference translations.,,
ood average Kendalls tau correlation (0.23) on a development dataset CITATION.,,
We compare our metric against standard BLEU CITATION, METEOR CITATION and other previous metrics reported in CITATION which also claim to use some form of semantic information (see Section 2 for their description).,,
The metric uses SRLs such as in CITATION.,,
The 116 \x0cinexact matching is based on the use of ontologies such as VerbNet CITATION and distributional semantics similarity metrics, such as Dekang Lins thesaurus CITATION .,,
Verbs are aligned using VerbNet CITATION and VerbOcean CITATION.,,
CITATION measure word choice and word order by the matching of words based on surface forms, stems, senses and semantic similarity.,,
CITATION propose to match bags of unigrams, bigrams and trigrams considering both recall and precision and F-measure giving more importance to recall, but also using WordNet synonyms.,,
CITATION use transformations in order to match short syntactic units defined as Basic Elements (BE).,,
CITATION uses Textual Entailment features extracted from the Standford Entailment Recognizer (MacCartney et al., 2006).,,
t metric to TINE CITATION, which also uses semantic roles as one of its 1 http://ml.nec-labs.com/senna/ 2 http://www.lsi.upc.edu/ srlconll/ 119 \x0cTable 2: Comparison with previous semanticallyoriented metrics using segment-level Kendalls tau correlation with human judgments Metric cz-en fr-en de-en es-en avg CITATION 0.34 0.34 0.38 0.34 0.35 CITATION 0.34 0.33 0.34 0.33 0.33 CITATION 0.33 0.27 0.37 0.32 0.32 METEOR 0.33 0.27 0.36 0.33 0.32 TINE 0.28 0.25 0.30 0.22 0.26 BLEU 0.26 0.22 0.27 0.28 0.26 (He et al., 2010) 0.15 0.14 0.17 0.21 0.17 CITATION 0.05 0.0 0.12 0.05 0.05 components, achieves better performance.,,
The most well-know metric is probably METEOR (CITATION; CITATION).,,
CITATION measure word choice and word order by the matching of words based on surface forms, stems, senses and semantic similarity.,,
CITATION propose to match bags of unigrams, bigrams and trigrams considering both recall and precision and F-measure giving more importance to recall, but also using WordNet synonyms.,,
CITATION use transformations in order to match short syntactic units defined as Basic Elements (BE).,,
The closest metric to TINE CITATION, which also uses semantic roles as one of its 1 http://ml.nec-labs.com/senna/ 2 http://www.lsi.upc.edu/ srlconll/ 119 \x0cTable 2: Comparison with previous semanticallyoriented metrics using segment-level Kendalls tau correlation with human judgments Metric cz-en fr-en de-en es-en avg CITATION 0.34 0.34 0.38 0.34 0.35 CITATION 0.34 0.33 0.34 0.33 0.33 CITATION 0.33 0.27 0.37 0.32 0.32 METEOR 0.33 0.27 0.36 0.33 0.32 TINE 0.28 0.25 0.30 0.22 0.26 BLEU 0.26 0.22 0.27 0.28 0.26 (He et al., 2010) 0.15 0.14 0.17 0.21 0.17 CITATION 0.05 0.0 0.12 0.05 0.05 components, achieves better performance.,,
