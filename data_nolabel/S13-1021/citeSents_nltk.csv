1 Introduction The Semantic Textual Similarity (STS) task (CITATION; CITATION) examines semantic similarity at a sentence-level.,,
1 Introduction The Semantic Textual Similarity (STS) task (CITATION; CITATION) examines semantic similarity at a sentence-level.,,
re 3 t other/RelativeInfoContentDifference n-grams/CharacterNGramMeasure 4 t other/NumbersSize string/GreedyStringTiling 3 t other/NumbersOverlap string/LongestCommonSubsequenceComparator t other/NumbersSubset string/LongestCommonSubsequenceNormComparator t other/SentenceSize string/LongestCommonSubstringComparator t other/CaseMatches t other/StocksSize t other/StocksOverlap matches S2, and how closely S2 matches S1: simneo(S1,S2) = 2 NE1 NE2 NE1 + NE2 (1) Additionally, we relax the constraint of requiring exact string matches between the two sentences by using the longest common subsequence CITATION and greedy string tiling CITATION algorithms.,,
Thus, we follow previous work in greedily aligning these named entities (CITATION; CITATION) into pairs.,,
The proposed MayoClinicNLP metrics are meant to complement DKPro CITATION and TakeLab CITATION metrics.,,
e parser described in CITATION with 1,000 headwords and 10 relational clusters, trained on the Wall Street Journal treebank.,,
3.1 Linear regression via DKPro Similarity For our baseline (MayoClinicNLPr1wtCDT), we used the UIMA-based DKPro Similarity system from STS 2012 CITATION.,,
Aside from the large number of sound similarity measures, this provided linear regression through the WEKA package CITATION to combine all of the disparate similarity metrics into a single one, and some preprocessing.,,
In our experiments, we performed named entity recognition with the Stanford NER tool using the standard English model CITATION.,,
Also, we used UKPs existing implementation of LCS and GST CITATION for the latter two measures.,,
2.2 Random indexing measures Random indexing (CITATION; CITATION) is another distributional semantics framework for representing terms as vectors.,,
Similar to LSA CITATION, an index is created that represents each term as a semantic vector.,,
The intuition for this means of dimensionality reduction is that these randomly-generated elemental vectors are like quasi-orthogonal bases in a traditional geometric semantic space, rather than, e.g., 300 fully orthogonal dimensions from singular value decomposition CITATION.,,
Thus we consider three different representations possible within Random Indexing (CITATION; CITATION).,,
Finally, because compositional distributional semantics is an important research topic (CITATION; CITATION), we sought to evaluate a principled composition strategy: structured vectorial semantics CITATION.,,
In our experiments, we performed named entity recognition with the Stanford NER tool using the standard English model CITATION.,,
Also, we used UKPs existing implementation of LCS and GST CITATION for the latter two measures.,,
2.2 Random indexing measures Random indexing (CITATION; CITATION) is another distributional semantics framework for representing terms as vectors.,,
Similar to LSA CITATION, an index is created that represents each term as a semantic vector.,,
3.1 Linear regression via DKPro Similarity For our baseline (MayoClinicNLPr1wtCDT), we used the UIMA-based DKPro Similarity system from STS 2012 CITATION.,,
Aside from the large number of sound similarity measures, this provided linear regression through the WEKA package CITATION to combine all of the disparate similarity metrics into a single one, and some preprocessing.,,
Thus we consider three different representations possible within Random Indexing (CITATION; CITATION).,,
Finally, because compositional distributional semantics is an important research topic (CITATION; CITATION), we sought to evaluate a principled composition strategy: structured vectorial semantics CITATION.,,
In our experiments, we performed named entity recognition with the Stanford NER tool using the standard English model CITATION.,,
Also, we used UKPs existing implementation of LCS and GST CITATION for the latter two measures.,,
2.2 Random indexing measures Random indexing (CITATION; CITATION) is another distributional semantics framework for representing terms as vectors.,,
Similar to LSA CITATION, an index is created that represents each term as a semantic vector.,,
Similar to LSA CITATION, an index is created that represents each term as a semantic vector.,,
The intuition for this means of dimensionality reduction is that these randomly-generated elemental vectors are like quasi-orthogonal bases in a traditional geometric semantic space, rather than, e.g., 300 fully orthogonal dimensions from singular value decomposition CITATION.,,
her/SentenceSize string/LongestCommonSubstringComparator t other/CaseMatches t other/StocksSize t other/StocksOverlap matches S2, and how closely S2 matches S1: simneo(S1,S2) = 2 NE1 NE2 NE1 + NE2 (1) Additionally, we relax the constraint of requiring exact string matches between the two sentences by using the longest common subsequence CITATION and greedy string tiling CITATION algorithms.,,
Thus, we follow previous work in greedily aligning these named entities (CITATION; CITATION) into pairs.,,
Thus we consider three different representations possible within Random Indexing (CITATION; CITATION).,,
Finally, because compositional distributional semantics is an important research topic (CITATION; CITATION), we sought to evaluate a principled composition strategy: structured vectorial semantics CITATION.,,
Thus we consider three different representations possible within Random Indexing (CITATION; CITATION).,,
Finally, because compositional distributional semantics is an important research topic (CITATION; CITATION), we sought to evaluate a principled composition strategy: structured vectorial semantics CITATION.,,
In our experiments, we performed named entity recognition with the Stanford NER tool using the standard English model CITATION.,,
Also, we used UKPs existing implementation of LCS and GST CITATION for the latter two measures.,,
2.2 Random indexing measures Random indexing (CITATION; CITATION) is another distributional semantics framework for representing terms as vectors.,,
Similar to LSA CITATION, an index is created that represents each term as a semantic vector.,,
The proposed MayoClinicNLP metrics are meant to complement DKPro CITATION and TakeLab CITATION metrics.,,
gestCommonSubstringComparator t other/CaseMatches t other/StocksSize t other/StocksOverlap matches S2, and how closely S2 matches S1: simneo(S1,S2) = 2 NE1 NE2 NE1 + NE2 (1) Additionally, we relax the constraint of requiring exact string matches between the two sentences by using the longest common subsequence CITATION and greedy string tiling CITATION algorithms.,,
Thus, we follow previous work in greedily aligning these named entities (CITATION; CITATION) into pairs.,,
Sentence vectors from any of these 4 Random Indexing-based models (standard, windowed, directional, positional) are just the sum of the vectors for each term vS = tS vt. We define 4 separate similarity metrics for STS as: simRI(S1,S2) = cos(vS1,vS2) (3) We used the semantic vectors package (CITATION; CITATION) in the default configuration for the standard model.,,
2.3 Semantic vectorial semantics measures Structured vectorial semantics (SVS) composes distributional semantic representations in syntactic context CITATION.,,
Sentence vectors from any of these 4 Random Indexing-based models (standard, windowed, directional, positional) are just the sum of the vectors for each term vS = tS vt. We define 4 separate similarity metrics for STS as: simRI(S1,S2) = cos(vS1,vS2) (3) We used the semantic vectors package (CITATION; CITATION) in the default configuration for the standard model.,,
2.3 Semantic vectorial semantics measures Structured vectorial semantics (SVS) composes distributional semantic representations in syntactic context CITATION.,,
s/CharacterNGramMeasure 4 t other/NumbersSize string/GreedyStringTiling 3 t other/NumbersOverlap string/LongestCommonSubsequenceComparator t other/NumbersSubset string/LongestCommonSubsequenceNormComparator t other/SentenceSize string/LongestCommonSubstringComparator t other/CaseMatches t other/StocksSize t other/StocksOverlap matches S2, and how closely S2 matches S1: simneo(S1,S2) = 2 NE1 NE2 NE1 + NE2 (1) Additionally, we relax the constraint of requiring exact string matches between the two sentences by using the longest common subsequence CITATION and greedy string tiling CITATION algorithms.,,
Thus, we follow previous work in greedily aligning these named entities (CITATION; CITATION) into pairs.,,
Thus we consider three different representations possible within Random Indexing (CITATION; CITATION).,,
Finally, because compositional distributional semantics is an important research topic (CITATION; CITATION), we sought to evaluate a principled composition strategy: structured vectorial semantics CITATION.,,
cs for STS as: simRI(S1,S2) = cos(vS1,vS2) (3) We used the semantic vectors package (CITATION; CITATION) in the default configuration for the standard model.,,
2.3 Semantic vectorial semantics measures Structured vectorial semantics (SVS) composes distributional semantic representations in syntactic context CITATION.,,
Further detail is in our previous work (CITATION; CITATION).,,
In our experiments, we used the parser described in CITATION with 1,000 headwords and 10 relational clusters, trained on the Wall Street Journal treebank.,,
3.1 Linear regression via DKPro Similarity For our baseline (MayoClinicNLPr1wtCDT), we used the UIMA-based DKPro Similarity system from STS 2012 CITATION.,,
Further detail is in our previous work (CITATION; CITATION).,,
